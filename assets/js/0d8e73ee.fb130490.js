"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[98622],{7227(e,n,s){s.d(n,{A:()=>r});s(96540);var t=s(18215);const o="tabItem_Ymn6";var l=s(74848);function r({children:e,hidden:n,className:s}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,t.A)(o,s),hidden:n,children:e})}},28453(e,n,s){s.d(n,{R:()=>r,x:()=>a});var t=s(96540);const o={},l=t.createContext(o);function r(e){const n=t.useContext(l);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(l.Provider,{value:n},e.children)}},49489(e,n,s){s.d(n,{A:()=>A});var t=s(96540),o=s(18215),l=s(24245),r=s(56347),a=s(36494),i=s(62814),c=s(45167),p=s(69900);function m(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:s}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return m(e).map(({props:{value:e,label:n,attributes:s,default:t}})=>({value:e,label:n,attributes:s,default:t}))}(s);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,s])}function d({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const s=(0,r.W6)(),o=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,i.aZ)(o),(0,t.useCallback)(e=>{if(!o)return;const n=new URLSearchParams(s.location.search);n.set(o,e),s.replace({...s.location,search:n.toString()})},[o,s])]}function _(e){const{defaultValue:n,queryString:s=!1,groupId:o}=e,l=u(e),[r,i]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!d({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const s=n.find(e=>e.default)??n[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:l})),[c,m]=h({queryString:s,groupId:o}),[_,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[s,o]=(0,p.Dv)(n);return[s,(0,t.useCallback)(e=>{n&&o.set(e)},[n,o])]}({groupId:o}),g=(()=>{const e=c??_;return d({value:e,tabValues:l})?e:null})();(0,a.A)(()=>{g&&i(g)},[g]);return{selectedValue:r,selectValue:(0,t.useCallback)(e=>{if(!d({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);i(e),m(e),x(e)},[m,x,l]),tabValues:l}}var x=s(11062);const g="tabList__CuJ",b="tabItem_LNqP";var j=s(74848);function f({className:e,block:n,selectedValue:s,selectValue:t,tabValues:r}){const a=[],{blockElementScrollPositionUntilNextRender:i}=(0,l.a_)(),c=e=>{const n=e.currentTarget,o=a.indexOf(n),l=r[o].value;l!==s&&(i(n),t(l))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const s=a.indexOf(e.currentTarget)+1;n=a[s]??a[0];break}case"ArrowLeft":{const s=a.indexOf(e.currentTarget)-1;n=a[s]??a[a.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:t})=>(0,j.jsx)("li",{role:"tab",tabIndex:s===e?0:-1,"aria-selected":s===e,ref:e=>{a.push(e)},onKeyDown:p,onClick:c,...t,className:(0,o.A)("tabs__item",b,t?.className,{"tabs__item--active":s===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:s}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===s);return e?(0,t.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==s}))})}function y(e){const n=_(e);return(0,j.jsxs)("div",{className:(0,o.A)("tabs-container",g),children:[(0,j.jsx)(f,{...n,...e}),(0,j.jsx)(v,{...n,...e})]})}function A(e){const n=(0,x.A)();return(0,j.jsx)(y,{...e,children:m(e.children)},String(n))}},92045(e,n,s){s.r(n),s.d(n,{assets:()=>p,contentTitle:()=>c,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"completion/provider_specific_params","title":"\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570","description":"\u63d0\u4f9b\u5546\u53ef\u80fd\u4f1a\u63d0\u4f9b OpenAI \u4e0d\u652f\u6301\u7684\u53c2\u6570\uff08\u4f8b\u5982 top_k\uff09\u3002LiteLLM \u5c06\u4efb\u4f55\u975e OpenAI \u53c2\u6570\u89c6\u4e3a\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8bf7\u6c42\u4f53\u4e2d\u7684\u5173\u952e\u5b57\u53c2\u6570\u4f20\u9012\u7ed9\u63d0\u4f9b\u5546\u3002\u67e5\u770b\u4fdd\u7559\u53c2\u6570","source":"@site/docs/completion/provider_specific_params.md","sourceDirName":"completion","slug":"/completion/provider_specific_params","permalink":"/docs/completion/provider_specific_params","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"\u6d41\u5f0f\u54cd\u5e94 + \u5f02\u6b65","permalink":"/docs/completion/stream"},"next":{"title":"\u4f7f\u7528\u89c6\u89c9\u6a21\u578b","permalink":"/docs/completion/vision"}}');var o=s(74848),l=s(28453),r=s(49489),a=s(7227);const i={},c="\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570",p={},m=[{value:"SDK \u4f7f\u7528",id:"sdk-\u4f7f\u7528",level:2},{value:"\u4f7f\u7528\u4ee3\u7406",id:"\u4f7f\u7528\u4ee3\u7406",level:2},{value:"\u63d0\u4f9b\u5546\u7279\u5b9a\u5143\u6570\u636e\u53c2\u6570",id:"\u63d0\u4f9b\u5546\u7279\u5b9a\u5143\u6570\u636e\u53c2\u6570",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570",children:"\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570"})}),"\n",(0,o.jsxs)(n.p,{children:["\u63d0\u4f9b\u5546\u53ef\u80fd\u4f1a\u63d0\u4f9b OpenAI \u4e0d\u652f\u6301\u7684\u53c2\u6570\uff08\u4f8b\u5982 top_k\uff09\u3002LiteLLM \u5c06\u4efb\u4f55\u975e OpenAI \u53c2\u6570\u89c6\u4e3a\u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8bf7\u6c42\u4f53\u4e2d\u7684\u5173\u952e\u5b57\u53c2\u6570\u4f20\u9012\u7ed9\u63d0\u4f9b\u5546\u3002",(0,o.jsx)(n.a,{href:"https://github.com/BerriAI/litellm/blob/aa2fd29e48245f360e771a8810a69376464b195e/litellm/main.py#L700",children:(0,o.jsx)(n.strong,{children:"\u67e5\u770b\u4fdd\u7559\u53c2\u6570"})})]}),"\n",(0,o.jsx)(n.p,{children:"\u60a8\u53ef\u4ee5\u4f7f\u7528\u4e24\u79cd\u65b9\u5f0f\u4f20\u9012\u8fd9\u4e9b\u53c2\u6570\uff1a"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\u901a\u8fc7 ",(0,o.jsx)(n.code,{children:"completion()"}),"\uff1a\u6211\u4eec\u5c06\u76f4\u63a5\u5c06\u975e OpenAI \u53c2\u6570\u4f5c\u4e3a\u8bf7\u6c42\u4f53\u7684\u4e00\u90e8\u5206\u4f20\u9012\u7ed9\u63d0\u4f9b\u5546\u3002","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\u4f8b\u5982\uff1a",(0,o.jsx)(n.code,{children:'completion(model="claude-instant-1", top_k=3)'})]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\u901a\u8fc7\u7279\u5b9a\u4e8e\u63d0\u4f9b\u5546\u7684\u914d\u7f6e\u53d8\u91cf\uff08\u4f8b\u5982 ",(0,o.jsx)(n.code,{children:"litellm.OpenAIConfig()"}),"\uff09\u3002"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"sdk-\u4f7f\u7528",children:"SDK \u4f7f\u7528"}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(a.A,{value:"openai",label:"OpenAI",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="gpt-3.5-turbo",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.OpenAIConfig(max_tokens=10)\n\nresponse_2 = litellm.completion(\n            model="gpt-3.5-turbo",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n\n\n</TabItem>\n<TabItem value="openai-text" label="OpenAI \u6587\u672c\u5b8c\u6210">\n\n```python\nimport litellm, os\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="text-davinci-003",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.OpenAITextCompletionConfig(max_tokens=10)\nresponse_2 = litellm.completion(\n            model="text-davinci-003",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"azure-openai",label:"Azure OpenAI",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["AZURE_API_BASE"] = "your-azure-api-base"\nos.environ["AZURE_API_TYPE"] = "azure" # [\u53ef\u9009]\nos.environ["AZURE_API_VERSION"] = "2023-07-01-preview" # [\u53ef\u9009]\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="azure/chatgpt-v-2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.AzureOpenAIConfig(max_tokens=10)\nresponse_2 = litellm.completion(\n            model="azure/chatgpt-v-2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"anthropic",label:"Anthropic",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="claude-instant-1",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.AnthropicConfig(max_tokens_to_sample=200)\nresponse_2 = litellm.completion(\n            model="claude-instant-1",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"huggingface",label:"Huggingface",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["HUGGINGFACE_API_KEY"] = "your-huggingface-key" #[\u53ef\u9009]\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="huggingface/mistralai/Mistral-7B-Instruct-v0.1",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            api_base="https://your-huggingface-api-endpoint",\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.HuggingfaceConfig(max_new_tokens=200)\nresponse_2 = litellm.completion(\n            model="huggingface/mistralai/Mistral-7B-Instruct-v0.1",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            api_base="https://your-huggingface-api-endpoint"\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"together_ai",label:"TogetherAI",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["TOGETHERAI_API_KEY"] = "your-togetherai-key" \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="together_ai/togethercomputer/llama-2-70b-chat",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.TogetherAIConfig(max_tokens_to_sample=200)\nresponse_2 = litellm.completion(\n            model="together_ai/togethercomputer/llama-2-70b-chat",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"ollama",label:"Ollama",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="ollama/llama2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.OllamConfig(num_predict=200)\nresponse_2 = litellm.completion(\n            model="ollama/llama2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"replicate",label:"Replicate",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["REPLICATE_API_KEY"] = "your-replicate-key" \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="replicate/meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.ReplicateConfig(max_new_tokens=200)\nresponse_2 = litellm.completion(\n            model="replicate/meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"petals",label:"Petals",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="petals/petals-team/StableBeluga2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            api_base="https://chat.petals.dev/api/v1/generate",\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.PetalsConfig(max_new_tokens=10)\nresponse_2 = litellm.completion(\n            model="petals/petals-team/StableBeluga2",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            api_base="https://chat.petals.dev/api/v1/generate",\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"palm",label:"Palm",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["PALM_API_KEY"] = "your-palm-key"  \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="palm/chat-bison",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.PalmConfig(maxOutputTokens=10)\nresponse_2 = litellm.completion(\n            model="palm/chat-bison",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"ai21",label:"AI21",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["AI21_API_KEY"] = "your-ai21-key"  \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="j2-mid",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.AI21Config(maxOutputTokens=10)\nresponse_2 = litellm.completion(\n            model="j2-mid",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})}),(0,o.jsx)(a.A,{value:"cohere",label:"Cohere",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm, os \n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["COHERE_API_KEY"] = "your-cohere-key"   \n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7 completion()\nresponse_1 = litellm.completion(\n            model="command-nightly",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n            max_tokens=10\n        )\n\nresponse_1_text = response_1.choices[0].message.content\n\n## \u8bbe\u7f6e\u6700\u5927\u4ee4\u724c\u6570 - \u901a\u8fc7\u914d\u7f6e\nlitellm.CohereConfig(max_tokens=200)\nresponse_2 = litellm.completion(\n            model="command-nightly",\n            messages=[{ "content": "Hello, how are you?","role": "user"}],\n        )\n\nresponse_2_text = response_2.choices[0].message.content\n\n## \u6d4b\u8bd5\u8f93\u51fa\nassert len(response_2_text) > len(response_1_text)\n'})})})]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"/docs/tutorials/provider_specific_params",children:(0,o.jsx)(n.strong,{children:"\u67e5\u770b\u6559\u7a0b\uff01"})})}),"\n",(0,o.jsx)(n.h2,{id:"\u4f7f\u7528\u4ee3\u7406",children:"\u4f7f\u7528\u4ee3\u7406"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"\u901a\u8fc7\u914d\u7f6e"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"model_list:\n    - model_name: llama-3-8b-instruct\n      litellm_params:\n        model: predibase/llama-3-8b-instruct\n        api_key: os.environ/PREDIBASE_API_KEY\n        tenant_id: os.environ/PREDIBASE_TENANT_ID\n        max_tokens: 256\n        adapter_base: <my-special_base> # \ud83d\udc48 \u63d0\u4f9b\u5546\u7279\u5b9a\u53c2\u6570\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"\u901a\u8fc7\u8bf7\u6c42"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'curl -X POST \'http://0.0.0.0:4000/chat/completions\' \\\n-H \'Content-Type: application/json\' \\\n-H \'Authorization: Bearer sk-1234\' \\\n-d \'{\n  "model": "llama-3-8b-instruct",\n  "messages": [\n    {\n      "role": "user",\n      "content": "What\'\\\'\'s the weather like in Boston today?"\n    }\n  ],\n  "adapater_id": "my-special-adapter-id"\n}\'\n'})}),"\n",(0,o.jsx)(n.h2,{id:"\u63d0\u4f9b\u5546\u7279\u5b9a\u5143\u6570\u636e\u53c2\u6570",children:"\u63d0\u4f9b\u5546\u7279\u5b9a\u5143\u6570\u636e\u53c2\u6570"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"\u63d0\u4f9b\u5546"}),(0,o.jsx)(n.th,{children:"\u53c2\u6570"}),(0,o.jsx)(n.th,{children:"\u4f7f\u7528\u573a\u666f"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"AWS Bedrock"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"requestMetadata"})}),(0,o.jsx)(n.td,{children:"\u6210\u672c\u5f52\u56e0\uff0c\u65e5\u5fd7\u8bb0\u5f55"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Gemini/Vertex AI"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"labels"})}),(0,o.jsx)(n.td,{children:"\u8d44\u6e90\u6807\u7b7e"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Anthropic"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"metadata"})}),(0,o.jsx)(n.td,{children:"\u7528\u6237\u8bc6\u522b"})]})]})]}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(a.A,{value:"bedrock",label:"AWS Bedrock",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm\n\nresponse = litellm.completion(\n    model="bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0",\n    messages=[{"role": "user", "content": "Hello!"}],\n    requestMetadata={"cost_center": "engineering"}\n)\n'})})}),(0,o.jsx)(a.A,{value:"gemini",label:"Gemini/Vertex AI",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm\n\nresponse = litellm.completion(\n    model="vertex_ai/gemini-pro",\n    messages=[{"role": "user", "content": "Hello!"}],\n    labels={"environment": "production"}\n)\n'})})}),(0,o.jsx)(a.A,{value:"anthropic",label:"Anthropic",children:(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import litellm\n\nresponse = litellm.completion(\n    model="anthropic/claude-3-sonnet-20240229",\n    messages=[{"role": "user", "content": "Hello!"}],\n    metadata={"user_id": "user123"}\n)\n'})})})]})]})}function d(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}}}]);