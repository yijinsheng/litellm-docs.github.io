"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[68607],{7227(e,n,t){t.d(n,{A:()=>r});t(96540);var l=t(18215);const i="tabItem_Ymn6";var s=t(74848);function r({children:e,hidden:n,className:t}){return(0,s.jsx)("div",{role:"tabpanel",className:(0,l.A)(i,t),hidden:n,children:e})}},28453(e,n,t){t.d(n,{R:()=>r,x:()=>a});var l=t(96540);const i={},s=l.createContext(i);function r(e){const n=l.useContext(s);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),l.createElement(s.Provider,{value:n},e.children)}},36620(e,n,t){t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>l,toc:()=>p});const l=JSON.parse('{"id":"integrations/letta","title":"Letta \u96c6\u6210","description":"Letta\uff08\u539f\u540d MemGPT\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u5177\u6709\u6301\u4e45\u5185\u5b58\u7684\u6709\u72b6\u6001 LLM \u4ee3\u7406\u7684\u6846\u67b6\u3002\u672c\u6307\u5357\u5c55\u793a\u5982\u4f55\u5c06 LiteLLM SDK \u548c LiteLLM Proxy \u4e0e Letta \u96c6\u6210\uff0c\u4ee5\u4fbf\u5728\u6784\u5efa\u652f\u6301\u5185\u5b58\u7684\u4ee3\u7406\u65f6\u5229\u7528\u591a\u4e2a LLM \u63d0\u4f9b\u5546\u3002","source":"@site/docs/integrations/letta.md","sourceDirName":"integrations","slug":"/integrations/letta","permalink":"/docs/integrations/letta","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}');var i=t(74848),s=t(28453),r=t(49489),a=t(7227);const o={},c="Letta \u96c6\u6210",d={},p=[{value:"\u4ec0\u4e48\u662f Letta\uff1f",id:"\u4ec0\u4e48\u662f-letta",level:2},{value:"\u524d\u7f6e\u6761\u4ef6",id:"\u524d\u7f6e\u6761\u4ef6",level:2},{value:"\u5feb\u901f\u5f00\u59cb",id:"\u5feb\u901f\u5f00\u59cb",level:2},{value:"1. \u542f\u52a8 LiteLLM \u4ee3\u7406",id:"1-\u542f\u52a8-litellm-\u4ee3\u7406",level:3},{value:"2. \u914d\u7f6e Letta \u4e0e LiteLLM \u4ee3\u7406",id:"2-\u914d\u7f6e-letta-\u4e0e-litellm-\u4ee3\u7406",level:3},{value:"1. \u914d\u7f6e LiteLLM SDK",id:"1-\u914d\u7f6e-litellm-sdk",level:3},{value:"2. \u4e3a Letta \u521b\u5efa\u81ea\u5b9a\u4e49 LLM \u5305\u88c5\u5668",id:"2-\u4e3a-letta-\u521b\u5efa\u81ea\u5b9a\u4e49-llm-\u5305\u88c5\u5668",level:3},{value:"3. \u521b\u5efa\u548c\u4f7f\u7528 Letta \u4ee3\u7406",id:"3-\u521b\u5efa\u548c\u4f7f\u7528-letta-\u4ee3\u7406",level:3},{value:"\u9ad8\u7ea7\u914d\u7f6e",id:"\u9ad8\u7ea7\u914d\u7f6e",level:2},{value:"\u4e3a\u4e0d\u540c\u7684\u4ee3\u7406\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u578b",id:"\u4e3a\u4e0d\u540c\u7684\u4ee3\u7406\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u578b",level:3},{value:"\u4f7f\u7528\u5de5\u5177\u8fdb\u884c\u51fd\u6570\u8c03\u7528",id:"\u4f7f\u7528\u5de5\u5177\u8fdb\u884c\u51fd\u6570\u8c03\u7528",level:3},{value:"\u8eab\u4efd\u9a8c\u8bc1",id:"\u8eab\u4efd\u9a8c\u8bc1",level:2},{value:"\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb",id:"\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb",level:2},{value:"\u76d1\u63a7\u548c\u53ef\u89c2\u5bdf\u6027",id:"\u76d1\u63a7\u548c\u53ef\u89c2\u5bdf\u6027",level:2},{value:"\u793a\u4f8b\uff1a\u591a\u4ee3\u7406\u7cfb\u7edf",id:"\u793a\u4f8b\u591a\u4ee3\u7406\u7cfb\u7edf",level:2},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"\u6545\u969c\u6392\u9664",id:"\u6545\u969c\u6392\u9664",level:2},{value:"\u8fde\u63a5\u95ee\u9898",id:"\u8fde\u63a5\u95ee\u9898",level:3},{value:"\u914d\u7f6e\u8c03\u8bd5",id:"\u914d\u7f6e\u8c03\u8bd5",level:3},{value:"\u5e38\u89c1\u4ee3\u7406\u95ee\u9898",id:"\u5e38\u89c1\u4ee3\u7406\u95ee\u9898",level:3},{value:"API \u5bc6\u94a5\u95ee\u9898",id:"api-\u5bc6\u94a5\u95ee\u9898",level:3},{value:"\u914d\u7f6e\u8c03\u8bd5",id:"\u914d\u7f6e\u8c03\u8bd5-1",level:3},{value:"\u5e38\u89c1 SDK \u95ee\u9898",id:"\u5e38\u89c1-sdk-\u95ee\u9898",level:3},{value:"\u8d44\u6e90",id:"\u8d44\u6e90",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"letta-\u96c6\u6210",children:"Letta \u96c6\u6210"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://github.com/letta-ai/letta",children:"Letta"}),"\uff08\u539f\u540d MemGPT\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u5177\u6709\u6301\u4e45\u5185\u5b58\u7684\u6709\u72b6\u6001 LLM \u4ee3\u7406\u7684\u6846\u67b6\u3002\u672c\u6307\u5357\u5c55\u793a\u5982\u4f55\u5c06 LiteLLM SDK \u548c LiteLLM Proxy \u4e0e Letta \u96c6\u6210\uff0c\u4ee5\u4fbf\u5728\u6784\u5efa\u652f\u6301\u5185\u5b58\u7684\u4ee3\u7406\u65f6\u5229\u7528\u591a\u4e2a LLM \u63d0\u4f9b\u5546\u3002"]}),"\n",(0,i.jsx)(n.h2,{id:"\u4ec0\u4e48\u662f-letta",children:"\u4ec0\u4e48\u662f Letta\uff1f"}),"\n",(0,i.jsx)(n.p,{children:"Letta \u5141\u8bb8\u60a8\u6784\u5efa\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u64cd\u4f5c\u7684 LLM \u4ee3\u7406\uff1a"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u5728\u5bf9\u8bdd\u4e2d\u7ef4\u62a4\u957f\u671f\u8bb0\u5fc6"}),"\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528\u51fd\u6570\u8c03\u7528\u8fdb\u884c\u5de5\u5177\u4ea4\u4e92"}),"\n",(0,i.jsx)(n.li,{children:"\u9ad8\u6548\u5904\u7406\u5927\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3"}),"\n",(0,i.jsx)(n.li,{children:"\u6301\u4e45\u5316\u4ee3\u7406\u72b6\u6001\u548c\u8bb0\u5fc6"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\u524d\u7f6e\u6761\u4ef6",children:"\u524d\u7f6e\u6761\u4ef6"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install letta litellm\n"})}),"\n",(0,i.jsx)(n.h2,{id:"\u5feb\u901f\u5f00\u59cb",children:"\u5feb\u901f\u5f00\u59cb"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsxs)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406",children:[(0,i.jsx)(n.h3,{id:"1-\u542f\u52a8-litellm-\u4ee3\u7406",children:"1. \u542f\u52a8 LiteLLM \u4ee3\u7406"}),(0,i.jsx)(n.p,{children:"\u9996\u5148\uff0c\u4e3a\u60a8\u7684 LiteLLM \u4ee3\u7406\u521b\u5efa\u914d\u7f6e\u6587\u4ef6\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# config.yaml\nmodel_list:\n  - model_name: gpt-4\n    litellm_params:\n      model: openai/gpt-4\n      api_key: os.environ/OPENAI_API_KEY\n\n  - model_name: claude-3-sonnet\n    litellm_params:\n      model: anthropic/claude-3-sonnet-20240229\n      api_key: os.environ/ANTHROPIC_API_KEY\n\n  - model_name: gpt-3.5-turbo\n    litellm_params:\n      model: azure/gpt-35-turbo\n      api_key: os.environ/AZURE_API_KEY\n      api_base: os.environ/AZURE_API_BASE\n      api_version: "2023-07-01-preview"\n'})}),(0,i.jsx)(n.p,{children:"\u542f\u52a8\u4ee3\u7406\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"litellm --config config.yaml --port 4000\n"})}),(0,i.jsx)(n.h3,{id:"2-\u914d\u7f6e-letta-\u4e0e-litellm-\u4ee3\u7406",children:"2. \u914d\u7f6e Letta \u4e0e LiteLLM \u4ee3\u7406"}),(0,i.jsx)(n.p,{children:"\u914d\u7f6e Letta \u4f7f\u7528\u60a8\u7684 LiteLLM \u4ee3\u7406\u7aef\u70b9\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client\n\n# \u914d\u7f6e Letta \u4f7f\u7528 LiteLLM \u4ee3\u7406\nclient = create_client()\n\n# \u914d\u7f6e LLM \u7aef\u70b9\nclient.set_default_llm_config(\n    model="gpt-4",  # \u8fd9\u5e94\u8be5\u4e0e\u60a8\u7684 LiteLLM \u914d\u7f6e\u4e2d\u7684\u6a21\u578b\u5339\u914d\n    model_endpoint_type="openai",\n    model_endpoint="http://localhost:4000",  # \u60a8\u7684 LiteLLM \u4ee3\u7406 URL\n    context_window=8192\n)\n\n# \u914d\u7f6e\u5d4c\u5165\u7aef\u70b9\uff08\u53ef\u9009\uff09\nclient.set_default_embedding_config(\n    embedding_endpoint_type="openai",\n    embedding_endpoint="http://localhost:4000",\n    embedding_model="text-embedding-ada-002"\n)\n'})})]}),(0,i.jsxs)(a.A,{value:"sdk",label:"LiteLLM SDK",children:[(0,i.jsx)(n.h3,{id:"1-\u914d\u7f6e-litellm-sdk",children:"1. \u914d\u7f6e LiteLLM SDK"}),(0,i.jsx)(n.p,{children:"\u8bbe\u7f6e\u60a8\u7684 API \u5bc6\u94a5\u5e76\u914d\u7f6e LiteLLM\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nimport litellm\n\n# \u8bbe\u7f6e\u60a8\u7684 API \u5bc6\u94a5\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\nos.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"\n\n# \u53ef\u9009\uff1a\u914d\u7f6e\u9ed8\u8ba4\u8bbe\u7f6e\nlitellm.set_verbose = True  # \u7528\u4e8e\u8c03\u8bd5\n'})}),(0,i.jsx)(n.h3,{id:"2-\u4e3a-letta-\u521b\u5efa\u81ea\u5b9a\u4e49-llm-\u5305\u88c5\u5668",children:"2. \u4e3a Letta \u521b\u5efa\u81ea\u5b9a\u4e49 LLM \u5305\u88c5\u5668"}),(0,i.jsx)(n.p,{children:"\u521b\u5efa\u4f7f\u7528 LiteLLM SDK \u7684\u81ea\u5b9a\u4e49 LLM \u5305\u88c5\u5668\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client\nfrom letta.llm_api.llm_api_base import LLMConfig\nimport litellm\nfrom typing import List, Dict, Any\n\nclass LiteLLMWrapper:\n    def __init__(self, model: str):\n        self.model = model\n\n    def chat_completions_create(self, messages: List[Dict], **kwargs):\n        # \u4f7f\u7528 LiteLLM SDK \u8fdb\u884c\u5b8c\u6210\n        response = litellm.completion(\n            model=self.model,\n            messages=messages,\n            **kwargs\n        )\n        return response\n\n# \u4f7f\u7528\u81ea\u5b9a\u4e49 LiteLLM \u5305\u88c5\u5668\u914d\u7f6e Letta\nclient = create_client()\n\n# \u4f7f\u7528\u76f4\u63a5 SDK \u96c6\u6210\u8bbe\u7f6e LLM \u914d\u7f6e\nllm_config = LLMConfig(\n    model="gpt-4",  # \u6216 "claude-3-sonnet"\u3001"azure/gpt-35-turbo" \u7b49\n    model_endpoint_type="openai",\n    context_window=8192\n)\n\nclient.set_default_llm_config(llm_config)\n'})})]})]}),"\n",(0,i.jsx)(n.h3,{id:"3-\u521b\u5efa\u548c\u4f7f\u7528-letta-\u4ee3\u7406",children:"3. \u521b\u5efa\u548c\u4f7f\u7528 Letta \u4ee3\u7406"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(a.A,{value:"proxy",label:"\u4f7f\u7528 LiteLLM \u4ee3\u7406",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client\n\n# \u521b\u5efa Letta \u5ba2\u6237\u7aef\nclient = create_client()\n\n# \u521b\u5efa\u65b0\u4ee3\u7406\nagent_state = client.create_agent(\n    name="my-assistant",\n    system="You are a helpful assistant with persistent memory.",\n    llm_config=client.get_default_llm_config(),\n    embedding_config=client.get_default_embedding_config()\n)\n\n# \u5411\u4ee3\u7406\u53d1\u9001\u6d88\u606f\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="Hi! My name is Alice and I love reading science fiction books."\n)\n\nprint(f"Agent response: {response.messages[-1].text}")\n\n# \u53d1\u9001\u53e6\u4e00\u6761\u6d88\u606f - \u4ee3\u7406\u5c06\u8bb0\u4f4f\u5148\u524d\u7684\u4e0a\u4e0b\u6587\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="What did I tell you about my interests?"\n)\n\nprint(f"Agent response: {response.messages[-1].text}")\n'})})}),(0,i.jsx)(a.A,{value:"sdk",label:"\u4f7f\u7528 LiteLLM SDK",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client\nimport litellm\nimport os\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\n\n# \u521b\u5efa\u5e26\u6709 LiteLLM \u96c6\u6210\u7684 Letta \u5ba2\u6237\u7aef\nclient = create_client()\n\n# \u521b\u5efa\u65b0\u4ee3\u7406\nagent_state = client.create_agent(\n    name="my-assistant",\n    system="You are a helpful assistant with persistent memory.",\n    llm_config=client.get_default_llm_config(),\n    embedding_config=client.get_default_embedding_config()\n)\n\n# \u5411\u4ee3\u7406\u53d1\u9001\u6d88\u606f\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="Hi! My name is Alice and I love reading science fiction books."\n)\n\nprint(f"Agent response: {response.messages[-1].text}")\n\n# \u53d1\u9001\u53e6\u4e00\u6761\u6d88\u606f - \u4ee3\u7406\u5c06\u8bb0\u4f4f\u5148\u524d\u7684\u4e0a\u4e0b\u6587\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="What did I tell you about my interests?"\n)\n\nprint(f"Agent response: {response.messages[-1].text}")\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"\u9ad8\u7ea7\u914d\u7f6e",children:"\u9ad8\u7ea7\u914d\u7f6e"}),"\n",(0,i.jsx)(n.h3,{id:"\u4e3a\u4e0d\u540c\u7684\u4ee3\u7406\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u578b",children:"\u4e3a\u4e0d\u540c\u7684\u4ee3\u7406\u4f7f\u7528\u4e0d\u540c\u7684\u6a21\u578b"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from letta import LLMConfig, EmbeddingConfig\n\n# \u6307\u5411\u60a8\u7684\u4ee3\u7406\u7684\u4e0d\u540c LLM \u914d\u7f6e\ngpt4_config = LLMConfig(\n    model="gpt-4",\n    model_endpoint_type="openai",\n    model_endpoint="http://localhost:4000",\n    context_window=8192\n)\n\nclaude_config = LLMConfig(\n    model="claude-3-sonnet",\n    model_endpoint_type="openai",  # \u4f7f\u7528 OpenAI \u517c\u5bb9\u7aef\u70b9\n    model_endpoint="http://localhost:4000",\n    context_window=200000\n)\n\n# \u4f7f\u7528\u4e0d\u540c\u914d\u7f6e\u521b\u5efa\u4ee3\u7406\nresearch_agent = client.create_agent(\n    name="research-agent",\n    system="You are a research assistant specialized in analysis.",\n    llm_config=claude_config  # \u4f7f\u7528 Claude \u8fdb\u884c\u7814\u7a76\u4efb\u52a1\n)\n\ncreative_agent = client.create_agent(\n    name="creative-agent",\n    system="You are a creative writing assistant.",\n    llm_config=gpt4_config  # \u4f7f\u7528 GPT-4 \u8fdb\u884c\u521b\u610f\u4efb\u52a1\n)\n'})})}),(0,i.jsx)(a.A,{value:"sdk",label:"LiteLLM SDK",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nimport litellm\nfrom letta import LLMConfig, EmbeddingConfig\n\n# \u4e3a\u4e0d\u540c\u63d0\u4f9b\u5546\u8bbe\u7f6e API \u5bc6\u94a5\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\nos.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"\n\n# \u4e3a\u76f4\u63a5 SDK \u4f7f\u7528\u521b\u5efa\u4e0d\u540c\u7684 LLM \u914d\u7f6e\ngpt4_config = LLMConfig(\n    model="openai/gpt-4",  # \u4f7f\u7528 LiteLLM \u6a21\u578b\u683c\u5f0f\n    model_endpoint_type="openai",\n    context_window=8192\n)\n\nclaude_config = LLMConfig(\n    model="anthropic/claude-3-sonnet-20240229",  # \u4f7f\u7528 LiteLLM \u6a21\u578b\u683c\u5f0f\n    model_endpoint_type="openai",\n    context_window=200000\n)\n\n# \u4f7f\u7528\u4e0d\u540c\u914d\u7f6e\u521b\u5efa\u4ee3\u7406\nresearch_agent = client.create_agent(\n    name="research-agent",\n    system="You are a research assistant specialized in analysis.",\n    llm_config=claude_config  # \u4f7f\u7528 Claude \u8fdb\u884c\u7814\u7a76\u4efb\u52a1\n)\n\ncreative_agent = client.create_agent(\n    name="creative-agent",\n    system="You are a creative writing assistant.",\n    llm_config=gpt4_config  # \u4f7f\u7528 GPT-4 \u8fdb\u884c\u521b\u610f\u4efb\u52a1\n)\n'})})})]}),"\n",(0,i.jsx)(n.h3,{id:"\u4f7f\u7528\u5de5\u5177\u8fdb\u884c\u51fd\u6570\u8c03\u7528",children:"\u4f7f\u7528\u5de5\u5177\u8fdb\u884c\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u4e3a\u60a8\u7684\u4ee3\u7406\u5b9a\u4e49\u81ea\u5b9a\u4e49\u5de5\u5177\ndef search_web(query: str) -> str:\n    """Search the web for information"""\n    # \u60a8\u7684\u7f51\u9875\u641c\u7d22\u5b9e\u73b0\n    return f"Search results for: {query}"\n\ndef save_note(content: str) -> str:\n    """Save a note to persistent storage"""\n    # \u60a8\u7684\u7b14\u8bb0\u4fdd\u5b58\u5b9e\u73b0\n    return f"Note saved: {content}"\n\n# \u4f7f\u7528\u4ee3\u7406\u7aef\u70b9\u521b\u5efa\u5e26\u6709\u5de5\u5177\u7684\u4ee3\u7406\nagent_state = client.create_agent(\n    name="research-assistant",\n    system="You are a research assistant that can search the web and save notes.",\n    llm_config=client.get_default_llm_config(),\n    embedding_config=client.get_default_embedding_config(),\n    tools=[search_web, save_note]\n)\n\n# \u4ee3\u7406\u73b0\u5728\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="Search for recent developments in AI and save important findings."\n)\n'})})}),(0,i.jsx)(a.A,{value:"sdk",label:"LiteLLM SDK",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import litellm\nimport os\n\n# \u8bbe\u7f6e API \u5bc6\u94a5\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\n\n# \u4e3a\u60a8\u7684\u4ee3\u7406\u5b9a\u4e49\u81ea\u5b9a\u4e49\u5de5\u5177\ndef search_web(query: str) -> str:\n    """Search the web for information"""\n    # \u60a8\u7684\u7f51\u9875\u641c\u7d22\u5b9e\u73b0\n    return f"Search results for: {query}"\n\ndef save_note(content: str) -> str:\n    """Save a note to persistent storage"""\n    # \u60a8\u7684\u7b14\u8bb0\u4fdd\u5b58\u5b9e\u73b0\n    return f"Note saved: {content}"\n\n# \u4f7f\u7528 LiteLLM SDK \u76f4\u63a5\u521b\u5efa\u5e26\u6709\u5de5\u5177\u7684\u4ee3\u7406\nagent_state = client.create_agent(\n    name="research-assistant",\n    system="You are a research assistant that can search the web and save notes.",\n    llm_config=LLMConfig(\n        model="openai/gpt-4",  # \u76f4\u63a5\u6a21\u578b\u89c4\u683c\n        model_endpoint_type="openai",\n        context_window=8192\n    ),\n    embedding_config=client.get_default_embedding_config(),\n    tools=[search_web, save_note]\n)\n\n# \u4ee3\u7406\u73b0\u5728\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\nresponse = client.user_message(\n    agent_id=agent_state.id,\n    message="Search for recent developments in AI and save important findings."\n)\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"\u8eab\u4efd\u9a8c\u8bc1",children:"\u8eab\u4efd\u9a8c\u8bc1"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsxs)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406\u8eab\u4efd\u9a8c\u8bc1",children:[(0,i.jsx)(n.p,{children:"\u5982\u679c\u60a8\u7684 LiteLLM \u4ee3\u7406\u9700\u8981\u8eab\u4efd\u9a8c\u8bc1\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nfrom letta import LLMConfig\n\n# \u8bbe\u7f6e\u7ecf\u8fc7\u8eab\u4efd\u9a8c\u8bc1\u7684\u914d\u7f6e\nllm_config = LLMConfig(\n    model="gpt-4",\n    model_endpoint_type="openai",\n    model_endpoint="http://localhost:4000",\n    model_wrapper="openai",\n    context_window=8192\n)\n\n# \u5982\u679c\u4f7f\u7528\u5e26\u6709 API \u5bc6\u94a5\u7684\u4ee3\u7406\nos.environ["OPENAI_API_KEY"] = "your-litellm-proxy-api-key"\n\nclient = create_client()\nclient.set_default_llm_config(llm_config)\n'})}),(0,i.jsx)(n.p,{children:"\u5bf9\u4e8e\u542f\u7528\u4e86\u8eab\u4efd\u9a8c\u8bc1\u7684\u4ee3\u7406\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# config.yaml with auth\ngeneral_settings:\n  master_key: "your-master-key"\n\nmodel_list:\n  - model_name: gpt-4\n    litellm_params:\n      model: openai/gpt-4\n      api_key: os.environ/OPENAI_API_KEY\n'})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u4f7f\u7528\u7ecf\u8fc7\u8eab\u4efd\u9a8c\u8bc1\u7684\u4ee3\u7406\u914d\u7f6e Letta\nllm_config = LLMConfig(\n    model="gpt-4",\n    model_endpoint_type="openai",\n    model_endpoint="http://localhost:4000",\n    context_window=8192,\n    api_key="your-master-key"  # \u4ee3\u7406\u4e3b\u5bc6\u94a5\n)\n'})})]}),(0,i.jsxs)(a.A,{value:"sdk",label:"LiteLLM SDK \u8eab\u4efd\u9a8c\u8bc1",children:[(0,i.jsx)(n.p,{children:"\u4f7f\u7528 LiteLLM SDK\uff0c\u76f4\u63a5\u8bbe\u7f6e\u60a8\u7684\u63d0\u4f9b\u5546 API \u5bc6\u94a5\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nimport litellm\n\n# \u4e3a\u4e0d\u540c\u63d0\u4f9b\u5546\u8bbe\u7f6e API \u5bc6\u94a5\nos.environ["OPENAI_API_KEY"] = "your-openai-api-key"\nos.environ["ANTHROPIC_API_KEY"] = "your-anthropic-api-key"\nos.environ["AZURE_API_KEY"] = "your-azure-api-key"\nos.environ["AZURE_API_BASE"] = "https://your-resource.openai.azure.com"\nos.environ["AZURE_API_VERSION"] = "2023-07-01-preview"\n\n# \u53ef\u9009\uff1a\u914d\u7f6e\u9ed8\u8ba4\u8bbe\u7f6e\nlitellm.api_key = os.environ.get("OPENAI_API_KEY")  # \u9ed8\u8ba4\u5bc6\u94a5\nlitellm.set_verbose = True  # \u7528\u4e8e\u8c03\u8bd5\n\n# \u5728 Letta \u914d\u7f6e\u4e2d\u4f7f\u7528\nfrom letta import LLMConfig\n\nllm_config = LLMConfig(\n    model="openai/gpt-4",  # \u5c06\u81ea\u52a8\u4f7f\u7528 OPENAI_API_KEY\n    model_endpoint_type="openai",\n    context_window=8192\n)\n\n# \u6216\u5bf9\u4e8e Azure\nazure_config = LLMConfig(\n    model="azure/gpt-35-turbo",\n    model_endpoint_type="openai",\n    context_window=4096\n)\n'})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb",children:"\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsxs)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406\u529f\u80fd",children:[(0,i.jsx)(n.p,{children:"LiteLLM \u4ee3\u7406\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb\u529f\u80fd\u4e0e Letta \u65e0\u7f1d\u534f\u4f5c\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# config.yaml with fallbacks\nmodel_list:\n  - model_name: gpt-4\n    litellm_params:\n      model: openai/gpt-4\n      api_key: os.environ/OPENAI_API_KEY\n    tpm: 40000\n    rpm: 500\n\n  - model_name: gpt-4  # Same model name for fallback\n    litellm_params:\n      model: azure/gpt-4\n      api_key: os.environ/AZURE_API_KEY\n      api_base: os.environ/AZURE_API_BASE\n      api_version: "2023-07-01-preview"\n    tpm: 80000\n    rpm: 800\n\nrouter_settings:\n  routing_strategy: "usage-based-routing"\n  fallbacks: [{"gpt-4": ["azure/gpt-4"]}]\n'})}),(0,i.jsx)(n.p,{children:"\u4ee3\u7406\u4e3a Letta \u900f\u660e\u5730\u5904\u7406\u6240\u6709\u8def\u7531\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u6545\u969c\u8f6c\u79fb\u3002"})]}),(0,i.jsxs)(a.A,{value:"sdk",label:"LiteLLM SDK \u8def\u7531\u5668",children:[(0,i.jsx)(n.p,{children:"\u4f7f\u7528 LiteLLM SDK\uff0c\u60a8\u53ef\u4ee5\u4ee5\u7f16\u7a0b\u65b9\u5f0f\u8bbe\u7f6e\u8def\u7531\u548c\u6545\u969c\u8f6c\u79fb\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import litellm\nfrom litellm import Router\n\n# \u914d\u7f6e\u591a\u4e2a\u6a21\u578b\u7684\u8def\u7531\u5668\nrouter = Router(\n    model_list=[\n        {\n            "model_name": "gpt-4",\n            "litellm_params": {\n                "model": "openai/gpt-4",\n                "api_key": os.environ["OPENAI_API_KEY"]\n            },\n            "tpm": 40000,\n            "rpm": 500\n        },\n        {\n            "model_name": "gpt-4",  # Same name for fallback\n            "litellm_params": {\n                "model": "azure/gpt-4",\n                "api_key": os.environ["AZURE_API_KEY"],\n                "api_base": os.environ["AZURE_API_BASE"],\n                "api_version": "2023-07-01-preview"\n            },\n            "tpm": 80000,\n            "rpm": 800\n        }\n    ],\n    fallbacks=[{"gpt-4": ["azure/gpt-4"]}],\n    routing_strategy="usage-based-routing"\n)\n\n# \u4e3a Letta \u521b\u5efa\u81ea\u5b9a\u4e49\u5b8c\u6210\u51fd\u6570\ndef custom_completion(messages, model="gpt-4", **kwargs):\n    return router.completion(\n        model=model,\n        messages=messages,\n        **kwargs\n    )\n\n# \u901a\u8fc7 monkey-patching \u6216\u81ea\u5b9a\u4e49\u5305\u88c5\u5668\u4e0e Letta \u4e00\u8d77\u4f7f\u7528\nlitellm.completion = custom_completion\n'})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"\u76d1\u63a7\u548c\u53ef\u89c2\u5bdf\u6027",children:"\u76d1\u63a7\u548c\u53ef\u89c2\u5bdf\u6027"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsxs)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406\u76d1\u63a7",children:[(0,i.jsx)(n.p,{children:"\u542f\u7528\u65e5\u5fd7\u8bb0\u5f55\u4ee5\u901a\u8fc7\u4ee3\u7406\u8ddf\u8e2a\u60a8\u7684 Letta \u4ee3\u7406\u7684 LLM \u4f7f\u7528\u60c5\u51b5\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# config.yaml with logging\nmodel_list:\n  # ... \u60a8\u7684\u6a21\u578b\n\nlitellm_settings:\n  success_callback: ["langfuse"]  # \u6216\u5176\u4ed6\u53ef\u89c2\u5bdf\u6027\u5de5\u5177\n\nenvironment_variables:\n  LANGFUSE_PUBLIC_KEY: "your-key"\n  LANGFUSE_SECRET_KEY: "your-secret"\n'})}),(0,i.jsx)(n.p,{children:"\u5728\u4ee3\u7406\u4eea\u8868\u677f\u4e2d\u67e5\u770b\u6307\u6807\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# \u4f7f\u7528 UI \u542f\u52a8\u4ee3\u7406\nlitellm --config config.yaml --port 4000 --detailed_debug\n"})})]}),(0,i.jsxs)(a.A,{value:"sdk",label:"LiteLLM SDK \u76d1\u63a7",children:[(0,i.jsx)(n.p,{children:"\u76f4\u63a5\u5728\u60a8\u7684 SDK \u96c6\u6210\u4e2d\u8bbe\u7f6e\u53ef\u89c2\u5bdf\u6027\uff1a"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import litellm\nimport os\n\n# \u914d\u7f6e\u53ef\u89c2\u5bdf\u6027\u56de\u8c03\nos.environ["LANGFUSE_PUBLIC_KEY"] = "your-key"\nos.environ["LANGFUSE_SECRET_KEY"] = "your-secret"\n\n# \u8bbe\u7f6e\u5168\u5c40\u56de\u8c03\nlitellm.success_callback = ["langfuse"]\nlitellm.failure_callback = ["langfuse"]\n\n# \u53ef\u9009\uff1a\u8bbe\u7f6e\u81ea\u5b9a\u4e49\u65e5\u5fd7\u8bb0\u5f55\nlitellm.set_verbose = True\n\n# \u521b\u5efa\u5e26\u6709\u65e5\u5fd7\u8bb0\u5f55\u7684\u81ea\u5b9a\u4e49\u5b8c\u6210\u5305\u88c5\u5668\ndef logged_completion(messages, model="gpt-4", **kwargs):\n    try:\n        response = litellm.completion(\n            model=model,\n            messages=messages,\n            **kwargs\n        )\n        # \u5982\u679c\u9700\u8981\uff0c\u5728\u6b64\u5904\u6dfb\u52a0\u81ea\u5b9a\u4e49\u65e5\u5fd7\u8bb0\u5f55\u903b\u8f91\n        return response\n    except Exception as e:\n        # \u81ea\u5b9a\u4e49\u9519\u8bef\u5904\u7406\n        print(f"LLM call failed: {e}")\n        raise\n\n# \u5728 Letta \u914d\u7f6e\u4e2d\u4f7f\u7528\nlitellm.completion = logged_completion\n'})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"\u793a\u4f8b\u591a\u4ee3\u7406\u7cfb\u7edf",children:"\u793a\u4f8b\uff1a\u591a\u4ee3\u7406\u7cfb\u7edf"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(a.A,{value:"proxy",label:"\u4f7f\u7528 LiteLLM \u4ee3\u7406",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client, LLMConfig\n\nclient = create_client()\n\n# \u4f7f\u7528\u4ee3\u7406\u7aef\u70b9\u521b\u5efa\u4e13\u7528\u4ee3\u7406\nagents = {}\n\n# \u4f7f\u7528 Claude \u8fdb\u884c\u5206\u6790\u7684\u7814\u7a76\u4ee3\u7406\nagents[\'researcher\'] = client.create_agent(\n    name="researcher",\n    system="You are a research specialist. Analyze information thoroughly.",\n    llm_config=LLMConfig(\n        model="claude-3-sonnet",\n        model_endpoint="http://localhost:4000",\n        model_endpoint_type="openai"\n    )\n)\n\n# \u4f7f\u7528 GPT-4 \u8fdb\u884c\u5185\u5bb9\u521b\u5efa\u7684\u7f16\u5199\u4ee3\u7406\nagents[\'writer\'] = client.create_agent(\n    name="writer",\n    system="You are a content writer. Create engaging, well-structured content.",\n    llm_config=LLMConfig(\n        model="gpt-4",\n        model_endpoint="http://localhost:4000",\n        model_endpoint_type="openai"\n    )\n)\n\n# \u534f\u8c03\u5668\u5de5\u4f5c\u6d41\ndef research_and_write_workflow(topic: str):\n    # \u7814\u7a76\u9636\u6bb5\n    research_response = client.user_message(\n        agent_id=agents[\'researcher\'].id,\n        message=f"Research the topic: {topic}. Provide key insights and data."\n    )\n\n    research_results = research_response.messages[-1].text\n\n    # \u7f16\u5199\u9636\u6bb5\n    write_response = client.user_message(\n        agent_id=agents[\'writer\'].id,\n        message=f"Based on this research: {research_results}\\n\\nWrite an article about {topic}."\n    )\n\n    return write_response.messages[-1].text\n\n# \u6267\u884c\u5de5\u4f5c\u6d41\narticle = research_and_write_workflow("The future of AI in healthcare")\nprint(article)\n'})})}),(0,i.jsx)(a.A,{value:"sdk",label:"\u4f7f\u7528 LiteLLM SDK",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import letta\nfrom letta import create_client, LLMConfig\nimport litellm\nimport os\n\n# \u8bbe\u7f6e\u73af\u5883\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\nos.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"\n\nclient = create_client()\n\n# \u4f7f\u7528\u76f4\u63a5 SDK \u6a21\u578b\u521b\u5efa\u4e13\u7528\u4ee3\u7406\nagents = {}\n\n# \u4f7f\u7528 Claude \u8fdb\u884c\u5206\u6790\u7684\u7814\u7a76\u4ee3\u7406\nagents[\'researcher\'] = client.create_agent(\n    name="researcher",\n    system="You are a research specialist. Analyze information thoroughly.",\n    llm_config=LLMConfig(\n        model="anthropic/claude-3-sonnet-20240229",\n        model_endpoint_type="openai"\n    )\n)\n\n# \u4f7f\u7528 GPT-4 \u8fdb\u884c\u5185\u5bb9\u521b\u5efa\u7684\u7f16\u5199\u4ee3\u7406\nagents[\'writer\'] = client.create_agent(\n    name="writer",\n    system="You are a content writer. Create engaging, well-structured content.",\n    llm_config=LLMConfig(\n        model="openai/gpt-4",\n        model_endpoint_type="openai"\n    )\n)\n\n# \u4f7f\u7528 GPT-3.5 \u7684\u6210\u672c\u610f\u8bc6\u4ee3\u7406\nagents[\'reviewer\'] = client.create_agent(\n    name="reviewer",\n    system="You are an editor. Review and improve content quality.",\n    llm_config=LLMConfig(\n        model="openai/gpt-3.5-turbo",\n        model_endpoint_type="openai"\n    )\n)\n\n# \u589e\u5f3a\u7684\u591a\u4ee3\u7406\u5de5\u4f5c\u6d41\ndef enhanced_workflow(topic: str):\n    # \u7814\u7a76\u9636\u6bb5\n    research_response = client.user_message(\n        agent_id=agents[\'researcher\'].id,\n        message=f"Research the topic: {topic}. Provide key insights and data."\n    )\n\n    research_results = research_response.messages[-1].text\n\n    # \u7f16\u5199\u9636\u6bb5\n    write_response = client.user_message(\n        agent_id=agents[\'writer\'].id,\n        message=f"Based on this research: {research_results}\\n\\nWrite an article about {topic}."\n    )\n\n    draft_article = write_response.messages[-1].text\n\n    # \u5ba1\u67e5\u9636\u6bb5\n    review_response = client.user_message(\n        agent_id=agents[\'reviewer\'].id,\n        message=f"Please review and improve this article:\\n\\n{draft_article}"\n    )\n\n    return review_response.messages[-1].text\n\n# \u6267\u884c\u589e\u5f3a\u5de5\u4f5c\u6d41\narticle = enhanced_workflow("The future of AI in healthcare")\nprint(article)\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406\u6700\u4f73\u5b9e\u8df5",children:(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u6a21\u578b\u9009\u62e9"}),"\uff1a\u4e3a\u4e0d\u540c\u7684\u4efb\u52a1\u4f7f\u7528\u5408\u9002\u7684\u6a21\u578b\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528 Claude \u8fdb\u884c\u5206\u6790\u548c\u63a8\u7406"}),"\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528 GPT-4 \u8fdb\u884c\u521b\u610f\u4efb\u52a1"}),"\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528 GPT-3.5-turbo \u8fdb\u884c\u7b80\u5355\u4ea4\u4e92"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u4ee3\u7406\u914d\u7f6e"}),"\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u8bbe\u7f6e\u9002\u5f53\u7684\u901f\u7387\u9650\u5236\u548c\u8d85\u65f6"}),"\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528\u6545\u969c\u8f6c\u79fb\u63d0\u9ad8\u53ef\u9760\u6027"}),"\n",(0,i.jsx)(n.li,{children:"\u4e3a\u751f\u4ea7\u73af\u5883\u542f\u7528\u8eab\u4efd\u9a8c\u8bc1"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u5185\u5b58\u7ba1\u7406"}),"\uff1aLetta \u81ea\u52a8\u5904\u7406\u5185\u5b58\uff0c\u4f46\u76d1\u63a7\u5927\u4e0a\u4e0b\u6587\u7684\u4f7f\u7528\u60c5\u51b5"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u6210\u672c\u4f18\u5316"}),"\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u4f7f\u7528\u4ee3\u7406\u7684\u9884\u7b97\u529f\u80fd\u63a7\u5236\u6210\u672c"}),"\n",(0,i.jsx)(n.li,{children:"\u4e3a\u6bcf\u4e2a\u7528\u6237/\u56e2\u961f\u8bbe\u7f6e\u901f\u7387\u9650\u5236"}),"\n",(0,i.jsx)(n.li,{children:"\u901a\u8fc7\u4ee3\u7406\u4eea\u8868\u677f\u76d1\u63a7 token \u4f7f\u7528\u60c5\u51b5"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u76d1\u63a7"}),"\uff1a\u542f\u7528\u53ef\u89c2\u5bdf\u6027\u4ee5\u8ddf\u8e2a\u4ee3\u7406\u6027\u80fd\u548c token \u4f7f\u7528\u60c5\u51b5"]}),"\n"]}),"\n"]})}),(0,i.jsx)(a.A,{value:"sdk",label:"LiteLLM SDK \u6700\u4f73\u5b9e\u8df5",children:(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u6a21\u578b\u9009\u62e9"}),"\uff1a\u6839\u636e\u4efb\u52a1\u8981\u6c42\u9009\u62e9\u6a21\u578b\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\u4f7f\u7528 ",(0,i.jsx)(n.code,{children:"openai/gpt-4"})," \u8fdb\u884c\u590d\u6742\u63a8\u7406"]}),"\n",(0,i.jsxs)(n.li,{children:["\u4f7f\u7528 ",(0,i.jsx)(n.code,{children:"anthropic/claude-3-sonnet-20240229"})," \u8fdb\u884c\u5206\u6790"]}),"\n",(0,i.jsxs)(n.li,{children:["\u4f7f\u7528 ",(0,i.jsx)(n.code,{children:"openai/gpt-3.5-turbo"})," \u8fdb\u884c\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u7b80\u5355\u4efb\u52a1"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u9519\u8bef\u5904\u7406"}),"\uff1a\u901a\u8fc7\u91cd\u8bd5\u5b9e\u73b0\u5f3a\u5927\u7684\u9519\u8bef\u5904\u7406\uff1a"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import litellm\nfrom litellm import completion\n\n# \u8bbe\u7f6e\u91cd\u8bd5\u903b\u8f91\nlitellm.num_retries = 3\nlitellm.request_timeout = 60\n\n# \u81ea\u5b9a\u4e49\u9519\u8bef\u5904\u7406\ndef safe_completion(**kwargs):\n    try:\n        return completion(**kwargs)\n    except Exception as e:\n        print(f"LLM call failed: {e}")\n        # \u5b9e\u65bd\u6545\u969c\u8f6c\u79fb\u903b\u8f91\n        return completion(model="openai/gpt-3.5-turbo", **kwargs)\n'})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u6210\u672c\u7ba1\u7406"}),"\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u4e3a\u975e\u5173\u952e\u4efb\u52a1\u4f7f\u7528\u66f4\u4fbf\u5b9c\u7684\u6a21\u578b"}),"\n",(0,i.jsx)(n.li,{children:"\u5b9e\u65bd token \u8ba1\u6570\u548c\u9884\u7b97"}),"\n",(0,i.jsx)(n.li,{children:"\u5728\u9002\u5f53\u7684\u60c5\u51b5\u4e0b\u7f13\u5b58\u54cd\u5e94"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u6027\u80fd"}),"\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u5bf9\u5e76\u53d1\u8bf7\u6c42\u4f7f\u7528\u5f02\u6b65\u64cd\u4f5c"}),"\n",(0,i.jsx)(n.li,{children:"\u5b9e\u65bd\u8fde\u63a5\u6c60"}),"\n",(0,i.jsx)(n.li,{children:"\u76d1\u63a7\u54cd\u5e94\u65f6\u95f4"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u5b89\u5168\u6027"}),"\uff1a"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u5b89\u5168\u5b58\u50a8 API \u5bc6\u94a5\uff08\u73af\u5883\u53d8\u91cf\uff09"}),"\n",(0,i.jsx)(n.li,{children:"\u5b9a\u671f\u8f6e\u6362\u5bc6\u94a5"}),"\n",(0,i.jsx)(n.li,{children:"\u5b9e\u65bd\u901f\u7387\u9650\u5236"}),"\n"]}),"\n"]}),"\n"]})})]}),"\n",(0,i.jsx)(n.h2,{id:"\u6545\u969c\u6392\u9664",children:"\u6545\u969c\u6392\u9664"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsxs)(a.A,{value:"proxy",label:"LiteLLM \u4ee3\u7406\u95ee\u9898",children:[(0,i.jsx)(n.h3,{id:"\u8fde\u63a5\u95ee\u9898",children:"\u8fde\u63a5\u95ee\u9898"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# \u6d4b\u8bd5\u60a8\u7684 LiteLLM \u4ee3\u7406\ncurl -X POST http://localhost:4000/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "gpt-4",\n    "messages": [{"role": "user", "content": "Hello"}]\n  }\'\n'})}),(0,i.jsx)(n.h3,{id:"\u914d\u7f6e\u8c03\u8bd5",children:"\u914d\u7f6e\u8c03\u8bd5"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# \u542f\u7528\u8be6\u7ec6\u65e5\u5fd7\u8bb0\u5f55\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# \u6d4b\u8bd5 Letta \u914d\u7f6e\nclient = create_client()\nprint(client.get_default_llm_config())\n"})}),(0,i.jsx)(n.h3,{id:"\u5e38\u89c1\u4ee3\u7406\u95ee\u9898",children:"\u5e38\u89c1\u4ee3\u7406\u95ee\u9898"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u7aef\u53e3\u51b2\u7a81"}),"\uff1a\u786e\u4fdd\u7aef\u53e3 4000 \u672a\u88ab\u4f7f\u7528"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u6a21\u578b\u672a\u627e\u5230"}),"\uff1a\u9a8c\u8bc1\u6a21\u578b\u540d\u79f0\u4e0e\u60a8\u7684 config.yaml \u5339\u914d"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u8eab\u4efd\u9a8c\u8bc1\u9519\u8bef"}),"\uff1a\u68c0\u67e5\u4e3b\u5bc6\u94a5\u914d\u7f6e"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u901f\u7387\u9650\u5236"}),"\uff1a\u76d1\u63a7\u4ee3\u7406\u65e5\u5fd7\u4e2d\u7684\u901f\u7387\u9650\u5236\u547d\u4e2d"]}),"\n"]})]}),(0,i.jsxs)(a.A,{value:"sdk",label:"LiteLLM SDK \u95ee\u9898",children:[(0,i.jsx)(n.h3,{id:"api-\u5bc6\u94a5\u95ee\u9898",children:"API \u5bc6\u94a5\u95ee\u9898"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nimport litellm\n\n# \u68c0\u67e5\u662f\u5426\u8bbe\u7f6e\u4e86 API \u5bc6\u94a5\nprint("OpenAI Key:", os.environ.get("OPENAI_API_KEY", "Not set"))\nprint("Anthropic Key:", os.environ.get("ANTHROPIC_API_KEY", "Not set"))\n\n# \u6d4b\u8bd5\u76f4\u63a5 LiteLLM \u8c03\u7528\ntry:\n    response = litellm.completion(\n        model="openai/gpt-3.5-turbo",\n        messages=[{"role": "user", "content": "Hello"}]\n    )\n    print("LiteLLM working:", response.choices[0].message.content)\nexcept Exception as e:\n    print("LiteLLM error:", e)\n'})}),(0,i.jsx)(n.h3,{id:"\u914d\u7f6e\u8c03\u8bd5-1",children:"\u914d\u7f6e\u8c03\u8bd5"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u542f\u7528\u8be6\u7ec6\u65e5\u5fd7\u8bb0\u5f55\nlitellm.set_verbose = True\n\n# \u6d4b\u8bd5\u6a21\u578b\u53ef\u7528\u6027\nmodels = ["openai/gpt-4", "anthropic/claude-3-sonnet-20240229"]\nfor model in models:\n    try:\n        response = litellm.completion(\n            model=model,\n            messages=[{"role": "user", "content": "Test"}],\n            max_tokens=10\n        )\n        print(f"\u2713 {model} working")\n    except Exception as e:\n        print(f"\u2717 {model} failed: {e}")\n'})}),(0,i.jsx)(n.h3,{id:"\u5e38\u89c1-sdk-\u95ee\u9898",children:"\u5e38\u89c1 SDK \u95ee\u9898"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u5bfc\u5165\u9519\u8bef"}),"\uff1a\u786e\u4fdd\u8fd0\u884c ",(0,i.jsx)(n.code,{children:"pip install litellm letta"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u6a21\u578b\u683c\u5f0f"}),"\uff1a\u4f7f\u7528 ",(0,i.jsx)(n.code,{children:"provider/model"})," \u683c\u5f0f\uff08\u4f8b\u5982 ",(0,i.jsx)(n.code,{children:"openai/gpt-4"}),"\uff09"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"API \u5bc6\u94a5\u683c\u5f0f"}),"\uff1a\u4e0d\u540c\u7684\u63d0\u4f9b\u5546\u6709\u4e0d\u540c\u7684\u5bc6\u94a5\u683c\u5f0f"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\u901f\u7387\u9650\u5236"}),"\uff1a\u4e3a\u91cd\u8bd5\u5b9e\u65bd\u6307\u6570\u9000\u907f"]}),"\n"]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"\u8d44\u6e90",children:"\u8d44\u6e90"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.letta.ai/",children:"Letta \u6587\u6863"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/proxy/quick_start",children:"LiteLLM \u4ee3\u7406\u6587\u6863"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/completion/input",children:"LiteLLM SDK \u6587\u6863"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/completion/function_call",children:"\u51fd\u6570\u8c03\u7528\u6307\u5357"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/observability/langfuse_integration",children:"\u53ef\u89c2\u5bdf\u6027\u8bbe\u7f6e"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/routing",children:"\u8def\u7531\u5668\u914d\u7f6e"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},49489(e,n,t){t.d(n,{A:()=>b});var l=t(96540),i=t(18215),s=t(24245),r=t(56347),a=t(36494),o=t(62814),c=t(45167),d=t(69900);function p(e){return l.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function m(e){const{values:n,children:t}=e;return(0,l.useMemo)(()=>{const e=n??function(e){return p(e).map(({props:{value:e,label:n,attributes:t,default:l}})=>({value:e,label:n,attributes:t,default:l}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function h({value:e,tabValues:n}){return n.some(n=>n.value===e)}function u({queryString:e=!1,groupId:n}){const t=(0,r.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(i),(0,l.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(t.location.search);n.set(i,e),t.replace({...t.location,search:n.toString()})},[i,t])]}function g(e){const{defaultValue:n,queryString:t=!1,groupId:i}=e,s=m(e),[r,o]=(0,l.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:s})),[c,p]=u({queryString:t,groupId:i}),[g,_]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,i]=(0,d.Dv)(n);return[t,(0,l.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),x=(()=>{const e=c??g;return h({value:e,tabValues:s})?e:null})();(0,a.A)(()=>{x&&o(x)},[x]);return{selectedValue:r,selectValue:(0,l.useCallback)(e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);o(e),p(e),_(e)},[p,_,s]),tabValues:s}}var _=t(11062);const x="tabList__CuJ",L="tabItem_LNqP";var f=t(74848);function j({className:e,block:n,selectedValue:t,selectValue:l,tabValues:r}){const a=[],{blockElementScrollPositionUntilNextRender:o}=(0,s.a_)(),c=e=>{const n=e.currentTarget,i=a.indexOf(n),s=r[i].value;s!==t&&(o(n),l(s))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=a.indexOf(e.currentTarget)+1;n=a[t]??a[0];break}case"ArrowLeft":{const t=a.indexOf(e.currentTarget)-1;n=a[t]??a[a.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:l})=>(0,f.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{a.push(e)},onKeyDown:d,onClick:c,...l,className:(0,i.A)("tabs__item",L,l?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:t}){const s=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=s.find(e=>e.props.value===t);return e?(0,l.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:s.map((e,n)=>(0,l.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function y(e){const n=g(e);return(0,f.jsxs)("div",{className:(0,i.A)("tabs-container",x),children:[(0,f.jsx)(j,{...n,...e}),(0,f.jsx)(v,{...n,...e})]})}function b(e){const n=(0,_.A)();return(0,f.jsx)(y,{...e,children:p(e.children)},String(n))}}}]);