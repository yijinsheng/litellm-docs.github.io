"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[95149],{373(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/add_prompt_use_var1-b82c67aa4db84ae69f7597e1b3fb0c8f.png"},2258(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/edit_prompt3-fddf675e320f42586424f4561362bb53.png"},7227(e,n,t){t.d(n,{A:()=>o});t(96540);var s=t(18215);const r="tabItem_Ymn6";var i=t(74848);function o({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,s.A)(r,t),hidden:n,children:e})}},16475(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/edit_prompt2-da10e9c66961568004be08ce74ad4fa5.png"},17213(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/edit_prompt-20bc1797ab336d1d5ceaf9c0c04c04b4.png"},28453(e,n,t){t.d(n,{R:()=>o,x:()=>a});var s=t(96540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}},42980(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/add_prompt-04fccc66f876fd8dfa4c84113176eae6.png"},49489(e,n,t){t.d(n,{A:()=>A});var s=t(96540),r=t(18215),i=t(24245),o=t(56347),a=t(36494),l=t(62814),c=t(45167),p=t(69900);function d(e){return s.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,s.useMemo)(()=>{const e=n??function(e){return d(e).map(({props:{value:e,label:n,attributes:t,default:s}})=>({value:e,label:n,attributes:t,default:s}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,o.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(r),(0,s.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function g(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,i=h(e),[o,l]=(0,s.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,d]=m({queryString:t,groupId:r}),[g,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,r]=(0,p.Dv)(n);return[t,(0,s.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),j=(()=>{const e=c??g;return u({value:e,tabValues:i})?e:null})();(0,a.A)(()=>{j&&l(j)},[j]);return{selectedValue:o,selectValue:(0,s.useCallback)(e=>{if(!u({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),d(e),x(e)},[d,x,i]),tabValues:i}}var x=t(11062);const j="tabList__CuJ",v="tabItem_LNqP";var b=t(74848);function y({className:e,block:n,selectedValue:t,selectValue:s,tabValues:o}){const a=[],{blockElementScrollPositionUntilNextRender:l}=(0,i.a_)(),c=e=>{const n=e.currentTarget,r=a.indexOf(n),i=o[r].value;i!==t&&(l(n),s(i))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=a.indexOf(e.currentTarget)+1;n=a[t]??a[0];break}case"ArrowLeft":{const t=a.indexOf(e.currentTarget)-1;n=a[t]??a[a.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:o.map(({value:e,label:n,attributes:s})=>(0,b.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{a.push(e)},onKeyDown:p,onClick:c,...s,className:(0,r.A)("tabs__item",v,s?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function f({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,s.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function w(e){const n=g(e);return(0,b.jsxs)("div",{className:(0,r.A)("tabs-container",j),children:[(0,b.jsx)(y,{...n,...e}),(0,b.jsx)(f,{...n,...e})]})}function A(e){const n=(0,x.A)();return(0,b.jsx)(w,{...e,children:d(e.children)},String(n))}},50981(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/prompt_table-785da09b565e4e174be873a0d2c5af0d.png"},70450(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/add_prompt_var-b82c67aa4db84ae69f7597e1b3fb0c8f.png"},74102(e,n,t){t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>c,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"proxy/litellm_prompt_management","title":"LiteLLM AI Gateway Prompt Management","description":"Use the LiteLLM AI Gateway to create, manage and version your prompts.","source":"@site/docs/proxy/litellm_prompt_management.md","sourceDirName":"proxy","slug":"/proxy/litellm_prompt_management","permalink":"/docs/proxy/litellm_prompt_management","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"integrationsSidebar","previous":{"title":"\ud83d\udcc8 Prometheus \u6307\u6807","permalink":"/docs/proxy/prometheus"},"next":{"title":"\u81ea\u5b9a\u4e49\u63d0\u793a\u7ba1\u7406","permalink":"/docs/proxy/custom_prompt_management"}}');var r=t(74848),i=t(28453),o=t(49489),a=t(7227);const l={},c="LiteLLM AI Gateway Prompt Management",p={},d=[{value:"Quick Start",id:"quick-start",level:2},{value:"Accessing the Prompts Interface",id:"accessing-the-prompts-interface",level:3},{value:"Create a Prompt",id:"create-a-prompt",level:2},{value:"Step 1: Select Your Model",id:"step-1-select-your-model",level:3},{value:"Step 2: Set the Developer Message",id:"step-2-set-the-developer-message",level:3},{value:"Step 3: Add Prompt Messages",id:"step-3-add-prompt-messages",level:3},{value:"Step 4: Use Variables in Your Prompts",id:"step-4-use-variables-in-your-prompts",level:3},{value:"Step 5: Test Your Prompt",id:"step-5-test-your-prompt",level:3},{value:"Step 6: Save Your Prompt",id:"step-6-save-your-prompt",level:3},{value:"Using Your Prompts",id:"using-your-prompts",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"With Custom Messages",id:"with-custom-messages",level:3},{value:"With Prompt Variables",id:"with-prompt-variables",level:3},{value:"Prompt Versioning",id:"prompt-versioning",level:2},{value:"View Prompt Details",id:"view-prompt-details",level:3},{value:"Update a Prompt",id:"update-a-prompt",level:3},{value:"View Version History",id:"view-version-history",level:3},{value:"View and Restore Older Versions",id:"view-and-restore-older-versions",level:3},{value:"Use Specific Versions in API Calls",id:"use-specific-versions-in-api-calls",level:3}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"litellm-ai-gateway-prompt-management",children:"LiteLLM AI Gateway Prompt Management"})}),"\n",(0,r.jsx)(n.p,{children:"Use the LiteLLM AI Gateway to create, manage and version your prompts."}),"\n",(0,r.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(n.h3,{id:"accessing-the-prompts-interface",children:"Accessing the Prompts Interface"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Navigate to ",(0,r.jsx)(n.strong,{children:"Experimental > Prompts"})," in your LiteLLM dashboard"]}),"\n",(0,r.jsxs)(n.li,{children:["You'll see a table displaying all your existing prompts with the following columns:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt ID"}),": Unique identifier for each prompt"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model"}),": The LLM model configured for the prompt"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Created At"}),": Timestamp when the prompt was created"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Updated At"}),": Timestamp of the last update"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Type"}),": Prompt type (e.g., db)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Actions"}),": Delete and manage prompt options (admin only)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Prompt Table",src:t(50981).A+"",width:"4400",height:"1610"})}),"\n",(0,r.jsx)(n.h2,{id:"create-a-prompt",children:"Create a Prompt"}),"\n",(0,r.jsxs)(n.p,{children:["Click the ",(0,r.jsx)(n.strong,{children:"+ Add New Prompt"})," button to create a new prompt."]}),"\n",(0,r.jsx)(n.h3,{id:"step-1-select-your-model",children:"Step 1: Select Your Model"}),"\n",(0,r.jsxs)(n.p,{children:["Choose the LLM model you want to use from the dropdown menu at the top. You can select from any of your configured models (e.g., ",(0,r.jsx)(n.code,{children:"aws/anthropic/bedrock-claude-3-5-sonnet"}),", ",(0,r.jsx)(n.code,{children:"gpt-4o"}),", etc.)."]}),"\n",(0,r.jsx)(n.h3,{id:"step-2-set-the-developer-message",children:"Step 2: Set the Developer Message"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Developer message"})," section allows you to set optional system instructions for the model. This acts as the system prompt that guides the model's behavior."]}),"\n",(0,r.jsx)(n.p,{children:"For example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Respond as jack sparrow would\n"})}),"\n",(0,r.jsx)(n.p,{children:"This will instruct the model to respond in the style of Captain Jack Sparrow from Pirates of the Caribbean."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Add Prompt with Developer Message",src:t(42980).A+"",width:"4400",height:"2614"})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-add-prompt-messages",children:"Step 3: Add Prompt Messages"}),"\n",(0,r.jsxs)(n.p,{children:["In the ",(0,r.jsx)(n.strong,{children:"Prompt messages"})," section, you can add the actual prompt content. Click ",(0,r.jsx)(n.strong,{children:"+ Add message"})," to add additional messages to your prompt template."]}),"\n",(0,r.jsx)(n.h3,{id:"step-4-use-variables-in-your-prompts",children:"Step 4: Use Variables in Your Prompts"}),"\n",(0,r.jsxs)(n.p,{children:["Variables allow you to create dynamic prompts that can be customized at runtime. Use the ",(0,r.jsx)(n.code,{children:"{{variable_name}}"})," syntax to insert variables into your prompts."]}),"\n",(0,r.jsx)(n.p,{children:"For example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Give me a recipe for {{dish}}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The UI will automatically detect variables in your prompt and display them in the ",(0,r.jsx)(n.strong,{children:"Detected variables"})," section."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Add Prompt with Variables",src:t(70450).A+"",width:"4400",height:"2686"})}),"\n",(0,r.jsx)(n.h3,{id:"step-5-test-your-prompt",children:"Step 5: Test Your Prompt"}),"\n",(0,r.jsx)(n.p,{children:"Before saving, you can test your prompt directly in the UI:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Fill in the template variables in the right panel (e.g., set ",(0,r.jsx)(n.code,{children:"dish"})," to ",(0,r.jsx)(n.code,{children:"cookies"}),")"]}),"\n",(0,r.jsx)(n.li,{children:"Type a message in the chat interface to test the prompt"}),"\n",(0,r.jsx)(n.li,{children:"The assistant will respond using your configured model, developer message, and substituted variables"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Test Prompt with Variables",src:t(373).A+"",width:"4400",height:"2686"})}),"\n",(0,r.jsx)(n.p,{children:"The result will show the model's response with your variables substituted:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Prompt Test Results",src:t(98414).A+"",width:"4400",height:"2600"})}),"\n",(0,r.jsx)(n.h3,{id:"step-6-save-your-prompt",children:"Step 6: Save Your Prompt"}),"\n",(0,r.jsxs)(n.p,{children:["Once you're satisfied with your prompt, click the ",(0,r.jsx)(n.strong,{children:"Save"})," button in the top right corner to save it to your prompt library."]}),"\n",(0,r.jsx)(n.h2,{id:"using-your-prompts",children:"Using Your Prompts"}),"\n",(0,r.jsxs)(n.p,{children:["Now that your prompt is published, you can use it in your application via the LiteLLM proxy API. Click the ",(0,r.jsx)(n.strong,{children:"Get Code"})," button in the UI to view code snippets customized for your prompt."]}),"\n",(0,r.jsx)(n.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,r.jsx)(n.p,{children:"Call a prompt using just the prompt ID and model:"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(a.A,{value:"curl",label:"cURL",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Basic Prompt Call"',children:"curl -X POST 'http://localhost:4000/chat/completions' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer sk-1234' \\\n  -d '{\n    \"model\": \"gpt-4\",\n    \"prompt_id\": \"your-prompt-id\"\n  }' | jq\n"})})}),(0,r.jsx)(a.A,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="basic_prompt.py"',children:'import openai\n\nclient = openai.OpenAI(\n    api_key="sk-1234",\n    base_url="http://localhost:4000"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    extra_body={\n        "prompt_id": "your-prompt-id"\n    }\n)\n\nprint(response)\n'})})}),(0,r.jsx)(a.A,{value:"javascript",label:"JavaScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",metastring:'showLineNumbers title="basicPrompt.js"',children:'import OpenAI from \'openai\';\n\nconst client = new OpenAI({\n    apiKey: "sk-1234",\n    baseURL: "http://localhost:4000"\n});\n\nasync function main() {\n    const response = await client.chat.completions.create({\n        model: "gpt-4",\n        prompt_id: "your-prompt-id"\n    });\n    \n    console.log(response);\n}\n\nmain();\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"with-custom-messages",children:"With Custom Messages"}),"\n",(0,r.jsx)(n.p,{children:"Add custom messages to your prompt:"}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(a.A,{value:"curl",label:"cURL",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Prompt with Custom Messages"',children:'curl -X POST \'http://localhost:4000/chat/completions\' \\\n  -H \'Content-Type: application/json\' \\\n  -H \'Authorization: Bearer sk-1234\' \\\n  -d \'{\n    "model": "gpt-4",\n    "prompt_id": "your-prompt-id",\n    "messages": [\n      {\n        "role": "user",\n        "content": "hi"\n      }\n    ]\n  }\' | jq\n'})})}),(0,r.jsx)(a.A,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="prompt_with_messages.py"',children:'import openai\n\nclient = openai.OpenAI(\n    api_key="sk-1234",\n    base_url="http://localhost:4000"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[\n        {"role": "user", "content": "hi"}\n    ],\n    extra_body={\n        "prompt_id": "your-prompt-id"\n    }\n)\n\nprint(response)\n'})})}),(0,r.jsx)(a.A,{value:"javascript",label:"JavaScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",metastring:'showLineNumbers title="promptWithMessages.js"',children:'import OpenAI from \'openai\';\n\nconst client = new OpenAI({\n    apiKey: "sk-1234",\n    baseURL: "http://localhost:4000"\n});\n\nasync function main() {\n    const response = await client.chat.completions.create({\n        model: "gpt-4",\n        messages: [\n            { role: "user", content: "hi" }\n        ],\n        prompt_id: "your-prompt-id"\n    });\n    \n    console.log(response);\n}\n\nmain();\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"with-prompt-variables",children:"With Prompt Variables"}),"\n",(0,r.jsxs)(n.p,{children:["Pass variables to your prompt template using ",(0,r.jsx)(n.code,{children:"prompt_variables"}),":"]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(a.A,{value:"curl",label:"cURL",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Prompt with Variables"',children:'curl -X POST \'http://localhost:4000/chat/completions\' \\\n  -H \'Content-Type: application/json\' \\\n  -H \'Authorization: Bearer sk-1234\' \\\n  -d \'{\n    "model": "gpt-4",\n    "prompt_id": "your-prompt-id",\n    "prompt_variables": {\n      "dish": "cookies"\n    }\n  }\' | jq\n'})})}),(0,r.jsx)(a.A,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="prompt_with_variables.py"',children:'import openai\n\nclient = openai.OpenAI(\n    api_key="sk-1234",\n    base_url="http://localhost:4000"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    extra_body={\n        "prompt_id": "your-prompt-id",\n        "prompt_variables": {\n            "dish": "cookies"\n        }\n    }\n)\n\nprint(response)\n'})})}),(0,r.jsx)(a.A,{value:"javascript",label:"JavaScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",metastring:'showLineNumbers title="promptWithVariables.js"',children:'import OpenAI from \'openai\';\n\nconst client = new OpenAI({\n    apiKey: "sk-1234",\n    baseURL: "http://localhost:4000"\n});\n\nasync function main() {\n    const response = await client.chat.completions.create({\n        model: "gpt-4",\n        prompt_id: "your-prompt-id",\n        prompt_variables: {\n            "dish": "cookies"\n        }\n    });\n    \n    console.log(response);\n}\n\nmain();\n'})})})]}),"\n",(0,r.jsx)(n.h2,{id:"prompt-versioning",children:"Prompt Versioning"}),"\n",(0,r.jsx)(n.p,{children:"LiteLLM automatically versions your prompts each time you update them. This allows you to maintain a complete history of changes and roll back to previous versions if needed."}),"\n",(0,r.jsx)(n.h3,{id:"view-prompt-details",children:"View Prompt Details"}),"\n",(0,r.jsx)(n.p,{children:"Click on any prompt ID in the prompts table to view its details page. This page shows:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt ID"}),": The unique identifier for your prompt"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Version"}),": The current version number (e.g., v4)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt Type"}),": The storage type (e.g., db)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Created At"}),": When the prompt was first created"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Last Updated"}),": Timestamp of the most recent update"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LiteLLM Parameters"}),": The raw JSON configuration"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Prompt Details",src:t(17213).A+"",width:"4400",height:"2274"})}),"\n",(0,r.jsx)(n.h3,{id:"update-a-prompt",children:"Update a Prompt"}),"\n",(0,r.jsx)(n.p,{children:"To update an existing prompt:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Click on the prompt you want to update from the prompts table"}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.strong,{children:"Prompt Studio"})," button in the top right"]}),"\n",(0,r.jsxs)(n.li,{children:["Make your changes to:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Model selection"}),"\n",(0,r.jsx)(n.li,{children:"Developer message (system instructions)"}),"\n",(0,r.jsx)(n.li,{children:"Prompt messages"}),"\n",(0,r.jsx)(n.li,{children:"Variables"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Test your changes in the chat interface on the right"}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.strong,{children:"Update"})," button to save the new version"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Edit Prompt in Studio",src:t(16475).A+"",width:"4400",height:"2426"})}),"\n",(0,r.jsxs)(n.p,{children:["Each time you click ",(0,r.jsx)(n.strong,{children:"Update"}),", a new version is created (v1 \u2192 v2 \u2192 v3, etc.) while maintaining the same prompt ID."]}),"\n",(0,r.jsx)(n.h3,{id:"view-version-history",children:"View Version History"}),"\n",(0,r.jsx)(n.p,{children:"To view all versions of a prompt:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Open the prompt in ",(0,r.jsx)(n.strong,{children:"Prompt Studio"})]}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.strong,{children:"History"})," button in the top right"]}),"\n",(0,r.jsxs)(n.li,{children:["A ",(0,r.jsx)(n.strong,{children:"Version History"})," panel will open on the right side"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Version History Panel",src:t(2258).A+"",width:"4400",height:"2678"})}),"\n",(0,r.jsx)(n.p,{children:"The version history panel displays:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Latest version"}),' (marked with a "Latest" badge and "Active" status)']}),"\n",(0,r.jsx)(n.li,{children:"All previous versions (v4, v3, v2, v1, etc.)"}),"\n",(0,r.jsx)(n.li,{children:"Timestamps for each version"}),"\n",(0,r.jsx)(n.li,{children:'Database save status ("Saved to Database")'}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"view-and-restore-older-versions",children:"View and Restore Older Versions"}),"\n",(0,r.jsx)(n.p,{children:"To view or restore an older version:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["In the ",(0,r.jsx)(n.strong,{children:"Version History"})," panel, click on any previous version (e.g., v2)"]}),"\n",(0,r.jsx)(n.li,{children:"The prompt studio will load that version's configuration"}),"\n",(0,r.jsxs)(n.li,{children:["You can see:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The developer message from that version"}),"\n",(0,r.jsx)(n.li,{children:"The prompt messages from that version"}),"\n",(0,r.jsx)(n.li,{children:"The model and parameters used"}),"\n",(0,r.jsx)(n.li,{children:"All variables defined at that time"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"View Older Version",src:t(74765).A+"",width:"4400",height:"2730"})}),"\n",(0,r.jsx)(n.p,{children:'The selected version will be highlighted with an "Active" badge in the version history panel.'}),"\n",(0,r.jsx)(n.p,{children:"To restore an older version:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"View the older version you want to restore"}),"\n",(0,r.jsxs)(n.li,{children:["Click the ",(0,r.jsx)(n.strong,{children:"Update"})," button"]}),"\n",(0,r.jsx)(n.li,{children:"This will create a new version with the content from the older version"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"use-specific-versions-in-api-calls",children:"Use Specific Versions in API Calls"}),"\n",(0,r.jsxs)(n.p,{children:["By default, API calls use the latest version of a prompt. To use a specific version, pass the ",(0,r.jsx)(n.code,{children:"prompt_version"})," parameter:"]}),"\n",(0,r.jsxs)(o.A,{children:[(0,r.jsx)(a.A,{value:"curl",label:"cURL",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Use Specific Prompt Version"',children:'curl -X POST \'http://localhost:4000/chat/completions\' \\\n  -H \'Content-Type: application/json\' \\\n  -H \'Authorization: Bearer sk-1234\' \\\n  -d \'{\n    "model": "gpt-4",\n    "prompt_id": "jack-sparrow",\n    "prompt_version": 2,\n    "messages": [\n      {\n        "role": "user",\n        "content": "Who are u"\n      }\n    ]\n  }\' | jq\n'})})}),(0,r.jsx)(a.A,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="prompt_version.py"',children:'import openai\n\nclient = openai.OpenAI(\n    api_key="sk-1234",\n    base_url="http://localhost:4000"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[\n        {"role": "user", "content": "Who are u"}\n    ],\n    extra_body={\n        "prompt_id": "jack-sparrow",\n        "prompt_version": 2\n    }\n)\n\nprint(response)\n'})})}),(0,r.jsx)(a.A,{value:"javascript",label:"JavaScript",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",metastring:'showLineNumbers title="promptVersion.js"',children:'import OpenAI from \'openai\';\n\nconst client = new OpenAI({\n    apiKey: "sk-1234",\n    baseURL: "http://localhost:4000"\n});\n\nasync function main() {\n    const response = await client.chat.completions.create({\n        model: "gpt-4",\n        messages: [\n            { role: "user", content: "Who are u" }\n        ],\n        prompt_id: "jack-sparrow",\n        prompt_version: 2\n    });\n    \n    console.log(response);\n}\n\nmain();\n'})})})]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},74765(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/edit_prompt4-8e401504cb15e04a408a72b92f5edc7d.png"},98414(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/add_prompt_use_var-302274ae931eea38191d358ec471c5f6.png"}}]);