"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[57706],{7227(e,n,t){t.d(n,{A:()=>a});t(96540);var o=t(18215);const s="tabItem_Ymn6";var l=t(74848);function a({children:e,hidden:n,className:t}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,o.A)(s,t),hidden:n,children:e})}},28453(e,n,t){t.d(n,{R:()=>a,x:()=>r});var o=t(96540);const s={},l=o.createContext(s);function a(e){const n=o.useContext(l);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(l.Provider,{value:n},e.children)}},49489(e,n,t){t.d(n,{A:()=>I});var o=t(96540),s=t(18215),l=t(24245),a=t(56347),r=t(36494),i=t(62814),c=t(45167),u=t(69900);function d(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return d(e).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function p({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,a.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,i.aZ)(s),(0,o.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})},[s,t])]}function b(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,l=h(e),[a,i]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:l})),[c,d]=m({queryString:t,groupId:s}),[b,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,u.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),f=(()=>{const e=c??b;return p({value:e,tabValues:l})?e:null})();(0,r.A)(()=>{f&&i(f)},[f]);return{selectedValue:a,selectValue:(0,o.useCallback)(e=>{if(!p({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);i(e),d(e),g(e)},[d,g,l]),tabValues:l}}var g=t(11062);const f="tabList__CuJ",x="tabItem_LNqP";var v=t(74848);function j({className:e,block:n,selectedValue:t,selectValue:o,tabValues:a}){const r=[],{blockElementScrollPositionUntilNextRender:i}=(0,l.a_)(),c=e=>{const n=e.currentTarget,s=r.indexOf(n),l=a[s].value;l!==t&&(i(n),o(l))},u=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:a.map(({value:e,label:n,attributes:o})=>(0,v.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{r.push(e)},onKeyDown:u,onClick:c,...o,className:(0,s.A)("tabs__item",x,o?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function _({lazy:e,children:n,selectedValue:t}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function y(e){const n=b(e);return(0,v.jsxs)("div",{className:(0,s.A)("tabs-container",f),children:[(0,v.jsx)(j,{...n,...e}),(0,v.jsx)(_,{...n,...e})]})}function I(e){const n=(0,g.A)();return(0,v.jsx)(y,{...e,children:d(e.children)},String(n))}},60968(e,n,t){t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>c,default:()=>p,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"completion/batching","title":"\u6279\u91cf\u5b8c\u6210()","description":"LiteLLM \u5141\u8bb8\u60a8\uff1a","source":"@site/docs/completion/batching.md","sourceDirName":"completion","slug":"/completion/batching","permalink":"/docs/completion/batching","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"\u5f02\u5e38\u6620\u5c04","permalink":"/docs/exception_mapping"},"next":{"title":"\u8c03\u7528\u5fae\u8c03\u6a21\u578b","permalink":"/docs/guides/finetuned_models"}}');var s=t(74848),l=t(28453),a=t(49489),r=t(7227);const i={},c="\u6279\u91cf\u5b8c\u6210()",u={},d=[{value:"\u5411 1 \u4e2a\u6a21\u578b\u53d1\u9001\u591a\u4e2a\u5b8c\u6210\u8c03\u7528",id:"\u5411-1-\u4e2a\u6a21\u578b\u53d1\u9001\u591a\u4e2a\u5b8c\u6210\u8c03\u7528",level:2},{value:"\u793a\u4f8b\u4ee3\u7801",id:"\u793a\u4f8b\u4ee3\u7801",level:3},{value:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6700\u5feb\u54cd\u5e94",id:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001-1-\u4e2a\u5b8c\u6210\u8c03\u7528\u8fd4\u56de\u6700\u5feb\u54cd\u5e94",level:2},{value:"\u793a\u4f8b\u4ee3\u7801",id:"\u793a\u4f8b\u4ee3\u7801-1",level:3},{value:"\u793a\u4f8b\u8bbe\u7f6e\uff1a",id:"\u793a\u4f8b\u8bbe\u7f6e",level:3},{value:"\u8f93\u51fa",id:"\u8f93\u51fa",level:3},{value:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6240\u6709\u54cd\u5e94",id:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001-1-\u4e2a\u5b8c\u6210\u8c03\u7528\u8fd4\u56de\u6240\u6709\u54cd\u5e94",level:2},{value:"\u793a\u4f8b\u4ee3\u7801",id:"\u793a\u4f8b\u4ee3\u7801-2",level:3},{value:"\u8f93\u51fa",id:"\u8f93\u51fa-1",level:3}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"\u6279\u91cf\u5b8c\u6210",children:"\u6279\u91cf\u5b8c\u6210()"})}),"\n",(0,s.jsx)(n.p,{children:"LiteLLM \u5141\u8bb8\u60a8\uff1a"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u5411 1 \u4e2a\u6a21\u578b\u53d1\u9001\u591a\u4e2a\u5b8c\u6210\u8c03\u7528"}),"\n",(0,s.jsx)(n.li,{children:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6700\u5feb\u54cd\u5e94"}),"\n",(0,s.jsx)(n.li,{children:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6240\u6709\u54cd\u5e94"}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["\u5c1d\u8bd5\u5728 LiteLLM \u4ee3\u7406\u4e0a\u8fdb\u884c\u6279\u91cf\u5b8c\u6210\uff1f\u8bf7\u8bbf\u95ee\uff1a",(0,s.jsx)(n.a,{href:"https://docs.litellm.ai/docs/proxy/user_keys#beta-batch-completions---pass-model-as-list",children:"https://docs.litellm.ai/docs/proxy/user_keys#beta-batch-completions---pass-model-as-list"})]})}),"\n",(0,s.jsx)(n.h2,{id:"\u5411-1-\u4e2a\u6a21\u578b\u53d1\u9001\u591a\u4e2a\u5b8c\u6210\u8c03\u7528",children:"\u5411 1 \u4e2a\u6a21\u578b\u53d1\u9001\u591a\u4e2a\u5b8c\u6210\u8c03\u7528"}),"\n",(0,s.jsxs)(n.p,{children:["\u5728 batch_completion \u65b9\u6cd5\u4e2d\uff0c\u60a8\u63d0\u4f9b\u4e00\u4e2a ",(0,s.jsx)(n.code,{children:"messages"})," \u5217\u8868\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b50\u5217\u8868\u7684\u6d88\u606f\u90fd\u4f1a\u4f20\u9012\u7ed9 ",(0,s.jsx)(n.code,{children:"litellm.completion()"}),"\uff0c\u5141\u8bb8\u60a8\u5728\u5355\u4e2a API \u8c03\u7528\u4e2d\u9ad8\u6548\u5730\u5904\u7406\u591a\u4e2a\u63d0\u793a\u3002"]}),"\n",(0,s.jsx)("a",{target:"_blank",href:"https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/LiteLLM_batch_completion.ipynb",children:(0,s.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,s.jsx)(n.h3,{id:"\u793a\u4f8b\u4ee3\u7801",children:"\u793a\u4f8b\u4ee3\u7801"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import litellm\nimport os\nfrom litellm import batch_completion\n\nos.environ[\'ANTHROPIC_API_KEY\'] = ""\n\n\nresponses = batch_completion(\n    model="claude-2",\n    messages = [\n        [\n            {\n                "role": "user",\n                "content": "good morning? "\n            }\n        ],\n        [\n            {\n                "role": "user",\n                "content": "what\'s the time? "\n            }\n        ]\n    ]\n)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001-1-\u4e2a\u5b8c\u6210\u8c03\u7528\u8fd4\u56de\u6700\u5feb\u54cd\u5e94",children:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6700\u5feb\u54cd\u5e94"}),"\n",(0,s.jsxs)(n.p,{children:["\u8fd9\u4f1a\u5411\u6307\u5b9a\u7684 ",(0,s.jsx)(n.code,{children:"models"})," \u53d1\u51fa\u5e76\u884c\u8c03\u7528\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a\u54cd\u5e94"]}),"\n",(0,s.jsx)(n.p,{children:"\u4f7f\u7528\u6b64\u65b9\u6cd5\u53ef\u4ee5\u51cf\u5c11\u5ef6\u8fdf"}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsxs)(r.A,{value:"sdk",label:"SDK",children:[(0,s.jsx)(n.h3,{id:"\u793a\u4f8b\u4ee3\u7801-1",children:"\u793a\u4f8b\u4ee3\u7801"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import litellm\nimport os\nfrom litellm import batch_completion_models\n\nos.environ[\'ANTHROPIC_API_KEY\'] = ""\nos.environ[\'OPENAI_API_KEY\'] = ""\nos.environ[\'COHERE_API_KEY\'] = ""\n\nresponse = batch_completion_models(\n    models=["gpt-3.5-turbo", "claude-instant-1.2", "command-nightly"],\n    messages=[{"role": "user", "content": "Hey, how\'s it going"}]\n)\nprint(result)\n'})})]}),(0,s.jsxs)(r.A,{value:"proxy",label:"PROXY",children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"#example-setup",children:"how to setup proxy config"})}),(0,s.jsxs)(n.p,{children:["\u53ea\u9700\u4f20\u9012\u9017\u53f7\u5206\u9694\u7684\u6a21\u578b\u540d\u79f0\u5b57\u7b26\u4e32\u548c\u6807\u5fd7 ",(0,s.jsx)(n.code,{children:"fastest_response=True"}),"\u3002"]}),(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"curl",label:"curl",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'\ncurl -X POST \'http://localhost:4000/chat/completions\' \\\n-H \'Content-Type: application/json\' \\\n-H \'Authorization: Bearer sk-1234\' \\\n-d \'{\n    "model": "gpt-4o, groq-llama", # \ud83d\udc48 \u9017\u53f7\u5206\u9694\u7684\u6a21\u578b\n    "messages": [\n      {\n        "role": "user",\n        "content": "What\'s the weather like in Boston today?"\n      }\n    ],\n    "stream": true,\n    "fastest_response": true # \ud83d\udc48 \u6807\u5fd7\n}\n\n\'\n'})})}),(0,s.jsx)(r.A,{value:"openai",label:"OpenAI SDK",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\nclient = openai.OpenAI(\n    api_key="anything",\n    base_url="http://0.0.0.0:4000"\n)\n\n# request sent to model set on litellm proxy, `litellm --model`\nresponse = client.chat.completions.create(\n    model="gpt-4o, groq-llama", # \ud83d\udc48 \u9017\u53f7\u5206\u9694\u7684\u6a21\u578b\n    messages = [\n        {\n            "role": "user",\n            "content": "this is a test request, write a short poem"\n        }\n    ],\n    extra_body={"fastest_response": true} # \ud83d\udc48 \u6807\u5fd7\n)\n\nprint(response)\n'})})})]}),(0,s.jsx)(n.hr,{}),(0,s.jsx)(n.h3,{id:"\u793a\u4f8b\u8bbe\u7f6e",children:"\u793a\u4f8b\u8bbe\u7f6e\uff1a"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"model_list:\n- model_name: groq-llama\n  litellm_params:\n    model: groq/llama3-8b-8192\n    api_key: os.environ/GROQ_API_KEY\n- model_name: gpt-4o\n  litellm_params:\n    model: gpt-4o\n    api_key: os.environ/OPENAI_API_KEY\n"})}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"litellm --config /path/to/config.yaml\n\n# \u8fd0\u884c\u5728 http://0.0.0.0:4000\n"})})]})]}),"\n",(0,s.jsx)(n.h3,{id:"\u8f93\u51fa",children:"\u8f93\u51fa"}),"\n",(0,s.jsx)(n.p,{children:"\u8fd4\u56de OpenAI \u683c\u5f0f\u7684\u7b2c\u4e00\u4e2a\u54cd\u5e94\u3002\u53d6\u6d88\u5176\u4ed6 LLM API \u8c03\u7528\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "object": "chat.completion",\n  "choices": [\n    {\n      "finish_reason": "stop",\n      "index": 0,\n      "message": {\n        "content": " I\'m doing well, thanks for asking! I\'m an AI assistant created by Anthropic to be helpful, harmless, and honest.",\n        "role": "assistant",\n        "logprobs": null\n      }\n    }\n  ],\n  "id": "chatcmpl-23273eed-e351-41be-a492-bafcf5cf3274",\n  "created": 1695154628.2076092,\n  "model": "command-nightly",\n  "usage": {\n    "prompt_tokens": 6,\n    "completion_tokens": 14,\n    "total_tokens": 20\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001-1-\u4e2a\u5b8c\u6210\u8c03\u7528\u8fd4\u56de\u6240\u6709\u54cd\u5e94",children:"\u5411\u591a\u4e2a\u6a21\u578b\u53d1\u9001 1 \u4e2a\u5b8c\u6210\u8c03\u7528\uff1a\u8fd4\u56de\u6240\u6709\u54cd\u5e94"}),"\n",(0,s.jsx)(n.p,{children:"\u8fd9\u4f1a\u5411\u6307\u5b9a\u7684\u6a21\u578b\u53d1\u51fa\u5e76\u884c\u8c03\u7528\u5e76\u8fd4\u56de\u6240\u6709\u54cd\u5e94"}),"\n",(0,s.jsx)(n.p,{children:"\u4f7f\u7528\u6b64\u65b9\u6cd5\u53ef\u4ee5\u5e76\u53d1\u5904\u7406\u8bf7\u6c42\u5e76\u4ece\u591a\u4e2a\u6a21\u578b\u83b7\u53d6\u54cd\u5e94\u3002"}),"\n",(0,s.jsx)(n.h3,{id:"\u793a\u4f8b\u4ee3\u7801-2",children:"\u793a\u4f8b\u4ee3\u7801"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import litellm\nimport os\nfrom litellm import batch_completion_models_all_responses\n\nos.environ[\'ANTHROPIC_API_KEY\'] = ""\nos.environ[\'OPENAI_API_KEY\'] = ""\nos.environ[\'COHERE_API_KEY\'] = ""\n\nresponses = batch_completion_models_all_responses(\n    models=["gpt-3.5-turbo", "claude-instant-1.2", "command-nightly"],\n    messages=[{"role": "user", "content": "Hey, how\'s it going"}]\n)\nprint(responses)\n\n'})}),"\n",(0,s.jsx)(n.h3,{id:"\u8f93\u51fa-1",children:"\u8f93\u51fa"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'[<ModelResponse chat.completion id=chatcmpl-e673ec8e-4e8f-4c9e-bf26-bf9fa7ee52b9 at 0x103a62160> JSON: {\n  "object": "chat.completion",\n  "choices": [\n    {\n      "finish_reason": "stop_sequence",\n      "index": 0,\n      "message": {\n        "content": " It\'s going well, thank you for asking! How about you?",\n        "role": "assistant",\n        "logprobs": null\n      }\n    }\n  ],\n  "id": "chatcmpl-e673ec8e-4e8f-4c9e-bf26-bf9fa7ee52b9",\n  "created": 1695222060.917964,\n  "model": "claude-instant-1.2",\n  "usage": {\n    "prompt_tokens": 14,\n    "completion_tokens": 9,\n    "total_tokens": 23\n  }\n}, <ModelResponse chat.completion id=chatcmpl-ab6c5bd3-b5d9-4711-9697-e28d9fb8a53c at 0x103a62b60> JSON: {\n  "object": "chat.completion",\n  "choices": [\n    {\n      "finish_reason": "stop",\n      "index": 0,\n      "message": {\n        "content": " It\'s going well, thank you for asking! How about you?",\n        "role": "assistant",\n        "logprobs": null\n      }\n    }\n  ],\n  "id": "chatcmpl-ab6c5bd3-b5d9-4711-9697-e28d9fb8a53c",\n  "created": 1695222061.0445492,\n  "model": "command-nightly",\n  "usage": {\n    "prompt_tokens": 6,\n    "completion_tokens": 14,\n    "total_tokens": 20\n  }\n}, <OpenAIObject chat.completion id=chatcmpl-80szFnKHzCxObW0RqCMw1hWW1Icrq at 0x102dd6430> JSON: {\n  "id": "chatcmpl-80szFnKHzCxObW0RqCMw1hWW1Icrq",\n  "object": "chat.completion",\n  "created": 1695222061,\n  "model": "gpt-3.5-turbo-0613",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "Hello! I\'m an AI language model, so I don\'t have feelings, but I\'m here to assist you with any questions or tasks you might have. How can I help you today?"\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 13,\n    "completion_tokens": 39,\n    "total_tokens": 52\n  }\n}]\n\n'})})]})}function p(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);