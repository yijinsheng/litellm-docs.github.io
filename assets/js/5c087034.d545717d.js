"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[74619],{7227(e,n,r){r.d(n,{A:()=>t});r(96540);var a=r(18215);const s="tabItem_Ymn6";var l=r(74848);function t({children:e,hidden:n,className:r}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)(s,r),hidden:n,children:e})}},18492(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>o,metadata:()=>a,toc:()=>u});const a=JSON.parse('{"id":"providers/predibase","title":"Predibase","description":"LiteLLM \u652f\u6301 Predibase \u4e0a\u7684\u6240\u6709\u6a21\u578b","source":"@site/docs/providers/predibase.md","sourceDirName":"providers","slug":"/providers/predibase","permalink":"/docs/providers/predibase","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"PublicAI","permalink":"/docs/providers/publicai"},"next":{"title":"Pydantic AI \u4ee3\u7406","permalink":"/docs/providers/pydantic_ai_agent"}}');var s=r(74848),l=r(28453),t=r(49489),i=r(7227);const o={},c="Predibase",d={},u=[{value:"\u7528\u6cd5",id:"\u7528\u6cd5",level:2},{value:"API \u5bc6\u94a5",id:"api-\u5bc6\u94a5",level:3},{value:"\u793a\u4f8b\u8c03\u7528",id:"\u793a\u4f8b\u8c03\u7528",level:3},{value:"\u9ad8\u7ea7\u7528\u6cd5 - \u63d0\u793a\u683c\u5f0f\u5316",id:"\u9ad8\u7ea7\u7528\u6cd5---\u63d0\u793a\u683c\u5f0f\u5316",level:2},{value:"\u4f20\u9012\u989d\u5916\u53c2\u6570 - max_tokens\u3001temperature",id:"\u4f20\u9012\u989d\u5916\u53c2\u6570---max_tokenstemperature",level:2},{value:"\u4f20\u9012 Predibase \u7279\u5b9a\u53c2\u6570 - adapter_id\u3001adapter_source",id:"\u4f20\u9012-predibase-\u7279\u5b9a\u53c2\u6570---adapter_idadapter_source",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"predibase",children:"Predibase"})}),"\n",(0,s.jsx)(n.p,{children:"LiteLLM \u652f\u6301 Predibase \u4e0a\u7684\u6240\u6709\u6a21\u578b"}),"\n",(0,s.jsx)(n.h2,{id:"\u7528\u6cd5",children:"\u7528\u6cd5"}),"\n",(0,s.jsxs)(t.A,{children:[(0,s.jsxs)(i.A,{value:"sdk",label:"SDK",children:[(0,s.jsx)(n.h3,{id:"api-\u5bc6\u94a5",children:"API \u5bc6\u94a5"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nos.environ["PREDIBASE_API_KEY"] = ""\n'})}),(0,s.jsx)(n.h3,{id:"\u793a\u4f8b\u8c03\u7528",children:"\u793a\u4f8b\u8c03\u7528"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["PREDIBASE_API_KEY"] = "predibase key"\nos.environ["PREDIBASE_TENANT_ID"] = "predibase tenant id"\n\n# predibase llama-3 \u8c03\u7528\nresponse = completion(\n    model="predibase/llama-3-8b-instruct",\n    messages = [{ "content": "\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f","role": "user"}]\n)\n'})})]}),(0,s.jsxs)(i.A,{value:"proxy",label:"PROXY",children:[(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"\u5c06\u6a21\u578b\u6dfb\u52a0\u5230\u60a8\u7684 config.yaml"}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"model_list:\n  - model_name: llama-3\n    litellm_params:\n      model: predibase/llama-3-8b-instruct\n      api_key: os.environ/PREDIBASE_API_KEY\n      tenant_id: os.environ/PREDIBASE_TENANT_ID\n"})}),(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:"\u542f\u52a8\u4ee3\u7406"}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"$ litellm --config /path/to/config.yaml --debug\n"})}),(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsx)(n.li,{children:"\u5411 LiteLLM \u4ee3\u7406\u670d\u52a1\u5668\u53d1\u9001\u8bf7\u6c42"}),"\n"]}),(0,s.jsxs)(t.A,{children:[(0,s.jsx)(i.A,{value:"openai",label:"OpenAI Python v1.0.0+",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import openai\nclient = openai.OpenAI(\n    api_key="sk-1234",             # \u5982\u679c\u60a8\u4f7f\u7528\u865a\u62df\u5bc6\u94a5\uff0c\u8bf7\u4f20\u9012 litellm \u4ee3\u7406\u5bc6\u94a5\n    base_url="http://0.0.0.0:4000" # litellm \u4ee3\u7406\u57fa\u672c url\n)\n\nresponse = client.chat.completions.create(\n    model="llama-3",\n    messages = [\n      {\n          "role": "system",\n          "content": "\u505a\u4e00\u4e2a\u597d\u4eba\uff01"\n      },\n      {\n          "role": "user",\n          "content": "\u4f60\u5bf9\u5730\u7403\u4e86\u89e3\u591a\u5c11\uff1f"\n      }\n  ]\n)\n\nprint(response)\n'})})}),(0,s.jsx)(i.A,{value:"curl",label:"curl",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'curl --location \'http://0.0.0.0:4000/chat/completions\' \\\n    --header \'Authorization: Bearer sk-1234\' \\\n    --header \'Content-Type: application/json\' \\\n    --data \'{\n    "model": "llama-3",\n    "messages": [\n      {\n        "role": "system",\n        "content": "\u505a\u4e00\u4e2a\u597d\u4eba\uff01"\n      },\n      {\n        "role": "user",\n        "content": "\u4f60\u5bf9\u5730\u7403\u4e86\u89e3\u591a\u5c11\uff1f"\n      }\n      ],\n    }\'\n'})})})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"\u9ad8\u7ea7\u7528\u6cd5---\u63d0\u793a\u683c\u5f0f\u5316",children:"\u9ad8\u7ea7\u7528\u6cd5 - \u63d0\u793a\u683c\u5f0f\u5316"}),"\n",(0,s.jsxs)(n.p,{children:["LiteLLM \u5177\u6709\u6240\u6709 ",(0,s.jsx)(n.code,{children:"meta-llama"})," llama3 instruct \u6a21\u578b\u7684\u63d0\u793a\u6a21\u677f\u6620\u5c04\u3002",(0,s.jsx)(n.a,{href:"https://github.com/BerriAI/litellm/blob/4f46b4c3975cd0f72b8c5acb2cb429d23580c18a/litellm/llms/prompt_templates/factory.py#L1360",children:(0,s.jsx)(n.strong,{children:"\u67e5\u770b\u4ee3\u7801"})})]}),"\n",(0,s.jsx)(n.p,{children:"\u8981\u5e94\u7528\u81ea\u5b9a\u4e49\u63d0\u793a\u6a21\u677f\uff1a"}),"\n",(0,s.jsxs)(t.A,{children:[(0,s.jsx)(i.A,{value:"sdk",label:"SDK",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import litellm\n\nimport os\nos.environ["PREDIBASE_API_KEY"] = ""\n\n# \u521b\u5efa\u60a8\u81ea\u5df1\u7684\u81ea\u5b9a\u4e49\u63d0\u793a\u6a21\u677f\nlitellm.register_prompt_template(\n    model="togethercomputer/LLaMA-2-7B-32K",\n    initial_prompt_value="You are a good assistant" # [\u53ef\u9009]\n    roles={\n        "system": {\n            "pre_message": "[INST] <<SYS>>\\n", # [\u53ef\u9009]\n            "post_message": "\\n<</SYS>>\\n [/INST]\\n" # [\u53ef\u9009]\n        },\n        "user": {\n            "pre_message": "[INST] ", # [\u53ef\u9009]\n            "post_message": " [/INST]" # [\u53ef\u9009]\n        },\n        "assistant": {\n            "pre_message": "\\n" # [\u53ef\u9009]\n            "post_message": "\\n" # [\u53ef\u9009]\n        }\n    }\n    final_prompt_value="Now answer as best you can:" # [\u53ef\u9009]\n)\n\ndef predibase_custom_model():\n    model = "predibase/togethercomputer/LLaMA-2-7B-32K"\n    response = completion(model=model, messages=messages)\n    print(response[\'choices\'][0][\'message\'][\'content\'])\n    return response\n\npredibase_custom_model()\n'})})}),(0,s.jsx)(i.A,{value:"proxy",label:"PROXY",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# \u6a21\u578b\u7279\u5b9a\u53c2\u6570\nmodel_list:\n  - model_name: mistral-7b # \u6a21\u578b\u522b\u540d\n    litellm_params: # litellm.completion() \u7684\u5b9e\u9645\u53c2\u6570\n      model: "predibase/mistralai/Mistral-7B-Instruct-v0.1"\n      api_key: os.environ/PREDIBASE_API_KEY\n      initial_prompt_value: "\\n"\n      roles: {"system":{"pre_message":"<|im_start|>system\\n", "post_message":"<|im_end|>"}, "assistant":{"pre_message":"<|im_start|>assistant\\n","post_message":"<|im_end|>"}, "user":{"pre_message":"<|im_start|>user\\n","post_message":"<|im_end|>"}}\n      final_prompt_value: "\\n"\n      bos_token: "<s>"\n      eos_token: "</s>"\n      max_tokens: 4096\n'})})})]}),"\n",(0,s.jsx)(n.h2,{id:"\u4f20\u9012\u989d\u5916\u53c2\u6570---max_tokenstemperature",children:"\u4f20\u9012\u989d\u5916\u53c2\u6570 - max_tokens\u3001temperature"}),"\n",(0,s.jsxs)(n.p,{children:["\u5728\u6b64\u67e5\u770b\u6240\u6709 litellm.completion \u652f\u6301\u7684\u53c2\u6570",(0,s.jsx)(n.a,{href:"https://docs.litellm.ai/docs/completion/input",children:"\u6b64\u5904"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# !pip install litellm\nfrom litellm import completion\nimport os\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["PREDIBASE_API_KEY"] = "predibase key"\n\n# predibase llama-3 \u8c03\u7528\nresponse = completion(\n    model="predibase/llama3-8b-instruct",\n    messages = [{ "content": "\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f","role": "user"}],\n    max_tokens=20,\n    temperature=0.5\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"\u4ee3\u7406"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"  model_list:\n    - model_name: llama-3\n      litellm_params:\n        model: predibase/llama-3-8b-instruct\n        api_key: os.environ/PREDIBASE_API_KEY\n        max_tokens: 20\n        temperature: 0.5\n"})}),"\n",(0,s.jsx)(n.h2,{id:"\u4f20\u9012-predibase-\u7279\u5b9a\u53c2\u6570---adapter_idadapter_source",children:"\u4f20\u9012 Predibase \u7279\u5b9a\u53c2\u6570 - adapter_id\u3001adapter_source"}),"\n",(0,s.jsxs)(n.p,{children:["\u53d1\u9001 ",(0,s.jsx)(n.a,{href:"https://docs.litellm.ai/docs/completion/input",children:(0,s.jsx)(n.code,{children:"litellm.completion()"})})," \u4e0d\u652f\u6301\u4f46 Predibase \u652f\u6301\u7684\u53c2\u6570\uff0c\u901a\u8fc7\u5c06\u5b83\u4eec\u4f20\u9012\u7ed9 ",(0,s.jsx)(n.code,{children:"litellm.completion"})]}),"\n",(0,s.jsxs)(n.p,{children:["\u793a\u4f8b ",(0,s.jsx)(n.code,{children:"adapter_id"}),"\u3001",(0,s.jsx)(n.code,{children:"adapter_source"})," \u662f Predibase \u7279\u5b9a\u53c2\u6570 - ",(0,s.jsx)(n.a,{href:"https://github.com/BerriAI/litellm/blob/8a35354dd6dbf4c2fcefcd6e877b980fcbd68c58/litellm/llms/predibase.py#L54",children:"\u67e5\u770b\u5217\u8868"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# !pip install litellm\nfrom litellm import completion\nimport os\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["PREDIBASE_API_KEY"] = "predibase key"\n\n# predibase llama3 \u8c03\u7528\nresponse = completion(\n    model="predibase/llama-3-8b-instruct",\n    messages = [{ "content": "\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f","role": "user"}],\n    adapter_id="my_repo/3",\n    adapter_source="pbase",\n)\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"\u4ee3\u7406"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"  model_list:\n    - model_name: llama-3\n      litellm_params:\n        model: predibase/llama-3-8b-instruct\n        api_key: os.environ/PREDIBASE_API_KEY\n        adapter_id: my_repo/3\n        adapter_source: pbase\n"})})]})}function m(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},28453(e,n,r){r.d(n,{R:()=>t,x:()=>i});var a=r(96540);const s={},l=a.createContext(s);function t(e){const n=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),a.createElement(l.Provider,{value:n},e.children)}},49489(e,n,r){r.d(n,{A:()=>A});var a=r(96540),s=r(18215),l=r(24245),t=r(56347),i=r(36494),o=r(62814),c=r(45167),d=r(69900);function u(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:r}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:r,default:a}})=>({value:e,label:n,attributes:r,default:a}))}(r);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,r])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const r=(0,t.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(s),(0,a.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(r.location.search);n.set(s,e),r.replace({...r.location,search:n.toString()})},[s,r])]}function b(e){const{defaultValue:n,queryString:r=!1,groupId:s}=e,l=p(e),[t,o]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=n.find(e=>e.default)??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:l})),[c,u]=h({queryString:r,groupId:s}),[b,_]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[r,s]=(0,d.Dv)(n);return[r,(0,a.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),x=(()=>{const e=c??b;return m({value:e,tabValues:l})?e:null})();(0,i.A)(()=>{x&&o(x)},[x]);return{selectedValue:t,selectValue:(0,a.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),_(e)},[u,_,l]),tabValues:l}}var _=r(11062);const x="tabList__CuJ",g="tabItem_LNqP";var f=r(74848);function v({className:e,block:n,selectedValue:r,selectValue:a,tabValues:t}){const i=[],{blockElementScrollPositionUntilNextRender:o}=(0,l.a_)(),c=e=>{const n=e.currentTarget,s=i.indexOf(n),l=t[s].value;l!==r&&(o(n),a(l))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const r=i.indexOf(e.currentTarget)+1;n=i[r]??i[0];break}case"ArrowLeft":{const r=i.indexOf(e.currentTarget)-1;n=i[r]??i[i.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:t.map(({value:e,label:n,attributes:a})=>(0,f.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:e=>{i.push(e)},onKeyDown:d,onClick:c,...a,className:(0,s.A)("tabs__item",g,a?.className,{"tabs__item--active":r===e}),children:n??e},e))})}function j({lazy:e,children:n,selectedValue:r}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===r);return e?(0,a.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==r}))})}function y(e){const n=b(e);return(0,f.jsxs)("div",{className:(0,s.A)("tabs-container",x),children:[(0,f.jsx)(v,{...n,...e}),(0,f.jsx)(j,{...n,...e})]})}function A(e){const n=(0,_.A)();return(0,f.jsx)(y,{...e,children:u(e.children)},String(n))}}}]);