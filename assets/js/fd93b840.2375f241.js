"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[49279],{28453(n,e,t){t.d(e,{R:()=>s,x:()=>r});var o=t(96540);const i={},l=o.createContext(i);function s(n){const e=o.useContext(l);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),o.createElement(l.Provider,{value:e},n.children)}},58817(n,e,t){t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>a});const o=JSON.parse('{"id":"completion/function_call","title":"\u51fd\u6570\u8c03\u7528","description":"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u51fd\u6570\u8c03\u7528","source":"@site/docs/completion/function_call.md","sourceDirName":"completion","slug":"/completion/function_call","permalink":"/docs/completion/function_call","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Web Fetch","permalink":"/docs/completion/web_fetch"},"next":{"title":"\u4f7f\u7528\u97f3\u9891\u6a21\u578b","permalink":"/docs/completion/audio"}}');var i=t(74848),l=t(28453);const s={},r="\u51fd\u6570\u8c03\u7528",c={},a=[{value:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u51fd\u6570\u8c03\u7528",id:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u51fd\u6570\u8c03\u7528",level:2},{value:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u5e76\u884c\u51fd\u6570\u8c03\u7528",id:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u5e76\u884c\u51fd\u6570\u8c03\u7528",level:2},{value:"\u5e76\u884c\u51fd\u6570\u8c03\u7528",id:"\u5e76\u884c\u51fd\u6570\u8c03\u7528",level:2},{value:"\u5feb\u901f\u5f00\u59cb - gpt-3.5-turbo-1106",id:"\u5feb\u901f\u5f00\u59cb---gpt-35-turbo-1106",level:2},{value:"\u5b8c\u6574\u4ee3\u7801 - \u4f7f\u7528 <code>gpt-3.5-turbo-1106</code> \u7684\u5e76\u884c\u51fd\u6570\u8c03\u7528",id:"\u5b8c\u6574\u4ee3\u7801---\u4f7f\u7528-gpt-35-turbo-1106-\u7684\u5e76\u884c\u51fd\u6570\u8c03\u7528",level:3},{value:"\u8bf4\u660e - \u5e76\u884c\u51fd\u6570\u8c03\u7528",id:"\u8bf4\u660e---\u5e76\u884c\u51fd\u6570\u8c03\u7528",level:3},{value:"\u6b65\u9aa4 1\uff1a\u5c06 <code>tools</code> \u8bbe\u7f6e\u4e3a <code>get_current_weather</code> \u7684 litellm.completion()",id:"\u6b65\u9aa4-1\u5c06-tools-\u8bbe\u7f6e\u4e3a-get_current_weather-\u7684-litellmcompletion",level:3},{value:"\u9884\u671f\u8f93\u51fa",id:"\u9884\u671f\u8f93\u51fa",level:5},{value:"\u6b65\u9aa4 2 - \u89e3\u6790\u6a21\u578b\u54cd\u5e94\u5e76\u6267\u884c\u51fd\u6570",id:"\u6b65\u9aa4-2---\u89e3\u6790\u6a21\u578b\u54cd\u5e94\u5e76\u6267\u884c\u51fd\u6570",level:3},{value:"\u6b65\u9aa4 3 - \u7b2c\u4e8c\u6b21 litellm.completion() \u8c03\u7528",id:"\u6b65\u9aa4-3---\u7b2c\u4e8c\u6b21-litellmcompletion-\u8c03\u7528",level:3},{value:"\u9884\u671f\u8f93\u51fa",id:"\u9884\u671f\u8f93\u51fa-1",level:4},{value:"\u5e76\u884c\u51fd\u6570\u8c03\u7528 - Azure OpenAI",id:"\u5e76\u884c\u51fd\u6570\u8c03\u7528---azure-openai",level:2},{value:"\u5df2\u5f03\u7528 - \u4f7f\u7528 <code>completion(functions=functions)</code> \u8fdb\u884c\u51fd\u6570\u8c03\u7528",id:"\u5df2\u5f03\u7528---\u4f7f\u7528-completionfunctionsfunctions-\u8fdb\u884c\u51fd\u6570\u8c03\u7528",level:2},{value:"litellm.function_to_dict - \u5c06\u51fd\u6570\u8f6c\u6362\u4e3a\u5b57\u5178\u4ee5\u8fdb\u884c OpenAI \u51fd\u6570\u8c03\u7528",id:"litellmfunction_to_dict---\u5c06\u51fd\u6570\u8f6c\u6362\u4e3a\u5b57\u5178\u4ee5\u8fdb\u884c-openai-\u51fd\u6570\u8c03\u7528",level:2},{value:"\u4f7f\u7528 <code>function_to_dict</code>",id:"\u4f7f\u7528-function_to_dict",level:3},{value:"function_to_dict \u7684\u8f93\u51fa",id:"function_to_dict-\u7684\u8f93\u51fa",level:4},{value:"\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u4f7f\u7528 function_to_dict",id:"\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u4f7f\u7528-function_to_dict",level:3},{value:"\u4e0d\u652f\u6301\u51fd\u6570\u8c03\u7528\u7684\u6a21\u578b\u7684\u51fd\u6570\u8c03\u7528",id:"\u4e0d\u652f\u6301\u51fd\u6570\u8c03\u7528\u7684\u6a21\u578b\u7684\u51fd\u6570\u8c03\u7528",level:2},{value:"\u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a",id:"\u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a",level:3},{value:"\u7528\u6cd5",id:"\u7528\u6cd5",level:4}];function u(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"\u51fd\u6570\u8c03\u7528",children:"\u51fd\u6570\u8c03\u7528"})}),"\n",(0,i.jsx)(e.h2,{id:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u51fd\u6570\u8c03\u7528",children:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsxs)(e.p,{children:["\u4f7f\u7528 ",(0,i.jsx)(e.code,{children:'litellm.supports_function_calling(model="")'})," -> \u5982\u679c\u6a21\u578b\u652f\u6301\u51fd\u6570\u8c03\u7528\u5219\u8fd4\u56de ",(0,i.jsx)(e.code,{children:"True"}),"\uff0c\u5426\u5219\u8fd4\u56de ",(0,i.jsx)(e.code,{children:"False"})]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'assert litellm.supports_function_calling(model="gpt-3.5-turbo") == True\nassert litellm.supports_function_calling(model="azure/gpt-4-1106-preview") == True\nassert litellm.supports_function_calling(model="palm/chat-bison") == False\nassert litellm.supports_function_calling(model="xai/grok-2-latest") == True\nassert litellm.supports_function_calling(model="ollama/llama2") == False\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u5e76\u884c\u51fd\u6570\u8c03\u7528",children:"\u68c0\u67e5\u6a21\u578b\u662f\u5426\u652f\u6301\u5e76\u884c\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsxs)(e.p,{children:["\u4f7f\u7528 ",(0,i.jsx)(e.code,{children:'litellm.supports_parallel_function_calling(model="")'})," -> \u5982\u679c\u6a21\u578b\u652f\u6301\u5e76\u884c\u51fd\u6570\u8c03\u7528\u5219\u8fd4\u56de ",(0,i.jsx)(e.code,{children:"True"}),"\uff0c\u5426\u5219\u8fd4\u56de ",(0,i.jsx)(e.code,{children:"False"})]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'assert litellm.supports_parallel_function_calling(model="gpt-4-turbo-preview") == True\nassert litellm.supports_parallel_function_calling(model="gpt-4") == False\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u5e76\u884c\u51fd\u6570\u8c03\u7528",children:"\u5e76\u884c\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsx)(e.p,{children:"\u5e76\u884c\u51fd\u6570\u8c03\u7528\u662f\u6a21\u578b\u540c\u65f6\u6267\u884c\u591a\u4e2a\u51fd\u6570\u8c03\u7528\u7684\u80fd\u529b\uff0c\u5141\u8bb8\u8fd9\u4e9b\u51fd\u6570\u8c03\u7528\u7684\u6548\u679c\u548c\u7ed3\u679c\u5e76\u884c\u89e3\u51b3"}),"\n",(0,i.jsx)(e.h2,{id:"\u5feb\u901f\u5f00\u59cb---gpt-35-turbo-1106",children:"\u5feb\u901f\u5f00\u59cb - gpt-3.5-turbo-1106"}),"\n",(0,i.jsx)("a",{target:"_blank",href:"https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/Parallel_function_calling.ipynb",children:(0,i.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,i.jsxs)(e.p,{children:["\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u51fd\u6570 ",(0,i.jsx)(e.code,{children:"get_current_weather"}),"\u3002"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["\u6b65\u9aa4 1\uff1a\u5411\u6a21\u578b\u53d1\u9001 ",(0,i.jsx)(e.code,{children:"get_current_weather"})," \u51fd\u6570\u548c\u7528\u6237\u95ee\u9898"]}),"\n",(0,i.jsxs)(e.li,{children:["\u6b65\u9aa4 2\uff1a\u89e3\u6790\u6a21\u578b\u54cd\u5e94\u7684\u8f93\u51fa - \u4f7f\u7528\u6a21\u578b\u63d0\u4f9b\u7684\u53c2\u6570\u6267\u884c ",(0,i.jsx)(e.code,{children:"get_current_weather"})]}),"\n",(0,i.jsxs)(e.li,{children:["\u6b65\u9aa4 3\uff1a\u5411\u6a21\u578b\u53d1\u9001\u8fd0\u884c ",(0,i.jsx)(e.code,{children:"get_current_weather"})," \u51fd\u6570\u7684\u8f93\u51fa"]}),"\n"]}),"\n",(0,i.jsxs)(e.h3,{id:"\u5b8c\u6574\u4ee3\u7801---\u4f7f\u7528-gpt-35-turbo-1106-\u7684\u5e76\u884c\u51fd\u6570\u8c03\u7528",children:["\u5b8c\u6574\u4ee3\u7801 - \u4f7f\u7528 ",(0,i.jsx)(e.code,{children:"gpt-3.5-turbo-1106"})," \u7684\u5e76\u884c\u51fd\u6570\u8c03\u7528"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import litellm\nimport json\n# \u8bbe\u7f6e openai api key\nimport os\nos.environ[\'OPENAI_API_KEY\'] = "" # litellm \u4ece .env \u8bfb\u53d6 OPENAI_API_KEY \u5e76\u53d1\u9001\u8bf7\u6c42\n\n# \u793a\u4f8b\u865a\u62df\u51fd\u6570\uff0c\u786c\u7f16\u7801\u4ee5\u8fd4\u56de\u76f8\u540c\u7684\u5929\u6c14\n# \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u8fd9\u53ef\u80fd\u662f\u60a8\u7684\u540e\u7aef API \u6216\u5916\u90e8 API\ndef get_current_weather(location, unit="fahrenheit"):\n    """\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14"""\n    if "tokyo" in location.lower():\n        return json.dumps({"location": "Tokyo", "temperature": "10", "unit": "celsius"})\n    elif "san francisco" in location.lower():\n        return json.dumps({"location": "San Francisco", "temperature": "72", "unit": "fahrenheit"})\n    elif "paris" in location.lower():\n        return json.dumps({"location": "Paris", "temperature": "22", "unit": "celsius"})\n    else:\n        return json.dumps({"location": location, "temperature": "unknown"})\n\n\ndef test_parallel_function_call():\n    try:\n        # \u6b65\u9aa4 1\uff1a\u5411\u6a21\u578b\u53d1\u9001\u5bf9\u8bdd\u548c\u53ef\u7528\u51fd\u6570\n        messages = [{"role": "user", "content": "What\'s the weather like in San Francisco, Tokyo, and Paris?"}]\n        tools = [\n            {\n                "type": "function",\n                "function": {\n                    "name": "get_current_weather",\n                    "description": "Get the current weather in a given location",\n                    "parameters": {\n                        "type": "object",\n                        "properties": {\n                            "location": {\n                                "type": "string",\n                                "description": "The city and state, e.g. San Francisco, CA",\n                            },\n                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},\n                        },\n                        "required": ["location"],\n                    },\n                },\n            }\n        ]\n        response = litellm.completion(\n            model="gpt-3.5-turbo-1106",\n            messages=messages,\n            tools=tools,\n            tool_choice="auto",  # auto \u662f\u9ed8\u8ba4\u503c\uff0c\u4f46\u6211\u4eec\u4f1a\u660e\u786e\u6307\u5b9a\n        )\n        print("\\nFirst LLM Response:\\n", response)\n        response_message = response.choices[0].message\n        tool_calls = response_message.tool_calls\n\n        print("\\nLength of tool calls", len(tool_calls))\n\n        # \u6b65\u9aa4 2\uff1a\u68c0\u67e5\u6a21\u578b\u662f\u5426\u60f3\u8981\u8c03\u7528\u51fd\u6570\n        if tool_calls:\n            # \u6b65\u9aa4 3\uff1a\u8c03\u7528\u51fd\u6570\n            # \u6ce8\u610f\uff1aJSON \u54cd\u5e94\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u6709\u6548\uff1b\u786e\u4fdd\u5904\u7406\u9519\u8bef\n            available_functions = {\n                "get_current_weather": get_current_weather,\n            }  # \u6b64\u793a\u4f8b\u4e2d\u53ea\u6709\u4e00\u4e2a\u51fd\u6570\uff0c\u4f46\u60a8\u53ef\u4ee5\u6709\u591a\u4e2a\n            messages.append(response_message)  # \u7528\u52a9\u624b\u7684\u56de\u590d\u6269\u5c55\u5bf9\u8bdd\n\n            # \u6b65\u9aa4 4\uff1a\u5411\u6a21\u578b\u53d1\u9001\u6bcf\u4e2a\u51fd\u6570\u8c03\u7528\u7684\u4fe1\u606f\u548c\u51fd\u6570\u54cd\u5e94\n            for tool_call in tool_calls:\n                function_name = tool_call.function.name\n                function_to_call = available_functions[function_name]\n                function_args = json.loads(tool_call.function.arguments)\n                function_response = function_to_call(\n                    location=function_args.get("location"),\n                    unit=function_args.get("unit"),\n                )\n                messages.append(\n                    {\n                        "tool_call_id": tool_call.id,\n                        "role": "tool",\n                        "name": function_name,\n                        "content": function_response,\n                    }\n                )  # \u7528\u51fd\u6570\u54cd\u5e94\u6269\u5c55\u5bf9\u8bdd\n            second_response = litellm.completion(\n                model="gpt-3.5-turbo-1106",\n                messages=messages,\n            )  # \u4ece\u6a21\u578b\u83b7\u53d6\u65b0\u54cd\u5e94\uff0c\u4f7f\u5176\u53ef\u4ee5\u770b\u5230\u51fd\u6570\u54cd\u5e94\n            print("\\nSecond LLM response:\\n", second_response)\n            return second_response\n    except Exception as e:\n      print(f"Error occurred: {e}")\n\ntest_parallel_function_call()\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u8bf4\u660e---\u5e76\u884c\u51fd\u6570\u8c03\u7528",children:"\u8bf4\u660e - \u5e76\u884c\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsxs)(e.p,{children:["\u4ee5\u4e0b\u662f\u4e0a\u8ff0\u4f7f\u7528 ",(0,i.jsx)(e.code,{children:"gpt-3.5-turbo-1106"})," \u8fdb\u884c\u5e76\u884c\u51fd\u6570\u8c03\u7528\u7684\u4ee3\u7801\u7247\u6bb5\u4e2d\u53d1\u751f\u7684\u60c5\u51b5\u7684\u8bf4\u660e"]}),"\n",(0,i.jsxs)(e.h3,{id:"\u6b65\u9aa4-1\u5c06-tools-\u8bbe\u7f6e\u4e3a-get_current_weather-\u7684-litellmcompletion",children:["\u6b65\u9aa4 1\uff1a\u5c06 ",(0,i.jsx)(e.code,{children:"tools"})," \u8bbe\u7f6e\u4e3a ",(0,i.jsx)(e.code,{children:"get_current_weather"})," \u7684 litellm.completion()"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import litellm\nimport json\n# \u8bbe\u7f6e openai api key\nimport os\nos.environ[\'OPENAI_API_KEY\'] = "" # litellm \u4ece .env \u8bfb\u53d6 OPENAI_API_KEY \u5e76\u53d1\u9001\u8bf7\u6c42\n# \u793a\u4f8b\u865a\u62df\u51fd\u6570\uff0c\u786c\u7f16\u7801\u4ee5\u8fd4\u56de\u76f8\u540c\u7684\u5929\u6c14\n# \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u8fd9\u53ef\u80fd\u662f\u60a8\u7684\u540e\u7aef API \u6216\u5916\u90e8 API\ndef get_current_weather(location, unit="fahrenheit"):\n    """\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14"""\n    if "tokyo" in location.lower():\n        return json.dumps({"location": "Tokyo", "temperature": "10", "unit": "celsius"})\n    elif "san francisco" in location.lower():\n        return json.dumps({"location": "San Francisco", "temperature": "72", "unit": "fahrenheit"})\n    elif "paris" in location.lower():\n        return json.dumps({"location": "Paris", "temperature": "22", "unit": "celsius"})\n    else:\n        return json.dumps({"location": location, "temperature": "unknown"})\n\nmessages = [{"role": "user", "content": "What\'s the weather like in San Francisco, Tokyo, and Paris?"}]\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_current_weather",\n            "description": "Get the current weather in a given location",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "The city and state, e.g. San Francisco, CA",\n                    },\n                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},\n                },\n                "required": ["location"],\n            },\n        },\n    }\n]\n\nresponse = litellm.completion(\n    model="gpt-3.5-turbo-1106",\n    messages=messages,\n    tools=tools,\n    tool_choice="auto",  # auto \u662f\u9ed8\u8ba4\u503c\uff0c\u4f46\u6211\u4eec\u4f1a\u660e\u786e\u6307\u5b9a\n)\nprint("\\nLLM Response1:\\n", response)\nresponse_message = response.choices[0].message\ntool_calls = response.choices[0].message.tool_calls\n'})}),"\n",(0,i.jsx)(e.h5,{id:"\u9884\u671f\u8f93\u51fa",children:"\u9884\u671f\u8f93\u51fa"}),"\n",(0,i.jsx)(e.p,{children:"\u5728\u8f93\u51fa\u4e2d\uff0c\u60a8\u53ef\u4ee5\u770b\u5230\u6a21\u578b\u591a\u6b21\u8c03\u7528\u8be5\u51fd\u6570 - \u7528\u4e8e San Francisco\u3001Tokyo\u3001Paris"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-json",children:"ModelResponse(\n  id='chatcmpl-8MHBKZ9t6bXuhBvUMzoKsfmmlv7xq',\n  choices=[\n    Choices(finish_reason='tool_calls',\n    index=0,\n    message=Message(content=None, role='assistant',\n      tool_calls=[\n        ChatCompletionMessageToolCall(id='call_DN6IiLULWZw7sobV6puCji1O', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n\n        ChatCompletionMessageToolCall(id='call_ERm1JfYO9AFo2oEWRmWUd40c', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n\n        ChatCompletionMessageToolCall(id='call_2lvUVB1y4wKunSxTenR0zClP', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n        ]))\n    ],\n    created=1700319953,\n    model='gpt-3.5-turbo-1106',\n    object='chat.completion',\n    system_fingerprint='fp_eeff13170a',\n    usage={'completion_tokens': 77, 'prompt_tokens': 88, 'total_tokens': 165},\n    _response_ms=1177.372\n)\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u6b65\u9aa4-2---\u89e3\u6790\u6a21\u578b\u54cd\u5e94\u5e76\u6267\u884c\u51fd\u6570",children:"\u6b65\u9aa4 2 - \u89e3\u6790\u6a21\u578b\u54cd\u5e94\u5e76\u6267\u884c\u51fd\u6570"}),"\n",(0,i.jsx)(e.p,{children:"\u53d1\u9001\u521d\u59cb\u8bf7\u6c42\u540e\uff0c\u89e3\u6790\u6a21\u578b\u54cd\u5e94\u4ee5\u8bc6\u522b\u5b83\u60f3\u8981\u8fdb\u884c\u7684\u51fd\u6570\u8c03\u7528\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u671f\u671b\u4e09\u4e2a\u5de5\u5177\u8c03\u7528\uff0c\u6bcf\u4e2a\u5bf9\u5e94\u4e00\u4e2a\u4f4d\u7f6e\uff08San Francisco\u3001Tokyo \u548c Paris\uff09\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# \u68c0\u67e5\u6a21\u578b\u662f\u5426\u60f3\u8981\u8c03\u7528\u51fd\u6570\nif tool_calls:\n    # \u6267\u884c\u51fd\u6570\u5e76\u51c6\u5907\u54cd\u5e94\n    available_functions = {\n        "get_current_weather": get_current_weather,\n    }\n\n    messages.append(response_message)  # \u7528\u52a9\u624b\u7684\u56de\u590d\u6269\u5c55\u5bf9\u8bdd\n\n    for tool_call in tool_calls:\n      print(f"\\nExecuting tool call\\n{tool_call}")\n      function_name = tool_call.function.name\n      function_to_call = available_functions[function_name]\n      function_args = json.loads(tool_call.function.arguments)\n      # \u8c03\u7528 get_current_weather() \u51fd\u6570\n      function_response = function_to_call(\n          location=function_args.get("location"),\n          unit=function_args.get("unit"),\n      )\n      print(f"Result from tool call\\n{function_response}\\n")\n\n      # \u7528\u51fd\u6570\u54cd\u5e94\u6269\u5c55\u5bf9\u8bdd\n      messages.append(\n          {\n              "tool_call_id": tool_call.id,\n              "role": "tool",\n              "name": function_name,\n              "content": function_response,\n          }\n      )\n\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u6b65\u9aa4-3---\u7b2c\u4e8c\u6b21-litellmcompletion-\u8c03\u7528",children:"\u6b65\u9aa4 3 - \u7b2c\u4e8c\u6b21 litellm.completion() \u8c03\u7528"}),"\n",(0,i.jsx)(e.p,{children:"\u51fd\u6570\u6267\u884c\u540e\uff0c\u5411\u6a21\u578b\u53d1\u9001\u6bcf\u4e2a\u51fd\u6570\u8c03\u7528\u53ca\u5176\u54cd\u5e94\u7684\u4fe1\u606f\u3002\u8fd9\u5141\u8bb8\u6a21\u578b\u5728\u8003\u8651\u51fd\u6570\u8c03\u7528\u6548\u679c\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u65b0\u54cd\u5e94\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'second_response = litellm.completion(\n    model="gpt-3.5-turbo-1106",\n    messages=messages,\n)\nprint("Second Response\\n", second_response)\n'})}),"\n",(0,i.jsx)(e.h4,{id:"\u9884\u671f\u8f93\u51fa-1",children:"\u9884\u671f\u8f93\u51fa"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-json",children:"ModelResponse(\n  id='chatcmpl-8MHBLh1ldADBP71OrifKap6YfAd4w',\n  choices=[\n    Choices(finish_reason='stop', index=0,\n    message=Message(content=\"The current weather in San Francisco is 72\xb0F, in Tokyo it's 10\xb0C, and in Paris it's 22\xb0C.\", role='assistant'))\n  ],\n  created=1700319955,\n  model='gpt-3.5-turbo-1106',\n  object='chat.completion',\n  system_fingerprint='fp_eeff13170a',\n  usage={'completion_tokens': 28, 'prompt_tokens': 169, 'total_tokens': 197},\n  _response_ms=1032.431\n)\n"})}),"\n",(0,i.jsx)(e.h2,{id:"\u5e76\u884c\u51fd\u6570\u8c03\u7528---azure-openai",children:"\u5e76\u884c\u51fd\u6570\u8c03\u7528 - Azure OpenAI"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# \u8bbe\u7f6e Azure \u73af\u5883\u53d8\u91cf\nimport os\nos.environ[\'AZURE_API_KEY\'] = "" # litellm \u4ece .env \u8bfb\u53d6 AZURE_API_KEY \u5e76\u53d1\u9001\u8bf7\u6c42\nos.environ[\'AZURE_API_BASE\'] = "https://openai-gpt-4-test-v-1.openai.azure.com/"\nos.environ[\'AZURE_API_VERSION\'] = "2023-07-01-preview"\n\nimport litellm\nimport json\n# \u793a\u4f8b\u865a\u62df\u51fd\u6570\uff0c\u786c\u7f16\u7801\u4ee5\u8fd4\u56de\u76f8\u540c\u7684\u5929\u6c14\n# \u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u8fd9\u53ef\u80fd\u662f\u60a8\u7684\u540e\u7aef API \u6216\u5916\u90e8 API\ndef get_current_weather(location, unit="fahrenheit"):\n    """\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14"""\n    if "tokyo" in location.lower():\n        return json.dumps({"location": "Tokyo", "temperature": "10", "unit": "celsius"})\n    elif "san francisco" in location.lower():\n        return json.dumps({"location": "San Francisco", "temperature": "72", "unit": "fahrenheit"})\n    elif "paris" in location.lower():\n        return json.dumps({"location": "Paris", "temperature": "22", "unit": "celsius"})\n    else:\n        return json.dumps({"location": location, "temperature": "unknown"})\n\n## \u6b65\u9aa4 1\uff1a\u5411\u6a21\u578b\u53d1\u9001\u5bf9\u8bdd\u548c\u53ef\u7528\u51fd\u6570\nmessages = [{"role": "user", "content": "What\'s the weather like in San Francisco, Tokyo, and Paris?"}]\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_current_weather",\n            "description": "Get the current weather in a given location",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "The city and state, e.g. San Francisco, CA",\n                    },\n                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},\n                },\n                "required": ["location"],\n            },\n        },\n    }\n]\n\nresponse = litellm.completion(\n    model="azure/chatgpt-functioncalling", # model = azure/<your-azure-deployment-name>\n    messages=messages,\n    tools=tools,\n    tool_choice="auto",  # auto \u662f\u9ed8\u8ba4\u503c\uff0c\u4f46\u6211\u4eec\u4f1a\u660e\u786e\u6307\u5b9a\n)\nprint("\\nLLM Response1:\\n", response)\nresponse_message = response.choices[0].message\ntool_calls = response.choices[0].message.tool_calls\nprint("\\nTool Choice:\\n", tool_calls)\n\n## \u6b65\u9aa4 2 - \u89e3\u6790\u6a21\u578b\u54cd\u5e94\u5e76\u6267\u884c\u51fd\u6570\n# \u68c0\u67e5\u6a21\u578b\u662f\u5426\u60f3\u8981\u8c03\u7528\u51fd\u6570\nif tool_calls:\n    # \u6267\u884c\u51fd\u6570\u5e76\u51c6\u5907\u54cd\u5e94\n    available_functions = {\n        "get_current_weather": get_current_weather,\n    }\n\n    messages.append(response_message)  # \u7528\u52a9\u624b\u7684\u56de\u590d\u6269\u5c55\u5bf9\u8bdd\n\n    for tool_call in tool_calls:\n      print(f"\\nExecuting tool call\\n{tool_call}")\n      function_name = tool_call.function.name\n      function_to_call = available_functions[function_name]\n      function_args = json.loads(tool_call.function.arguments)\n      # \u8c03\u7528 get_current_weather() \u51fd\u6570\n      function_response = function_to_call(\n          location=function_args.get("location"),\n          unit=function_args.get("unit"),\n      )\n      print(f"Result from tool call\\n{function_response}\\n")\n\n      # \u7528\u51fd\u6570\u54cd\u5e94\u6269\u5c55\u5bf9\u8bdd\n      messages.append(\n          {\n              "tool_call_id": tool_call.id,\n              "role": "tool",\n              "name": function_name,\n              "content": function_response,\n          }\n      )\n\n## \u6b65\u9aa4 3 - \u7b2c\u4e8c\u6b21 litellm.completion() \u8c03\u7528\nsecond_response = litellm.completion(\n    model="azure/chatgpt-functioncalling",\n    messages=messages,\n)\nprint("Second Response\\n", second_response)\nprint("Second Response Message\\n", second_response.choices[0].message.content)\n\n'})}),"\n",(0,i.jsxs)(e.h2,{id:"\u5df2\u5f03\u7528---\u4f7f\u7528-completionfunctionsfunctions-\u8fdb\u884c\u51fd\u6570\u8c03\u7528",children:["\u5df2\u5f03\u7528 - \u4f7f\u7528 ",(0,i.jsx)(e.code,{children:"completion(functions=functions)"})," \u8fdb\u884c\u51fd\u6570\u8c03\u7528"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import os, litellm\nfrom litellm import completion\n\nos.environ[\'OPENAI_API_KEY\'] = ""\n\nmessages = [\n    {"role": "user", "content": "What is the weather like in Boston?"}\n]\n\n# \u5c06\u88ab\u6267\u884c\u7684 python \u51fd\u6570\ndef get_current_weather(location):\n  if location == "Boston, MA":\n    return "The weather is 12F"\n\n# \u4f20\u9012\u7ed9 OpenAI \u7684 JSON Schema\nfunctions = [\n    {\n      "name": "get_current_weather",\n      "description": "Get the current weather in a given location",\n      "parameters": {\n        "type": "object",\n        "properties": {\n          "location": {\n            "type": "string",\n            "description": "The city and state, e.g. San Francisco, CA"\n          },\n          "unit": {\n            "type": "string",\n            "enum": ["celsius", "fahrenheit"]\n          }\n        },\n        "required": ["location"]\n      }\n    }\n  ]\n\nresponse = completion(model="gpt-3.5-turbo-0613", messages=messages, functions=functions)\nprint(response)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"litellmfunction_to_dict---\u5c06\u51fd\u6570\u8f6c\u6362\u4e3a\u5b57\u5178\u4ee5\u8fdb\u884c-openai-\u51fd\u6570\u8c03\u7528",children:"litellm.function_to_dict - \u5c06\u51fd\u6570\u8f6c\u6362\u4e3a\u5b57\u5178\u4ee5\u8fdb\u884c OpenAI \u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.code,{children:"function_to_dict"})," \u5141\u8bb8\u60a8\u4f20\u9012\u51fd\u6570\u6587\u6863\u5b57\u7b26\u4e32\u5e76\u751f\u6210\u53ef\u7528\u4e8e OpenAI \u51fd\u6570\u8c03\u7528\u7684\u5b57\u5178"]}),"\n",(0,i.jsxs)(e.h3,{id:"\u4f7f\u7528-function_to_dict",children:["\u4f7f\u7528 ",(0,i.jsx)(e.code,{children:"function_to_dict"})]}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\u5b9a\u4e49\u60a8\u7684\u51fd\u6570 ",(0,i.jsx)(e.code,{children:"get_current_weather"})]}),"\n",(0,i.jsxs)(e.li,{children:["\u4e3a\u60a8\u7684\u51fd\u6570 ",(0,i.jsx)(e.code,{children:"get_current_weather"})," \u6dfb\u52a0\u6587\u6863\u5b57\u7b26\u4e32"]}),"\n",(0,i.jsxs)(e.li,{children:["\u5c06\u51fd\u6570\u4f20\u9012\u7ed9 ",(0,i.jsx)(e.code,{children:"litellm.utils.function_to_dict"})," \u4ee5\u83b7\u53d6\u7528\u4e8e OpenAI \u51fd\u6570\u8c03\u7528\u7684\u5b57\u5178"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# \u5e26\u6709\u6587\u6863\u5b57\u7b26\u4e32\u7684\u51fd\u6570\ndef get_current_weather(location: str, unit: str):\n        """\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14\n\n        Parameters\n        ----------\n        location : str\n            \u57ce\u5e02\u548c\u5dde\uff0c\u4f8b\u5982 San Francisco, CA\n        unit : {\'celsius\', \'fahrenheit\'}\n            \u6e29\u5ea6\u5355\u4f4d\n\n        Returns\n        -------\n        str\n            \u8868\u793a\u5929\u6c14\u7684\u53e5\u5b50\n        """\n        if location == "Boston, MA":\n            return "The weather is 12F"\n\n# \u4f7f\u7528 litellm.utils.function_to_dict \u5c06\u51fd\u6570\u8f6c\u6362\u4e3a\u5b57\u5178\nfunction_json = litellm.utils.function_to_dict(get_current_weather)\nprint(function_json)\n'})}),"\n",(0,i.jsx)(e.h4,{id:"function_to_dict-\u7684\u8f93\u51fa",children:"function_to_dict \u7684\u8f93\u51fa"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-json",children:"{\n    'name': 'get_current_weather',\n    'description': 'Get the current weather in a given location',\n    'parameters': {\n        'type': 'object',\n        'properties': {\n            'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'},\n            'unit': {'type': 'string', 'description': 'Temperature unit', 'enum': \"['fahrenheit', 'celsius']\"}\n        },\n        'required': ['location', 'unit']\n    }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u4f7f\u7528-function_to_dict",children:"\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u4f7f\u7528 function_to_dict"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import os, litellm\nfrom litellm import completion\n\nos.environ[\'OPENAI_API_KEY\'] = ""\n\nmessages = [\n    {"role": "user", "content": "What is the weather like in Boston?"}\n]\n\ndef get_current_weather(location: str, unit: str):\n    """\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14\n\n    Parameters\n    ----------\n    location : str\n        \u57ce\u5e02\u548c\u5dde\uff0c\u4f8b\u5982 San Francisco, CA\n    unit : str {\'celsius\', \'fahrenheit\'}\n        \u6e29\u5ea6\u5355\u4f4d\n\n    Returns\n    -------\n    str\n        \u8868\u793a\u5929\u6c14\u7684\u53e5\u5b50\n    """\n    if location == "Boston, MA":\n        return "The weather is 12F"\n\nfunctions = [litellm.utils.function_to_dict(get_current_weather)]\n\nresponse = completion(model="gpt-3.5-turbo-0613", messages=messages, functions=functions)\nprint(response)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u4e0d\u652f\u6301\u51fd\u6570\u8c03\u7528\u7684\u6a21\u578b\u7684\u51fd\u6570\u8c03\u7528",children:"\u4e0d\u652f\u6301\u51fd\u6570\u8c03\u7528\u7684\u6a21\u578b\u7684\u51fd\u6570\u8c03\u7528"}),"\n",(0,i.jsx)(e.h3,{id:"\u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a",children:"\u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a"}),"\n",(0,i.jsxs)(e.p,{children:["\u5bf9\u4e8e\u4e0d\u652f\u6301\u51fd\u6570\u8c03\u7528\u7684\u6a21\u578b/\u63d0\u4f9b\u5546\uff0cLiteLLM \u5141\u8bb8\u60a8\u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a\u96c6\uff1a",(0,i.jsx)(e.code,{children:"litellm.add_function_to_prompt = True"})]}),"\n",(0,i.jsx)(e.h4,{id:"\u7528\u6cd5",children:"\u7528\u6cd5"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import os, litellm\nfrom litellm import completion\n\n# \u91cd\u8981 - \u5c06\u6b64\u9879\u8bbe\u7f6e\u4e3a TRUE\uff0c\u4ee5\u4fbf\u4e3a\u975e OpenAI LLM \u5c06\u51fd\u6570\u6dfb\u52a0\u5230\u63d0\u793a\nlitellm.add_function_to_prompt = True # \u4e3a\u975e OpenAI LLM \u8bbe\u7f6e add_function_to_prompt\n\nos.environ[\'ANTHROPIC_API_KEY\'] = ""\n\nmessages = [\n    {"role": "user", "content": "What is the weather like in Boston?"}\n]\n\ndef get_current_weather(location):\n  if location == "Boston, MA":\n    return "The weather is 12F"\n\nfunctions = [\n    {\n      "name": "get_current_weather",\n      "description": "Get the current weather in a given location",\n      "parameters": {\n        "type": "object",\n        "properties": {\n          "location": {\n            "type": "string",\n            "description": "The city and state, e.g. San Francisco, CA"\n          },\n          "unit": {\n            "type": "string",\n            "enum": ["celsius", "fahrenheit"]\n          }\n        },\n        "required": ["location"]\n      }\n    }\n  ]\n\nresponse = completion(model="claude-2", messages=messages, functions=functions)\nprint(response)\n'})})]})}function p(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(u,{...n})}):u(n)}}}]);