(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[84961],{7227(e,i,l){"use strict";l.d(i,{A:()=>t});l(96540);var s=l(18215);const r="tabItem_Ymn6";var n=l(74848);function t({children:e,hidden:i,className:l}){return(0,n.jsx)("div",{role:"tabpanel",className:(0,s.A)(r,l),hidden:i,children:e})}},49489(e,i,l){"use strict";l.d(i,{A:()=>k});var s=l(96540),r=l(18215),n=l(24245),t=l(56347),a=l(36494),o=l(62814),c=l(45167),d=l(69900);function h(e){return s.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:i}=e;return!!i&&"object"==typeof i&&"value"in i}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:i,children:l}=e;return(0,s.useMemo)(()=>{const e=i??function(e){return h(e).map(({props:{value:e,label:i,attributes:l,default:s}})=>({value:e,label:i,attributes:l,default:s}))}(l);return function(e){const i=(0,c.XI)(e,(e,i)=>e.value===i.value);if(i.length>0)throw new Error(`Docusaurus error: Duplicate values "${i.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[i,l])}function p({value:e,tabValues:i}){return i.some(i=>i.value===e)}function m({queryString:e=!1,groupId:i}){const l=(0,t.W6)(),r=function({queryString:e=!1,groupId:i}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!i)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return i??null}({queryString:e,groupId:i});return[(0,o.aZ)(r),(0,s.useCallback)(e=>{if(!r)return;const i=new URLSearchParams(l.location.search);i.set(r,e),l.replace({...l.location,search:i.toString()})},[r,l])]}function g(e){const{defaultValue:i,queryString:l=!1,groupId:r}=e,n=u(e),[t,o]=(0,s.useState)(()=>function({defaultValue:e,tabValues:i}){if(0===i.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:i}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${i.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const l=i.find(e=>e.default)??i[0];if(!l)throw new Error("Unexpected error: 0 tabValues");return l.value}({defaultValue:i,tabValues:n})),[c,h]=m({queryString:l,groupId:r}),[g,x]=function({groupId:e}){const i=function(e){return e?`docusaurus.tab.${e}`:null}(e),[l,r]=(0,d.Dv)(i);return[l,(0,s.useCallback)(e=>{i&&r.set(e)},[i,r])]}({groupId:r}),j=(()=>{const e=c??g;return p({value:e,tabValues:n})?e:null})();(0,a.A)(()=>{j&&o(j)},[j]);return{selectedValue:t,selectValue:(0,s.useCallback)(e=>{if(!p({value:e,tabValues:n}))throw new Error(`Can't select invalid tab value=${e}`);o(e),h(e),x(e)},[h,x,n]),tabValues:n}}var x=l(11062);const j="tabList__CuJ",f="tabItem_LNqP";var b=l(74848);function A({className:e,block:i,selectedValue:l,selectValue:s,tabValues:t}){const a=[],{blockElementScrollPositionUntilNextRender:o}=(0,n.a_)(),c=e=>{const i=e.currentTarget,r=a.indexOf(i),n=t[r].value;n!==l&&(o(i),s(n))},d=e=>{let i=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const l=a.indexOf(e.currentTarget)+1;i=a[l]??a[0];break}case"ArrowLeft":{const l=a.indexOf(e.currentTarget)-1;i=a[l]??a[a.length-1];break}}i?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":i},e),children:t.map(({value:e,label:i,attributes:s})=>(0,b.jsx)("li",{role:"tab",tabIndex:l===e?0:-1,"aria-selected":l===e,ref:e=>{a.push(e)},onKeyDown:d,onClick:c,...s,className:(0,r.A)("tabs__item",f,s?.className,{"tabs__item--active":l===e}),children:i??e},e))})}function v({lazy:e,children:i,selectedValue:l}){const n=(Array.isArray(i)?i:[i]).filter(Boolean);if(e){const e=n.find(e=>e.props.value===l);return e?(0,s.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:n.map((e,i)=>(0,s.cloneElement)(e,{key:i,hidden:e.props.value!==l}))})}function w(e){const i=g(e);return(0,b.jsxs)("div",{className:(0,r.A)("tabs-container",j),children:[(0,b.jsx)(A,{...i,...e}),(0,b.jsx)(v,{...i,...e})]})}function k(e){const i=(0,x.A)();return(0,b.jsx)(w,{...e,children:h(e.children)},String(i))}},63603(e,i,l){"use strict";l.r(i),l.d(i,{assets:()=>h,contentTitle:()=>d,default:()=>m,frontMatter:()=>c,metadata:()=>s,toc:()=>u});var s=l(71720),r=l(74848),n=l(28453),t=l(90547),a=l(49489),o=l(7227);const c={title:"v1.68.0-stable",slug:"v1.68.0-stable",date:new Date("2025-05-03T10:00:00.000Z"),authors:[{name:"Krrish Dholakia",title:"CEO, LiteLLM",url:"https://www.linkedin.com/in/krish-d/",image_url:"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8"},{name:"Ishaan Jaffer",title:"CTO, LiteLLM",url:"https://www.linkedin.com/in/reffajnaahsi/",image_url:"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg"}],hide_table_of_contents:!1},d=void 0,h={authorsImageUrls:[void 0,void 0]},u=[{value:"Deploy this version",id:"deploy-this-version",level:2},{value:"Key Highlights",id:"key-highlights",level:2},{value:"Bedrock Knowledge Base (Vector Store)",id:"bedrock-knowledge-base-vector-store",level:2},{value:"Rate Limiting",id:"rate-limiting",level:2},{value:"New Models / Updated Models",id:"new-models--updated-models",level:2},{value:"LLM API Endpoints",id:"llm-api-endpoints",level:2},{value:"Spend Tracking / Budget Improvements",id:"spend-tracking--budget-improvements",level:2},{value:"Management Endpoints / UI",id:"management-endpoints--ui",level:2},{value:"Logging / Guardrail Integrations",id:"logging--guardrail-integrations",level:2},{value:"Performance / Loadbalancing / Reliability improvements",id:"performance--loadbalancing--reliability-improvements",level:2},{value:"General Proxy Improvements",id:"general-proxy-improvements",level:2}];function p(e){const i={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.h2,{id:"deploy-this-version",children:"Deploy this version"}),"\n",(0,r.jsxs)(a.A,{children:[(0,r.jsx)(o.A,{value:"docker",label:"Docker",children:(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-showLineNumbers",metastring:'title="docker run litellm"',children:"docker run\n-e STORE_MODEL_IN_DB=True\n-p 4000:4000\ndocker.litellm.ai/berriai/litellm:main-v1.68.0-stable\n"})})}),(0,r.jsx)(o.A,{value:"pip",label:"Pip",children:(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-showLineNumbers",metastring:'title="pip install litellm"',children:"pip install litellm==1.68.0.post1\n"})})})]}),"\n",(0,r.jsx)(i.h2,{id:"key-highlights",children:"Key Highlights"}),"\n",(0,r.jsx)(i.p,{children:"LiteLLM v1.68.0-stable will be live soon. Here are the key highlights of this release:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Bedrock Knowledge Base"}),": You can now call query your Bedrock Knowledge Base with all LiteLLM models via ",(0,r.jsx)(i.code,{children:"/chat/completion"})," or ",(0,r.jsx)(i.code,{children:"/responses"})," API."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Rate Limits"}),": This release brings accurate rate limiting across multiple instances, reducing spillover to at most 10 additional requests in high traffic."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Meta Llama API"}),": Added support for Meta Llama API ",(0,r.jsx)(i.a,{href:"https://docs.litellm.ai/docs/providers/meta_llama",children:"Get Started"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"LlamaFile"}),": Added support for LlamaFile ",(0,r.jsx)(i.a,{href:"https://docs.litellm.ai/docs/providers/llamafile",children:"Get Started"})]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"bedrock-knowledge-base-vector-store",children:"Bedrock Knowledge Base (Vector Store)"}),"\n",(0,r.jsx)(t.A,{img:l(98120)}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(i.p,{children:"This release adds support for Bedrock vector stores (knowledge bases) in LiteLLM. With this update, you can:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Use Bedrock vector stores in the OpenAI /chat/completions spec with all LiteLLM supported models."}),"\n",(0,r.jsx)(i.li,{children:"View all available vector stores through the LiteLLM UI or API."}),"\n",(0,r.jsx)(i.li,{children:"Configure vector stores to be always active for specific models."}),"\n",(0,r.jsx)(i.li,{children:"Track vector store usage in LiteLLM Logs."}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"For the next release we plan on allowing you to set key, user, team, org permissions for vector stores."}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.a,{href:"https://docs.litellm.ai/docs/completion/knowledgebase",children:"Read more here"})}),"\n",(0,r.jsx)(i.h2,{id:"rate-limiting",children:"Rate Limiting"}),"\n",(0,r.jsx)(t.A,{img:l(92958)}),"\n",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(i.p,{children:"This release brings accurate multi-instance rate limiting across keys/users/teams. Outlining key engineering changes below:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Change"}),": Instances now increment cache value instead of setting it. To avoid calling Redis on each request, this is synced every 0.01s."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Accuracy"}),": In testing, we saw a maximum spill over from expected of 10 requests, in high traffic (100 RPS, 3 instances), vs. current 189 request spillover"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Performance"}),": Our load tests show this to reduce median response time by 100ms in high traffic\xa0"]}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"This is currently behind a feature flag, and we plan to have this be the default by next week. To enable this today, just add this environment variable:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"export LITELLM_RATE_LIMIT_ACCURACY=true\n"})}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.a,{href:"../../docs/proxy/users#beta-multi-instance-rate-limiting",children:"Read more here"})}),"\n",(0,r.jsx)(i.h2,{id:"new-models--updated-models",children:"New Models / Updated Models"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsxs)(i.strong,{children:["Gemini (",(0,r.jsx)(i.a,{href:"https://docs.litellm.ai/docs/providers/vertex#usage-with-litellm-proxy-server",children:"VertexAI"})," + ",(0,r.jsx)(i.a,{href:"https://docs.litellm.ai/docs/providers/gemini",children:"Google AI Studio"}),")"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Handle more json schema - openapi schema conversion edge cases ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10351",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Tool calls - return \u2018finish_reason=\u201ctool_calls\u201d\u2019 on gemini tool calling response ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10485",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/vertex#metallama-api",children:"VertexAI"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Meta/llama-4 model support ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10492",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Meta/llama3 - handle tool call result in content ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10492",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Meta/* - return \u2018finish_reason=\u201ctool_calls\u201d\u2019 on tool calling response ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10492",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/bedrock#litellm-proxy-usage",children:"Bedrock"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/providers/bedrock#image-generation",children:"Image Generation"})," - Support new \u2018stable-image-core\u2019 models - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10351",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/completion/knowledgebase",children:"Knowledge Bases"})," - support using Bedrock knowledge bases with ",(0,r.jsx)(i.code,{children:"/chat/completions"})," ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10413",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/providers/bedrock#litellm-proxy-usage",children:"Anthropic"})," - add \u2018supports_pdf_input\u2019 for claude-3.7-bedrock models ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/9917",children:"PR"}),", ",(0,r.jsx)(i.a,{href:"../../docs/completion/document_understanding#checking-if-a-model-supports-pdf-input",children:"Get Started"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/openai",children:"OpenAI"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Support OPENAI_BASE_URL in addition to OPENAI_API_BASE ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10423",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Correctly re-raise 504 timeout errors ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10462",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Native Gpt-4o-mini-tts support ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10462",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\ud83c\udd95 ",(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/meta_llama",children:"Meta Llama API"})})," provider ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10451",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["\ud83c\udd95 ",(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/llamafile",children:"LlamaFile"})})," provider ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10482",children:"PR"})]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"llm-api-endpoints",children:"LLM API Endpoints"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/response_api",children:"Response API"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Fix for handling multi turn sessions ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10415",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/embedding/supported_embedding",children:"Embeddings"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Caching fixes - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10424",children:"PR"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"handle str -> list cache"}),"\n",(0,r.jsx)(i.li,{children:"Return usage tokens for cache hit"}),"\n",(0,r.jsx)(i.li,{children:"Combine usage tokens on partial cache hits"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\ud83c\udd95 ",(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/completion/knowledgebase",children:"Vector Stores"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Allow defining Vector Store Configs - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10448",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["New StandardLoggingPayload field for requests made when a vector store is used - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10509",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Show Vector Store / KB Request on LiteLLM Logs Page  - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10514",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Allow using vector store in OpenAI API spec with tools - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10516",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/mcp",children:"MCP"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Ensure Non-Admin virtual keys can access /mcp routes - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10473",children:"PR"})]}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Note:"})," Currently, all Virtual Keys are able to access the MCP endpoints. We are working on a feature to allow restricting MCP access by keys/teams/users/orgs. Follow ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/discussions/9891",children:"here"})," for updates."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Moderations"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Add logging callback support for ",(0,r.jsx)(i.code,{children:"/moderations"})," API - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10390",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"spend-tracking--budget-improvements",children:"Spend Tracking / Budget Improvements"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/openai",children:"OpenAI"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/providers/openai/responses_api#computer-use",children:"computer-use-preview"})," cost tracking / pricing ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10422",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/providers/openai/text_to_speech",children:"gpt-4o-mini-tts"})," input cost tracking - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10462",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/fireworks_ai",children:"Fireworks AI"})})," - pricing updates - new ",(0,r.jsx)(i.code,{children:"0-4b"})," model pricing tier + llama4 model pricing"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/proxy/users#set-budgets",children:"Budgets"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/proxy/users#reset-budgets",children:"Budget resets"})," now happen as start of day/week/month - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10333",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Trigger ",(0,r.jsx)(i.a,{href:"../../docs/proxy/alerting#soft-budget-alerts-for-virtual-keys",children:"Soft Budget Alerts"})," When Key Crosses Threshold - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10491",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/completion/token_usage#3-token_counter",children:"Token Counting"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Rewrite of token_counter() function to handle to prevent undercounting tokens - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10409",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"management-endpoints--ui",children:"Management Endpoints / UI"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Virtual Keys"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Fix filtering on key alias - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10455",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Support global filtering on keys - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10455",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Pagination - fix clicking on next/back buttons on table - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10528",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Models"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Triton - Support adding model/provider on UI - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10456",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["VertexAI - Fix adding vertex models with reusable credentials - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10528",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["LLM Credentials - show existing credentials for easy editing - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10519",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Teams"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Allow reassigning team to other org - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10527",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Organizations"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Fix showing org budget on table - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10528",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"logging--guardrail-integrations",children:"Logging / Guardrail Integrations"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/observability/langsmith_integration",children:"Langsmith"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Respect ",(0,r.jsx)(i.a,{href:"../../docs/observability/langsmith_integration#local-testing---control-batch-size",children:"langsmith_batch_size"})," param - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10411",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"performance--loadbalancing--reliability-improvements",children:"Performance / Loadbalancing / Reliability improvements"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/proxy/caching",children:"Redis"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Ensure all redis queues are periodically flushed, this fixes an issue where redis queue size was growing indefinitely when request tags were used - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10393",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/proxy/users#set-rate-limit",children:"Rate Limits"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"../../docs/proxy/users#beta-multi-instance-rate-limiting",children:"Multi-instance rate limiting"})," support across keys/teams/users/customers - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10458",children:"PR"}),", ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10497",children:"PR"}),", ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10500",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:(0,r.jsx)(i.a,{href:"../../docs/providers/azure#entra-id---use-azure_ad_token",children:"Azure OpenAI OIDC"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["allow using litellm defined params for ",(0,r.jsx)(i.a,{href:"../../docs/providers/azure#entra-id---use-azure_ad_token",children:"OIDC Auth"})," - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10394",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"general-proxy-improvements",children:"General Proxy Improvements"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Security"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Allow ",(0,r.jsx)(i.a,{href:"../../docs/proxy/enterprise#blocking-web-crawlers",children:"blocking web crawlers"})," - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10420",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Auth"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Support ",(0,r.jsxs)(i.a,{href:"../../docs/pass_through/vertex_ai#use-with-virtual-keys",children:[(0,r.jsx)(i.code,{children:"x-litellm-api-key"})," header param by default"]}),", this fixes an issue from the prior release where ",(0,r.jsx)(i.code,{children:"x-litellm-api-key"})," was not being used on vertex ai passthrough requests - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10392",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Allow key at max budget to call non-llm api endpoints - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10392",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\ud83c\udd95 ",(0,r.jsxs)(i.strong,{children:[(0,r.jsx)(i.a,{href:"../../docs/proxy/management_cli",children:"Python Client Library"})," for LiteLLM Proxy management endpoints"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Initial PR - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10445",children:"PR"})]}),"\n",(0,r.jsxs)(i.li,{children:["Support for doing HTTP requests - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10452",children:"PR"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Dependencies"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Don\u2019t require uvloop for windows - ",(0,r.jsx)(i.a,{href:"https://github.com/BerriAI/litellm/pull/10483",children:"PR"})]}),"\n"]}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:i}={...(0,n.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},71720(e){"use strict";e.exports=JSON.parse('{"permalink":"/release_notes/v1.68.0-stable","source":"@site/release_notes/v1.68.0-stable/index.md","title":"v1.68.0-stable","description":"Deploy this version","date":"2025-05-03T10:00:00.000Z","tags":[],"hasTruncateMarker":false,"authors":[{"name":"Krrish Dholakia","title":"CEO, LiteLLM","url":"https://www.linkedin.com/in/krish-d/","image_url":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","imageURL":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","socials":{},"key":null,"page":null},{"name":"Ishaan Jaffer","title":"CTO, LiteLLM","url":"https://www.linkedin.com/in/reffajnaahsi/","image_url":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","imageURL":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","socials":{},"key":null,"page":null}],"frontMatter":{"title":"v1.68.0-stable","slug":"v1.68.0-stable","date":"2025-05-03T10:00:00.000Z","authors":[{"name":"Krrish Dholakia","title":"CEO, LiteLLM","url":"https://www.linkedin.com/in/krish-d/","image_url":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","imageURL":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8"},{"name":"Ishaan Jaffer","title":"CTO, LiteLLM","url":"https://www.linkedin.com/in/reffajnaahsi/","image_url":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","imageURL":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg"}],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"v1.69.0-stable - Loadbalance Batch API Models","permalink":"/release_notes/v1.69.0-stable"},"nextItem":{"title":"v1.67.4-stable - Improved User Management","permalink":"/release_notes/v1.67.4-stable"}}')},92958(e,i,l){e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:l.p+"assets/ideal-img/multi_instance_rate_limiting.d7cae8c.640.png 640w,"+l.p+"assets/ideal-img/multi_instance_rate_limiting.06ee750.1800.png 1800w",images:[{path:l.p+"assets/ideal-img/multi_instance_rate_limiting.d7cae8c.640.png",width:640,height:335},{path:l.p+"assets/ideal-img/multi_instance_rate_limiting.06ee750.1800.png",width:1800,height:941}],src:l.p+"assets/ideal-img/multi_instance_rate_limiting.d7cae8c.640.png",placeholder:void 0,width:640,height:335}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAABCcAAAQnAEmzTo0AAAAgklEQVR4nD2OzQ6EIAyEff93dFVuHkCQVkQ036Zs1sOknWZ+OvgQCCEQY2TbtneqKq01ruvqGJxzjOPIZ5pYlgXj0zyzriu1VkopP+F9352c5USPg1oKTYQswr7vPdkMg6ljSqSUEFU0RrJzZFVEhMPMJrQ//rD0vj8POWe8973Nbl9skcAOHTyQ7AAAAABJRU5ErkJggg=="}},98120(e,i,l){e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:l.p+"assets/ideal-img/bedrock_kb.09fd982.640.png 640w,"+l.p+"assets/ideal-img/bedrock_kb.ac190fc.1920.png 1920w",images:[{path:l.p+"assets/ideal-img/bedrock_kb.09fd982.640.png",width:640,height:334},{path:l.p+"assets/ideal-img/bedrock_kb.ac190fc.1920.png",width:1920,height:1003}],src:l.p+"assets/ideal-img/bedrock_kb.09fd982.640.png",placeholder:void 0,width:640,height:334}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAgklEQVR4nEWOuRKEIBAF+f9vNLE0BEsOxRkYeos9aoPO3tHuOA5CCMQYERG0NVT1S6O1ieK2bWNZFtZ1fQfLdWHD0G6c5eG8hCodNxu9d8wMUaVcN7kUvA/ElHhEGICbKz/mbbfBGSP7vuO9574rY4D7++jHp3dqraSUKCWTs+C98QJuIsG3UDdKPQAAAABJRU5ErkJggg=="}}}]);