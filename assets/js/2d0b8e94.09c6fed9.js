"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[79925],{7227(e,n,t){t.d(n,{A:()=>s});t(96540);var a=t(18215);const r="tabItem_Ymn6";var l=t(74848);function s({children:e,hidden:n,className:t}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)(r,t),hidden:n,children:e})}},8379(e,n,t){t.r(n),t.d(n,{assets:()=>m,contentTitle:()=>c,default:()=>p,frontMatter:()=>i,metadata:()=>a,toc:()=>u});const a=JSON.parse('{"id":"providers/meta_llama","title":"Meta Llama","description":"| \u5c5e\u6027 | \u8be6\u60c5 |","source":"@site/docs/providers/meta_llama.md","sourceDirName":"providers","slug":"/providers/meta_llama","permalink":"/docs/providers/meta_llama","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"LM Studio","permalink":"/docs/providers/lm_studio"},"next":{"title":"Milvus - \u5411\u91cf\u5b58\u50a8","permalink":"/docs/providers/milvus_vector_stores"}}');var r=t(74848),l=t(28453),s=t(49489),o=t(7227);const i={},c="Meta Llama",m={},u=[{value:"\u5fc5\u9700\u53d8\u91cf",id:"\u5fc5\u9700\u53d8\u91cf",level:2},{value:"\u6d41\u5f0f\u4f20\u8f93",id:"\u6d41\u5f0f\u4f20\u8f93",level:3},{value:"\u51fd\u6570\u8c03\u7528",id:"\u51fd\u6570\u8c03\u7528",level:3},{value:"\u5de5\u5177\u4f7f\u7528",id:"\u5de5\u5177\u4f7f\u7528",level:3},{value:"\u4f7f\u7528 - LiteLLM \u4ee3\u7406",id:"\u4f7f\u7528---litellm-\u4ee3\u7406",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"meta-llama",children:"Meta Llama"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"\u5c5e\u6027"}),(0,r.jsx)(n.th,{children:"\u8be6\u60c5"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u63cf\u8ff0"}),(0,r.jsx)(n.td,{children:"Meta \u7684 Llama API \u63d0\u4f9b\u4e86\u5bf9 Meta \u5bb6\u65cf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bbf\u95ee\u3002"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"LiteLLM \u63d0\u4f9b\u5546\u8def\u7531"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"meta_llama/"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u652f\u6301\u7684\u7aef\u70b9"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"/chat/completions"}),", ",(0,r.jsx)(n.code,{children:"/completions"}),", ",(0,r.jsx)(n.code,{children:"/responses"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"API \u53c2\u8003"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"https://llama.developer.meta.com?utm_source=partner-litellm&utm_medium=website",children:"Llama API \u53c2\u8003 \u2197"})})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"\u5fc5\u9700\u53d8\u91cf",children:"\u5fc5\u9700\u53d8\u91cf"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="\u73af\u5883\u53d8\u91cf"',children:'os.environ["LLAMA_API_KEY"] = ""  # \u60a8\u7684 Meta Llama API \u5bc6\u94a5\n\n\n## \u652f\u6301\u7684\u6a21\u578b\n\n:::info\n\u8fd9\u91cc https://llama.developer.meta.com/docs/models/ \u5217\u51fa\u7684\u6240\u6709\u6a21\u578b\u5747\u53d7\u652f\u6301\u3002\u6211\u4eec\u79ef\u6781\u7ef4\u62a4\u6a21\u578b\u5217\u8868\u3001\u4e0a\u4e0b\u6587\u7a97\u53e3\u7b49\u4fe1\u606f [\u5728\u8fd9\u91cc](https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json)\u3002\n\n:::\n\n\n| \u6a21\u578b ID | \u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6 | \u8f93\u51fa\u4e0a\u4e0b\u6587\u957f\u5ea6 | \u8f93\u5165\u6a21\u6001 | \u8f93\u51fa\u6a21\u6001 |\n| --- | --- | --- | --- | --- |\n| `Llama-4-Scout-17B-16E-Instruct-FP8` | 128k | 4028 | \u6587\u672c, \u56fe\u50cf | \u6587\u672c |\n| `Llama-4-Maverick-17B-128E-Instruct-FP8` | 128k | 4028 | \u6587\u672c, \u56fe\u50cf | \u6587\u672c |\n| `Llama-3.3-70B-Instruct` | 128k | 4028 | \u6587\u672c | \u6587\u672c |\n| `Llama-3.3-8B-Instruct` | 128k | 4028 | \u6587\u672c | \u6587\u672c |\n\n## \u4f7f\u7528 - LiteLLM Python SDK\n\n### \u975e\u6d41\u5f0f\u4f20\u8f93\n\n```python showLineNumbers title="Meta Llama \u975e\u6d41\u5f0f\u4f20\u8f93\u8865\u5168"\nimport os\nimport litellm\nfrom litellm import completion\n\nos.environ["LLAMA_API_KEY"] = ""  # \u60a8\u7684 Meta Llama API \u5bc6\u94a5\n\nmessages = [{"content": "Hello, how are you?", "role": "user"}]\n\n# Meta Llama \u8c03\u7528\nresponse = completion(model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8", messages=messages)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u6d41\u5f0f\u4f20\u8f93",children:"\u6d41\u5f0f\u4f20\u8f93"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u6d41\u5f0f\u4f20\u8f93\u8865\u5168"',children:'import os\nimport litellm\nfrom litellm import completion\n\nos.environ["LLAMA_API_KEY"] = ""  # \u60a8\u7684 Meta Llama API \u5bc6\u94a5\n\nmessages = [{"content": "Hello, how are you?", "role": "user"}]\n\n# Meta Llama \u8c03\u7528\u5e76\u542f\u7528\u6d41\u5f0f\u4f20\u8f93\nresponse = completion(\n    model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",\n    messages=messages,\n    stream=True\n)\n\nfor chunk in response:\n    print(chunk)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u51fd\u6570\u8c03\u7528",children:"\u51fd\u6570\u8c03\u7528"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u51fd\u6570\u8c03\u7528"',children:'import os\nimport litellm\nfrom litellm import completion\n\nos.environ["LLAMA_API_KEY"] = ""  # \u60a8\u7684 Meta Llama API \u5bc6\u94a5\n\nmessages = [{"content": "What\'s the weather like in San Francisco?", "role": "user"}]\n\n# \u5b9a\u4e49\u51fd\u6570\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "description": "\u83b7\u53d6\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u5f53\u524d\u5929\u6c14",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "\u57ce\u5e02\u548c\u5dde\uff0c\u4f8b\u5982 San Francisco, CA"\n                    },\n                    "unit": {\n                        "type": "string",\n                        "enum": ["celsius", "fahrenheit"]\n                    }\n                },\n                "required": ["location"]\n            }\n        }\n    }\n]\n\n# Meta Llama \u8c03\u7528\u5e76\u542f\u7528\u51fd\u6570\u8c03\u7528\nresponse = completion(\n    model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",\n    messages=messages,\n    tools=tools,\n    tool_choice="auto"\n)\n\nprint(response.choices[0].message.tool_calls)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u5de5\u5177\u4f7f\u7528",children:"\u5de5\u5177\u4f7f\u7528"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u5de5\u5177\u4f7f\u7528"',children:'import os\nimport litellm\nfrom litellm import completion\n\nos.environ["LLAMA_API_KEY"] = ""  # \u60a8\u7684 Meta Llama API \u5bc6\u94a5\n\nmessages = [{"content": "Create a chart showing the population growth of New York City from 2010 to 2020", "role": "user"}]\n\n# \u5b9a\u4e49\u5de5\u5177\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "create_chart",\n            "description": "\u6839\u636e\u63d0\u4f9b\u7684\u6570\u636e\u521b\u5efa\u56fe\u8868",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "chart_type": {\n                        "type": "string",\n                        "enum": ["bar", "line", "pie", "scatter"],\n                        "description": "\u8981\u521b\u5efa\u7684\u56fe\u8868\u7c7b\u578b"\n                    },\n                    "title": {\n                        "type": "string",\n                        "description": "\u56fe\u8868\u6807\u9898"\n                    },\n                    "data": {\n                        "type": "object",\n                        "description": "\u8981\u5728\u56fe\u8868\u4e2d\u7ed8\u5236\u7684\u6570\u636e"\n                    }\n                },\n                "required": ["chart_type", "title", "data"]\n            }\n        }\n    }\n]\n\n# Meta Llama \u8c03\u7528\u5e76\u542f\u7528\u5de5\u5177\u4f7f\u7528\nresponse = completion(\n    model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",\n    messages=messages,\n    tools=tools,\n    tool_choice="auto"\n)\n\nprint(response.choices[0].message.content)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u4f7f\u7528---litellm-\u4ee3\u7406",children:"\u4f7f\u7528 - LiteLLM \u4ee3\u7406"}),"\n",(0,r.jsx)(n.p,{children:"\u5728\u60a8\u7684 LiteLLM \u4ee3\u7406\u914d\u7f6e\u6587\u4ef6\u4e2d\u6dfb\u52a0\u4ee5\u4e0b\u5185\u5bb9\uff1a"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",metastring:'showLineNumbers title="config.yaml"',children:"model_list:\n  - model_name: meta_llama/Llama-3.3-70B-Instruct\n    litellm_params:\n      model: meta_llama/Llama-3.3-70B-Instruct\n      api_key: os.environ/LLAMA_API_KEY\n\n  - model_name: meta_llama/Llama-3.3-8B-Instruct\n    litellm_params:\n      model: meta_llama/Llama-3.3-8B-Instruct\n      api_key: os.environ/LLAMA_API_KEY\n"})}),"\n",(0,r.jsx)(n.p,{children:"\u542f\u52a8\u60a8\u7684 LiteLLM \u4ee3\u7406\u670d\u52a1\u5668\uff1a"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="\u542f\u52a8 LiteLLM \u4ee3\u7406"',children:"litellm --config config.yaml\n\n# \u6b63\u5728\u8fd0\u884c http://0.0.0.0:4000\n"})}),"\n",(0,r.jsxs)(s.A,{children:[(0,r.jsxs)(o.A,{value:"openai-sdk",label:"OpenAI SDK",children:[(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - \u975e\u6d41\u5f0f\u4f20\u8f93"',children:'from openai import OpenAI\n\n# \u4f7f\u7528\u60a8\u7684\u4ee3\u7406 URL \u521d\u59cb\u5316\u5ba2\u6237\u7aef\nclient = OpenAI(\n    base_url="http://localhost:4000",  # \u60a8\u7684\u4ee3\u7406 URL\n    api_key="your-proxy-api-key"       # \u60a8\u7684\u4ee3\u7406 API \u5bc6\u94a5\n)\n\n# \u975e\u6d41\u5f0f\u4f20\u8f93\u54cd\u5e94\nresponse = client.chat.completions.create(\n    model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",\n    messages=[{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}]\n)\n\nprint(response.choices[0].message.content)\n'})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - \u6d41\u5f0f\u4f20\u8f93"',children:'from openai import OpenAI\n\n# \u4f7f\u7528\u60a8\u7684\u4ee3\u7406 URL \u521d\u59cb\u5316\u5ba2\u6237\u7aef\nclient = OpenAI(\n    base_url="http://localhost:4000",  # \u60a8\u7684\u4ee3\u7406 URL\n    api_key="your-proxy-api-key"       # \u60a8\u7684\u4ee3\u7406 API \u5bc6\u94a5\n)\n\n# \u6d41\u5f0f\u4f20\u8f93\u54cd\u5e94\nresponse = client.chat.completions.create(\n    model="meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",\n    messages=[{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}],\n    stream=True\n)\n\nfor chunk in response:\n    if chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end="")\n'})})]}),(0,r.jsxs)(o.A,{value:"litellm-sdk",label:"LiteLLM SDK",children:[(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - LiteLLM SDK"',children:'import litellm\n\n# \u914d\u7f6e LiteLLM \u4f7f\u7528\u60a8\u7684\u4ee3\u7406\nresponse = litellm.completion(\n    model="litellm_proxy/meta_llama/Llama-3.3-70B-Instruct",\n    messages=[{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}],\n    api_base="http://localhost:4000",\n    api_key="your-proxy-api-key"\n)\n\nprint(response.choices[0].message.content)\n'})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - LiteLLM SDK \u6d41\u5f0f\u4f20\u8f93"',children:'import litellm\n\n# \u914d\u7f6e LiteLLM \u4f7f\u7528\u60a8\u7684\u4ee3\u7406\u5e76\u542f\u7528\u6d41\u5f0f\u4f20\u8f93\nresponse = litellm.completion(\n    model="litellm_proxy/meta_llama/Llama-3.3-70B-Instruct",\n    messages=[{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}],\n    api_base="http://localhost:4000",\n    api_key="your-proxy-api-key",\n    stream=True\n)\n\nfor chunk in response:\n    if hasattr(chunk.choices[0], \'delta\') and chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end="")\n'})})]}),(0,r.jsxs)(o.A,{value:"curl",label:"cURL",children:[(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - cURL"',children:'curl http://localhost:4000/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer your-proxy-api-key" \\\n  -d \'{\n    "model": "meta_llama/Llama-3.3-70B-Instruct",\n    "messages": [{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}]\n  }\'\n'})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'showLineNumbers title="Meta Llama \u901a\u8fc7\u4ee3\u7406 - cURL \u6d41\u5f0f\u4f20\u8f93"',children:'curl http://localhost:4000/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer your-proxy-api-key" \\\n  -d \'{\n    "model": "meta_llama/Llama-3.3-70B-Instruct",\n    "messages": [{"role": "user", "content": "\u5199\u4e00\u9996\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u77ed\u8bd7\u3002"}],\n    "stream": true\n  }\'\n'})})]})]}),"\n",(0,r.jsxs)(n.p,{children:["\u6709\u5173\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 ",(0,r.jsx)(n.a,{href:"../providers/litellm_proxy",children:"LiteLLM \u4ee3\u7406\u6587\u6863"}),"\u3002"]})]})}function p(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453(e,n,t){t.d(n,{R:()=>s,x:()=>o});var a=t(96540);const r={},l=a.createContext(r);function s(e){const n=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(l.Provider,{value:n},e.children)}},49489(e,n,t){t.d(n,{A:()=>_});var a=t(96540),r=t(18215),l=t(24245),s=t(56347),o=t(36494),i=t(62814),c=t(45167),m=t(69900);function u(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d(e){const{values:n,children:t}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:a}})=>({value:e,label:n,attributes:t,default:a}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function p({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const t=(0,s.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,i.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function L(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,l=d(e),[s,i]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:l})),[c,u]=h({queryString:t,groupId:r}),[L,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,r]=(0,m.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),b=(()=>{const e=c??L;return p({value:e,tabValues:l})?e:null})();(0,o.A)(()=>{b&&i(b)},[b]);return{selectedValue:s,selectValue:(0,a.useCallback)(e=>{if(!p({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),g(e)},[u,g,l]),tabValues:l}}var g=t(11062);const b="tabList__CuJ",f="tabItem_LNqP";var x=t(74848);function v({className:e,block:n,selectedValue:t,selectValue:a,tabValues:s}){const o=[],{blockElementScrollPositionUntilNextRender:i}=(0,l.a_)(),c=e=>{const n=e.currentTarget,r=o.indexOf(n),l=s[r].value;l!==t&&(i(n),a(l))},m=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:a})=>(0,x.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:m,onClick:c,...a,className:(0,r.A)("tabs__item",f,a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function y({lazy:e,children:n,selectedValue:t}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function j(e){const n=L(e);return(0,x.jsxs)("div",{className:(0,r.A)("tabs-container",b),children:[(0,x.jsx)(v,{...n,...e}),(0,x.jsx)(y,{...n,...e})]})}function _(e){const n=(0,g.A)();return(0,x.jsx)(j,{...e,children:u(e.children)},String(n))}}}]);