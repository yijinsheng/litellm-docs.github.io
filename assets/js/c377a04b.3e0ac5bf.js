"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[45742],{7227(e,n,l){l.d(n,{A:()=>t});l(96540);var o=l(18215);const r="tabItem_Ymn6";var s=l(74848);function t({children:e,hidden:n,className:l}){return(0,s.jsx)("div",{role:"tabpanel",className:(0,o.A)(r,l),hidden:n,children:e})}},28453(e,n,l){l.d(n,{R:()=>t,x:()=>i});var o=l(96540);const r={},s=o.createContext(r);function t(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),o.createElement(s.Provider,{value:n},e.children)}},49489(e,n,l){l.d(n,{A:()=>b});var o=l(96540),r=l(18215),s=l(24245),t=l(56347),i=l(36494),a=l(62814),c=l(45167),d=l(69900);function p(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:l}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return p(e).map(({props:{value:e,label:n,attributes:l,default:o}})=>({value:e,label:n,attributes:l,default:o}))}(l);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,l])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const l=(0,t.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,a.aZ)(r),(0,o.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(l.location.search);n.set(r,e),l.replace({...l.location,search:n.toString()})},[r,l])]}function g(e){const{defaultValue:n,queryString:l=!1,groupId:r}=e,s=h(e),[t,a]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const l=n.find(e=>e.default)??n[0];if(!l)throw new Error("Unexpected error: 0 tabValues");return l.value}({defaultValue:n,tabValues:s})),[c,p]=m({queryString:l,groupId:r}),[g,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[l,r]=(0,d.Dv)(n);return[l,(0,o.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),j=(()=>{const e=c??g;return u({value:e,tabValues:s})?e:null})();(0,i.A)(()=>{j&&a(j)},[j]);return{selectedValue:t,selectValue:(0,o.useCallback)(e=>{if(!u({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);a(e),p(e),x(e)},[p,x,s]),tabValues:s}}var x=l(11062);const j="tabList__CuJ",_="tabItem_LNqP";var y=l(74848);function v({className:e,block:n,selectedValue:l,selectValue:o,tabValues:t}){const i=[],{blockElementScrollPositionUntilNextRender:a}=(0,s.a_)(),c=e=>{const n=e.currentTarget,r=i.indexOf(n),s=t[r].value;s!==l&&(a(n),o(s))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const l=i.indexOf(e.currentTarget)+1;n=i[l]??i[0];break}case"ArrowLeft":{const l=i.indexOf(e.currentTarget)-1;n=i[l]??i[i.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:t.map(({value:e,label:n,attributes:o})=>(0,y.jsx)("li",{role:"tab",tabIndex:l===e?0:-1,"aria-selected":l===e,ref:e=>{i.push(e)},onKeyDown:d,onClick:c,...o,className:(0,r.A)("tabs__item",_,o?.className,{"tabs__item--active":l===e}),children:n??e},e))})}function A({lazy:e,children:n,selectedValue:l}){const s=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=s.find(e=>e.props.value===l);return e?(0,o.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:s.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==l}))})}function f(e){const n=g(e);return(0,y.jsxs)("div",{className:(0,r.A)("tabs-container",j),children:[(0,y.jsx)(v,{...n,...e}),(0,y.jsx)(A,{...n,...e})]})}function b(e){const n=(0,x.A)();return(0,y.jsx)(f,{...e,children:p(e.children)},String(n))}},83012(e,n,l){l.r(n),l.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>p});const o=JSON.parse('{"id":"index","title":"LiteLLM - \u5feb\u901f\u5165\u95e8","description":"https://github.com/BerriAI/litellm","source":"@site/docs/index.md","sourceDirName":".","slug":"/","permalink":"/docs/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","next":{"title":"completion()","permalink":"/docs/completion/input"}}');var r=l(74848),s=l(28453),t=l(49489),i=l(7227);const a={},c="LiteLLM - \u5feb\u901f\u5165\u95e8",d={},p=[{value:"<strong>\u4f7f\u7528 OpenAI \u8f93\u5165/\u8f93\u51fa\u683c\u5f0f\u8c03\u7528 100+ LLM</strong>",id:"\u4f7f\u7528-openai-\u8f93\u5165\u8f93\u51fa\u683c\u5f0f\u8c03\u7528-100-llm",level:2},{value:"\u5982\u4f55\u4f7f\u7528 LiteLLM",id:"\u5982\u4f55\u4f7f\u7528-litellm",level:2},{value:"<strong>LiteLLM Python SDK</strong>",id:"litellm-python-sdk",level:2},{value:"\u57fa\u672c\u7528\u6cd5",id:"\u57fa\u672c\u7528\u6cd5",level:3},{value:"\u54cd\u5e94\u683c\u5f0f\uff08OpenAI \u804a\u5929\u5b8c\u6210\u683c\u5f0f\uff09",id:"\u54cd\u5e94\u683c\u5f0fopenai-\u804a\u5929\u5b8c\u6210\u683c\u5f0f",level:3},{value:"\u6d41\u5f0f\u4f20\u8f93",id:"\u6d41\u5f0f\u4f20\u8f93",level:3},{value:"\u6d41\u5f0f\u54cd\u5e94\u683c\u5f0f\uff08OpenAI \u683c\u5f0f\uff09",id:"\u6d41\u5f0f\u54cd\u5e94\u683c\u5f0fopenai-\u683c\u5f0f",level:3},{value:"\u5f02\u5e38\u5904\u7406",id:"\u5f02\u5e38\u5904\u7406",level:3},{value:"\u4e86\u89e3 LiteLLM \u5982\u4f55\u8f6c\u6362\u60a8\u7684\u8bf7\u6c42",id:"\u4e86\u89e3-litellm-\u5982\u4f55\u8f6c\u6362\u60a8\u7684\u8bf7\u6c42",level:3},{value:"\u65e5\u5fd7\u8bb0\u5f55\u53ef\u89c2\u5bdf\u6027 - \u8bb0\u5f55 LLM \u8f93\u5165/\u8f93\u51fa\uff08\u6587\u6863\uff09",id:"\u65e5\u5fd7\u8bb0\u5f55\u53ef\u89c2\u5bdf\u6027---\u8bb0\u5f55-llm-\u8f93\u5165\u8f93\u51fa\u6587\u6863",level:3},{value:"\u8ddf\u8e2a\u6d41\u5f0f\u4f20\u8f93\u7684\u6210\u672c\u3001\u4f7f\u7528\u60c5\u51b5\u3001\u5ef6\u8fdf",id:"\u8ddf\u8e2a\u6d41\u5f0f\u4f20\u8f93\u7684\u6210\u672c\u4f7f\u7528\u60c5\u51b5\u5ef6\u8fdf",level:3},{value:"<strong>LiteLLM \u4ee3\u7406\u670d\u52a1\u5668\uff08LLM \u7f51\u5173\uff09</strong>",id:"litellm-\u4ee3\u7406\u670d\u52a1\u5668llm-\u7f51\u5173",level:2},{value:"\ud83d\udcd6 \u4ee3\u7406\u7aef\u70b9 - Swagger \u6587\u6863",id:"-\u4ee3\u7406\u7aef\u70b9---swagger-\u6587\u6863",level:3},{value:"\u4ee3\u7406\u5feb\u901f\u5165\u95e8 - CLI",id:"\u4ee3\u7406\u5feb\u901f\u5165\u95e8---cli",level:3},{value:"\u6b65\u9aa4 1\uff1a\u542f\u52a8 litellm \u4ee3\u7406",id:"\u6b65\u9aa4-1\u542f\u52a8-litellm-\u4ee3\u7406",level:4},{value:"\u6b65\u9aa4 2\uff1a\u5411\u4ee3\u7406\u53d1\u51fa ChatCompletions \u8bf7\u6c42",id:"\u6b65\u9aa4-2\u5411\u4ee3\u7406\u53d1\u51fa-chatcompletions-\u8bf7\u6c42",level:4},{value:"\u66f4\u591a\u8be6\u60c5",id:"\u66f4\u591a\u8be6\u60c5",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"litellm---\u5feb\u901f\u5165\u95e8",children:"LiteLLM - \u5feb\u901f\u5165\u95e8"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/BerriAI/litellm",children:"https://github.com/BerriAI/litellm"})}),"\n",(0,r.jsx)(n.h2,{id:"\u4f7f\u7528-openai-\u8f93\u5165\u8f93\u51fa\u683c\u5f0f\u8c03\u7528-100-llm",children:(0,r.jsx)(n.strong,{children:"\u4f7f\u7528 OpenAI \u8f93\u5165/\u8f93\u51fa\u683c\u5f0f\u8c03\u7528 100+ LLM"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u5c06\u8f93\u5165\u8f6c\u6362\u4e3a\u63d0\u4f9b\u5546\u7684\u7aef\u70b9\uff08",(0,r.jsx)(n.code,{children:"/chat/completions"}),"\u3001",(0,r.jsx)(n.code,{children:"/responses"}),"\u3001",(0,r.jsx)(n.code,{children:"/embeddings"}),"\u3001",(0,r.jsx)(n.code,{children:"/images"}),"\u3001",(0,r.jsx)(n.code,{children:"/audio"}),"\u3001",(0,r.jsx)(n.code,{children:"/batches"})," \u7b49\uff09"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/supported_endpoints",children:"\u4e00\u81f4\u7684\u8f93\u51fa\u683c\u5f0f"})," - \u65e0\u8bba\u60a8\u4f7f\u7528\u54ea\u4e2a\u63d0\u4f9b\u5546\uff0c\u54cd\u5e94\u683c\u5f0f\u90fd\u76f8\u540c"]}),"\n",(0,r.jsxs)(n.li,{children:["\u8de8\u591a\u4e2a\u90e8\u7f72\u7684\u91cd\u8bd5/\u56de\u9000\u903b\u8f91\uff08\u4f8b\u5982 Azure/OpenAI\uff09 - ",(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/routing",children:"\u8def\u7531\u5668"})]}),"\n",(0,r.jsxs)(n.li,{children:["\u8ddf\u8e2a\u6bcf\u4e2a\u9879\u76ee\u7684\u652f\u51fa\u5e76\u8bbe\u7f6e\u9884\u7b97 ",(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/simple_proxy",children:"LiteLLM \u4ee3\u7406\u670d\u52a1\u5668"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"\u5982\u4f55\u4f7f\u7528-litellm",children:"\u5982\u4f55\u4f7f\u7528 LiteLLM"}),"\n",(0,r.jsx)(n.p,{children:"\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee3\u7406\u670d\u52a1\u5668\u6216 Python SDK \u4f7f\u7528 LiteLLM\u3002\u4e24\u8005\u90fd\u4e3a\u60a8\u63d0\u4f9b\u8bbf\u95ee\u591a\u4e2a LLM\uff08100+ LLM\uff09\u7684\u7edf\u4e00\u63a5\u53e3\u3002\u9009\u62e9\u6700\u9002\u5408\u60a8\u9700\u6c42\u7684\u9009\u9879\uff1a"}),"\n",(0,r.jsxs)("table",{style:{width:"100%",tableLayout:"fixed"},children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{style:{width:"14%"}}),(0,r.jsx)("th",{style:{width:"43%"},children:(0,r.jsx)("strong",{children:(0,r.jsx)("a",{href:"#litellm-proxy-server-llm-gateway",children:"LiteLLM \u4ee3\u7406\u670d\u52a1\u5668"})})}),(0,r.jsx)("th",{style:{width:"43%"},children:(0,r.jsx)("strong",{children:(0,r.jsx)("a",{href:"#basic-usage",children:"LiteLLM Python SDK"})})})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{style:{width:"14%"},children:(0,r.jsx)("strong",{children:"\u4f7f\u7528\u573a\u666f"})}),(0,r.jsx)("td",{style:{width:"43%"},children:"\u8bbf\u95ee\u591a\u4e2a LLM \u7684\u4e2d\u5fc3\u670d\u52a1\uff08LLM \u7f51\u5173\uff09"}),(0,r.jsx)("td",{style:{width:"43%"},children:"\u76f4\u63a5\u5728\u60a8\u7684 Python \u4ee3\u7801\u4e2d\u4f7f\u7528 LiteLLM"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{style:{width:"14%"},children:(0,r.jsx)("strong",{children:"\u4f7f\u7528\u8005"})}),(0,r.jsx)("td",{style:{width:"43%"},children:"Gen AI \u8d4b\u80fd / ML \u5e73\u53f0\u56e2\u961f"}),(0,r.jsx)("td",{style:{width:"43%"},children:"\u6784\u5efa LLM \u9879\u76ee\u7684\u5f00\u53d1\u8005"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{style:{width:"14%"},children:(0,r.jsx)("strong",{children:"\u6838\u5fc3\u529f\u80fd"})}),(0,r.jsxs)("td",{style:{width:"43%"},children:["\u2022 \u5e26\u6709\u8eab\u4efd\u9a8c\u8bc1\u548c\u6388\u6743\u7684\u96c6\u4e2d\u5f0f API \u7f51\u5173",(0,r.jsx)("br",{}),"\u2022 \u6bcf\u4e2a\u9879\u76ee/\u7528\u6237\u7684\u591a\u79df\u6237\u6210\u672c\u8ddf\u8e2a\u548c\u652f\u51fa\u7ba1\u7406",(0,r.jsx)("br",{}),"\u2022 \u6bcf\u4e2a\u9879\u76ee\u81ea\u5b9a\u4e49\uff08\u65e5\u5fd7\u8bb0\u5f55\u3001\u9632\u62a4\u680f\u3001\u7f13\u5b58\uff09",(0,r.jsx)("br",{}),"\u2022 \u7528\u4e8e\u5b89\u5168\u8bbf\u95ee\u63a7\u5236\u7684\u865a\u62df\u5bc6\u94a5",(0,r.jsx)("br",{}),"\u2022 \u7528\u4e8e\u76d1\u63a7\u548c\u7ba1\u7406\u7684\u7ba1\u7406\u4eea\u8868\u677f UI"]}),(0,r.jsxs)("td",{style:{width:"43%"},children:["\u2022 \u76f4\u63a5\u5728\u4ee3\u7801\u5e93\u4e2d\u96c6\u6210 Python \u5e93",(0,r.jsx)("br",{}),"\u2022 \u8de8\u591a\u4e2a\u90e8\u7f72\u7684\u91cd\u8bd5/\u56de\u9000\u903b\u8f91\u8def\u7531\u5668\uff08\u4f8b\u5982 Azure/OpenAI\uff09 - ",(0,r.jsx)("a",{href:"https://docs.litellm.ai/docs/routing",children:"\u8def\u7531\u5668"}),(0,r.jsx)("br",{}),"\u2022 \u5e94\u7528\u7ea7\u8d1f\u8f7d\u5747\u8861\u548c\u6210\u672c\u8ddf\u8e2a",(0,r.jsx)("br",{}),"\u2022 \u517c\u5bb9 OpenAI \u7684\u5f02\u5e38\u5904\u7406",(0,r.jsx)("br",{}),"\u2022 \u53ef\u89c2\u5bdf\u6027\u56de\u8c03\uff08Lunary\u3001MLflow\u3001Langfuse \u7b49\uff09"]})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"litellm-python-sdk",children:(0,r.jsx)(n.strong,{children:"LiteLLM Python SDK"})}),"\n",(0,r.jsx)(n.h3,{id:"\u57fa\u672c\u7528\u6cd5",children:"\u57fa\u672c\u7528\u6cd5"}),"\n",(0,r.jsx)("a",{target:"_blank",href:"https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb",children:(0,r.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"\u5728 Colab \u4e2d\u6253\u5f00"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"pip install litellm\n"})}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(i.A,{value:"openai",label:"OpenAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENAI_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="openai/gpt-4o",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"anthropic",label:"Anthropic",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["ANTHROPIC_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="anthropic/claude-3-sonnet-20240229",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"xai",label:"xAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["XAI_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="xai/grok-2-latest",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"vertex",label:"VertexAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n# \u8ba4\u8bc1\uff1a\u8fd0\u884c \'gcloud auth application-default\'\nos.environ["VERTEXAI_PROJECT"] = "hardy-device-386718"\nos.environ["VERTEXAI_LOCATION"] = "us-central1"\n\nresponse = completion(\n  model="vertex_ai/gemini-1.5-pro",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"nvidia",label:"NVIDIA",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["NVIDIA_NIM_API_KEY"] = "nvidia_api_key"\nos.environ["NVIDIA_NIM_API_BASE"] = "nvidia_nim_endpoint_url"\n\nresponse = completion(\n  model="nvidia_nim/<model_name>",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"hugging",label:"HuggingFace",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\nos.environ["HUGGINGFACE_API_KEY"] = "huggingface_api_key"\n\n# \u4f8b\u5982\uff1a\u8c03\u7528\u6258\u7ba1\u5728 HF Inference \u7aef\u70b9\u4e0a\u7684 \'WizardLM/WizardCoder-Python-34B-V1.0\'\nresponse = completion(\n  model="huggingface/WizardLM/WizardCoder-Python-34B-V1.0",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  api_base="https://my-endpoint.huggingface.cloud"\n)\n\nprint(response)\n'})})}),(0,r.jsx)(i.A,{value:"azure",label:"Azure OpenAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["AZURE_API_KEY"] = ""\nos.environ["AZURE_API_BASE"] = ""\nos.environ["AZURE_API_VERSION"] = ""\n\n# azure \u8c03\u7528\nresponse = completion(\n  "azure/<your_deployment_name>",\n  messages = [{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"ollama",label:"Ollama",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\n\nresponse = completion(\n            model="ollama/llama2",\n            messages = [{ "content": "Hello, how are you?","role": "user"}],\n            api_base="http://localhost:11434"\n)\n'})})}),(0,r.jsx)(i.A,{value:"or",label:"Openrouter",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENROUTER_API_KEY"] = "openrouter_api_key"\n\nresponse = completion(\n  model="openrouter/google/palm-2-chat-bison",\n  messages = [{ "content": "Hello, how are you?","role": "user"}],\n)\n'})})}),(0,r.jsx)(i.A,{value:"novita",label:"Novita AI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u3002\u8bbf\u95ee https://novita.ai/settings/key-management \u83b7\u53d6\u60a8\u7684 API \u5bc6\u94a5\nos.environ["NOVITA_API_KEY"] = "novita-api-key"\n\nresponse = completion(\n  model="novita/deepseek/deepseek-r1",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})}),(0,r.jsx)(i.A,{value:"vercel",label:"Vercel AI Gateway",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u3002\u8bbf\u95ee https://vercel.com/docs/ai-gateway#using-the-ai-gateway-with-an-api-key \u83b7\u53d6\u5bc6\u94a5\u8bf4\u660e\nos.environ["VERCEL_AI_GATEWAY_API_KEY"] = "your-vercel-api-key"\n\nresponse = completion(\n  model="vercel_ai_gateway/openai/gpt-4o",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n)\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"\u54cd\u5e94\u683c\u5f0fopenai-\u804a\u5929\u5b8c\u6210\u683c\u5f0f",children:"\u54cd\u5e94\u683c\u5f0f\uff08OpenAI \u804a\u5929\u5b8c\u6210\u683c\u5f0f\uff09"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n    "id": "chatcmpl-565d891b-a42e-4c39-8d14-82a1f5208885",\n    "created": 1734366691,\n    "model": "gpt-4o-2024-08-06",\n    "object": "chat.completion",\n    "system_fingerprint": null,\n    "choices": [\n        {\n            "finish_reason": "stop",\n            "index": 0,\n            "message": {\n                "content": "Hello! As an AI language model, I don\'t have feelings, but I\'m operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?",\n                "role": "assistant",\n                "tool_calls": null,\n                "function_call": null\n            }\n        }\n    ],\n    "usage": {\n        "completion_tokens": 43,\n        "prompt_tokens": 13,\n        "total_tokens": 56,\n        "completion_tokens_details": null,\n        "prompt_tokens_details": {\n            "audio_tokens": null,\n            "cached_tokens": 0\n        },\n        "cache_creation_input_tokens": 0,\n        "cache_read_input_tokens": 0\n    }\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u6d41\u5f0f\u4f20\u8f93",children:"\u6d41\u5f0f\u4f20\u8f93"}),"\n",(0,r.jsxs)(n.p,{children:["\u5728 ",(0,r.jsx)(n.code,{children:"completion"})," \u53c2\u6570\u4e2d\u8bbe\u7f6e ",(0,r.jsx)(n.code,{children:"stream=True"}),"\u3002"]}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(i.A,{value:"openai",label:"OpenAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENAI_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="openai/gpt-4o",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"anthropic",label:"Anthropic",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["ANTHROPIC_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="anthropic/claude-3-sonnet-20240229",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"xai",label:"xAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["XAI_API_KEY"] = "your-api-key"\n\nresponse = completion(\n  model="xai/grok-2-latest",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"vertex",label:"VertexAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n# \u8ba4\u8bc1\uff1a\u8fd0\u884c \'gcloud auth application-default\'\nos.environ["VERTEX_PROJECT"] = "hardy-device-386718"\nos.environ["VERTEX_LOCATION"] = "us-central1"\n\nresponse = completion(\n  model="vertex_ai/gemini-1.5-pro",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"nvidia",label:"NVIDIA",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["NVIDIA_NIM_API_KEY"] = "nvidia_api_key"\nos.environ["NVIDIA_NIM_API_BASE"] = "nvidia_nim_endpoint_url"\n\nresponse = completion(\n  model="nvidia_nim/<model_name>",\n  messages=[{ "content": "Hello, how are you?","role": "user"}]\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"hugging",label:"HuggingFace",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\nos.environ["HUGGINGFACE_API_KEY"] = "huggingface_api_key"\n\n# \u4f8b\u5982\uff1a\u8c03\u7528\u6258\u7ba1\u5728 HF Inference \u7aef\u70b9\u4e0a\u7684 \'WizardLM/WizardCoder-Python-34B-V1.0\'\nresponse = completion(\n  model="huggingface/WizardLM/WizardCoder-Python-34B-V1.0",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  api_base="https://my-endpoint.huggingface.cloud",\n  stream=True,\n)\n\nprint(response)\n'})})}),(0,r.jsx)(i.A,{value:"azure",label:"Azure OpenAI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["AZURE_API_KEY"] = ""\nos.environ["AZURE_API_BASE"] = ""\nos.environ["AZURE_API_VERSION"] = ""\n\n# azure \u8c03\u7528\nresponse = completion(\n  "azure/<your_deployment_name>",\n  messages = [{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"ollama",label:"Ollama",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\n\nresponse = completion(\n            model="ollama/llama2",\n            messages = [{ "content": "Hello, how are you?","role": "user"}],\n            api_base="http://localhost:11434",\n            stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"or",label:"Openrouter",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\nos.environ["OPENROUTER_API_KEY"] = "openrouter_api_key"\n\nresponse = completion(\n  model="openrouter/google/palm-2-chat-bison",\n  messages = [{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"novita",label:"Novita AI",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u3002\u8bbf\u95ee https://novita.ai/settings/key-management \u83b7\u53d6\u60a8\u7684 API \u5bc6\u94a5\nos.environ["NOVITA_API_KEY"] = "novita_api_key"\n\nresponse = completion(\n  model="novita/deepseek/deepseek-r1",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})}),(0,r.jsx)(i.A,{value:"vercel",label:"Vercel AI Gateway",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\nimport os\n\n## \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u3002\u8bbf\u95ee https://vercel.com/docs/ai-gateway#using-the-ai-gateway-with-an-api-key \u83b7\u53d6\u5bc6\u94a5\u8bf4\u660e\nos.environ["VERCEL_AI_GATEWAY_API_KEY"] = "your-vercel-api-key"\n\nresponse = completion(\n  model="vercel_ai_gateway/openai/gpt-4o",\n  messages=[{ "content": "Hello, how are you?","role": "user"}],\n  stream=True,\n)\n'})})})]}),"\n",(0,r.jsx)(n.h3,{id:"\u6d41\u5f0f\u54cd\u5e94\u683c\u5f0fopenai-\u683c\u5f0f",children:"\u6d41\u5f0f\u54cd\u5e94\u683c\u5f0f\uff08OpenAI \u683c\u5f0f\uff09"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n    "id": "chatcmpl-2be06597-eb60-4c70-9ec5-8cd2ab1b4697",\n    "created": 1734366925,\n    "model": "claude-3-sonnet-20240229",\n    "object": "chat.completion.chunk",\n    "system_fingerprint": null,\n    "choices": [\n        {\n            "finish_reason": null,\n            "index": 0,\n            "delta": {\n                "content": "Hello",\n                "role": "assistant",\n                "function_call": null,\n                "tool_calls": null,\n                "audio": null\n            },\n            "logprobs": null\n        }\n    ]\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u5f02\u5e38\u5904\u7406",children:"\u5f02\u5e38\u5904\u7406"}),"\n",(0,r.jsx)(n.p,{children:"LiteLLM \u5c06\u6240\u6709\u53d7\u652f\u6301\u63d0\u4f9b\u5546\u7684\u5f02\u5e38\u6620\u5c04\u5230 OpenAI \u5f02\u5e38\u3002\u6211\u4eec\u6240\u6709\u7684\u5f02\u5e38\u90fd\u7ee7\u627f\u81ea OpenAI \u7684\u5f02\u5e38\u7c7b\u578b\uff0c\u56e0\u6b64\u60a8\u5bf9\u8be5\u5f02\u5e38\u7684\u4efb\u4f55\u9519\u8bef\u5904\u7406\u90fd\u53ef\u4ee5\u76f4\u63a5\u4e0e LiteLLM \u914d\u5408\u4f7f\u7528\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import litellm\nfrom litellm import completion\nimport os\n\nos.environ["ANTHROPIC_API_KEY"] = "bad-key"\ntry:\n    completion(model="anthropic/claude-instant-1", messages=[{"role": "user", "content": "Hey, how\'s it going?"}])\nexcept litellm.AuthenticationError as e:\n    # \u5f53 API \u5bc6\u94a5\u65e0\u6548\u65f6\u629b\u51fa\n    print(f"Authentication failed: {e}")\nexcept litellm.RateLimitError as e:\n    # \u5f53\u60a8\u8d85\u8fc7\u901f\u7387\u9650\u5236\u65f6\u629b\u51fa\n    print(f"Rate limited: {e}")\nexcept litellm.APIError as e:\n    # \u4e00\u822c API \u9519\u8bef\u65f6\u629b\u51fa\n    print(f"API error: {e}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u4e86\u89e3-litellm-\u5982\u4f55\u8f6c\u6362\u60a8\u7684\u8bf7\u6c42",children:"\u4e86\u89e3 LiteLLM \u5982\u4f55\u8f6c\u6362\u60a8\u7684\u8bf7\u6c42"}),"\n",(0,r.jsxs)(n.p,{children:["\u60f3\u8981\u4e86\u89e3 LiteLLM \u5982\u4f55\u89e3\u6790\u548c\u89c4\u8303\u5316\u60a8\u7684 LLM API \u8bf7\u6c42\u5417\uff1f\u4f7f\u7528 ",(0,r.jsx)(n.code,{children:"/utils/transform_request"})," \u7aef\u70b9\u67e5\u770b\u60a8\u7684\u8bf7\u6c42\u5728\u5185\u90e8\u662f\u5982\u4f55\u8f6c\u6362\u7684\u3002"]}),"\n",(0,r.jsxs)(n.p,{children:["\u60a8\u73b0\u5728\u53ef\u4ee5\u76f4\u63a5\u5728\u6211\u4eec\u7684\u6f14\u793a\u5e94\u7528\u4e0a\u8bd5\u7528\uff01\n\u524d\u5f80 ",(0,r.jsx)(n.a,{href:"https://litellm-api.up.railway.app/#/llm%20utils/transform_request_utils_transform_request_post",children:"LiteLLM API \u6587\u6863\u67e5\u770b transform_request"})]}),"\n",(0,r.jsx)(n.p,{children:"LiteLLM \u5c06\u5411\u60a8\u663e\u793a\u8bf7\u6c42\u7684\u89c4\u8303\u5316\u3001\u4e0e\u63d0\u4f9b\u5546\u65e0\u5173\u7684\u7248\u672c\u3002\u8fd9\u5bf9\u4e8e\u8c03\u8bd5\u3001\u5b66\u4e60\u548c\u4e86\u89e3 LiteLLM \u5982\u4f55\u5904\u7406\u4e0d\u540c\u7684\u63d0\u4f9b\u5546\u548c\u9009\u9879\u975e\u5e38\u6709\u7528\u3002"}),"\n",(0,r.jsxs)(n.h3,{id:"\u65e5\u5fd7\u8bb0\u5f55\u53ef\u89c2\u5bdf\u6027---\u8bb0\u5f55-llm-\u8f93\u5165\u8f93\u51fa\u6587\u6863",children:["\u65e5\u5fd7\u8bb0\u5f55\u53ef\u89c2\u5bdf\u6027 - \u8bb0\u5f55 LLM \u8f93\u5165/\u8f93\u51fa\uff08",(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/observability/callbacks",children:"\u6587\u6863"}),"\uff09"]}),"\n",(0,r.jsx)(n.p,{children:"LiteLLM \u63d0\u4f9b\u9884\u5b9a\u4e49\u7684\u56de\u8c03\uff0c\u7528\u4e8e\u5411 Lunary\u3001MLflow\u3001Langfuse\u3001Helicone\u3001Promptlayer\u3001Traceloop\u3001Slack \u53d1\u9001\u6570\u636e"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from litellm import completion\n\n## \u8bbe\u7f6e\u65e5\u5fd7\u5de5\u5177\u7684\u73af\u5883\u53d8\u91cf\uff08\u4f7f\u7528 MLflow \u65f6\u4e0d\u9700\u8981\u8bbe\u7f6e API \u5bc6\u94a5\uff09\nos.environ["LUNARY_PUBLIC_KEY"] = "your-lunary-public-key" # \u5728 https://app.lunary.ai/settings \u83b7\u53d6\u60a8\u7684\u516c\u94a5\nos.environ["HELICONE_API_KEY"] = "your-helicone-key"\nos.environ["LANGFUSE_PUBLIC_KEY"] = ""\nos.environ["LANGFUSE_SECRET_KEY"] = ""\n\nos.environ["OPENAI_API_KEY"]\n\n# \u8bbe\u7f6e\u56de\u8c03\nlitellm.success_callback = ["lunary", "mlflow", "langfuse", "helicone"] # \u5c06\u8f93\u5165/\u8f93\u51fa\u8bb0\u5f55\u5230 lunary\u3001mlflow\u3001langfuse\u3001helicone\n\n#openai \u8c03\u7528\nresponse = completion(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hi - i\'m openai"}])\n'})}),"\n",(0,r.jsx)(n.h3,{id:"\u8ddf\u8e2a\u6d41\u5f0f\u4f20\u8f93\u7684\u6210\u672c\u4f7f\u7528\u60c5\u51b5\u5ef6\u8fdf",children:"\u8ddf\u8e2a\u6d41\u5f0f\u4f20\u8f93\u7684\u6210\u672c\u3001\u4f7f\u7528\u60c5\u51b5\u3001\u5ef6\u8fdf"}),"\n",(0,r.jsxs)(n.p,{children:["\u4f7f\u7528\u56de\u8c03\u51fd\u6570\u6765\u5b9e\u73b0 - \u66f4\u591a\u5173\u4e8e\u81ea\u5b9a\u4e49\u56de\u8c03\u7684\u4fe1\u606f\uff1a",(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/observability/custom_callback",children:"https://docs.litellm.ai/docs/observability/custom_callback"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import litellm\n\n# track_cost_callback\ndef track_cost_callback(\n    kwargs,                 # completion \u7684\u53c2\u6570\n    completion_response,    # completion \u7684\u54cd\u5e94\n    start_time, end_time    # \u5f00\u59cb/\u7ed3\u675f\u65f6\u95f4\n):\n    try:\n      response_cost = kwargs.get("response_cost", 0)\n      print("streaming response_cost", response_cost)\n    except:\n        pass\n# \u8bbe\u7f6e\u56de\u8c03\nlitellm.success_callback = [track_cost_callback] # \u8bbe\u7f6e\u81ea\u5b9a\u4e49\u56de\u8c03\u51fd\u6570\n\n# litellm.completion() \u8c03\u7528\nresponse = completion(\n    model="gpt-3.5-turbo",\n    messages=[\n        {\n            "role": "user",\n            "content": "Hi - i\'m openai"\n        }\n    ],\n    stream=True\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"litellm-\u4ee3\u7406\u670d\u52a1\u5668llm-\u7f51\u5173",children:(0,r.jsx)(n.strong,{children:"LiteLLM \u4ee3\u7406\u670d\u52a1\u5668\uff08LLM \u7f51\u5173\uff09"})}),"\n",(0,r.jsx)(n.p,{children:"\u8ddf\u8e2a\u8de8\u591a\u4e2a\u9879\u76ee/\u4eba\u5458\u7684\u652f\u51fa"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033",alt:"ui_3"})}),"\n",(0,r.jsx)(n.p,{children:"\u4ee3\u7406\u63d0\u4f9b\uff1a"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth",children:"\u8eab\u4efd\u9a8c\u8bc1\u94a9\u5b50"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class",children:"\u65e5\u5fd7\u8bb0\u5f55\u94a9\u5b50"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend",children:"\u6210\u672c\u8ddf\u8e2a"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.litellm.ai/docs/proxy/users#set-rate-limits",children:"\u901f\u7387\u9650\u5236"})}),"\n"]}),"\n",(0,r.jsxs)(n.h3,{id:"-\u4ee3\u7406\u7aef\u70b9---swagger-\u6587\u6863",children:["\ud83d\udcd6 \u4ee3\u7406\u7aef\u70b9 - ",(0,r.jsx)(n.a,{href:"https://litellm-api.up.railway.app/()",children:"Swagger \u6587\u6863"})]}),"\n",(0,r.jsxs)(n.p,{children:["\u524d\u5f80\u8fd9\u91cc\u67e5\u770b\u5305\u542b\u5bc6\u94a5 + \u901f\u7387\u9650\u5236\u7684\u5b8c\u6574\u6559\u7a0b - ",(0,r.jsx)(n.a,{href:"/docs/proxy/docker_quick_start",children:(0,r.jsx)(n.strong,{children:"\u8fd9\u91cc"})})]}),"\n",(0,r.jsx)(n.h3,{id:"\u4ee3\u7406\u5feb\u901f\u5165\u95e8---cli",children:"\u4ee3\u7406\u5feb\u901f\u5165\u95e8 - CLI"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"pip install 'litellm[proxy]'\n"})}),"\n",(0,r.jsx)(n.h4,{id:"\u6b65\u9aa4-1\u542f\u52a8-litellm-\u4ee3\u7406",children:"\u6b65\u9aa4 1\uff1a\u542f\u52a8 litellm \u4ee3\u7406"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(i.A,{label:"pip \u5305",value:"pip",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"$ litellm --model huggingface/bigcode/starcoder\n\n#INFO: \u4ee3\u7406\u8fd0\u884c\u5728 http://0.0.0.0:4000\n"})})}),(0,r.jsxs)(i.A,{label:"Docker \u5bb9\u5668",value:"docker",children:[(0,r.jsx)(n.p,{children:"\u6b65\u9aa4 1. \u521b\u5efa config.yaml"}),(0,r.jsxs)(n.p,{children:["\u793a\u4f8b ",(0,r.jsx)(n.code,{children:"litellm_config.yaml"})]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'model_list:\n  - model_name: gpt-3.5-turbo\n    litellm_params:\n      model: azure/<your-azure-model-deployment>\n      api_base: os.environ/AZURE_API_BASE # \u8fd0\u884c os.getenv("AZURE_API_BASE")\n      api_key: os.environ/AZURE_API_KEY # \u8fd0\u884c os.getenv("AZURE_API_KEY")\n      api_version: "2023-07-01-preview"\n'})}),(0,r.jsx)(n.p,{children:"\u6b65\u9aa4 2. \u8fd0\u884c Docker \u955c\u50cf"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"docker run \\\n    -v $(pwd)/litellm_config.yaml:/app/config.yaml \\\n    -e AZURE_API_KEY=d6*********** \\\n    -e AZURE_API_BASE=https://openai-***********/ \\\n    -p 4000:4000 \\\n    docker.litellm.ai/berriai/litellm:main-latest \\\n    --config /app/config.yaml --detailed_debug\n"})})]})]}),"\n",(0,r.jsx)(n.h4,{id:"\u6b65\u9aa4-2\u5411\u4ee3\u7406\u53d1\u51fa-chatcompletions-\u8bf7\u6c42",children:"\u6b65\u9aa4 2\uff1a\u5411\u4ee3\u7406\u53d1\u51fa ChatCompletions \u8bf7\u6c42"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import openai # openai v1.0.0+\nclient = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # \u5c06\u4ee3\u7406\u8bbe\u7f6e\u4e3a base_url\n# \u8bf7\u6c42\u53d1\u9001\u5230\u5728 litellm \u4ee3\u7406\u4e0a\u8bbe\u7f6e\u7684\u6a21\u578b\uff0c`litellm --model`\nresponse = client.chat.completions.create(model="gpt-3.5-turbo", messages = [\n    {\n        "role": "user",\n        "content": "this is a test request, write a short poem"\n    }\n])\n\nprint(response)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u66f4\u591a\u8be6\u60c5",children:"\u66f4\u591a\u8be6\u60c5"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/exception_mapping",children:"\u5f02\u5e38\u6620\u5c04"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/completion/reliable_completions",children:"completion() \u7684\u91cd\u8bd5 + \u6a21\u578b\u56de\u9000"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/proxy/virtual_keys",children:"\u4ee3\u7406\u865a\u62df\u5bc6\u94a5\u548c\u652f\u51fa\u7ba1\u7406"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/proxy/docker_quick_start",children:"LiteLLM \u4ee3\u7406\u670d\u52a1\u5668\u7684\u7aef\u5230\u7aef\u6559\u7a0b"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);