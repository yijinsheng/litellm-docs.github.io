(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[11456],{34832(e,l,i){e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:i.p+"assets/ideal-img/ui_usage.c3911d7.640.png 640w,"+i.p+"assets/ideal-img/ui_usage.3ffdba3.1200.png 1200w",images:[{path:i.p+"assets/ideal-img/ui_usage.c3911d7.640.png",width:640,height:334},{path:i.p+"assets/ideal-img/ui_usage.3ffdba3.1200.png",width:1200,height:627}],src:i.p+"assets/ideal-img/ui_usage.c3911d7.640.png",placeholder:void 0,width:640,height:334}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAgklEQVR4nE2OQQ6DMBAD8/+H9E2FG6f0koIKJJvNLlOFtqKWRj5Ysh3SM5FSYp5n1nVFtVGronphrRGmaWIYBsZxJMZILoV9z7gfHMeHrEZorWFmuDu1VkTKGXb512/3SOjhjyJCLkIRZRFlb8by2ngsG+H/S//nDmaOmp+NIn2l8gZKO8HzLK4OjwAAAABJRU5ErkJggg=="}},36500(e,l,i){"use strict";i.r(l),i.d(l,{assets:()=>d,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>t,toc:()=>h});var t=i(73540),s=i(74848),n=i(28453),r=i(90547);const a={title:"v1.65.0-stable - Model Context Protocol",slug:"v1.65.0-stable",date:new Date("2025-03-30T10:00:00.000Z"),authors:[{name:"Krrish Dholakia",title:"CEO, LiteLLM",url:"https://www.linkedin.com/in/krish-d/",image_url:"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8"},{name:"Ishaan Jaffer",title:"CTO, LiteLLM",url:"https://www.linkedin.com/in/reffajnaahsi/",image_url:"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg"}],tags:["mcp","custom_prompt_management"],hide_table_of_contents:!1},o=void 0,d={authorsImageUrls:[void 0,void 0]},h=[{value:"Model Context Protocol (MCP)",id:"model-context-protocol-mcp",level:2},{value:"UI view total usage after 1M+ logs",id:"ui-view-total-usage-after-1m-logs",level:2},{value:"New Models / Updated Models",id:"new-models--updated-models",level:2},{value:"LLM Translation",id:"llm-translation",level:2},{value:"Spend Tracking Improvements",id:"spend-tracking-improvements",level:2},{value:"UI",id:"ui",level:2},{value:"Model Management",id:"model-management",level:3},{value:"Request Logs",id:"request-logs",level:3},{value:"Usage Tab",id:"usage-tab",level:3},{value:"Logging Integrations",id:"logging-integrations",level:2},{value:"Performance / Reliability Improvements",id:"performance--reliability-improvements",level:2},{value:"General Improvements",id:"general-improvements",level:2},{value:"Security",id:"security",level:2},{value:"Complete Git Diff",id:"complete-git-diff",level:2}];function p(e){const l={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(l.p,{children:"v1.65.0-stable is live now. Here are the key highlights of this release:"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:[(0,s.jsx)(l.strong,{children:"MCP Support"}),": Support for adding and using MCP servers on the LiteLLM proxy."]}),"\n",(0,s.jsxs)(l.li,{children:[(0,s.jsx)(l.strong,{children:"UI view total usage after 1M+ logs"}),": You can now view usage analytics after crossing 1M+ logs in DB."]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"model-context-protocol-mcp",children:"Model Context Protocol (MCP)"}),"\n",(0,s.jsxs)(l.p,{children:["This release introduces support for centrally adding MCP servers on LiteLLM. This allows you to add MCP server endpoints and your developers can ",(0,s.jsx)(l.code,{children:"list"})," and ",(0,s.jsx)(l.code,{children:"call"})," MCP tools through LiteLLM."]}),"\n",(0,s.jsxs)(l.p,{children:["Read more about MCP ",(0,s.jsx)(l.a,{href:"https://docs.litellm.ai/docs/mcp",children:"here"}),"."]}),"\n",(0,s.jsx)(r.A,{img:i(67883),style:{width:"100%",display:"block",margin:"2rem auto"}}),"\n",(0,s.jsx)("p",{style:{textAlign:"left",color:"#666"},children:(0,s.jsx)(l.p,{children:"Expose and use MCP servers through LiteLLM"})}),"\n",(0,s.jsx)(l.h2,{id:"ui-view-total-usage-after-1m-logs",children:"UI view total usage after 1M+ logs"}),"\n",(0,s.jsx)(l.p,{children:"This release brings the ability to view total usage analytics even after exceeding 1M+ logs in your database. We've implemented a scalable architecture that stores only aggregate usage data, resulting in significantly more efficient queries and reduced database CPU utilization."}),"\n",(0,s.jsx)(r.A,{img:i(34832),style:{width:"100%",display:"block",margin:"2rem auto"}}),"\n",(0,s.jsx)("p",{style:{textAlign:"left",color:"#666"},children:(0,s.jsx)(l.p,{children:"View total usage after 1M+ logs"})}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["\n",(0,s.jsx)(l.p,{children:"How this works:"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsx)(l.li,{children:"We now aggregate usage data into a dedicated DailyUserSpend table, significantly reducing query load and CPU usage even beyond 1M+ logs."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(l.li,{children:["\n",(0,s.jsx)(l.p,{children:"Daily Spend Breakdown API:"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsx)(l.li,{children:"Retrieve granular daily usage data (by model, provider, and API key) with a single endpoint.\nExample Request:"}),"\n"]}),"\n",(0,s.jsx)(l.pre,{children:(0,s.jsx)(l.code,{className:"language-shell",metastring:'title="Daily Spend Breakdown API" showLineNumbers',children:"curl -L -X GET 'http://localhost:4000/user/daily/activity?start_date=2025-03-20&end_date=2025-03-27' \\\n-H 'Authorization: Bearer sk-...'\n"})}),"\n",(0,s.jsx)(l.pre,{children:(0,s.jsx)(l.code,{className:"language-json",metastring:'title="Daily Spend Breakdown API Response" showLineNumbers',children:'{\n    "results": [\n        {\n            "date": "2025-03-27",\n            "metrics": {\n                "spend": 0.0177072,\n                "prompt_tokens": 111,\n                "completion_tokens": 1711,\n                "total_tokens": 1822,\n                "api_requests": 11\n            },\n            "breakdown": {\n                "models": {\n                    "gpt-4o-mini": {\n                        "spend": 1.095e-05,\n                        "prompt_tokens": 37,\n                        "completion_tokens": 9,\n                        "total_tokens": 46,\n                        "api_requests": 1\n                },\n                "providers": { "openai": { ... }, "azure_ai": { ... } },\n                "api_keys": { "3126b6eaf1...": { ... } }\n            }\n        }\n    ],\n    "metadata": {\n        "total_spend": 0.7274667,\n        "total_prompt_tokens": 280990,\n        "total_completion_tokens": 376674,\n        "total_api_requests": 14\n    }\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"new-models--updated-models",children:"New Models / Updated Models"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Support for Vertex AI gemini-2.0-flash-lite & Google AI Studio gemini-2.0-flash-lite ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9523",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support for Vertex AI Fine-Tuned LLMs ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9542",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Nova Canvas image generation support ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9525",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["OpenAI gpt-4o-transcribe support ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9517",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Added new Vertex AI text embedding model ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9476",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"llm-translation",children:"LLM Translation"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["OpenAI Web Search Tool Call Support ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9465",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Vertex AI topLogprobs support ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9518",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support for sending images and video to Vertex AI multimodal embedding ",(0,s.jsx)(l.a,{href:"https://docs.litellm.ai/docs/providers/vertex#multi-modal-embeddings",children:"Doc"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support litellm.api_base for Vertex AI + Gemini across completion, embedding, image_generation ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9516",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Bug fix for returning ",(0,s.jsx)(l.code,{children:"response_cost"})," when using litellm python SDK with LiteLLM Proxy ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/commit/6fd18651d129d606182ff4b980e95768fc43ca3d",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support for ",(0,s.jsx)(l.code,{children:"max_completion_tokens"})," on Mistral API ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9606",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Refactored Vertex AI passthrough routes - fixes unpredictable behaviour with auto-setting default_vertex_region on router model add ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9467",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"spend-tracking-improvements",children:"Spend Tracking Improvements"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Log 'api_base' on spend logs ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9509",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support for Gemini audio token cost tracking ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9535",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Fixed OpenAI audio input token cost tracking ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9535",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"ui",children:"UI"}),"\n",(0,s.jsx)(l.h3,{id:"model-management",children:"Model Management"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Allowed team admins to add/update/delete models on UI ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9572",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Added render supports_web_search on model hub ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9469",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h3,{id:"request-logs",children:"Request Logs"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Show API base and model ID on request logs ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9572",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Allow viewing keyinfo on request logs ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9568",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h3,{id:"usage-tab",children:"Usage Tab"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Added Daily User Spend Aggregate view - allows UI Usage tab to work > 1m rows ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9538",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:['Connected UI to "LiteLLM_DailyUserSpend" spend table ',(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9603",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"logging-integrations",children:"Logging Integrations"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Fixed StandardLoggingPayload for GCS Pub Sub Logging Integration ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9508",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Track ",(0,s.jsx)(l.code,{children:"litellm_model_name"})," on ",(0,s.jsx)(l.code,{children:"StandardLoggingPayload"})," ",(0,s.jsx)(l.a,{href:"https://docs.litellm.ai/docs/proxy/logging_spec#standardlogginghiddenparams",children:"Docs"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"performance--reliability-improvements",children:"Performance / Reliability Improvements"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["LiteLLM Redis semantic caching implementation ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9356",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Gracefully handle exceptions when DB is having an outage ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9533",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Allow Pods to startup + passing /health/readiness when allow_requests_on_db_unavailable: True and DB is down ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9569",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"general-improvements",children:"General Improvements"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Support for exposing MCP tools on litellm proxy ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9426",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Support discovering Gemini, Anthropic, xAI models by calling their /v1/model endpoint ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9530",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Fixed route check for non-proxy admins on JWT auth ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9454",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["Added baseline Prisma database migrations ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9565",children:"PR"})]}),"\n",(0,s.jsxs)(l.li,{children:["View all wildcard models on /model/info ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9572",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"security",children:"Security"}),"\n",(0,s.jsxs)(l.ul,{children:["\n",(0,s.jsxs)(l.li,{children:["Bumped next from 14.2.21 to 14.2.25 in UI dashboard ",(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/pull/9458",children:"PR"})]}),"\n"]}),"\n",(0,s.jsx)(l.h2,{id:"complete-git-diff",children:"Complete Git Diff"}),"\n",(0,s.jsx)(l.p,{children:(0,s.jsx)(l.a,{href:"https://github.com/BerriAI/litellm/compare/v1.63.14-stable.patch1...v1.65.0-stable",children:"Here's the complete git diff"})})]})}function c(e={}){const{wrapper:l}={...(0,n.R)(),...e.components};return l?(0,s.jsx)(l,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},67883(e,l,i){e.exports={src:Object.assign(Object.create({toString(){return this.src}}),{srcSet:i.p+"assets/ideal-img/mcp_ui.cdfd72e.640.png 640w,"+i.p+"assets/ideal-img/mcp_ui.2857485.1920.png 1920w",images:[{path:i.p+"assets/ideal-img/mcp_ui.cdfd72e.640.png",width:640,height:363},{path:i.p+"assets/ideal-img/mcp_ui.2857485.1920.png",width:1920,height:1089}],src:i.p+"assets/ideal-img/mcp_ui.cdfd72e.640.png",placeholder:void 0,width:640,height:363}),preSrc:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAAsTAAALEwEAmpwYAAAArElEQVR4nEWOMW4CQQxF92ZcIvdIm+twiTQUlFEKekS2owAF7bJLdsZjm5kXOQil+LItv//tbhyvTNOEqmJmuBnNDVWLuQFRc5dzJlRUqW7MxTkm/+ullHYdBpYl5S5SAoxEUePt88TL+xe7S8YlteNhzzw8QRFMC4vded32rNYfbE8JVNplnLjd5gcYip+ozuF7ZtOfcdO40mJXRP7BhxyTjKefp7nVWsOQfwHfIeSIkE4rfwAAAABJRU5ErkJggg=="}},73540(e){"use strict";e.exports=JSON.parse('{"permalink":"/release_notes/v1.65.0-stable","source":"@site/release_notes/v1.65.0-stable/index.md","title":"v1.65.0-stable - Model Context Protocol","description":"v1.65.0-stable is live now. Here are the key highlights of this release:","date":"2025-03-30T10:00:00.000Z","tags":[{"inline":true,"label":"mcp","permalink":"/release_notes/tags/mcp"},{"inline":true,"label":"custom_prompt_management","permalink":"/release_notes/tags/custom-prompt-management"}],"hasTruncateMarker":false,"authors":[{"name":"Krrish Dholakia","title":"CEO, LiteLLM","url":"https://www.linkedin.com/in/krish-d/","image_url":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","imageURL":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","socials":{},"key":null,"page":null},{"name":"Ishaan Jaffer","title":"CTO, LiteLLM","url":"https://www.linkedin.com/in/reffajnaahsi/","image_url":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","imageURL":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","socials":{},"key":null,"page":null}],"frontMatter":{"title":"v1.65.0-stable - Model Context Protocol","slug":"v1.65.0-stable","date":"2025-03-30T10:00:00.000Z","authors":[{"name":"Krrish Dholakia","title":"CEO, LiteLLM","url":"https://www.linkedin.com/in/krish-d/","image_url":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8","imageURL":"https://media.licdn.com/dms/image/v2/D4D03AQGrlsJ3aqpHmQ/profile-displayphoto-shrink_400_400/B4DZSAzgP7HYAg-/0/1737327772964?e=1749686400&v=beta&t=Hkl3U8Ps0VtvNxX0BNNq24b4dtX5wQaPFp6oiKCIHD8"},{"name":"Ishaan Jaffer","title":"CTO, LiteLLM","url":"https://www.linkedin.com/in/reffajnaahsi/","image_url":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg","imageURL":"https://pbs.twimg.com/profile_images/1613813310264340481/lz54oEiB_400x400.jpg"}],"tags":["mcp","custom_prompt_management"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"v1.65.4-stable","permalink":"/release_notes/v1.65.4-stable"},"nextItem":{"title":"v1.65.0 - Team Model Add - update","permalink":"/release_notes/v1.65.0"}}')}}]);