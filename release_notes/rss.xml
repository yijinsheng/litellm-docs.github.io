<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>liteLLM Blog</title>
        <link>https://docs.litellm.ai/release_notes</link>
        <description>liteLLM Blog</description>
        <lastBuildDate>Sat, 20 Dec 2025 10:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-CN</language>
        <item>
            <title><![CDATA[[Preview] v1.80.11 - Google Interactions API]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-80-11</link>
            <guid>https://docs.litellm.ai/release_notes/v1-80-11</guid>
            <pubDate>Sat, 20 Dec 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-80-11#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.80.11.rc.1</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.11</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-80-11#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Gemini 3 Flash Preview</strong> - <a href="https://docs.litellm.ai/docs/providers/gemini">Day 0 support for Google's Gemini 3 Flash Preview with reasoning capabilities</a></li>
<li><strong>Stability AI Image Generation</strong> - <a href="https://docs.litellm.ai/docs/providers/stability">New provider for Stability AI image generation and editing</a></li>
<li><strong>LiteLLM Content Filter</strong> - <a href="https://docs.litellm.ai/docs/proxy/guardrails/litellm_content_filter">Built-in guardrails for harmful content, bias, and PII detection with image support</a></li>
<li><strong>New Provider: Venice.ai</strong> - Support for Venice.ai API via providers.json</li>
<li><strong>Unified Skills API</strong> - <a href="https://docs.litellm.ai/docs/skills">Skills API works across Anthropic, Vertex, Azure, and Bedrock</a></li>
<li><strong>Azure Sentinel Logging</strong> - <a href="https://docs.litellm.ai/docs/observability/azure_sentinel">New logging integration for Azure Sentinel</a></li>
<li><strong>Guardrails Load Balancing</strong> - <a href="https://docs.litellm.ai/docs/proxy/guardrails">Load balance between multiple guardrail providers</a></li>
<li><strong>Email Budget Alerts</strong> - <a href="https://docs.litellm.ai/docs/proxy/email">Send email notifications when budgets are reached</a></li>
<li><strong>Cloudzero Integration on UI</strong> - Setup your Cloudzero Integration Directly on the UI</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cloudzero-integration-on-ui">Cloudzero Integration on UI<a href="https://docs.litellm.ai/release_notes/v1-80-11#cloudzero-integration-on-ui" class="hash-link" aria-label="Cloudzero Integration on UI的直接链接" title="Cloudzero Integration on UI的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAc0lEQVR4nFWNuw7CMBAE/f8/R08JFUgQZOLE9xx0oklW2mY0q22iyrYZ6+pMFdQMVSMiiEjCnYykuTvL8qb3D7uNv2iGVd2JOcGdVssxBqpKhuEm1EvxY1pm8u0dEeX2Ch49T8JJVBWmKJc7XJ+Fk+LH/gCW6MRTg1/h0gAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="309"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/ui_cloudzero.2349047.640.png" srcset="/assets/ideal-img/ui_cloudzero.2349047.640.png 640w,/assets/ideal-img/ui_cloudzero.7c5cc2f.1005.png 1005w" width="640" height="309"></noscript></div>
<p>Users can now configure their Cloudzero Integration directly on the UI.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-50-reduction-in-memory-usage-and-import-latency-for-the-litellm-sdk">Performance: 50% Reduction in Memory Usage and Import Latency for the LiteLLM SDK<a href="https://docs.litellm.ai/release_notes/v1-80-11#performance-50-reduction-in-memory-usage-and-import-latency-for-the-litellm-sdk" class="hash-link" aria-label="Performance: 50% Reduction in Memory Usage and Import Latency for the LiteLLM SDK的直接链接" title="Performance: 50% Reduction in Memory Usage and Import Latency for the LiteLLM SDK的直接链接">​</a></h3>
<p>We've completely restructured <code>litellm.__init__.py</code> to defer heavy imports until they're actually needed, implementing lazy loading for <strong>109 components</strong>.</p>
<p>This refactoring includes <strong>41 provider config classes</strong>, <strong>40 utility functions</strong>, cache implementations (Redis, DualCache, InMemoryCache), HTTP handlers, logging, types, and other heavy dependencies. Heavy libraries like tiktoken and boto3 are now loaded on-demand rather than eagerly at import time.</p>
<p>This makes LiteLLM especially beneficial for serverless functions, Lambda deployments, and containerized environments where cold start times and memory footprint matter.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-and-endpoints">New Providers and Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-providers-and-endpoints" class="hash-link" aria-label="New Providers and Endpoints的直接链接" title="New Providers and Endpoints的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-5-new-providers">New Providers (5 new providers)<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-providers-5-new-providers" class="hash-link" aria-label="New Providers (5 new providers)的直接链接" title="New Providers (5 new providers)的直接链接">​</a></h3>
<table><thead><tr><th>Provider</th><th>Supported LiteLLM Endpoints</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://docs.litellm.ai/docs/providers/stability">Stability AI</a></td><td><code>/images/generations</code>, <code>/images/edits</code></td><td>Stable Diffusion 3, SD3.5, image editing and generation</td></tr><tr><td>Venice.ai</td><td><code>/chat/completions</code>, <code>/messages</code>, <code>/responses</code></td><td>Venice.ai API integration via providers.json</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/pydantic_ai_agent">Pydantic AI Agents</a></td><td><code>/a2a</code></td><td>Pydantic AI agents for A2A protocol workflows</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/vertex_ai_agent_engine">VertexAI Agent Engine</a></td><td><code>/a2a</code></td><td>Google Vertex AI Agent Engine for agentic workflows</td></tr><tr><td><a href="https://docs.litellm.ai/docs/search/linkup">LinkUp Search</a></td><td><code>/search</code></td><td>LinkUp web search API integration</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-llm-api-endpoints-2-new-endpoints">New LLM API Endpoints (2 new endpoints)<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-llm-api-endpoints-2-new-endpoints" class="hash-link" aria-label="New LLM API Endpoints (2 new endpoints)的直接链接" title="New LLM API Endpoints (2 new endpoints)的直接链接">​</a></h3>
<table><thead><tr><th>Endpoint</th><th>Method</th><th>Description</th><th>Documentation</th></tr></thead><tbody><tr><td><code>/interactions</code></td><td>POST</td><td>Google Interactions API for conversational AI</td><td><a href="https://docs.litellm.ai/docs/interactions">Docs</a></td></tr><tr><td><code>/search</code></td><td>POST</td><td>RAG Search API with rerankers</td><td><a href="https://docs.litellm.ai/docs/search/index">Docs</a></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support-55-new-models">New Model Support (55+ new models)<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-model-support-55-new-models" class="hash-link" aria-label="New Model Support (55+ new models)的直接链接" title="New Model Support (55+ new models)的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Gemini</td><td><code>gemini/gemini-3-flash-preview</code></td><td>1M</td><td>$0.50</td><td>$3.00</td><td>Reasoning, vision, audio, video, PDF</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/gemini-3-flash-preview</code></td><td>1M</td><td>$0.50</td><td>$3.00</td><td>Reasoning, vision, audio, video, PDF</td></tr><tr><td>Azure AI</td><td><code>azure_ai/deepseek-v3.2</code></td><td>164K</td><td>$0.58</td><td>$1.68</td><td>Reasoning, function calling, caching</td></tr><tr><td>Azure AI</td><td><code>azure_ai/cohere-rerank-v4.0-pro</code></td><td>32K</td><td>$0.0025/query</td><td>-</td><td>Rerank</td></tr><tr><td>Azure AI</td><td><code>azure_ai/cohere-rerank-v4.0-fast</code></td><td>32K</td><td>$0.002/query</td><td>-</td><td>Rerank</td></tr><tr><td>OpenRouter</td><td><code>openrouter/openai/gpt-5.2</code></td><td>400K</td><td>$1.75</td><td>$14.00</td><td>Reasoning, vision, caching</td></tr><tr><td>OpenRouter</td><td><code>openrouter/openai/gpt-5.2-pro</code></td><td>400K</td><td>$21.00</td><td>$168.00</td><td>Reasoning, vision</td></tr><tr><td>OpenRouter</td><td><code>openrouter/mistralai/devstral-2512</code></td><td>262K</td><td>$0.15</td><td>$0.60</td><td>Function calling</td></tr><tr><td>OpenRouter</td><td><code>openrouter/mistralai/ministral-3b-2512</code></td><td>131K</td><td>$0.10</td><td>$0.10</td><td>Function calling, vision</td></tr><tr><td>OpenRouter</td><td><code>openrouter/mistralai/ministral-8b-2512</code></td><td>262K</td><td>$0.15</td><td>$0.15</td><td>Function calling, vision</td></tr><tr><td>OpenRouter</td><td><code>openrouter/mistralai/ministral-14b-2512</code></td><td>262K</td><td>$0.20</td><td>$0.20</td><td>Function calling, vision</td></tr><tr><td>OpenRouter</td><td><code>openrouter/mistralai/mistral-large-2512</code></td><td>262K</td><td>$0.50</td><td>$1.50</td><td>Function calling, vision</td></tr><tr><td>OpenAI</td><td><code>gpt-4o-transcribe-diarize</code></td><td>16K</td><td>$6.00/audio</td><td>-</td><td>Audio transcription with diarization</td></tr><tr><td>OpenAI</td><td><code>gpt-image-1.5-2025-12-16</code></td><td>-</td><td>Various</td><td>Various</td><td>Image generation</td></tr><tr><td>Stability</td><td><code>stability/sd3-large</code></td><td>-</td><td>-</td><td>$0.065/image</td><td>Image generation</td></tr><tr><td>Stability</td><td><code>stability/sd3.5-large</code></td><td>-</td><td>-</td><td>$0.065/image</td><td>Image generation</td></tr><tr><td>Stability</td><td><code>stability/stable-image-ultra</code></td><td>-</td><td>-</td><td>$0.08/image</td><td>Image generation</td></tr><tr><td>Stability</td><td><code>stability/inpaint</code></td><td>-</td><td>-</td><td>$0.005/image</td><td>Image editing</td></tr><tr><td>Stability</td><td><code>stability/outpaint</code></td><td>-</td><td>-</td><td>$0.004/image</td><td>Image editing</td></tr><tr><td>Bedrock</td><td><code>stability.stable-conservative-upscale-v1:0</code></td><td>-</td><td>-</td><td>$0.40/image</td><td>Image upscaling</td></tr><tr><td>Bedrock</td><td><code>stability.stable-creative-upscale-v1:0</code></td><td>-</td><td>-</td><td>$0.60/image</td><td>Image upscaling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/deepseek-ai/deepseek-ocr-maas</code></td><td>-</td><td>$0.30</td><td>$1.20</td><td>OCR</td></tr><tr><td>LinkUp</td><td><code>linkup/search</code></td><td>-</td><td>$5.87/1K queries</td><td>-</td><td>Web search</td></tr><tr><td>LinkUp</td><td><code>linkup/search-deep</code></td><td>-</td><td>$58.67/1K queries</td><td>-</td><td>Deep web search</td></tr><tr><td>GitHub Copilot</td><td>20+ models</td><td>Various</td><td>-</td><td>-</td><td>Chat completions</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-80-11#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Add Gemini 3 Flash Preview day 0 support with reasoning - <a href="https://github.com/BerriAI/litellm/pull/18135" target="_blank" rel="noopener noreferrer">PR #18135</a></li>
<li>Support extra_headers in batch embeddings - <a href="https://github.com/BerriAI/litellm/pull/18004" target="_blank" rel="noopener noreferrer">PR #18004</a></li>
<li>Propagate token usage when generating images - <a href="https://github.com/BerriAI/litellm/pull/17987" target="_blank" rel="noopener noreferrer">PR #17987</a></li>
<li>Use JSON instead of form-data for image edit requests - <a href="https://github.com/BerriAI/litellm/pull/18012" target="_blank" rel="noopener noreferrer">PR #18012</a></li>
<li>Fix web search requests count - <a href="https://github.com/BerriAI/litellm/pull/17921" target="_blank" rel="noopener noreferrer">PR #17921</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Use dynamic max_tokens based on model - <a href="https://github.com/BerriAI/litellm/pull/17900" target="_blank" rel="noopener noreferrer">PR #17900</a></li>
<li>Fix claude-3-7-sonnet max_tokens to 64K default - <a href="https://github.com/BerriAI/litellm/pull/17979" target="_blank" rel="noopener noreferrer">PR #17979</a></li>
<li>Add OpenAI-compatible API with modify_params=True - <a href="https://github.com/BerriAI/litellm/pull/17106" target="_blank" rel="noopener noreferrer">PR #17106</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Add Gemini 3 Flash Preview support - <a href="https://github.com/BerriAI/litellm/pull/18164" target="_blank" rel="noopener noreferrer">PR #18164</a></li>
<li>Add reasoning support for gemini-3-flash-preview - <a href="https://github.com/BerriAI/litellm/pull/18175" target="_blank" rel="noopener noreferrer">PR #18175</a></li>
<li>Fix image edit credential source - <a href="https://github.com/BerriAI/litellm/pull/18121" target="_blank" rel="noopener noreferrer">PR #18121</a></li>
<li>Pass credentials to PredictionServiceClient for custom endpoints - <a href="https://github.com/BerriAI/litellm/pull/17757" target="_blank" rel="noopener noreferrer">PR #17757</a></li>
<li>Fix multimodal embeddings for text + base64 image combinations - <a href="https://github.com/BerriAI/litellm/pull/18172" target="_blank" rel="noopener noreferrer">PR #18172</a></li>
<li>Add OCR support for DeepSeek model - <a href="https://github.com/BerriAI/litellm/pull/17971" target="_blank" rel="noopener noreferrer">PR #17971</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure_ai">Azure AI</a></strong>
<ul>
<li>Add Azure Cohere 4 reranking models - <a href="https://github.com/BerriAI/litellm/pull/17961" target="_blank" rel="noopener noreferrer">PR #17961</a></li>
<li>Add Azure DeepSeek V3.2 versions - <a href="https://github.com/BerriAI/litellm/pull/18019" target="_blank" rel="noopener noreferrer">PR #18019</a></li>
<li>Return AzureAnthropicConfig for Claude models in get_provider_chat_config - <a href="https://github.com/BerriAI/litellm/pull/18086" target="_blank" rel="noopener noreferrer">PR #18086</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI</a></strong>
<ul>
<li>Add reasoning param support for Fireworks AI models - <a href="https://github.com/BerriAI/litellm/pull/17967" target="_blank" rel="noopener noreferrer">PR #17967</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Add Qwen 2 and Qwen 3 to get_bedrock_model_id - <a href="https://github.com/BerriAI/litellm/pull/18100" target="_blank" rel="noopener noreferrer">PR #18100</a></li>
<li>Remove ttl field when routing to bedrock - <a href="https://github.com/BerriAI/litellm/pull/18049" target="_blank" rel="noopener noreferrer">PR #18049</a></li>
<li>Add Bedrock Stability image edit models - <a href="https://github.com/BerriAI/litellm/pull/18254" target="_blank" rel="noopener noreferrer">PR #18254</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/perplexity">Perplexity</a></strong>
<ul>
<li>Use API-provided cost instead of manual calculation - <a href="https://github.com/BerriAI/litellm/pull/17887" target="_blank" rel="noopener noreferrer">PR #17887</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Add diarize model for audio transcription - <a href="https://github.com/BerriAI/litellm/pull/18117" target="_blank" rel="noopener noreferrer">PR #18117</a></li>
<li>Add gpt-image-1.5-2025-12-16 in model cost map - <a href="https://github.com/BerriAI/litellm/pull/18107" target="_blank" rel="noopener noreferrer">PR #18107</a></li>
<li>Fix cost calculation of gpt-image-1 model - <a href="https://github.com/BerriAI/litellm/pull/17966" target="_blank" rel="noopener noreferrer">PR #17966</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/github_copilot">GitHub Copilot</a></strong>
<ul>
<li>Add github_copilot model info - <a href="https://github.com/BerriAI/litellm/pull/17858" target="_blank" rel="noopener noreferrer">PR #17858</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/custom_llm_server">Custom LLM</a></strong>
<ul>
<li>Add image_edit and aimage_edit support - <a href="https://github.com/BerriAI/litellm/pull/17999" target="_blank" rel="noopener noreferrer">PR #17999</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-11#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Fix pricing for Gemini 3 Flash on Vertex AI - <a href="https://github.com/BerriAI/litellm/pull/18202" target="_blank" rel="noopener noreferrer">PR #18202</a></li>
<li>Add output_cost_per_image_token for gemini-2.5-flash-image models - <a href="https://github.com/BerriAI/litellm/pull/18156" target="_blank" rel="noopener noreferrer">PR #18156</a></li>
<li>Fix properties should be non-empty for OBJECT type - <a href="https://github.com/BerriAI/litellm/pull/18237" target="_blank" rel="noopener noreferrer">PR #18237</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Qwen</a></strong>
<ul>
<li>Add qwen3-embedding-8b input per token price - <a href="https://github.com/BerriAI/litellm/pull/18018" target="_blank" rel="noopener noreferrer">PR #18018</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Fix image URL handling - <a href="https://github.com/BerriAI/litellm/pull/18139" target="_blank" rel="noopener noreferrer">PR #18139</a></li>
<li>Support Signed URLs with Query Parameters in Image Processing - <a href="https://github.com/BerriAI/litellm/pull/17976" target="_blank" rel="noopener noreferrer">PR #17976</a></li>
<li>Add none to encoding_format instead of omitting it - <a href="https://github.com/BerriAI/litellm/pull/18042" target="_blank" rel="noopener noreferrer">PR #18042</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-11#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-80-11#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>Add provider specific tools support - <a href="https://github.com/BerriAI/litellm/pull/17980" target="_blank" rel="noopener noreferrer">PR #17980</a></li>
<li>Add custom headers support - <a href="https://github.com/BerriAI/litellm/pull/18036" target="_blank" rel="noopener noreferrer">PR #18036</a></li>
<li>Fix tool calls transformation in completion bridge - <a href="https://github.com/BerriAI/litellm/pull/18226" target="_blank" rel="noopener noreferrer">PR #18226</a></li>
<li>Use list format with input_text for tool results - <a href="https://github.com/BerriAI/litellm/pull/18257" target="_blank" rel="noopener noreferrer">PR #18257</a></li>
<li>Add cost tracking in background mode - <a href="https://github.com/BerriAI/litellm/pull/18236" target="_blank" rel="noopener noreferrer">PR #18236</a></li>
<li>Fix Claude code responses API bridge errors - <a href="https://github.com/BerriAI/litellm/pull/18194" target="_blank" rel="noopener noreferrer">PR #18194</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/completion/input">Chat Completions API</a></strong>
<ul>
<li>Add support for agent skills - <a href="https://github.com/BerriAI/litellm/pull/18031" target="_blank" rel="noopener noreferrer">PR #18031</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/skills">Skills API</a></strong>
<ul>
<li>Unified Skills API works across Anthropic, Vertex, Azure, Bedrock - <a href="https://github.com/BerriAI/litellm/pull/18232" target="_blank" rel="noopener noreferrer">PR #18232</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/search/index">Search API</a></strong>
<ul>
<li>Add new RAG Search API with rerankers - <a href="https://github.com/BerriAI/litellm/pull/18217" target="_blank" rel="noopener noreferrer">PR #18217</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/interactions">Interactions API</a></strong>
<ul>
<li>Add Google Interactions API on SDK and AI Gateway - <a href="https://github.com/BerriAI/litellm/pull/18079" target="_blank" rel="noopener noreferrer">PR #18079</a>, <a href="https://github.com/BerriAI/litellm/pull/18081" target="_blank" rel="noopener noreferrer">PR #18081</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/image_edits">Image Edit API</a></strong>
<ul>
<li>Add drop_params support and fix Vertex AI config - <a href="https://github.com/BerriAI/litellm/pull/18077" target="_blank" rel="noopener noreferrer">PR #18077</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Skip adding beta headers for Vertex AI as it is not supported - <a href="https://github.com/BerriAI/litellm/pull/18037" target="_blank" rel="noopener noreferrer">PR #18037</a></li>
<li>Fix managed files endpoint - <a href="https://github.com/BerriAI/litellm/pull/18046" target="_blank" rel="noopener noreferrer">PR #18046</a></li>
<li>Allow base_model for non-Azure providers in proxy - <a href="https://github.com/BerriAI/litellm/pull/18038" target="_blank" rel="noopener noreferrer">PR #18038</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-11#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix basemodel import in guardrail translation - <a href="https://github.com/BerriAI/litellm/pull/17977" target="_blank" rel="noopener noreferrer">PR #17977</a></li>
<li>Fix No module named 'fastapi' error - <a href="https://github.com/BerriAI/litellm/pull/18239" target="_blank" rel="noopener noreferrer">PR #18239</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-80-11#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-80-11#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Virtual Keys</strong>
<ul>
<li>Add master key rotation for credentials table - <a href="https://github.com/BerriAI/litellm/pull/17952" target="_blank" rel="noopener noreferrer">PR #17952</a></li>
<li>Fix tag management to preserve encrypted fields in litellm_params - <a href="https://github.com/BerriAI/litellm/pull/17484" target="_blank" rel="noopener noreferrer">PR #17484</a></li>
<li>Fix key delete and regenerate permissions - <a href="https://github.com/BerriAI/litellm/pull/18214" target="_blank" rel="noopener noreferrer">PR #18214</a></li>
</ul>
</li>
<li><strong>Models + Endpoints</strong>
<ul>
<li>Add Models Conditional Rendering in UI - <a href="https://github.com/BerriAI/litellm/pull/18071" target="_blank" rel="noopener noreferrer">PR #18071</a></li>
<li>Add Health Check Model for Wildcard Model in UI - <a href="https://github.com/BerriAI/litellm/pull/18269" target="_blank" rel="noopener noreferrer">PR #18269</a></li>
<li>Auto Resolve Vector Store Embedding Model Config - <a href="https://github.com/BerriAI/litellm/pull/18167" target="_blank" rel="noopener noreferrer">PR #18167</a></li>
</ul>
</li>
<li><strong>Vector Stores</strong>
<ul>
<li>Add Milvus Vector Store UI support - <a href="https://github.com/BerriAI/litellm/pull/18030" target="_blank" rel="noopener noreferrer">PR #18030</a></li>
<li>Persist Vector Store Settings in Team Update - <a href="https://github.com/BerriAI/litellm/pull/18274" target="_blank" rel="noopener noreferrer">PR #18274</a></li>
</ul>
</li>
<li><strong>Logs &amp; Spend</strong>
<ul>
<li>Add LiteLLM Overhead to Logs - <a href="https://github.com/BerriAI/litellm/pull/18033" target="_blank" rel="noopener noreferrer">PR #18033</a></li>
<li>Show LiteLLM Overhead in Logs UI - <a href="https://github.com/BerriAI/litellm/pull/18034" target="_blank" rel="noopener noreferrer">PR #18034</a></li>
<li>Resolve Team ID to Team Alias in Usage Page - <a href="https://github.com/BerriAI/litellm/pull/18275" target="_blank" rel="noopener noreferrer">PR #18275</a></li>
<li>Fix Usage Page Top Key View Button Visibility - <a href="https://github.com/BerriAI/litellm/pull/18203" target="_blank" rel="noopener noreferrer">PR #18203</a></li>
</ul>
</li>
<li><strong>SSO &amp; Health</strong>
<ul>
<li>Add SSO Readiness Health Check - <a href="https://github.com/BerriAI/litellm/pull/18078" target="_blank" rel="noopener noreferrer">PR #18078</a></li>
<li>Fix /health/test_connection to resolve env variables like /chat/completions - <a href="https://github.com/BerriAI/litellm/pull/17752" target="_blank" rel="noopener noreferrer">PR #17752</a></li>
</ul>
</li>
<li><strong>CloudZero</strong>
<ul>
<li>Add CloudZero Cost Tracking UI - <a href="https://github.com/BerriAI/litellm/pull/18163" target="_blank" rel="noopener noreferrer">PR #18163</a></li>
<li>Add Delete CloudZero Settings Route and UI - <a href="https://github.com/BerriAI/litellm/pull/18168" target="_blank" rel="noopener noreferrer">PR #18168</a>, <a href="https://github.com/BerriAI/litellm/pull/18170" target="_blank" rel="noopener noreferrer">PR #18170</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Update UI path handling for non-root Docker - <a href="https://github.com/BerriAI/litellm/pull/17989" target="_blank" rel="noopener noreferrer">PR #17989</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-11#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>UI Fixes</strong>
<ul>
<li>Fix Login Page Failed To Parse JSON Error - <a href="https://github.com/BerriAI/litellm/pull/18159" target="_blank" rel="noopener noreferrer">PR #18159</a></li>
<li>Fix new user route user_id collision handling - <a href="https://github.com/BerriAI/litellm/pull/17559" target="_blank" rel="noopener noreferrer">PR #17559</a></li>
<li>Fix Callback Environment Variables Casing - <a href="https://github.com/BerriAI/litellm/pull/17912" target="_blank" rel="noopener noreferrer">PR #17912</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-integrations">AI Integrations<a href="https://docs.litellm.ai/release_notes/v1-80-11#ai-integrations" class="hash-link" aria-label="AI Integrations的直接链接" title="AI Integrations的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging">Logging<a href="https://docs.litellm.ai/release_notes/v1-80-11#logging" class="hash-link" aria-label="Logging的直接链接" title="Logging的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/observability/azure_sentinel">Azure Sentinel</a></strong>
<ul>
<li>Add new Azure Sentinel Logger integration - <a href="https://github.com/BerriAI/litellm/pull/18146" target="_blank" rel="noopener noreferrer">PR #18146</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#prometheus">Prometheus</a></strong>
<ul>
<li>Add extraction of top level metadata for custom labels - <a href="https://github.com/BerriAI/litellm/pull/18087" target="_blank" rel="noopener noreferrer">PR #18087</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong>
<ul>
<li>Fix not working log_failure_event - <a href="https://github.com/BerriAI/litellm/pull/18234" target="_blank" rel="noopener noreferrer">PR #18234</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/observability/phoenix_integration">Arize Phoenix</a></strong>
<ul>
<li>Fix nested spans - <a href="https://github.com/BerriAI/litellm/pull/18102" target="_blank" rel="noopener noreferrer">PR #18102</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Change extra_headers to additional_headers - <a href="https://github.com/BerriAI/litellm/pull/17950" target="_blank" rel="noopener noreferrer">PR #17950</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-80-11#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/litellm_content_filter">LiteLLM Content Filter</a></strong>
<ul>
<li>Add built-in guardrails for harmful content, bias, etc. - <a href="https://github.com/BerriAI/litellm/pull/18029" target="_blank" rel="noopener noreferrer">PR #18029</a></li>
<li>Add support for running content filters on images - <a href="https://github.com/BerriAI/litellm/pull/18044" target="_blank" rel="noopener noreferrer">PR #18044</a></li>
<li>Add support for Brazil PII field - <a href="https://github.com/BerriAI/litellm/pull/18076" target="_blank" rel="noopener noreferrer">PR #18076</a></li>
<li>Add configurable guardrail options for content filtering - <a href="https://github.com/BerriAI/litellm/pull/18007" target="_blank" rel="noopener noreferrer">PR #18007</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/adding_provider/generic_guardrail_api">Guardrails API</a></strong>
<ul>
<li>Support LLM tool call response checks on <code>/chat/completions</code>, <code>/v1/responses</code>, <code>/v1/messages</code> - <a href="https://github.com/BerriAI/litellm/pull/17619" target="_blank" rel="noopener noreferrer">PR #17619</a></li>
<li>Add guardrails load balancing - <a href="https://github.com/BerriAI/litellm/pull/18181" target="_blank" rel="noopener noreferrer">PR #18181</a></li>
<li>Fix guardrails for passthrough endpoint - <a href="https://github.com/BerriAI/litellm/pull/18109" target="_blank" rel="noopener noreferrer">PR #18109</a></li>
<li>Add headers to metadata for guardrails on pass-through endpoints - <a href="https://github.com/BerriAI/litellm/pull/17992" target="_blank" rel="noopener noreferrer">PR #17992</a></li>
<li>Various fixes for guardrail on OpenRouter models - <a href="https://github.com/BerriAI/litellm/pull/18085" target="_blank" rel="noopener noreferrer">PR #18085</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/lakera_ai">Lakera</a></strong>
<ul>
<li>Add monitor mode for Lakera - <a href="https://github.com/BerriAI/litellm/pull/18084" target="_blank" rel="noopener noreferrer">PR #18084</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/pillar_security">Pillar Security</a></strong>
<ul>
<li>Add masking support and MCP call support - <a href="https://github.com/BerriAI/litellm/pull/17959" target="_blank" rel="noopener noreferrer">PR #17959</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/bedrock">Bedrock Guardrails</a></strong>
<ul>
<li>Add support for Bedrock image guardrails - <a href="https://github.com/BerriAI/litellm/pull/18115" target="_blank" rel="noopener noreferrer">PR #18115</a></li>
<li>Guardrails block action takes precedence over masking - <a href="https://github.com/BerriAI/litellm/pull/17968" target="_blank" rel="noopener noreferrer">PR #17968</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="secret-managers">Secret Managers<a href="https://docs.litellm.ai/release_notes/v1-80-11#secret-managers" class="hash-link" aria-label="Secret Managers的直接链接" title="Secret Managers的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/secret_managers/hashicorp_vault">HashiCorp Vault</a></strong>
<ul>
<li>Add documentation for configurable Vault mount - <a href="https://github.com/BerriAI/litellm/pull/18082" target="_blank" rel="noopener noreferrer">PR #18082</a></li>
<li>Add per-team Vault configuration - <a href="https://github.com/BerriAI/litellm/pull/18150" target="_blank" rel="noopener noreferrer">PR #18150</a></li>
</ul>
</li>
<li><strong>UI</strong>
<ul>
<li>Add secret manager settings controls to team management UI - <a href="https://github.com/BerriAI/litellm/pull/18149" target="_blank" rel="noopener noreferrer">PR #18149</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-80-11#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Email Budget Alerts</strong> - Send email notifications when budgets are reached - <a href="https://github.com/BerriAI/litellm/pull/17995" target="_blank" rel="noopener noreferrer">PR #17995</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-80-11#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>Auth Header Propagation</strong> - Add MCP auth header propagation - <a href="https://github.com/BerriAI/litellm/pull/17963" target="_blank" rel="noopener noreferrer">PR #17963</a></li>
<li><strong>Fix deepcopy error</strong> - Fix MCP tool call deepcopy error when processing requests - <a href="https://github.com/BerriAI/litellm/pull/18010" target="_blank" rel="noopener noreferrer">PR #18010</a></li>
<li><strong>Fix list tool</strong> - Fix MCP list_tools not working without database connection - <a href="https://github.com/BerriAI/litellm/pull/18161" target="_blank" rel="noopener noreferrer">PR #18161</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agent-gateway-a2a">Agent Gateway (A2A)<a href="https://docs.litellm.ai/release_notes/v1-80-11#agent-gateway-a2a" class="hash-link" aria-label="Agent Gateway (A2A)的直接链接" title="Agent Gateway (A2A)的直接链接">​</a></h2>
<ul>
<li><strong>New Provider: Agent Gateway</strong> - Add pydantic ai agents support - <a href="https://github.com/BerriAI/litellm/pull/18013" target="_blank" rel="noopener noreferrer">PR #18013</a></li>
<li><strong>VertexAI Agent Engine</strong> - Add Vertex AI Agent Engine provider - <a href="https://github.com/BerriAI/litellm/pull/18014" target="_blank" rel="noopener noreferrer">PR #18014</a></li>
<li><strong>Fix model extraction</strong> - Fix get_model_from_request() to extract model ID from Vertex AI passthrough URLs - <a href="https://github.com/BerriAI/litellm/pull/18097" target="_blank" rel="noopener noreferrer">PR #18097</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-80-11#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>Lazy Imports</strong> - Use per-attribute lazy imports and extract shared constants - <a href="https://github.com/BerriAI/litellm/pull/17994" target="_blank" rel="noopener noreferrer">PR #17994</a></li>
<li><strong>Lazy Load HTTP Handlers</strong> - Lazy load http handlers - <a href="https://github.com/BerriAI/litellm/pull/17997" target="_blank" rel="noopener noreferrer">PR #17997</a></li>
<li><strong>Lazy Load Caches</strong> - Lazy load caches - <a href="https://github.com/BerriAI/litellm/pull/18001" target="_blank" rel="noopener noreferrer">PR #18001</a></li>
<li><strong>Lazy Load Types</strong> - Lazy load bedrock types, .types.utils, GuardrailItem - <a href="https://github.com/BerriAI/litellm/pull/18053" target="_blank" rel="noopener noreferrer">PR #18053</a>, <a href="https://github.com/BerriAI/litellm/pull/18054" target="_blank" rel="noopener noreferrer">PR #18054</a>, <a href="https://github.com/BerriAI/litellm/pull/18072" target="_blank" rel="noopener noreferrer">PR #18072</a></li>
<li><strong>Lazy Load Configs</strong> - Lazy load 41 configuration classes - <a href="https://github.com/BerriAI/litellm/pull/18267" target="_blank" rel="noopener noreferrer">PR #18267</a></li>
<li><strong>Lazy Load Client Decorators</strong> - Lazy load heavy client decorator imports - <a href="https://github.com/BerriAI/litellm/pull/18064" target="_blank" rel="noopener noreferrer">PR #18064</a></li>
<li><strong>Prisma Build Time</strong> - Download Prisma binaries at build time instead of runtime for security restricted environments - <a href="https://github.com/BerriAI/litellm/pull/17695" target="_blank" rel="noopener noreferrer">PR #17695</a></li>
<li><strong>Docker Alpine</strong> - Add libsndfile to Alpine image for ARM64 audio processing - <a href="https://github.com/BerriAI/litellm/pull/18092" target="_blank" rel="noopener noreferrer">PR #18092</a></li>
<li><strong>Security</strong> - Prevent LiteLLM API key leakage on /health endpoint failures - <a href="https://github.com/BerriAI/litellm/pull/18133" target="_blank" rel="noopener noreferrer">PR #18133</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-80-11#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li><strong>SAP Docs</strong> - Update SAP documentation - <a href="https://github.com/BerriAI/litellm/pull/17974" target="_blank" rel="noopener noreferrer">PR #17974</a></li>
<li><strong>Pydantic AI Agents</strong> - Add docs on using pydantic ai agents with LiteLLM A2A gateway - <a href="https://github.com/BerriAI/litellm/pull/18026" target="_blank" rel="noopener noreferrer">PR #18026</a></li>
<li><strong>Vertex AI Agent Engine</strong> - Add Vertex AI Agent Engine documentation - <a href="https://github.com/BerriAI/litellm/pull/18027" target="_blank" rel="noopener noreferrer">PR #18027</a></li>
<li><strong>Router Order</strong> - Add router order parameter documentation - <a href="https://github.com/BerriAI/litellm/pull/18045" target="_blank" rel="noopener noreferrer">PR #18045</a></li>
<li><strong>Secret Manager Settings</strong> - Improve secret manager settings documentation - <a href="https://github.com/BerriAI/litellm/pull/18235" target="_blank" rel="noopener noreferrer">PR #18235</a></li>
<li><strong>Gemini 3 Flash</strong> - Add version requirement in Gemini 3 Flash blog - <a href="https://github.com/BerriAI/litellm/pull/18227" target="_blank" rel="noopener noreferrer">PR #18227</a></li>
<li><strong>README</strong> - Expand Responses API section and update endpoints - <a href="https://github.com/BerriAI/litellm/pull/17354" target="_blank" rel="noopener noreferrer">PR #17354</a></li>
<li><strong>Amazon Nova</strong> - Add Amazon Nova to sidebar and supported models - <a href="https://github.com/BerriAI/litellm/pull/18220" target="_blank" rel="noopener noreferrer">PR #18220</a></li>
<li><strong>Benchmarks</strong> - Add infrastructure recommendations to benchmarks documentation - <a href="https://github.com/BerriAI/litellm/pull/18264" target="_blank" rel="noopener noreferrer">PR #18264</a></li>
<li><strong>Broken Links</strong> - Fix broken link corrections - <a href="https://github.com/BerriAI/litellm/pull/18104" target="_blank" rel="noopener noreferrer">PR #18104</a></li>
<li><strong>README Fixes</strong> - Various README improvements - <a href="https://github.com/BerriAI/litellm/pull/18206" target="_blank" rel="noopener noreferrer">PR #18206</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure--cicd">Infrastructure / CI/CD<a href="https://docs.litellm.ai/release_notes/v1-80-11#infrastructure--cicd" class="hash-link" aria-label="Infrastructure / CI/CD的直接链接" title="Infrastructure / CI/CD的直接链接">​</a></h2>
<ul>
<li><strong>PR Templates</strong> - Add LiteLLM team PR template and CI/CD rules - <a href="https://github.com/BerriAI/litellm/pull/17983" target="_blank" rel="noopener noreferrer">PR #17983</a>, <a href="https://github.com/BerriAI/litellm/pull/17985" target="_blank" rel="noopener noreferrer">PR #17985</a></li>
<li><strong>Issue Labeling</strong> - Improve issue labeling with component dropdown and more provider keywords - <a href="https://github.com/BerriAI/litellm/pull/17957" target="_blank" rel="noopener noreferrer">PR #17957</a></li>
<li><strong>PR Template Cleanup</strong> - Remove redundant fields from PR template - <a href="https://github.com/BerriAI/litellm/pull/17956" target="_blank" rel="noopener noreferrer">PR #17956</a></li>
<li><strong>Dependencies</strong> - Bump altcha-lib from 1.3.0 to 1.4.1 - <a href="https://github.com/BerriAI/litellm/pull/18017" target="_blank" rel="noopener noreferrer">PR #18017</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-80-11#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@dongbin-lunark made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17757" target="_blank" rel="noopener noreferrer">PR #17757</a></li>
<li>@qdrddr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18004" target="_blank" rel="noopener noreferrer">PR #18004</a></li>
<li>@donicrosby made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17962" target="_blank" rel="noopener noreferrer">PR #17962</a></li>
<li>@NicolaivdSmagt made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17992" target="_blank" rel="noopener noreferrer">PR #17992</a></li>
<li>@Reapor-Yurnero made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18085" target="_blank" rel="noopener noreferrer">PR #18085</a></li>
<li>@jk-f5 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18086" target="_blank" rel="noopener noreferrer">PR #18086</a></li>
<li>@castrapel made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18077" target="_blank" rel="noopener noreferrer">PR #18077</a></li>
<li>@dtikhonov made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17484" target="_blank" rel="noopener noreferrer">PR #17484</a></li>
<li>@opleonnn made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18175" target="_blank" rel="noopener noreferrer">PR #18175</a></li>
<li>@eurogig made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/18084" target="_blank" rel="noopener noreferrer">PR #18084</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-80-11#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.80.10-nightly...v1.80.11" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[Preview] v1.80.10.rc.1 - Agent Gateway: Azure Foundry & Bedrock AgentCore]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-80-10</link>
            <guid>https://docs.litellm.ai/release_notes/v1-80-10</guid>
            <pubDate>Sat, 13 Dec 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-80-10#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.80.10.rc.1</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.10</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-80-10#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Agent (A2A) Gateway with Cost Tracking</strong> - <a href="https://docs.litellm.ai/docs/a2a_cost_tracking">Track agent costs per query, per token pricing, and view agent usage in the dashboard</a></li>
<li><strong>2 New Agent Providers</strong> - <a href="https://docs.litellm.ai/docs/providers/langgraph">LangGraph Agents</a> and <a href="https://docs.litellm.ai/docs/providers/azure_ai_agents">Azure AI Foundry Agents</a> for agentic workflows</li>
<li><strong>New Provider: SAP Gen AI Hub</strong> - <a href="https://docs.litellm.ai/docs/providers/sap">Full support for SAP Generative AI Hub with chat completions</a></li>
<li><strong>New Bedrock Writer Models</strong> - Add Palmyra-X4 and Palmyra-X5 models on Bedrock</li>
<li><strong>OpenAI GPT-5.2 Models</strong> - Full support for GPT-5.2, GPT-5.2-pro, and Azure GPT-5.2 models with reasoning support</li>
<li><strong>227 New Fireworks AI Models</strong> - Comprehensive model coverage for Fireworks AI platform</li>
<li><strong>MCP Support on /chat/completions</strong> - <a href="https://docs.litellm.ai/docs/mcp">Use MCP servers directly via chat completions endpoint</a></li>
<li><strong>Performance Improvements</strong> - Reduced memory leaks by 50%</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-gateway---4-new-agent-providers">Agent Gateway - 4 New Agent Providers<a href="https://docs.litellm.ai/release_notes/v1-80-10#agent-gateway---4-new-agent-providers" class="hash-link" aria-label="Agent Gateway - 4 New Agent Providers的直接链接" title="Agent Gateway - 4 New Agent Providers的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAtklEQVR4nAXB207CMACA4d6qiDpY18UVx1h3YCsnIdoQ5iRxMdGohEC88v3f4vf7hK9n+NGMS8+QFI5y0VKt38nXXwzyT2R9JqiPiCvPcOGl+HpBZhvi0jGavhCvftBPfwT2F1mfEP1wTk/NUaljbFuUcSizJaw6otWBYfGBZzrEXdxwO265L/ckyzeCokFmO3yzRaaOG/1MP9oghqZjUH4TZq8k+SN6siR8sMioQmrLtarpySn/dqVJj/uoxrMAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="331"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/a2a_gateway2.85fac86.640.png" srcset="/assets/ideal-img/a2a_gateway2.85fac86.640.png 640w,/assets/ideal-img/a2a_gateway2.59b6608.1920.png 1920w" width="640" height="331"></noscript></div>
<br>
<p>This release adds support for agents from the following providers:</p>
<ul>
<li><strong>LangGraph Agents</strong> - Deploy and manage LangGraph-based agents</li>
<li><strong>Azure AI Foundry Agents</strong> - Enterprise agent deployments on Azure</li>
<li><strong>Bedrock AgentCore</strong> - AWS Bedrock agent integration</li>
<li><strong>A2A Agents</strong> - Agent-to-Agent protocol support</li>
</ul>
<p>AI Gateway admins can now add agents from any of these providers, and developers can invoke them through a unified interface using the A2A protocol.</p>
<p>For all agent requests running through the AI Gateway, LiteLLM automatically tracks request/response logs, cost, and token usage.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-a2a-usage-ui">Agent (A2A) Usage UI<a href="https://docs.litellm.ai/release_notes/v1-80-10#agent-a2a-usage-ui" class="hash-link" aria-label="Agent (A2A) Usage UI的直接链接" title="Agent (A2A) Usage UI的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAi0lEQVR4nDWNUQrCQAxE9/7441U8gMdQ6ZetUvRnW6htN8lunmy1Aw8CM5MJMUYq0zQhIn8U1R8pCapCaNuWpmnougfzvJBqwAruTilOzsYwKMHM2FmWFc95M+u3YhlVQyQT9rkkAl64fxLXcQZ3Ui548e0OtSmqeDbeq3K89RwuPadn5PwaqVqt8AWD4MDKrwIwXAAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/agent_usage.fe62c3e.640.png" srcset="/assets/ideal-img/agent_usage.fe62c3e.640.png 640w,/assets/ideal-img/agent_usage.186e6c2.1920.png 1920w" width="640" height="334"></noscript></div>
<p>Users can now filter usage statistics by agents, providing the same granular filtering capabilities available for teams, organizations, and customers.</p>
<p><strong>Details:</strong></p>
<ul>
<li>Filter usage analytics, spend logs, and activity metrics by agent ID</li>
<li>View breakdowns on a per-agent basis</li>
<li>Consistent filtering experience across all usage and analytics views</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-and-endpoints">New Providers and Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-providers-and-endpoints" class="hash-link" aria-label="New Providers and Endpoints的直接链接" title="New Providers and Endpoints的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-5-new-providers">New Providers (5 new providers)<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-providers-5-new-providers" class="hash-link" aria-label="New Providers (5 new providers)的直接链接" title="New Providers (5 new providers)的直接链接">​</a></h3>
<table><thead><tr><th>Provider</th><th>Supported LiteLLM Endpoints</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://docs.litellm.ai/docs/providers/sap">SAP Gen AI Hub</a></td><td><code>/chat/completions</code>, <code>/messages</code>, <code>/responses</code></td><td>SAP Generative AI Hub integration for enterprise AI</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/langgraph">LangGraph</a></td><td><code>/chat/completions</code>, <code>/messages</code>, <code>/responses</code>, <code>/a2a</code></td><td>LangGraph agents for agentic workflows</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/azure_ai_agents">Azure AI Foundry Agents</a></td><td><code>/chat/completions</code>, <code>/messages</code>, <code>/responses</code>, <code>/a2a</code></td><td>Azure AI Foundry Agents for enterprise agent deployments</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/voyage">Voyage AI Rerank</a></td><td><code>/rerank</code></td><td>Voyage AI rerank models support</td></tr><tr><td><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI Rerank</a></td><td><code>/rerank</code></td><td>Fireworks AI rerank endpoint support</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-llm-api-endpoints-4-new-endpoints">New LLM API Endpoints (4 new endpoints)<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-llm-api-endpoints-4-new-endpoints" class="hash-link" aria-label="New LLM API Endpoints (4 new endpoints)的直接链接" title="New LLM API Endpoints (4 new endpoints)的直接链接">​</a></h3>
<table><thead><tr><th>Endpoint</th><th>Method</th><th>Description</th><th>Documentation</th></tr></thead><tbody><tr><td><code>/containers/{id}/files</code></td><td>GET</td><td>List files in a container</td><td><a href="https://docs.litellm.ai/docs/container_files">Docs</a></td></tr><tr><td><code>/containers/{id}/files/{file_id}</code></td><td>GET</td><td>Retrieve container file metadata</td><td><a href="https://docs.litellm.ai/docs/container_files">Docs</a></td></tr><tr><td><code>/containers/{id}/files/{file_id}</code></td><td>DELETE</td><td>Delete a file from a container</td><td><a href="https://docs.litellm.ai/docs/container_files">Docs</a></td></tr><tr><td><code>/containers/{id}/files/{file_id}/content</code></td><td>GET</td><td>Retrieve container file content</td><td><a href="https://docs.litellm.ai/docs/container_files">Docs</a></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support-270-new-models">New Model Support (270+ new models)<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-model-support-270-new-models" class="hash-link" aria-label="New Model Support (270+ new models)的直接链接" title="New Model Support (270+ new models)的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>OpenAI</td><td><code>gpt-5.2</code></td><td>400K</td><td>$1.75</td><td>$14.00</td><td>Reasoning, vision, PDF, caching</td></tr><tr><td>OpenAI</td><td><code>gpt-5.2-pro</code></td><td>400K</td><td>$21.00</td><td>$168.00</td><td>Reasoning, web search, vision</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.2</code></td><td>400K</td><td>$1.75</td><td>$14.00</td><td>Reasoning, vision, PDF, caching</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.2-pro</code></td><td>400K</td><td>$21.00</td><td>$168.00</td><td>Reasoning, web search</td></tr><tr><td>Bedrock</td><td><code>us.writer.palmyra-x4-v1:0</code></td><td>128K</td><td>$2.50</td><td>$10.00</td><td>Function calling, PDF input</td></tr><tr><td>Bedrock</td><td><code>us.writer.palmyra-x5-v1:0</code></td><td>1M</td><td>$0.60</td><td>$6.00</td><td>Function calling, PDF input</td></tr><tr><td>Bedrock</td><td><code>eu.anthropic.claude-opus-4-5-20251101-v1:0</code></td><td>200K</td><td>$5.00</td><td>$25.00</td><td>Reasoning, computer use, vision</td></tr><tr><td>Bedrock</td><td><code>google.gemma-3-12b-it</code></td><td>128K</td><td>$0.10</td><td>$0.30</td><td>Audio input</td></tr><tr><td>Bedrock</td><td><code>moonshot.kimi-k2-thinking</code></td><td>128K</td><td>$0.60</td><td>$2.50</td><td>Reasoning</td></tr><tr><td>Bedrock</td><td><code>nvidia.nemotron-nano-12b-v2</code></td><td>128K</td><td>$0.20</td><td>$0.60</td><td>Vision</td></tr><tr><td>Bedrock</td><td><code>qwen.qwen3-next-80b-a3b</code></td><td>128K</td><td>$0.15</td><td>$1.20</td><td>Function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/deepseek-ai/deepseek-v3.2-maas</code></td><td>164K</td><td>$0.56</td><td>$1.68</td><td>Reasoning, caching</td></tr><tr><td>Mistral</td><td><code>mistral/codestral-2508</code></td><td>256K</td><td>$0.30</td><td>$0.90</td><td>Function calling</td></tr><tr><td>Mistral</td><td><code>mistral/devstral-2512</code></td><td>256K</td><td>$0.40</td><td>$2.00</td><td>Function calling</td></tr><tr><td>Mistral</td><td><code>mistral/labs-devstral-small-2512</code></td><td>256K</td><td>$0.10</td><td>$0.30</td><td>Function calling</td></tr><tr><td>Cerebras</td><td><code>cerebras/zai-glm-4.6</code></td><td>128K</td><td>-</td><td>-</td><td>Chat completions</td></tr><tr><td>NVIDIA NIM</td><td><code>nvidia_nim/ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2</code></td><td>-</td><td>Free</td><td>Free</td><td>Rerank</td></tr><tr><td>Voyage</td><td><code>voyage/rerank-2.5</code></td><td>32K</td><td>$0.05/1K tokens</td><td>-</td><td>Rerank</td></tr><tr><td>Fireworks AI</td><td>227 new models</td><td>Various</td><td>Various</td><td>Various</td><td>Full model catalog</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-80-10#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Add support for OpenAI GPT-5.2 models with reasoning_effort='xhigh' - <a href="https://github.com/BerriAI/litellm/pull/17836" target="_blank" rel="noopener noreferrer">PR #17836</a>, <a href="https://github.com/BerriAI/litellm/pull/17875" target="_blank" rel="noopener noreferrer">PR #17875</a></li>
<li>Include 'user' param for responses API models - <a href="https://github.com/BerriAI/litellm/pull/17648" target="_blank" rel="noopener noreferrer">PR #17648</a></li>
<li>Use optimized async http client for text completions - <a href="https://github.com/BerriAI/litellm/pull/17831" target="_blank" rel="noopener noreferrer">PR #17831</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong>
<ul>
<li>Add Azure GPT-5.2 models support - <a href="https://github.com/BerriAI/litellm/pull/17866" target="_blank" rel="noopener noreferrer">PR #17866</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure_ai">Azure AI</a></strong>
<ul>
<li>Fix Azure AI Anthropic api-key header and passthrough cost calculation - <a href="https://github.com/BerriAI/litellm/pull/17656" target="_blank" rel="noopener noreferrer">PR #17656</a></li>
<li>Remove unsupported params from Azure AI Anthropic requests - <a href="https://github.com/BerriAI/litellm/pull/17822" target="_blank" rel="noopener noreferrer">PR #17822</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Prevent duplicate tool_result blocks with same tool - <a href="https://github.com/BerriAI/litellm/pull/17632" target="_blank" rel="noopener noreferrer">PR #17632</a></li>
<li>Handle partial JSON chunks in streaming responses - <a href="https://github.com/BerriAI/litellm/pull/17493" target="_blank" rel="noopener noreferrer">PR #17493</a></li>
<li>Preserve server_tool_use and web_search_tool_result in multi-turn conversations - <a href="https://github.com/BerriAI/litellm/pull/17746" target="_blank" rel="noopener noreferrer">PR #17746</a></li>
<li>Capture web_search_tool_result in streaming for multi-turn conversations - <a href="https://github.com/BerriAI/litellm/pull/17798" target="_blank" rel="noopener noreferrer">PR #17798</a></li>
<li>Add retrieve batches and retrieve file content support - <a href="https://github.com/BerriAI/litellm/pull/17700" target="_blank" rel="noopener noreferrer">PR #17700</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Add new Bedrock OSS models to model list - <a href="https://github.com/BerriAI/litellm/pull/17638" target="_blank" rel="noopener noreferrer">PR #17638</a></li>
<li>Add Bedrock Writer models (Palmyra-X4, Palmyra-X5) - <a href="https://github.com/BerriAI/litellm/pull/17685" target="_blank" rel="noopener noreferrer">PR #17685</a></li>
<li>Add EU Claude Opus 4.5 model - <a href="https://github.com/BerriAI/litellm/pull/17897" target="_blank" rel="noopener noreferrer">PR #17897</a></li>
<li>Add serviceTier support for Converse API - <a href="https://github.com/BerriAI/litellm/pull/17810" target="_blank" rel="noopener noreferrer">PR #17810</a></li>
<li>Fix header forwarding with custom API for Bedrock embeddings - <a href="https://github.com/BerriAI/litellm/pull/17872" target="_blank" rel="noopener noreferrer">PR #17872</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Add support for computer use for Gemini - <a href="https://github.com/BerriAI/litellm/pull/17756" target="_blank" rel="noopener noreferrer">PR #17756</a></li>
<li>Handle context window errors - <a href="https://github.com/BerriAI/litellm/pull/17751" target="_blank" rel="noopener noreferrer">PR #17751</a></li>
<li>Add speechConfig to GenerationConfig for Gemini TTS - <a href="https://github.com/BerriAI/litellm/pull/17851" target="_blank" rel="noopener noreferrer">PR #17851</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Add DeepSeek-V3.2 model support - <a href="https://github.com/BerriAI/litellm/pull/17770" target="_blank" rel="noopener noreferrer">PR #17770</a></li>
<li>Preserve systemInstructions for generate content request - <a href="https://github.com/BerriAI/litellm/pull/17803" target="_blank" rel="noopener noreferrer">PR #17803</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong>
<ul>
<li>Add Codestral 2508, Devstral 2512 models - <a href="https://github.com/BerriAI/litellm/pull/17801" target="_blank" rel="noopener noreferrer">PR #17801</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/cerebras">Cerebras</a></strong>
<ul>
<li>Add zai-glm-4.6 model support - <a href="https://github.com/BerriAI/litellm/pull/17683" target="_blank" rel="noopener noreferrer">PR #17683</a></li>
<li>Fix context window errors not recognized - <a href="https://github.com/BerriAI/litellm/pull/17587" target="_blank" rel="noopener noreferrer">PR #17587</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/deepseek">DeepSeek</a></strong>
<ul>
<li>Add native support for thinking and reasoning_effort params - <a href="https://github.com/BerriAI/litellm/pull/17712" target="_blank" rel="noopener noreferrer">PR #17712</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/nvidia_nim_rerank">NVIDIA NIM Rerank</a></strong>
<ul>
<li>Add llama-3.2-nv-rerankqa-1b-v2 rerank model - <a href="https://github.com/BerriAI/litellm/pull/17670" target="_blank" rel="noopener noreferrer">PR #17670</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI</a></strong>
<ul>
<li>Add 227 new Fireworks AI models - <a href="https://github.com/BerriAI/litellm/pull/17692" target="_blank" rel="noopener noreferrer">PR #17692</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/dashscope">Dashscope</a></strong>
<ul>
<li>Fix default base_url error - <a href="https://github.com/BerriAI/litellm/pull/17584" target="_blank" rel="noopener noreferrer">PR #17584</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-10#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Fix missing content in Anthropic to OpenAI conversion - <a href="https://github.com/BerriAI/litellm/pull/17693" target="_blank" rel="noopener noreferrer">PR #17693</a></li>
<li>Avoid error when we have just the tool_calls in input - <a href="https://github.com/BerriAI/litellm/pull/17753" target="_blank" rel="noopener noreferrer">PR #17753</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong>
<ul>
<li>Fix error about encoding video id for Azure - <a href="https://github.com/BerriAI/litellm/pull/17708" target="_blank" rel="noopener noreferrer">PR #17708</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure_ai">Azure AI</a></strong>
<ul>
<li>Fix LLM provider for azure_ai in model map - <a href="https://github.com/BerriAI/litellm/pull/17805" target="_blank" rel="noopener noreferrer">PR #17805</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/watsonx">Watsonx</a></strong>
<ul>
<li>Fix Watsonx Audio Transcription to only send supported params to API - <a href="https://github.com/BerriAI/litellm/pull/17840" target="_blank" rel="noopener noreferrer">PR #17840</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/routing">Router</a></strong>
<ul>
<li>Handle tools=None in completion requests - <a href="https://github.com/BerriAI/litellm/pull/17684" target="_blank" rel="noopener noreferrer">PR #17684</a></li>
<li>Add minimum request threshold for error rate cooldown - <a href="https://github.com/BerriAI/litellm/pull/17464" target="_blank" rel="noopener noreferrer">PR #17464</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-10#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-80-10#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>Add usage details in responses usage object - <a href="https://github.com/BerriAI/litellm/pull/17641" target="_blank" rel="noopener noreferrer">PR #17641</a></li>
<li>Fix error for response API polling - <a href="https://github.com/BerriAI/litellm/pull/17654" target="_blank" rel="noopener noreferrer">PR #17654</a></li>
<li>Fix streaming tool_calls being dropped when text + tool_calls - <a href="https://github.com/BerriAI/litellm/pull/17652" target="_blank" rel="noopener noreferrer">PR #17652</a></li>
<li>Transform image content in tool results for Responses API - <a href="https://github.com/BerriAI/litellm/pull/17799" target="_blank" rel="noopener noreferrer">PR #17799</a></li>
<li>Fix responses api not applying tpm rate limits on api keys - <a href="https://github.com/BerriAI/litellm/pull/17707" target="_blank" rel="noopener noreferrer">PR #17707</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/containers">Containers API</a></strong>
<ul>
<li>Allow using LIST, Create Containers using custom-llm-provider - <a href="https://github.com/BerriAI/litellm/pull/17740" target="_blank" rel="noopener noreferrer">PR #17740</a></li>
<li>Add new container API file management + UI Interface - <a href="https://github.com/BerriAI/litellm/pull/17745" target="_blank" rel="noopener noreferrer">PR #17745</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/rerank">Rerank API</a></strong>
<ul>
<li>Add support for forwarding client headers in /rerank endpoint - <a href="https://github.com/BerriAI/litellm/pull/17873" target="_blank" rel="noopener noreferrer">PR #17873</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/files_endpoints">Files API</a></strong>
<ul>
<li>Add support for expires_after param in Files endpoint - <a href="https://github.com/BerriAI/litellm/pull/17860" target="_blank" rel="noopener noreferrer">PR #17860</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/videos">Video API</a></strong>
<ul>
<li>Use litellm params for all videos APIs - <a href="https://github.com/BerriAI/litellm/pull/17732" target="_blank" rel="noopener noreferrer">PR #17732</a></li>
<li>Respect videos content db creds - <a href="https://github.com/BerriAI/litellm/pull/17771" target="_blank" rel="noopener noreferrer">PR #17771</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/embedding">Embeddings API</a></strong>
<ul>
<li>Fix handling token array input decoding for embeddings - <a href="https://github.com/BerriAI/litellm/pull/17468" target="_blank" rel="noopener noreferrer">PR #17468</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/completion/input">Chat Completions API</a></strong>
<ul>
<li>Add v0 target storage support - store files in Azure AI storage and use with chat completions API - <a href="https://github.com/BerriAI/litellm/pull/17758" target="_blank" rel="noopener noreferrer">PR #17758</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">generateContent API</a></strong>
<ul>
<li>Support model names with slashes on Gemini generateContent endpoints - <a href="https://github.com/BerriAI/litellm/pull/17743" target="_blank" rel="noopener noreferrer">PR #17743</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Use audio content for caching - <a href="https://github.com/BerriAI/litellm/pull/17651" target="_blank" rel="noopener noreferrer">PR #17651</a></li>
<li>Return 403 exception when calling GET responses API - <a href="https://github.com/BerriAI/litellm/pull/17629" target="_blank" rel="noopener noreferrer">PR #17629</a></li>
<li>Add nested field removal support to additional_drop_params - <a href="https://github.com/BerriAI/litellm/pull/17711" target="_blank" rel="noopener noreferrer">PR #17711</a></li>
<li>Async post_call_streaming_iterator_hook now properly iterates async generators - <a href="https://github.com/BerriAI/litellm/pull/17626" target="_blank" rel="noopener noreferrer">PR #17626</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-10#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix handle string content in is_cached_message - <a href="https://github.com/BerriAI/litellm/pull/17853" target="_blank" rel="noopener noreferrer">PR #17853</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-80-10#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-80-10#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>UI Settings</strong>
<ul>
<li>Add Get and Update Backend Routes for UI Settings - <a href="https://github.com/BerriAI/litellm/pull/17689" target="_blank" rel="noopener noreferrer">PR #17689</a></li>
<li>UI Settings page implementation - <a href="https://github.com/BerriAI/litellm/pull/17697" target="_blank" rel="noopener noreferrer">PR #17697</a></li>
<li>Ensure Model Page honors UI Settings - <a href="https://github.com/BerriAI/litellm/pull/17804" target="_blank" rel="noopener noreferrer">PR #17804</a></li>
<li>Add All Proxy Models to Default User Settings - <a href="https://github.com/BerriAI/litellm/pull/17902" target="_blank" rel="noopener noreferrer">PR #17902</a></li>
</ul>
</li>
<li><strong>Agent &amp; Usage UI</strong>
<ul>
<li>Daily Agent Usage Backend - <a href="https://github.com/BerriAI/litellm/pull/17781" target="_blank" rel="noopener noreferrer">PR #17781</a></li>
<li>Agent Usage UI - <a href="https://github.com/BerriAI/litellm/pull/17797" target="_blank" rel="noopener noreferrer">PR #17797</a></li>
<li>Add agent cost tracking on UI - <a href="https://github.com/BerriAI/litellm/pull/17899" target="_blank" rel="noopener noreferrer">PR #17899</a></li>
<li>New Badge for Agent Usage - <a href="https://github.com/BerriAI/litellm/pull/17883" target="_blank" rel="noopener noreferrer">PR #17883</a></li>
<li>Usage Entity labels for filtering - <a href="https://github.com/BerriAI/litellm/pull/17896" target="_blank" rel="noopener noreferrer">PR #17896</a></li>
<li>Agent Usage Page minor fixes - <a href="https://github.com/BerriAI/litellm/pull/17901" target="_blank" rel="noopener noreferrer">PR #17901</a></li>
<li>Usage Page View Select component - <a href="https://github.com/BerriAI/litellm/pull/17854" target="_blank" rel="noopener noreferrer">PR #17854</a></li>
<li>Usage Page Components refactor - <a href="https://github.com/BerriAI/litellm/pull/17848" target="_blank" rel="noopener noreferrer">PR #17848</a></li>
</ul>
</li>
<li><strong>Logs &amp; Spend</strong>
<ul>
<li>Enhanced spend analytics in logs view - <a href="https://github.com/BerriAI/litellm/pull/17623" target="_blank" rel="noopener noreferrer">PR #17623</a></li>
<li>Add user info delete modal for user management - <a href="https://github.com/BerriAI/litellm/pull/17625" target="_blank" rel="noopener noreferrer">PR #17625</a></li>
<li>Show request and response details in logs view - <a href="https://github.com/BerriAI/litellm/pull/17928" target="_blank" rel="noopener noreferrer">PR #17928</a></li>
</ul>
</li>
<li><strong>Virtual Keys</strong>
<ul>
<li>Fix x-litellm-key-spend header update - <a href="https://github.com/BerriAI/litellm/pull/17864" target="_blank" rel="noopener noreferrer">PR #17864</a></li>
</ul>
</li>
<li><strong>Models &amp; Endpoints</strong>
<ul>
<li>Model Hub Useful Links Rearrange - <a href="https://github.com/BerriAI/litellm/pull/17859" target="_blank" rel="noopener noreferrer">PR #17859</a></li>
<li>Create Team Model Dropdown honors Organization's Models - <a href="https://github.com/BerriAI/litellm/pull/17834" target="_blank" rel="noopener noreferrer">PR #17834</a></li>
</ul>
</li>
<li><strong>SSO &amp; Auth</strong>
<ul>
<li>Allow upserting user role when SSO provider role changes - <a href="https://github.com/BerriAI/litellm/pull/17754" target="_blank" rel="noopener noreferrer">PR #17754</a></li>
<li>Allow fetching role from generic SSO provider (Keycloak) - <a href="https://github.com/BerriAI/litellm/pull/17787" target="_blank" rel="noopener noreferrer">PR #17787</a></li>
<li>JWT Auth - allow selecting team_id from request header - <a href="https://github.com/BerriAI/litellm/pull/17884" target="_blank" rel="noopener noreferrer">PR #17884</a></li>
<li>Remove SSO Config Values from Config Table on SSO Update - <a href="https://github.com/BerriAI/litellm/pull/17668" target="_blank" rel="noopener noreferrer">PR #17668</a></li>
</ul>
</li>
<li><strong>Teams</strong>
<ul>
<li>Attach team to org table - <a href="https://github.com/BerriAI/litellm/pull/17832" target="_blank" rel="noopener noreferrer">PR #17832</a></li>
<li>Expose the team alias when authenticating - <a href="https://github.com/BerriAI/litellm/pull/17725" target="_blank" rel="noopener noreferrer">PR #17725</a></li>
</ul>
</li>
<li><strong>MCP Server Management</strong>
<ul>
<li>Add extra_headers and allowed_tools to UpdateMCPServerRequest - <a href="https://github.com/BerriAI/litellm/pull/17940" target="_blank" rel="noopener noreferrer">PR #17940</a></li>
</ul>
</li>
<li><strong>Notifications</strong>
<ul>
<li>Show progress and pause on hover for Notifications - <a href="https://github.com/BerriAI/litellm/pull/17942" target="_blank" rel="noopener noreferrer">PR #17942</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Allow Root Path to Redirect when Docs not on Root Path - <a href="https://github.com/BerriAI/litellm/pull/16843" target="_blank" rel="noopener noreferrer">PR #16843</a></li>
<li>Show UI version number on top left near logo - <a href="https://github.com/BerriAI/litellm/pull/17891" target="_blank" rel="noopener noreferrer">PR #17891</a></li>
<li>Re-organize left navigation with correct categories and agents on root - <a href="https://github.com/BerriAI/litellm/pull/17890" target="_blank" rel="noopener noreferrer">PR #17890</a></li>
<li>UI Playground - allow custom model names in model selector dropdown - <a href="https://github.com/BerriAI/litellm/pull/17892" target="_blank" rel="noopener noreferrer">PR #17892</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-10#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>UI Fixes</strong>
<ul>
<li>Fix links + old login page deprecation message - <a href="https://github.com/BerriAI/litellm/pull/17624" target="_blank" rel="noopener noreferrer">PR #17624</a></li>
<li>Filtering for Chat UI Endpoint Selector - <a href="https://github.com/BerriAI/litellm/pull/17567" target="_blank" rel="noopener noreferrer">PR #17567</a></li>
<li>Race Condition Handling in SCIM v2 - <a href="https://github.com/BerriAI/litellm/pull/17513" target="_blank" rel="noopener noreferrer">PR #17513</a></li>
<li>Make /litellm_model_cost_map public - <a href="https://github.com/BerriAI/litellm/pull/16795" target="_blank" rel="noopener noreferrer">PR #16795</a></li>
<li>Custom Callback on UI - <a href="https://github.com/BerriAI/litellm/pull/17522" target="_blank" rel="noopener noreferrer">PR #17522</a></li>
<li>Add User Writable Directory to Non Root Docker for Logo - <a href="https://github.com/BerriAI/litellm/pull/17180" target="_blank" rel="noopener noreferrer">PR #17180</a></li>
<li>Swap URL Input and Display Name inputs - <a href="https://github.com/BerriAI/litellm/pull/17682" target="_blank" rel="noopener noreferrer">PR #17682</a></li>
<li>Change deprecation banner to only show on /sso/key/generate - <a href="https://github.com/BerriAI/litellm/pull/17681" target="_blank" rel="noopener noreferrer">PR #17681</a></li>
<li>Change credential encryption to only affect db credentials - <a href="https://github.com/BerriAI/litellm/pull/17741" target="_blank" rel="noopener noreferrer">PR #17741</a></li>
</ul>
</li>
<li><strong>Auth &amp; Routes</strong>
<ul>
<li>Return 403 instead of 503 for unauthorized routes - <a href="https://github.com/BerriAI/litellm/pull/17723" target="_blank" rel="noopener noreferrer">PR #17723</a></li>
<li>AI Gateway Auth - allow using wildcard patterns for public routes - <a href="https://github.com/BerriAI/litellm/pull/17686" target="_blank" rel="noopener noreferrer">PR #17686</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-integrations">AI Integrations<a href="https://docs.litellm.ai/release_notes/v1-80-10#ai-integrations" class="hash-link" aria-label="AI Integrations的直接链接" title="AI Integrations的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-integrations-4-new-integrations">New Integrations (4 new integrations)<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-integrations-4-new-integrations" class="hash-link" aria-label="New Integrations (4 new integrations)的直接链接" title="New Integrations (4 new integrations)的直接链接">​</a></h3>
<table><thead><tr><th>Integration</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://docs.litellm.ai/docs/proxy/logging#sumologic">SumoLogic</a></td><td>Logging</td><td>Native webhook integration for SumoLogic - <a href="https://github.com/BerriAI/litellm/pull/17630" target="_blank" rel="noopener noreferrer">PR #17630</a></td></tr><tr><td><a href="https://docs.litellm.ai/docs/proxy/arize_phoenix_prompts">Arize Phoenix</a></td><td>Prompt Management</td><td>Arize Phoenix OSS prompt management integration - <a href="https://github.com/BerriAI/litellm/pull/17750" target="_blank" rel="noopener noreferrer">PR #17750</a></td></tr><tr><td><a href="https://docs.litellm.ai/docs/proxy/email">Sendgrid</a></td><td>Email</td><td>Sendgrid email notifications integration - <a href="https://github.com/BerriAI/litellm/pull/17775" target="_blank" rel="noopener noreferrer">PR #17775</a></td></tr><tr><td><a href="https://docs.litellm.ai/docs/proxy/guardrails/onyx_security">Onyx</a></td><td>Guardrails</td><td>Onyx guardrail hooks integration - <a href="https://github.com/BerriAI/litellm/pull/16591" target="_blank" rel="noopener noreferrer">PR #16591</a></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging">Logging<a href="https://docs.litellm.ai/release_notes/v1-80-10#logging" class="hash-link" aria-label="Logging的直接链接" title="Logging的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong>
<ul>
<li>Propagate Langfuse trace_id - <a href="https://github.com/BerriAI/litellm/pull/17669" target="_blank" rel="noopener noreferrer">PR #17669</a></li>
<li>Prefer standard trace id for Langfuse logging - <a href="https://github.com/BerriAI/litellm/pull/17791" target="_blank" rel="noopener noreferrer">PR #17791</a></li>
<li>Move query params to create_pass_through_route call in Langfuse passthrough - <a href="https://github.com/BerriAI/litellm/pull/17660" target="_blank" rel="noopener noreferrer">PR #17660</a></li>
<li>Add support for custom masking function - <a href="https://github.com/BerriAI/litellm/pull/17826" target="_blank" rel="noopener noreferrer">PR #17826</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#prometheus">Prometheus</a></strong>
<ul>
<li>Add 'exception_status' to prometheus logger - <a href="https://github.com/BerriAI/litellm/pull/17847" target="_blank" rel="noopener noreferrer">PR #17847</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#otel">OpenTelemetry</a></strong>
<ul>
<li>Add latency metrics (TTFT, TPOT, Total Generation Time) to OTEL payload - <a href="https://github.com/BerriAI/litellm/pull/17888" target="_blank" rel="noopener noreferrer">PR #17888</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Add polling via cache feature for async logging - <a href="https://github.com/BerriAI/litellm/pull/16862" target="_blank" rel="noopener noreferrer">PR #16862</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-80-10#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/hiddenlayer">HiddenLayer</a></strong>
<ul>
<li>Add HiddenLayer Guardrail Hooks - <a href="https://github.com/BerriAI/litellm/pull/17728" target="_blank" rel="noopener noreferrer">PR #17728</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/pillar_security">Pillar Security</a></strong>
<ul>
<li>Add opt-in evidence results for Pillar Security guardrail during monitoring - <a href="https://github.com/BerriAI/litellm/pull/17812" target="_blank" rel="noopener noreferrer">PR #17812</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/panw_prisma_airs">PANW Prisma AIRS</a></strong>
<ul>
<li>Add configurable fail-open, timeout, and app_user tracking - <a href="https://github.com/BerriAI/litellm/pull/17785" target="_blank" rel="noopener noreferrer">PR #17785</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/pii_masking_v2">Presidio</a></strong>
<ul>
<li>Add support for configurable confidence score thresholds and scope in Presidio PII masking - <a href="https://github.com/BerriAI/litellm/pull/17817" target="_blank" rel="noopener noreferrer">PR #17817</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/litellm_content_filter">LiteLLM Content Filter</a></strong>
<ul>
<li>Mask all regex pattern matches, not just first - <a href="https://github.com/BerriAI/litellm/pull/17727" target="_blank" rel="noopener noreferrer">PR #17727</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/secret_detection">Regex Guardrails</a></strong>
<ul>
<li>Add enhanced regex pattern matching for guardrails - <a href="https://github.com/BerriAI/litellm/pull/17915" target="_blank" rel="noopener noreferrer">PR #17915</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/grayswan">Gray Swan Guardrail</a></strong>
<ul>
<li>Add passthrough mode for model response - <a href="https://github.com/BerriAI/litellm/pull/17102" target="_blank" rel="noopener noreferrer">PR #17102</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-80-10#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h3>
<ul>
<li><strong>General</strong>
<ul>
<li>New API for integrating prompt management providers - <a href="https://github.com/BerriAI/litellm/pull/17829" target="_blank" rel="noopener noreferrer">PR #17829</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-80-10#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Service Tier Pricing</strong> - Extract service_tier from response/usage for OpenAI flex pricing - <a href="https://github.com/BerriAI/litellm/pull/17748" target="_blank" rel="noopener noreferrer">PR #17748</a></li>
<li><strong>Agent Cost Tracking</strong> - Track agent_id in SpendLogs - <a href="https://github.com/BerriAI/litellm/pull/17795" target="_blank" rel="noopener noreferrer">PR #17795</a></li>
<li><strong>Tag Activity</strong> - Deduplicate /tag/daily/activity metadata - <a href="https://github.com/BerriAI/litellm/pull/16764" target="_blank" rel="noopener noreferrer">PR #16764</a></li>
<li><strong>Rate Limiting</strong> - Dynamic Rate Limiter - allow specifying ttl for in memory cache - <a href="https://github.com/BerriAI/litellm/pull/17679" target="_blank" rel="noopener noreferrer">PR #17679</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-80-10#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>Chat Completions Integration</strong> - Add support for using MCPs on /chat/completions - <a href="https://github.com/BerriAI/litellm/pull/17747" target="_blank" rel="noopener noreferrer">PR #17747</a></li>
<li><strong>UI Session Permissions</strong> - Fix UI session MCP permissions across real teams - <a href="https://github.com/BerriAI/litellm/pull/17620" target="_blank" rel="noopener noreferrer">PR #17620</a></li>
<li><strong>OAuth Callback</strong> - Fix MCP OAuth callback routing and URL handling - <a href="https://github.com/BerriAI/litellm/pull/17789" target="_blank" rel="noopener noreferrer">PR #17789</a></li>
<li><strong>Tool Name Prefix</strong> - Fix MCP tool name prefix - <a href="https://github.com/BerriAI/litellm/pull/17908" target="_blank" rel="noopener noreferrer">PR #17908</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agent-gateway-a2a">Agent Gateway (A2A)<a href="https://docs.litellm.ai/release_notes/v1-80-10#agent-gateway-a2a" class="hash-link" aria-label="Agent Gateway (A2A)的直接链接" title="Agent Gateway (A2A)的直接链接">​</a></h2>
<ul>
<li><strong>Cost Per Query</strong> - Add cost per query for agent invocations - <a href="https://github.com/BerriAI/litellm/pull/17774" target="_blank" rel="noopener noreferrer">PR #17774</a></li>
<li><strong>Token Counting</strong> - Add token counting non streaming + streaming - <a href="https://github.com/BerriAI/litellm/pull/17779" target="_blank" rel="noopener noreferrer">PR #17779</a></li>
<li><strong>Cost Per Token</strong> - Add cost per token pricing for A2A - <a href="https://github.com/BerriAI/litellm/pull/17780" target="_blank" rel="noopener noreferrer">PR #17780</a></li>
<li><strong>LangGraph Provider</strong> - Add LangGraph provider for Agent Gateway - <a href="https://github.com/BerriAI/litellm/pull/17783" target="_blank" rel="noopener noreferrer">PR #17783</a></li>
<li><strong>Bedrock &amp; LangGraph Agents</strong> - Allow using Bedrock AgentCore, LangGraph agents with A2A Gateway - <a href="https://github.com/BerriAI/litellm/pull/17786" target="_blank" rel="noopener noreferrer">PR #17786</a></li>
<li><strong>Agent Management</strong> - Allow adding LangGraph, Bedrock Agent Core agents - <a href="https://github.com/BerriAI/litellm/pull/17802" target="_blank" rel="noopener noreferrer">PR #17802</a></li>
<li><strong>Azure Foundry Agents</strong> - Add Azure AI Foundry Agents support - <a href="https://github.com/BerriAI/litellm/pull/17845" target="_blank" rel="noopener noreferrer">PR #17845</a></li>
<li><strong>Azure Foundry UI</strong> - Allow adding Azure Foundry Agents on UI - <a href="https://github.com/BerriAI/litellm/pull/17909" target="_blank" rel="noopener noreferrer">PR #17909</a></li>
<li><strong>Azure Foundry Fixes</strong> - Ensure Azure Foundry agents work correctly - <a href="https://github.com/BerriAI/litellm/pull/17943" target="_blank" rel="noopener noreferrer">PR #17943</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-80-10#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>Memory Leak Fix</strong> - Cut memory leak in half - <a href="https://github.com/BerriAI/litellm/pull/17784" target="_blank" rel="noopener noreferrer">PR #17784</a></li>
<li><strong>Spend Logs Memory</strong> - Reduce memory accumulation of spend_logs - <a href="https://github.com/BerriAI/litellm/pull/17742" target="_blank" rel="noopener noreferrer">PR #17742</a></li>
<li><strong>Router Optimization</strong> - Replace time.perf_counter() with time.time() - <a href="https://github.com/BerriAI/litellm/pull/17881" target="_blank" rel="noopener noreferrer">PR #17881</a></li>
<li><strong>Filter Internal Params</strong> - Filter internal params in fallback code - <a href="https://github.com/BerriAI/litellm/pull/17941" target="_blank" rel="noopener noreferrer">PR #17941</a></li>
<li><strong>Gunicorn Suggestion</strong> - Suggest Gunicorn instead of uvicorn when using max_requests_before_restart - <a href="https://github.com/BerriAI/litellm/pull/17788" target="_blank" rel="noopener noreferrer">PR #17788</a></li>
<li><strong>Pydantic Warnings</strong> - Mitigate PydanticDeprecatedSince20 warnings - <a href="https://github.com/BerriAI/litellm/pull/17657" target="_blank" rel="noopener noreferrer">PR #17657</a></li>
<li><strong>Python 3.14 Support</strong> - Add Python 3.14 support via grpcio version constraints - <a href="https://github.com/BerriAI/litellm/pull/17666" target="_blank" rel="noopener noreferrer">PR #17666</a></li>
<li><strong>OpenAI Package</strong> - Bump openai package to 2.9.0 - <a href="https://github.com/BerriAI/litellm/pull/17818" target="_blank" rel="noopener noreferrer">PR #17818</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-80-10#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li><strong>Contributing</strong> - Update clone instructions to recommend forking first - <a href="https://github.com/BerriAI/litellm/pull/17637" target="_blank" rel="noopener noreferrer">PR #17637</a></li>
<li><strong>Getting Started</strong> - Improve Getting Started page and SDK documentation structure - <a href="https://github.com/BerriAI/litellm/pull/17614" target="_blank" rel="noopener noreferrer">PR #17614</a></li>
<li><strong>JSON Mode</strong> - Make it clearer how to get Pydantic model output - <a href="https://github.com/BerriAI/litellm/pull/17671" target="_blank" rel="noopener noreferrer">PR #17671</a></li>
<li><strong>drop_params</strong> - Update litellm docs for drop_params - <a href="https://github.com/BerriAI/litellm/pull/17658" target="_blank" rel="noopener noreferrer">PR #17658</a></li>
<li><strong>Environment Variables</strong> - Document missing environment variables and fix incorrect types - <a href="https://github.com/BerriAI/litellm/pull/17649" target="_blank" rel="noopener noreferrer">PR #17649</a></li>
<li><strong>SumoLogic</strong> - Add SumoLogic integration documentation - <a href="https://github.com/BerriAI/litellm/pull/17647" target="_blank" rel="noopener noreferrer">PR #17647</a></li>
<li><strong>SAP Gen AI</strong> - Add SAP Gen AI provider documentation - <a href="https://github.com/BerriAI/litellm/pull/17667" target="_blank" rel="noopener noreferrer">PR #17667</a></li>
<li><strong>Authentication</strong> - Add Note for Authentication - <a href="https://github.com/BerriAI/litellm/pull/17733" target="_blank" rel="noopener noreferrer">PR #17733</a></li>
<li><strong>Known Issues</strong> - Adding known issues to 1.80.5-stable docs - <a href="https://github.com/BerriAI/litellm/pull/17738" target="_blank" rel="noopener noreferrer">PR #17738</a></li>
<li><strong>Supported Endpoints</strong> - Fix Supported Endpoints page - <a href="https://github.com/BerriAI/litellm/pull/17710" target="_blank" rel="noopener noreferrer">PR #17710</a></li>
<li><strong>Token Count</strong> - Document token count endpoint - <a href="https://github.com/BerriAI/litellm/pull/17772" target="_blank" rel="noopener noreferrer">PR #17772</a></li>
<li><strong>Overview</strong> - Made litellm proxy and SDK difference cleaner in overview with a table - <a href="https://github.com/BerriAI/litellm/pull/17790" target="_blank" rel="noopener noreferrer">PR #17790</a></li>
<li><strong>Containers API</strong> - Add docs for containers files API + code interpreter on LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/17749" target="_blank" rel="noopener noreferrer">PR #17749</a></li>
<li><strong>Target Storage</strong> - Add documentation for target storage - <a href="https://github.com/BerriAI/litellm/pull/17882" target="_blank" rel="noopener noreferrer">PR #17882</a></li>
<li><strong>Agent Usage</strong> - Agent Usage documentation - <a href="https://github.com/BerriAI/litellm/pull/17931" target="_blank" rel="noopener noreferrer">PR #17931</a>, <a href="https://github.com/BerriAI/litellm/pull/17932" target="_blank" rel="noopener noreferrer">PR #17932</a>, <a href="https://github.com/BerriAI/litellm/pull/17934" target="_blank" rel="noopener noreferrer">PR #17934</a></li>
<li><strong>Cursor Integration</strong> - Cursor Integration documentation - <a href="https://github.com/BerriAI/litellm/pull/17855" target="_blank" rel="noopener noreferrer">PR #17855</a>, <a href="https://github.com/BerriAI/litellm/pull/17939" target="_blank" rel="noopener noreferrer">PR #17939</a></li>
<li><strong>A2A Cost Tracking</strong> - A2A cost tracking docs - <a href="https://github.com/BerriAI/litellm/pull/17913" target="_blank" rel="noopener noreferrer">PR #17913</a></li>
<li><strong>Azure Search</strong> - Update azure search docs - <a href="https://github.com/BerriAI/litellm/pull/17726" target="_blank" rel="noopener noreferrer">PR #17726</a></li>
<li><strong>Milvus Client</strong> - Fix milvus client docs - <a href="https://github.com/BerriAI/litellm/pull/17736" target="_blank" rel="noopener noreferrer">PR #17736</a></li>
<li><strong>Streaming Logging</strong> - Remove streaming logging doc - <a href="https://github.com/BerriAI/litellm/pull/17739" target="_blank" rel="noopener noreferrer">PR #17739</a></li>
<li><strong>Integration Docs</strong> - Update integration docs location - <a href="https://github.com/BerriAI/litellm/pull/17644" target="_blank" rel="noopener noreferrer">PR #17644</a></li>
<li><strong>Links</strong> - Updated docs links for mistral and anthropic - <a href="https://github.com/BerriAI/litellm/pull/17852" target="_blank" rel="noopener noreferrer">PR #17852</a></li>
<li><strong>Community</strong> - Add community doc link - <a href="https://github.com/BerriAI/litellm/pull/17734" target="_blank" rel="noopener noreferrer">PR #17734</a></li>
<li><strong>Pricing</strong> - Update pricing for global.anthropic.claude-haiku-4-5-20251001-v1:0 - <a href="https://github.com/BerriAI/litellm/pull/17703" target="_blank" rel="noopener noreferrer">PR #17703</a></li>
<li><strong>gpt-image-1-mini</strong> - Correct model type for gpt-image-1-mini - <a href="https://github.com/BerriAI/litellm/pull/17635" target="_blank" rel="noopener noreferrer">PR #17635</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure--deployment">Infrastructure / Deployment<a href="https://docs.litellm.ai/release_notes/v1-80-10#infrastructure--deployment" class="hash-link" aria-label="Infrastructure / Deployment的直接链接" title="Infrastructure / Deployment的直接链接">​</a></h2>
<ul>
<li><strong>Docker</strong> - Use python instead of wget for healthcheck in docker-compose.yml - <a href="https://github.com/BerriAI/litellm/pull/17646" target="_blank" rel="noopener noreferrer">PR #17646</a></li>
<li><strong>Helm Chart</strong> - Add extraResources support for Helm chart deployments - <a href="https://github.com/BerriAI/litellm/pull/17627" target="_blank" rel="noopener noreferrer">PR #17627</a></li>
<li><strong>Helm Versioning</strong> - Add semver prerelease suffix to helm chart versions - <a href="https://github.com/BerriAI/litellm/pull/17678" target="_blank" rel="noopener noreferrer">PR #17678</a></li>
<li><strong>Database Schema</strong> - Add storage_backend and storage_url columns to schema.prisma for target storage feature - <a href="https://github.com/BerriAI/litellm/pull/17936" target="_blank" rel="noopener noreferrer">PR #17936</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-80-10#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@xianzongxie-stripe made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16862" target="_blank" rel="noopener noreferrer">PR #16862</a></li>
<li>@krisxia0506 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17637" target="_blank" rel="noopener noreferrer">PR #17637</a></li>
<li>@chetanchoudhary-sumo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17630" target="_blank" rel="noopener noreferrer">PR #17630</a></li>
<li>@kevinmarx made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17632" target="_blank" rel="noopener noreferrer">PR #17632</a></li>
<li>@expruc made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17627" target="_blank" rel="noopener noreferrer">PR #17627</a></li>
<li>@rcII made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17626" target="_blank" rel="noopener noreferrer">PR #17626</a></li>
<li>@tamirkiviti13 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16591" target="_blank" rel="noopener noreferrer">PR #16591</a></li>
<li>@Eric84626 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17629" target="_blank" rel="noopener noreferrer">PR #17629</a></li>
<li>@vasilisazayka made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16053" target="_blank" rel="noopener noreferrer">PR #16053</a></li>
<li>@juliettech13 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17663" target="_blank" rel="noopener noreferrer">PR #17663</a></li>
<li>@jason-nance made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17660" target="_blank" rel="noopener noreferrer">PR #17660</a></li>
<li>@yisding made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17671" target="_blank" rel="noopener noreferrer">PR #17671</a></li>
<li>@emilsvennesson made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17656" target="_blank" rel="noopener noreferrer">PR #17656</a></li>
<li>@kumekay made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17646" target="_blank" rel="noopener noreferrer">PR #17646</a></li>
<li>@chenzhaofei01 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17584" target="_blank" rel="noopener noreferrer">PR #17584</a></li>
<li>@shivamrawat1 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17733" target="_blank" rel="noopener noreferrer">PR #17733</a></li>
<li>@ephrimstanley made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17723" target="_blank" rel="noopener noreferrer">PR #17723</a></li>
<li>@hwittenborn made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17743" target="_blank" rel="noopener noreferrer">PR #17743</a></li>
<li>@peterkc made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17727" target="_blank" rel="noopener noreferrer">PR #17727</a></li>
<li>@saisurya237 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17725" target="_blank" rel="noopener noreferrer">PR #17725</a></li>
<li>@Ashton-Sidhu made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17728" target="_blank" rel="noopener noreferrer">PR #17728</a></li>
<li>@CyrusTC made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17810" target="_blank" rel="noopener noreferrer">PR #17810</a></li>
<li>@jichmi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17703" target="_blank" rel="noopener noreferrer">PR #17703</a></li>
<li>@ryan-crabbe made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17852" target="_blank" rel="noopener noreferrer">PR #17852</a></li>
<li>@nlineback made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17851" target="_blank" rel="noopener noreferrer">PR #17851</a></li>
<li>@butnarurazvan made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17468" target="_blank" rel="noopener noreferrer">PR #17468</a></li>
<li>@yoshi-p27 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17915" target="_blank" rel="noopener noreferrer">PR #17915</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-80-10#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.80.8.rc.1...v1.80.10" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.80.8-stable - Introducing A2A Agent Gateway]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-80-8</link>
            <guid>https://docs.litellm.ai/release_notes/v1-80-8</guid>
            <pubDate>Sat, 06 Dec 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-80-8#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.80.8-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.8</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-80-8#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Agent Gateway (A2A)</strong> - <a href="https://docs.litellm.ai/docs/a2a">Invoke agents through the AI Gateway with request/response logging and access controls</a></li>
<li><strong>Guardrails API v2</strong> - <a href="https://docs.litellm.ai/docs/adding_provider/generic_guardrail_api">Generic Guardrail API with streaming support, structured messages, and tool call checks</a></li>
<li><strong>Customer (End User) Usage UI</strong> - <a href="https://docs.litellm.ai/docs/proxy/customer_usage">Track and visualize end-user spend directly in the dashboard</a></li>
<li><strong>vLLM Batch + Files API</strong> - <a href="https://docs.litellm.ai/docs/batches">Support for batch and files API with vLLM deployments</a></li>
<li><strong>Dynamic Rate Limiting on Teams</strong> - <a href="https://docs.litellm.ai/docs/proxy/team_budgets">Enable dynamic rate limits and priority reservation on team-level</a></li>
<li><strong>Google Cloud Chirp3 HD</strong> - <a href="https://docs.litellm.ai/docs/text_to_speech">New text-to-speech provider with Chirp3 HD voices</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-gateway-a2a">Agent Gateway (A2A)<a href="https://docs.litellm.ai/release_notes/v1-80-8#agent-gateway-a2a" class="hash-link" aria-label="Agent Gateway (A2A)的直接链接" title="Agent Gateway (A2A)的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAIAAAB1kpiRAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAtklEQVR4nB3Gyw7BQBQA0EHn3plOqUc7jyu0HkkRFoQgRCSs7ET4Kksbn2BlL/ENfklIzuIwKUgKQrDGZAn1U5cZnSE3kK8iNww8zQsxgg19cqO9mx9LPslSGvW2xajHYjeod6cqSARNFrfX4fEpz45BnA03J9tasGqtq91AopNuvLo+N/d3ZXlRxWZDp7Www8CzvGAEEOYiPdwl67PwjFRJWG4HqsEEkkQSfz7Xyot/BwvcItAXFv0VgL1fhlMAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="381"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/a2a_gateway.4b90229.640.png" srcset="/assets/ideal-img/a2a_gateway.4b90229.640.png 640w,/assets/ideal-img/a2a_gateway.9582a3f.1344.png 1344w" width="640" height="381"></noscript></div>
<br>
<p>This release introduces <strong>A2A Agent Gateway</strong> for LiteLLM, allowing you to invoke and manage A2A agents with the same controls you have for LLM APIs.</p>
<p>As a <strong>LiteLLM Gateway Admin</strong>, you can now do the following:</p>
<ul>
<li><strong>Request/Response Logging</strong> - Every agent invocation is logged to the Logs page with full request and response tracking.</li>
<li><strong>Access Control</strong> - Control which Team/Key can access which agents.</li>
</ul>
<p>As a developer, you can continue using the A2A SDK, all you need to do is point you <code>A2AClient</code> to the LiteLLM proxy URL and your API key.</p>
<p><strong>Works with the A2A SDK:</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> a2a</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">client </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> A2AClient</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> A2AClient</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"http://localhost:4000"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Your LiteLLM proxy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"sk-1234"</span><span class="token plain">                   </span><span class="token comment" style="color:#999988;font-style:italic"># LiteLLM API key</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">send_message</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    agent_id</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"my-agent"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    message</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"What's the status of my order?"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Get started with Agent Gateway here: <a href="https://docs.litellm.ai/docs/a2a">Agent Gateway Documentation</a></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="customer-end-user-usage-ui">Customer (End User) Usage UI<a href="https://docs.litellm.ai/release_notes/v1-80-8#customer-end-user-usage-ui" class="hash-link" aria-label="Customer (End User) Usage UI的直接链接" title="Customer (End User) Usage UI的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAkklEQVR4nD2OTQrCMBQGc0u9g1fwPl5GKLRuFFdKF4I/sbVJ895LRiLFxWw+huFzwzDivSfGSEqykP6IJMwU13UdbdsyTYEQZ0QM0UxSRVTJOfO8C67W3ksxhICpYWZkU6zKIoQgOFWlUocqnafE5tCz6188kkIplFJw9UecZ8jG3ge2xxur5sq6uXD6zD9p1MwXGsy+lh2zMRYAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/customer_usage.2937330.640.png" srcset="/assets/ideal-img/customer_usage.2937330.640.png 640w,/assets/ideal-img/customer_usage.e539153.1920.png 1920w" width="640" height="334"></noscript></div>
<p>Users can now filter usage statistics by customers, providing the same granular filtering capabilities available for teams and organizations.</p>
<p><strong>Details:</strong></p>
<ul>
<li>Filter usage analytics, spend logs, and activity metrics by customer ID</li>
<li>View customer-level breakdowns alongside existing team and user-level filters</li>
<li>Consistent filtering experience across all usage and analytics views</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-and-endpoints">New Providers and Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-providers-and-endpoints" class="hash-link" aria-label="New Providers and Endpoints的直接链接" title="New Providers and Endpoints的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-5-new-providers">New Providers (5 new providers)<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-providers-5-new-providers" class="hash-link" aria-label="New Providers (5 new providers)的直接链接" title="New Providers (5 new providers)的直接链接">​</a></h3>
<table><thead><tr><th>Provider</th><th>Supported LiteLLM Endpoints</th><th>Description</th></tr></thead><tbody><tr><td><strong><a href="https://docs.litellm.ai/docs/providers/zai">Z.AI (Zhipu AI)</a></strong></td><td><code>/v1/chat/completions</code>, <code>/v1/responses</code>, <code>/v1/messages</code></td><td>Built-in support for Zhipu AI GLM models</td></tr><tr><td><strong><a href="https://docs.litellm.ai/docs/providers/ragflow">RAGFlow</a></strong></td><td><code>/v1/chat/completions</code>, <code>/v1/responses</code>, <code>/v1/messages</code>, <code>/v1/vector_stores</code></td><td>RAG-based chat completions with vector store support</td></tr><tr><td><strong><a href="https://docs.litellm.ai/docs/providers/publicai">PublicAI</a></strong></td><td><code>/v1/chat/completions</code>, <code>/v1/responses</code>, <code>/v1/messages</code></td><td>OpenAI-compatible provider via JSON config</td></tr><tr><td><strong><a href="https://docs.litellm.ai/docs/text_to_speech">Google Cloud Chirp3 HD</a></strong></td><td><code>/v1/audio/speech</code>, <code>/v1/audio/speech/stream</code></td><td>Text-to-speech with Google Cloud Chirp3 HD voices</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-llm-api-endpoints-2-new-endpoints">New LLM API Endpoints (2 new endpoints)<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-llm-api-endpoints-2-new-endpoints" class="hash-link" aria-label="New LLM API Endpoints (2 new endpoints)的直接链接" title="New LLM API Endpoints (2 new endpoints)的直接链接">​</a></h3>
<table><thead><tr><th>Endpoint</th><th>Method</th><th>Description</th><th>Documentation</th></tr></thead><tbody><tr><td><code>/v1/agents/invoke</code></td><td>POST</td><td>Invoke A2A agents through the AI Gateway</td><td><a href="https://docs.litellm.ai/docs/a2a">Agent Gateway</a></td></tr><tr><td><code>/cursor/chat/completions</code></td><td>POST</td><td>Cursor BYOK endpoint - accepts Responses API input, returns Chat Completions output</td><td><a href="https://docs.litellm.ai/docs/tutorials/cursor_integration">Cursor Integration</a></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support-33-new-models">New Model Support (33 new models)<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-model-support-33-new-models" class="hash-link" aria-label="New Model Support (33 new models)的直接链接" title="New Model Support (33 new models)的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>OpenAI</td><td><code>gpt-5.1-codex-max</code></td><td>400K</td><td>$1.25</td><td>$10.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-codex-max</code></td><td>400K</td><td>$1.25</td><td>$10.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>Anthropic</td><td><code>claude-opus-4-5</code></td><td>200K</td><td>$5.00</td><td>$25.00</td><td>Computer use, reasoning, vision</td></tr><tr><td>Bedrock</td><td><code>global.anthropic.claude-opus-4-5-20251101-v1:0</code></td><td>200K</td><td>$5.00</td><td>$25.00</td><td>Computer use, reasoning, vision</td></tr><tr><td>Bedrock</td><td><code>amazon.nova-2-lite-v1:0</code></td><td>1M</td><td>$0.30</td><td>$2.50</td><td>Reasoning, vision, video, PDF input</td></tr><tr><td>Bedrock</td><td><code>amazon.titan-image-generator-v2:0</code></td><td>-</td><td>-</td><td>$0.008/image</td><td>Image generation</td></tr><tr><td>Fireworks</td><td><code>fireworks_ai/deepseek-v3p2</code></td><td>164K</td><td>$1.20</td><td>$1.20</td><td>Function calling, response schema</td></tr><tr><td>Fireworks</td><td><code>fireworks_ai/kimi-k2-instruct-0905</code></td><td>262K</td><td>$0.60</td><td>$2.50</td><td>Function calling, response schema</td></tr><tr><td>DeepSeek</td><td><code>deepseek/deepseek-v3.2</code></td><td>164K</td><td>$0.28</td><td>$0.40</td><td>Reasoning, function calling</td></tr><tr><td>Mistral</td><td><code>mistral/mistral-large-3</code></td><td>256K</td><td>$0.50</td><td>$1.50</td><td>Function calling, vision</td></tr><tr><td>Azure AI</td><td><code>azure_ai/mistral-large-3</code></td><td>256K</td><td>$0.50</td><td>$1.50</td><td>Function calling, vision</td></tr><tr><td>Moonshot</td><td><code>moonshot/kimi-k2-0905-preview</code></td><td>262K</td><td>$0.60</td><td>$2.50</td><td>Function calling, web search</td></tr><tr><td>Moonshot</td><td><code>moonshot/kimi-k2-turbo-preview</code></td><td>262K</td><td>$1.15</td><td>$8.00</td><td>Function calling, web search</td></tr><tr><td>Moonshot</td><td><code>moonshot/kimi-k2-thinking-turbo</code></td><td>262K</td><td>$1.15</td><td>$8.00</td><td>Function calling, web search</td></tr><tr><td>OpenRouter</td><td><code>openrouter/deepseek/deepseek-v3.2</code></td><td>164K</td><td>$0.28</td><td>$0.40</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-haiku-4-5</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-opus-4</code></td><td>200K</td><td>$15.00</td><td>$75.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-opus-4-1</code></td><td>200K</td><td>$15.00</td><td>$75.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-opus-4-5</code></td><td>200K</td><td>$5.00</td><td>$25.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-sonnet-4</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-claude-sonnet-4-1</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Reasoning, function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gemini-2-5-flash</code></td><td>1M</td><td>$0.30</td><td>$2.50</td><td>Function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gemini-2-5-pro</code></td><td>1M</td><td>$1.25</td><td>$10.00</td><td>Function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gpt-5</code></td><td>400K</td><td>$1.25</td><td>$10.00</td><td>Function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gpt-5-1</code></td><td>400K</td><td>$1.25</td><td>$10.00</td><td>Function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gpt-5-mini</code></td><td>400K</td><td>$0.25</td><td>$2.00</td><td>Function calling</td></tr><tr><td>Databricks</td><td><code>databricks/databricks-gpt-5-nano</code></td><td>400K</td><td>$0.05</td><td>$0.40</td><td>Function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/chirp</code></td><td>-</td><td>$30.00/1M chars</td><td>-</td><td>Text-to-speech (Chirp3 HD)</td></tr><tr><td>Z.AI</td><td><code>zai/glm-4.6</code></td><td>200K</td><td>$0.60</td><td>$2.20</td><td>Function calling</td></tr><tr><td>Z.AI</td><td><code>zai/glm-4.5</code></td><td>128K</td><td>$0.60</td><td>$2.20</td><td>Function calling</td></tr><tr><td>Z.AI</td><td><code>zai/glm-4.5v</code></td><td>128K</td><td>$0.60</td><td>$1.80</td><td>Function calling, vision</td></tr><tr><td>Z.AI</td><td><code>zai/glm-4.5-flash</code></td><td>128K</td><td>Free</td><td>Free</td><td>Function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/bge-large-en-v1.5</code></td><td>-</td><td>-</td><td>-</td><td>BGE Embeddings</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-80-8#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Add <code>gpt-5.1-codex-max</code> model pricing and configuration - <a href="https://github.com/BerriAI/litellm/pull/17541" target="_blank" rel="noopener noreferrer">PR #17541</a></li>
<li>Add xhigh reasoning effort for gpt-5.1-codex-max - <a href="https://github.com/BerriAI/litellm/pull/17585" target="_blank" rel="noopener noreferrer">PR #17585</a></li>
<li>Add clear error message for empty LLM endpoint responses - <a href="https://github.com/BerriAI/litellm/pull/17445" target="_blank" rel="noopener noreferrer">PR #17445</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure/azure">Azure OpenAI</a></strong></p>
<ul>
<li>Allow reasoning_effort='none' for Azure gpt-5.1 models - <a href="https://github.com/BerriAI/litellm/pull/17311" target="_blank" rel="noopener noreferrer">PR #17311</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Add <code>claude-opus-4-5</code> alias to pricing data - <a href="https://github.com/BerriAI/litellm/pull/17313" target="_blank" rel="noopener noreferrer">PR #17313</a></li>
<li>Parse <code>&lt;budget:thinking&gt;</code> blocks for opus 4.5 - <a href="https://github.com/BerriAI/litellm/pull/17534" target="_blank" rel="noopener noreferrer">PR #17534</a></li>
<li>Update new Anthropic features as reviewed - <a href="https://github.com/BerriAI/litellm/pull/17142" target="_blank" rel="noopener noreferrer">PR #17142</a></li>
<li>Skip empty text blocks in Anthropic system messages - <a href="https://github.com/BerriAI/litellm/pull/17442" target="_blank" rel="noopener noreferrer">PR #17442</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Add Nova embedding support - <a href="https://github.com/BerriAI/litellm/pull/17253" target="_blank" rel="noopener noreferrer">PR #17253</a></li>
<li>Add support for Bedrock Qwen 2 imported model - <a href="https://github.com/BerriAI/litellm/pull/17461" target="_blank" rel="noopener noreferrer">PR #17461</a></li>
<li>Bedrock OpenAI model support - <a href="https://github.com/BerriAI/litellm/pull/17368" target="_blank" rel="noopener noreferrer">PR #17368</a></li>
<li>Add support for file content download for Bedrock batches - <a href="https://github.com/BerriAI/litellm/pull/17470" target="_blank" rel="noopener noreferrer">PR #17470</a></li>
<li>Make streaming chunk size configurable in Bedrock API - <a href="https://github.com/BerriAI/litellm/pull/17357" target="_blank" rel="noopener noreferrer">PR #17357</a></li>
<li>Add experimental latest-user filtering for Bedrock - <a href="https://github.com/BerriAI/litellm/pull/17282" target="_blank" rel="noopener noreferrer">PR #17282</a></li>
<li>Handle Cohere v4 embed response dictionary format - <a href="https://github.com/BerriAI/litellm/pull/17220" target="_blank" rel="noopener noreferrer">PR #17220</a></li>
<li>Remove not compatible beta header from Bedrock - <a href="https://github.com/BerriAI/litellm/pull/17301" target="_blank" rel="noopener noreferrer">PR #17301</a></li>
<li>Add model price and details for Global Opus 4.5 Bedrock endpoint - <a href="https://github.com/BerriAI/litellm/pull/17380" target="_blank" rel="noopener noreferrer">PR #17380</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini (Google AI Studio + Vertex AI)</a></strong></p>
<ul>
<li>Add better handling in image generation for Gemini models - <a href="https://github.com/BerriAI/litellm/pull/17292" target="_blank" rel="noopener noreferrer">PR #17292</a></li>
<li>Fix reasoning_content showing duplicate content in streaming responses - <a href="https://github.com/BerriAI/litellm/pull/17266" target="_blank" rel="noopener noreferrer">PR #17266</a></li>
<li>Handle partial JSON chunks after first valid chunk - <a href="https://github.com/BerriAI/litellm/pull/17496" target="_blank" rel="noopener noreferrer">PR #17496</a></li>
<li>Fix Gemini 3 last chunk thinking block - <a href="https://github.com/BerriAI/litellm/pull/17403" target="_blank" rel="noopener noreferrer">PR #17403</a></li>
<li>Fix Gemini image_tokens treated as text tokens in cost calculation - <a href="https://github.com/BerriAI/litellm/pull/17554" target="_blank" rel="noopener noreferrer">PR #17554</a></li>
<li>Make sure that media resolution is only for Gemini 3 model - <a href="https://github.com/BerriAI/litellm/pull/17137" target="_blank" rel="noopener noreferrer">PR #17137</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong></p>
<ul>
<li>Add Google Cloud Chirp3 HD support on /speech - <a href="https://github.com/BerriAI/litellm/pull/17391" target="_blank" rel="noopener noreferrer">PR #17391</a></li>
<li>Add BGE Embeddings support - <a href="https://github.com/BerriAI/litellm/pull/17362" target="_blank" rel="noopener noreferrer">PR #17362</a></li>
<li>Handle global location for Vertex AI image generation endpoint - <a href="https://github.com/BerriAI/litellm/pull/17255" target="_blank" rel="noopener noreferrer">PR #17255</a></li>
<li>Add Google Private API Endpoint to Vertex AI fields - <a href="https://github.com/BerriAI/litellm/pull/17382" target="_blank" rel="noopener noreferrer">PR #17382</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/zai">Z.AI (Zhipu AI)</a></strong></p>
<ul>
<li>Add Z.AI as built-in provider - <a href="https://github.com/BerriAI/litellm/pull/17307" target="_blank" rel="noopener noreferrer">PR #17307</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/github_copilot">GitHub Copilot</a></strong></p>
<ul>
<li>Add Embedding API support - <a href="https://github.com/BerriAI/litellm/pull/17278" target="_blank" rel="noopener noreferrer">PR #17278</a></li>
<li>Preserve encrypted_content in reasoning items for multi-turn conversations - <a href="https://github.com/BerriAI/litellm/pull/17130" target="_blank" rel="noopener noreferrer">PR #17130</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/databricks">Databricks</a></strong></p>
<ul>
<li>Update Databricks model pricing and add new models - <a href="https://github.com/BerriAI/litellm/pull/17277" target="_blank" rel="noopener noreferrer">PR #17277</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/ovhcloud">OVHcloud</a></strong></p>
<ul>
<li>Add support of audio transcription for OVHcloud - <a href="https://github.com/BerriAI/litellm/pull/17305" target="_blank" rel="noopener noreferrer">PR #17305</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong></p>
<ul>
<li>Add Mistral Large 3 model support - <a href="https://github.com/BerriAI/litellm/pull/17547" target="_blank" rel="noopener noreferrer">PR #17547</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/moonshot">Moonshot</a></strong></p>
<ul>
<li>Fix missing Moonshot turbo models and fix incorrect pricing - <a href="https://github.com/BerriAI/litellm/pull/17432" target="_blank" rel="noopener noreferrer">PR #17432</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/togetherai">Together AI</a></strong></p>
<ul>
<li>Add context window exception mapping for Together AI - <a href="https://github.com/BerriAI/litellm/pull/17284" target="_blank" rel="noopener noreferrer">PR #17284</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/watsonx/index">WatsonX</a></strong></p>
<ul>
<li>Allow passing zen_api_key dynamically - <a href="https://github.com/BerriAI/litellm/pull/16655" target="_blank" rel="noopener noreferrer">PR #16655</a></li>
<li>Fix Watsonx Audio Transcription API - <a href="https://github.com/BerriAI/litellm/pull/17326" target="_blank" rel="noopener noreferrer">PR #17326</a></li>
<li>Fix audio transcriptions, don't force content type in request headers - <a href="https://github.com/BerriAI/litellm/pull/17546" target="_blank" rel="noopener noreferrer">PR #17546</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI</a></strong></p>
<ul>
<li>Add new model <code>fireworks_ai/kimi-k2-instruct-0905</code> - <a href="https://github.com/BerriAI/litellm/pull/17328" target="_blank" rel="noopener noreferrer">PR #17328</a></li>
<li>Add <code>fireworks/deepseek-v3p2</code> - <a href="https://github.com/BerriAI/litellm/pull/17395" target="_blank" rel="noopener noreferrer">PR #17395</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/deepseek">DeepSeek</a></strong></p>
<ul>
<li>Support Deepseek 3.2 with Reasoning - <a href="https://github.com/BerriAI/litellm/pull/17384" target="_blank" rel="noopener noreferrer">PR #17384</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Nova Lite 2</a></strong></p>
<ul>
<li>Add Nova Lite 2 reasoning support with reasoningConfig - <a href="https://github.com/BerriAI/litellm/pull/17371" target="_blank" rel="noopener noreferrer">PR #17371</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong></p>
<ul>
<li>Fix auth not working with ollama.com - <a href="https://github.com/BerriAI/litellm/pull/17191" target="_blank" rel="noopener noreferrer">PR #17191</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/groq">Groq</a></strong></p>
<ul>
<li>Fix supports_response_schema before using json_tool_call workaround - <a href="https://github.com/BerriAI/litellm/pull/17438" target="_blank" rel="noopener noreferrer">PR #17438</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vllm">vLLM</a></strong></p>
<ul>
<li>Fix empty response + vLLM streaming - <a href="https://github.com/BerriAI/litellm/pull/17516" target="_blank" rel="noopener noreferrer">PR #17516</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure_ai">Azure AI</a></strong></p>
<ul>
<li>Migrate Anthropic provider to Azure AI - <a href="https://github.com/BerriAI/litellm/pull/17202" target="_blank" rel="noopener noreferrer">PR #17202</a></li>
<li>Fix GA path for Azure OpenAI realtime models - <a href="https://github.com/BerriAI/litellm/pull/17260" target="_blank" rel="noopener noreferrer">PR #17260</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock#twelvelabs-pegasus---video-understanding">Bedrock TwelveLabs</a></strong></p>
<ul>
<li>Add support for TwelveLabs Pegasus video understanding - <a href="https://github.com/BerriAI/litellm/pull/17193" target="_blank" rel="noopener noreferrer">PR #17193</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-8#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Fix extra_headers in messages API bedrock invoke - <a href="https://github.com/BerriAI/litellm/pull/17271" target="_blank" rel="noopener noreferrer">PR #17271</a></li>
<li>Fix Bedrock models in model map - <a href="https://github.com/BerriAI/litellm/pull/17419" target="_blank" rel="noopener noreferrer">PR #17419</a></li>
<li>Make Bedrock converse messages respect modify_params as expected - <a href="https://github.com/BerriAI/litellm/pull/17427" target="_blank" rel="noopener noreferrer">PR #17427</a></li>
<li>Fix Anthropic beta headers for Bedrock imported Qwen models - <a href="https://github.com/BerriAI/litellm/pull/17467" target="_blank" rel="noopener noreferrer">PR #17467</a></li>
<li>Preserve usage from JSON response for OpenAI provider in Bedrock - <a href="https://github.com/BerriAI/litellm/pull/17589" target="_blank" rel="noopener noreferrer">PR #17589</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/sambanova">SambaNova</a></strong></p>
<ul>
<li>Fix acompletion throws error with SambaNova models - <a href="https://github.com/BerriAI/litellm/pull/17217" target="_blank" rel="noopener noreferrer">PR #17217</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fix AttributeError when metadata is null in request body - <a href="https://github.com/BerriAI/litellm/pull/17306" target="_blank" rel="noopener noreferrer">PR #17306</a></li>
<li>Fix 500 error for malformed request - <a href="https://github.com/BerriAI/litellm/pull/17291" target="_blank" rel="noopener noreferrer">PR #17291</a></li>
<li>Respect custom LLM provider in header - <a href="https://github.com/BerriAI/litellm/pull/17290" target="_blank" rel="noopener noreferrer">PR #17290</a></li>
<li>Replace deprecated .dict() with .model_dump() in streaming_handler - <a href="https://github.com/BerriAI/litellm/pull/17359" target="_blank" rel="noopener noreferrer">PR #17359</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-8#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-80-8#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Add cost tracking for responses API - <a href="https://github.com/BerriAI/litellm/pull/17258" target="_blank" rel="noopener noreferrer">PR #17258</a></li>
<li>Map output_tokens_details of responses API to completion_tokens_details - <a href="https://github.com/BerriAI/litellm/pull/17458" target="_blank" rel="noopener noreferrer">PR #17458</a></li>
<li>Add image generation support for Responses API - <a href="https://github.com/BerriAI/litellm/pull/16586" target="_blank" rel="noopener noreferrer">PR #16586</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/batches">Batch API</a></strong></p>
<ul>
<li>Add vLLM batch+files API support - <a href="https://github.com/BerriAI/litellm/pull/15823" target="_blank" rel="noopener noreferrer">PR #15823</a></li>
<li>Fix optional parameter default value - <a href="https://github.com/BerriAI/litellm/pull/17434" target="_blank" rel="noopener noreferrer">PR #17434</a></li>
<li>Add status parameter as optional for FileObject - <a href="https://github.com/BerriAI/litellm/pull/17431" target="_blank" rel="noopener noreferrer">PR #17431</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/videos">Video Generation API</a></strong></p>
<ul>
<li>Add passthrough cost tracking for Veo - <a href="https://github.com/BerriAI/litellm/pull/17296" target="_blank" rel="noopener noreferrer">PR #17296</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/ocr">OCR API</a></strong></p>
<ul>
<li>Add missing OCR and aOCR to CallTypes enum - <a href="https://github.com/BerriAI/litellm/pull/17435" target="_blank" rel="noopener noreferrer">PR #17435</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Support routing to only websearch supported deployments - <a href="https://github.com/BerriAI/litellm/pull/17500" target="_blank" rel="noopener noreferrer">PR #17500</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-8#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix streaming error validation - <a href="https://github.com/BerriAI/litellm/pull/17242" target="_blank" rel="noopener noreferrer">PR #17242</a></li>
<li>Add length validation for empty tool_calls in delta - <a href="https://github.com/BerriAI/litellm/pull/17523" target="_blank" rel="noopener noreferrer">PR #17523</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-80-8#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-80-8#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>New Login Page</strong></p>
<ul>
<li>New Login Page UI - <a href="https://github.com/BerriAI/litellm/pull/17443" target="_blank" rel="noopener noreferrer">PR #17443</a></li>
<li>Refactor /login route - <a href="https://github.com/BerriAI/litellm/pull/17379" target="_blank" rel="noopener noreferrer">PR #17379</a></li>
<li>Add auto_redirect_to_sso to UI Config - <a href="https://github.com/BerriAI/litellm/pull/17399" target="_blank" rel="noopener noreferrer">PR #17399</a></li>
<li>Add Auto Redirect to SSO to New Login Page - <a href="https://github.com/BerriAI/litellm/pull/17451" target="_blank" rel="noopener noreferrer">PR #17451</a></li>
</ul>
</li>
<li>
<p><strong>Customer (End User) Usage</strong></p>
<ul>
<li>Customer (end user) Usage feature - <a href="https://github.com/BerriAI/litellm/pull/17498" target="_blank" rel="noopener noreferrer">PR #17498</a></li>
<li>Customer Usage UI - <a href="https://github.com/BerriAI/litellm/pull/17506" target="_blank" rel="noopener noreferrer">PR #17506</a></li>
<li>Add Info Banner for Customer Usage - <a href="https://github.com/BerriAI/litellm/pull/17598" target="_blank" rel="noopener noreferrer">PR #17598</a></li>
</ul>
</li>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Standardize API Key vs Virtual Key in UI - <a href="https://github.com/BerriAI/litellm/pull/17325" target="_blank" rel="noopener noreferrer">PR #17325</a></li>
<li>Add User Alias Column to Internal User Table - <a href="https://github.com/BerriAI/litellm/pull/17321" target="_blank" rel="noopener noreferrer">PR #17321</a></li>
<li>Delete Credential Enhancements - <a href="https://github.com/BerriAI/litellm/pull/17317" target="_blank" rel="noopener noreferrer">PR #17317</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Show all credential values on Edit Credential Modal - <a href="https://github.com/BerriAI/litellm/pull/17397" target="_blank" rel="noopener noreferrer">PR #17397</a></li>
<li>Change Edit Team Models Shown to Match Create Team - <a href="https://github.com/BerriAI/litellm/pull/17394" target="_blank" rel="noopener noreferrer">PR #17394</a></li>
<li>Support Images in Compare UI - <a href="https://github.com/BerriAI/litellm/pull/17562" target="_blank" rel="noopener noreferrer">PR #17562</a></li>
</ul>
</li>
<li>
<p><strong>Callbacks</strong></p>
<ul>
<li>Show all callbacks on UI - <a href="https://github.com/BerriAI/litellm/pull/16335" target="_blank" rel="noopener noreferrer">PR #16335</a></li>
<li>Credentials to use React Query - <a href="https://github.com/BerriAI/litellm/pull/17465" target="_blank" rel="noopener noreferrer">PR #17465</a></li>
</ul>
</li>
<li>
<p><strong>Management Routes</strong></p>
<ul>
<li>Allow admin viewer to access global tag usage - <a href="https://github.com/BerriAI/litellm/pull/17501" target="_blank" rel="noopener noreferrer">PR #17501</a></li>
<li>Allow wildcard routes for nonproxy admin (SCIM) - <a href="https://github.com/BerriAI/litellm/pull/17178" target="_blank" rel="noopener noreferrer">PR #17178</a></li>
<li>Return 404 when a user is not found on /user/info - <a href="https://github.com/BerriAI/litellm/pull/16850" target="_blank" rel="noopener noreferrer">PR #16850</a></li>
</ul>
</li>
<li>
<p><strong>OCI Configuration</strong></p>
<ul>
<li>Enable Oracle Cloud Infrastructure configuration via UI - <a href="https://github.com/BerriAI/litellm/pull/17159" target="_blank" rel="noopener noreferrer">PR #17159</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-8#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li>
<p><strong>UI Fixes</strong></p>
<ul>
<li>Fix Request and Response Panel JSONViewer - <a href="https://github.com/BerriAI/litellm/pull/17233" target="_blank" rel="noopener noreferrer">PR #17233</a></li>
<li>Adding Button Loading States to Edit Settings - <a href="https://github.com/BerriAI/litellm/pull/17236" target="_blank" rel="noopener noreferrer">PR #17236</a></li>
<li>Fix Various Text, button state, and test changes - <a href="https://github.com/BerriAI/litellm/pull/17237" target="_blank" rel="noopener noreferrer">PR #17237</a></li>
<li>Fix Fallbacks Immediately Deleting before API resolves - <a href="https://github.com/BerriAI/litellm/pull/17238" target="_blank" rel="noopener noreferrer">PR #17238</a></li>
<li>Remove Feature Flags - <a href="https://github.com/BerriAI/litellm/pull/17240" target="_blank" rel="noopener noreferrer">PR #17240</a></li>
<li>Fix metadata tags and model name display in UI for Azure passthrough - <a href="https://github.com/BerriAI/litellm/pull/17258" target="_blank" rel="noopener noreferrer">PR #17258</a></li>
<li>Change labeling around Vertex Fields - <a href="https://github.com/BerriAI/litellm/pull/17383" target="_blank" rel="noopener noreferrer">PR #17383</a></li>
<li>Remove second scrollbar when sidebar is expanded + tooltip z index - <a href="https://github.com/BerriAI/litellm/pull/17436" target="_blank" rel="noopener noreferrer">PR #17436</a></li>
<li>Fix Select in Edit Membership Modal - <a href="https://github.com/BerriAI/litellm/pull/17524" target="_blank" rel="noopener noreferrer">PR #17524</a></li>
<li>Change useAuthorized Hook to redirect to new Login Page - <a href="https://github.com/BerriAI/litellm/pull/17553" target="_blank" rel="noopener noreferrer">PR #17553</a></li>
</ul>
</li>
<li>
<p><strong>SSO</strong></p>
<ul>
<li>Fix the generic SSO provider - <a href="https://github.com/BerriAI/litellm/pull/17227" target="_blank" rel="noopener noreferrer">PR #17227</a></li>
<li>Clear SSO integration for all users - <a href="https://github.com/BerriAI/litellm/pull/17287" target="_blank" rel="noopener noreferrer">PR #17287</a></li>
<li>Fix SSO users not added to Entra synced team - <a href="https://github.com/BerriAI/litellm/pull/17331" target="_blank" rel="noopener noreferrer">PR #17331</a></li>
</ul>
</li>
<li>
<p><strong>Auth / JWT</strong></p>
<ul>
<li>JWT Auth - Allow using regular OIDC flow with user info endpoints - <a href="https://github.com/BerriAI/litellm/pull/17324" target="_blank" rel="noopener noreferrer">PR #17324</a></li>
<li>Fix litellm user auth not passing issue - <a href="https://github.com/BerriAI/litellm/pull/17342" target="_blank" rel="noopener noreferrer">PR #17342</a></li>
<li>Add other routes in JWT auth - <a href="https://github.com/BerriAI/litellm/pull/17345" target="_blank" rel="noopener noreferrer">PR #17345</a></li>
<li>Fix new org team validate against org - <a href="https://github.com/BerriAI/litellm/pull/17333" target="_blank" rel="noopener noreferrer">PR #17333</a></li>
<li>Fix litellm_enterprise ensure imported routes exist - <a href="https://github.com/BerriAI/litellm/pull/17337" target="_blank" rel="noopener noreferrer">PR #17337</a></li>
<li>Use organization.members instead of deprecated organization field - <a href="https://github.com/BerriAI/litellm/pull/17557" target="_blank" rel="noopener noreferrer">PR #17557</a></li>
</ul>
</li>
<li>
<p><strong>Organizations/Teams</strong></p>
<ul>
<li>Fix organization max budget not enforced - <a href="https://github.com/BerriAI/litellm/pull/17334" target="_blank" rel="noopener noreferrer">PR #17334</a></li>
<li>Fix budget update to allow null max_budget - <a href="https://github.com/BerriAI/litellm/pull/17545" target="_blank" rel="noopener noreferrer">PR #17545</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-integrations-2-new-integrations">AI Integrations (2 new integrations)<a href="https://docs.litellm.ai/release_notes/v1-80-8#ai-integrations-2-new-integrations" class="hash-link" aria-label="AI Integrations (2 new integrations)的直接链接" title="AI Integrations (2 new integrations)的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging-1-new-integration">Logging (1 new integration)<a href="https://docs.litellm.ai/release_notes/v1-80-8#logging-1-new-integration" class="hash-link" aria-label="Logging (1 new integration)的直接链接" title="Logging (1 new integration)的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-integration">New Integration<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-integration" class="hash-link" aria-label="New Integration的直接链接" title="New Integration的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging">Weave</a></strong>
<ul>
<li>Basic Weave OTEL integration - <a href="https://github.com/BerriAI/litellm/pull/17439" target="_blank" rel="noopener noreferrer">PR #17439</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="improvements--fixes">Improvements &amp; Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-8#improvements--fixes" class="hash-link" aria-label="Improvements &amp; Fixes的直接链接" title="Improvements &amp; Fixes的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">DataDog</a></strong></p>
<ul>
<li>Fix Datadog callback regression when ddtrace is installed - <a href="https://github.com/BerriAI/litellm/pull/17393" target="_blank" rel="noopener noreferrer">PR #17393</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/observability/arize_integration">Arize Phoenix</a></strong></p>
<ul>
<li>Fix clean arize-phoenix traces - <a href="https://github.com/BerriAI/litellm/pull/16611" target="_blank" rel="noopener noreferrer">PR #16611</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#mlflow">MLflow</a></strong></p>
<ul>
<li>Fix MLflow streaming spans for Anthropic passthrough - <a href="https://github.com/BerriAI/litellm/pull/17288" target="_blank" rel="noopener noreferrer">PR #17288</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong></p>
<ul>
<li>Fix Langfuse logger test mock setup - <a href="https://github.com/BerriAI/litellm/pull/17591" target="_blank" rel="noopener noreferrer">PR #17591</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Improve PII anonymization handling in logging callbacks - <a href="https://github.com/BerriAI/litellm/pull/17207" target="_blank" rel="noopener noreferrer">PR #17207</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails-1-new-integration">Guardrails (1 new integration)<a href="https://docs.litellm.ai/release_notes/v1-80-8#guardrails-1-new-integration" class="hash-link" aria-label="Guardrails (1 new integration)的直接链接" title="Guardrails (1 new integration)的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-integration-1">New Integration<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-integration-1" class="hash-link" aria-label="New Integration的直接链接" title="New Integration的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/adding_provider/generic_guardrail_api">Generic Guardrail API</a></strong>
<ul>
<li>Generic Guardrail API - allows guardrail providers to add INSTANT support for LiteLLM w/out PR to repo - <a href="https://github.com/BerriAI/litellm/pull/17175" target="_blank" rel="noopener noreferrer">PR #17175</a></li>
<li>Guardrails API V2 - user api key metadata, session id, specify input type (request/response), image support - <a href="https://github.com/BerriAI/litellm/pull/17338" target="_blank" rel="noopener noreferrer">PR #17338</a></li>
<li>Guardrails API - add streaming support - <a href="https://github.com/BerriAI/litellm/pull/17400" target="_blank" rel="noopener noreferrer">PR #17400</a></li>
<li>Guardrails API - support tool call checks on OpenAI <code>/chat/completions</code>, OpenAI <code>/responses</code>, Anthropic <code>/v1/messages</code> - <a href="https://github.com/BerriAI/litellm/pull/17459" target="_blank" rel="noopener noreferrer">PR #17459</a></li>
<li>Guardrails API - new <code>structured_messages</code> param - <a href="https://github.com/BerriAI/litellm/pull/17518" target="_blank" rel="noopener noreferrer">PR #17518</a></li>
<li>Correctly map a v1/messages call to the anthropic unified guardrail - <a href="https://github.com/BerriAI/litellm/pull/17424" target="_blank" rel="noopener noreferrer">PR #17424</a></li>
<li>Support during_call event type for unified guardrails - <a href="https://github.com/BerriAI/litellm/pull/17514" target="_blank" rel="noopener noreferrer">PR #17514</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="improvements--fixes-1">Improvements &amp; Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-8#improvements--fixes-1" class="hash-link" aria-label="Improvements &amp; Fixes的直接链接" title="Improvements &amp; Fixes的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/noma_security">Noma Guardrail</a></strong></p>
<ul>
<li>Refactor Noma guardrail to use shared Responses transformation and include system instructions - <a href="https://github.com/BerriAI/litellm/pull/17315" target="_blank" rel="noopener noreferrer">PR #17315</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/pii_masking_v2">Presidio</a></strong></p>
<ul>
<li>Handle empty content and error dict responses in guardrails - <a href="https://github.com/BerriAI/litellm/pull/17489" target="_blank" rel="noopener noreferrer">PR #17489</a></li>
<li>Fix Presidio guardrail test TypeError and license base64 decoding error - <a href="https://github.com/BerriAI/litellm/pull/17538" target="_blank" rel="noopener noreferrer">PR #17538</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/tool_permission">Tool Permissions</a></strong></p>
<ul>
<li>Add regex-based tool_name/tool_type matching for tool-permission - <a href="https://github.com/BerriAI/litellm/pull/17164" target="_blank" rel="noopener noreferrer">PR #17164</a></li>
<li>Add images for tool permission guardrail documentation - <a href="https://github.com/BerriAI/litellm/pull/17322" target="_blank" rel="noopener noreferrer">PR #17322</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/aim_security">AIM Guardrails</a></strong></p>
<ul>
<li>Fix AIM guardrail tests - <a href="https://github.com/BerriAI/litellm/pull/17499" target="_blank" rel="noopener noreferrer">PR #17499</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/bedrock">Bedrock Guardrails</a></strong></p>
<ul>
<li>Fix Bedrock Guardrail indent and import - <a href="https://github.com/BerriAI/litellm/pull/17378" target="_blank" rel="noopener noreferrer">PR #17378</a></li>
</ul>
</li>
<li>
<p><strong>General Guardrails</strong></p>
<ul>
<li>Mask all matching keywords in content filter - <a href="https://github.com/BerriAI/litellm/pull/17521" target="_blank" rel="noopener noreferrer">PR #17521</a></li>
<li>Ensure guardrail metadata is preserved in request_data - <a href="https://github.com/BerriAI/litellm/pull/17593" target="_blank" rel="noopener noreferrer">PR #17593</a></li>
<li>Fix apply_guardrail method and improve test isolation - <a href="https://github.com/BerriAI/litellm/pull/17555" target="_blank" rel="noopener noreferrer">PR #17555</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="secret-managers">Secret Managers<a href="https://docs.litellm.ai/release_notes/v1-80-8#secret-managers" class="hash-link" aria-label="Secret Managers的直接链接" title="Secret Managers的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/secret_managers/cyberark">CyberArk</a></strong></p>
<ul>
<li>Allow setting SSL verify to false - <a href="https://github.com/BerriAI/litellm/pull/17433" target="_blank" rel="noopener noreferrer">PR #17433</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Make email and secret manager operations independent in key management hooks - <a href="https://github.com/BerriAI/litellm/pull/17551" target="_blank" rel="noopener noreferrer">PR #17551</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-80-8#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Rate Limiting</strong></p>
<ul>
<li>Parallel Request Limiter with /messages - <a href="https://github.com/BerriAI/litellm/pull/17426" target="_blank" rel="noopener noreferrer">PR #17426</a></li>
<li>Allow using dynamic rate limit/priority reservation on teams - <a href="https://github.com/BerriAI/litellm/pull/17061" target="_blank" rel="noopener noreferrer">PR #17061</a></li>
<li>Dynamic Rate Limiter - Fix token count increases/decreases by 1 instead of actual count + Redis TTL - <a href="https://github.com/BerriAI/litellm/pull/17558" target="_blank" rel="noopener noreferrer">PR #17558</a></li>
</ul>
</li>
<li>
<p><strong>Spend Logs</strong></p>
<ul>
<li>Deprecate <code>spend/logs</code> &amp; add <code>spend/logs/v2</code> - <a href="https://github.com/BerriAI/litellm/pull/17167" target="_blank" rel="noopener noreferrer">PR #17167</a></li>
<li>Optimize SpendLogs queries to use timestamp filtering for index usage - <a href="https://github.com/BerriAI/litellm/pull/17504" target="_blank" rel="noopener noreferrer">PR #17504</a></li>
</ul>
</li>
<li>
<p><strong>Enforce User Param</strong></p>
<ul>
<li>Enforce support of enforce_user_param to OpenAI post endpoints - <a href="https://github.com/BerriAI/litellm/pull/17407" target="_blank" rel="noopener noreferrer">PR #17407</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-80-8#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li>
<p><strong>MCP Configuration</strong></p>
<ul>
<li>Remove URL format validation for MCP server endpoints - <a href="https://github.com/BerriAI/litellm/pull/17270" target="_blank" rel="noopener noreferrer">PR #17270</a></li>
<li>Add stack trace to MCP error message - <a href="https://github.com/BerriAI/litellm/pull/17269" target="_blank" rel="noopener noreferrer">PR #17269</a></li>
</ul>
</li>
<li>
<p><strong>MCP Tool Results</strong></p>
<ul>
<li>Preserve tool metadata in CallToolResult - <a href="https://github.com/BerriAI/litellm/pull/17561" target="_blank" rel="noopener noreferrer">PR #17561</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agent-gateway-a2a-1">Agent Gateway (A2A)<a href="https://docs.litellm.ai/release_notes/v1-80-8#agent-gateway-a2a-1" class="hash-link" aria-label="Agent Gateway (A2A)的直接链接" title="Agent Gateway (A2A)的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Agent Invocation</strong></p>
<ul>
<li>Allow invoking agents through AI Gateway - <a href="https://github.com/BerriAI/litellm/pull/17440" target="_blank" rel="noopener noreferrer">PR #17440</a></li>
<li>Allow tracking request/response in "Logs" Page - <a href="https://github.com/BerriAI/litellm/pull/17449" target="_blank" rel="noopener noreferrer">PR #17449</a></li>
</ul>
</li>
<li>
<p><strong>Agent Access Control</strong></p>
<ul>
<li>Enforce Allowed agents by key, team + add agent access groups on backend - <a href="https://github.com/BerriAI/litellm/pull/17502" target="_blank" rel="noopener noreferrer">PR #17502</a></li>
</ul>
</li>
<li>
<p><strong>Agent Gateway UI</strong></p>
<ul>
<li>Allow testing agents on UI - <a href="https://github.com/BerriAI/litellm/pull/17455" target="_blank" rel="noopener noreferrer">PR #17455</a></li>
<li>Set allowed agents by key, team - <a href="https://github.com/BerriAI/litellm/pull/17511" target="_blank" rel="noopener noreferrer">PR #17511</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-80-8#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Audio/Speech Performance</strong></p>
<ul>
<li>Fix <code>/audio/speech</code> performance by using <code>shared_sessions</code> - <a href="https://github.com/BerriAI/litellm/pull/16739" target="_blank" rel="noopener noreferrer">PR #16739</a></li>
</ul>
</li>
<li>
<p><strong>Memory Optimization</strong></p>
<ul>
<li>Prevent memory leak in aiohttp connection pooling - <a href="https://github.com/BerriAI/litellm/pull/17388" target="_blank" rel="noopener noreferrer">PR #17388</a></li>
<li>Lazy-load utils to reduce memory + import time - <a href="https://github.com/BerriAI/litellm/pull/17171" target="_blank" rel="noopener noreferrer">PR #17171</a></li>
</ul>
</li>
<li>
<p><strong>Database</strong></p>
<ul>
<li>Update default database connection number - <a href="https://github.com/BerriAI/litellm/pull/17353" target="_blank" rel="noopener noreferrer">PR #17353</a></li>
<li>Update default proxy_batch_write_at number - <a href="https://github.com/BerriAI/litellm/pull/17355" target="_blank" rel="noopener noreferrer">PR #17355</a></li>
<li>Add background health checks to db - <a href="https://github.com/BerriAI/litellm/pull/17528" target="_blank" rel="noopener noreferrer">PR #17528</a></li>
</ul>
</li>
<li>
<p><strong>Proxy Caching</strong></p>
<ul>
<li>Fix proxy caching between requests in aiohttp transport - <a href="https://github.com/BerriAI/litellm/pull/17122" target="_blank" rel="noopener noreferrer">PR #17122</a></li>
</ul>
</li>
<li>
<p><strong>Session Management</strong></p>
<ul>
<li>Fix session consistency, move Lasso API version away from source code - <a href="https://github.com/BerriAI/litellm/pull/17316" target="_blank" rel="noopener noreferrer">PR #17316</a></li>
<li>Conditionally pass enable_cleanup_closed to aiohttp TCPConnector - <a href="https://github.com/BerriAI/litellm/pull/17367" target="_blank" rel="noopener noreferrer">PR #17367</a></li>
</ul>
</li>
<li>
<p><strong>Vector Store</strong></p>
<ul>
<li>Fix vector store configuration synchronization failure - <a href="https://github.com/BerriAI/litellm/pull/17525" target="_blank" rel="noopener noreferrer">PR #17525</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-80-8#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Add Azure AI Foundry documentation for Claude models - <a href="https://github.com/BerriAI/litellm/pull/17104" target="_blank" rel="noopener noreferrer">PR #17104</a></li>
<li>Document responses and embedding API for GitHub Copilot - <a href="https://github.com/BerriAI/litellm/pull/17456" target="_blank" rel="noopener noreferrer">PR #17456</a></li>
<li>Add gpt-5.1-codex-max to OpenAI provider documentation - <a href="https://github.com/BerriAI/litellm/pull/17602" target="_blank" rel="noopener noreferrer">PR #17602</a></li>
<li>Update Instructions For Phoenix Integration - <a href="https://github.com/BerriAI/litellm/pull/17373" target="_blank" rel="noopener noreferrer">PR #17373</a></li>
</ul>
</li>
<li>
<p><strong>Guides</strong></p>
<ul>
<li>Add guide on how to debug gateway error vs provider error - <a href="https://github.com/BerriAI/litellm/pull/17387" target="_blank" rel="noopener noreferrer">PR #17387</a></li>
<li>Agent Gateway documentation - <a href="https://github.com/BerriAI/litellm/pull/17454" target="_blank" rel="noopener noreferrer">PR #17454</a></li>
<li>A2A Permission management documentation - <a href="https://github.com/BerriAI/litellm/pull/17515" target="_blank" rel="noopener noreferrer">PR #17515</a></li>
<li>Update docs to link agent hub - <a href="https://github.com/BerriAI/litellm/pull/17462" target="_blank" rel="noopener noreferrer">PR #17462</a></li>
</ul>
</li>
<li>
<p><strong>Projects</strong></p>
<ul>
<li>Add Google ADK and Harbor to projects - <a href="https://github.com/BerriAI/litellm/pull/17352" target="_blank" rel="noopener noreferrer">PR #17352</a></li>
<li>Add Microsoft Agent Lightning to projects - <a href="https://github.com/BerriAI/litellm/pull/17422" target="_blank" rel="noopener noreferrer">PR #17422</a></li>
</ul>
</li>
<li>
<p><strong>Cleanup</strong></p>
<ul>
<li>Cleanup: Remove orphan docs pages and Docusaurus template files - <a href="https://github.com/BerriAI/litellm/pull/17356" target="_blank" rel="noopener noreferrer">PR #17356</a></li>
<li>Remove <code>source .env</code> from docs - <a href="https://github.com/BerriAI/litellm/pull/17466" target="_blank" rel="noopener noreferrer">PR #17466</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure--cicd">Infrastructure / CI/CD<a href="https://docs.litellm.ai/release_notes/v1-80-8#infrastructure--cicd" class="hash-link" aria-label="Infrastructure / CI/CD的直接链接" title="Infrastructure / CI/CD的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Helm Chart</strong></p>
<ul>
<li>Add ingress-only labels - <a href="https://github.com/BerriAI/litellm/pull/17348" target="_blank" rel="noopener noreferrer">PR #17348</a></li>
</ul>
</li>
<li>
<p><strong>Docker</strong></p>
<ul>
<li>Add retry logic to apk package installation in Dockerfile.non_root - <a href="https://github.com/BerriAI/litellm/pull/17596" target="_blank" rel="noopener noreferrer">PR #17596</a></li>
<li>Chainguard fixes - <a href="https://github.com/BerriAI/litellm/pull/17406" target="_blank" rel="noopener noreferrer">PR #17406</a></li>
</ul>
</li>
<li>
<p><strong>OpenAPI Schema</strong></p>
<ul>
<li>Refactor add_schema_to_components to move definitions to components/schemas - <a href="https://github.com/BerriAI/litellm/pull/17389" target="_blank" rel="noopener noreferrer">PR #17389</a></li>
</ul>
</li>
<li>
<p><strong>Security</strong></p>
<ul>
<li>Fix security vulnerability: update mdast-util-to-hast to 13.2.1 - <a href="https://github.com/BerriAI/litellm/pull/17601" target="_blank" rel="noopener noreferrer">PR #17601</a></li>
<li>Bump jws from 3.2.2 to 3.2.3 - <a href="https://github.com/BerriAI/litellm/pull/17494" target="_blank" rel="noopener noreferrer">PR #17494</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-80-8#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@weichiet made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17242" target="_blank" rel="noopener noreferrer">PR #17242</a></li>
<li>@AndyForest made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17220" target="_blank" rel="noopener noreferrer">PR #17220</a></li>
<li>@omkar806 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17217" target="_blank" rel="noopener noreferrer">PR #17217</a></li>
<li>@v0rtex20k made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17178" target="_blank" rel="noopener noreferrer">PR #17178</a></li>
<li>@hxomer made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17207" target="_blank" rel="noopener noreferrer">PR #17207</a></li>
<li>@orgersh92 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17316" target="_blank" rel="noopener noreferrer">PR #17316</a></li>
<li>@dannykopping made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17313" target="_blank" rel="noopener noreferrer">PR #17313</a></li>
<li>@rioiart made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17333" target="_blank" rel="noopener noreferrer">PR #17333</a></li>
<li>@codgician made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17278" target="_blank" rel="noopener noreferrer">PR #17278</a></li>
<li>@epistoteles made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17277" target="_blank" rel="noopener noreferrer">PR #17277</a></li>
<li>@kothamah made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17368" target="_blank" rel="noopener noreferrer">PR #17368</a></li>
<li>@flozonn made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17371" target="_blank" rel="noopener noreferrer">PR #17371</a></li>
<li>@richardmcsong made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17389" target="_blank" rel="noopener noreferrer">PR #17389</a></li>
<li>@matt-greathouse made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17384" target="_blank" rel="noopener noreferrer">PR #17384</a></li>
<li>@mossbanay made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17380" target="_blank" rel="noopener noreferrer">PR #17380</a></li>
<li>@mhielpos-asapp made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17376" target="_blank" rel="noopener noreferrer">PR #17376</a></li>
<li>@Joilence made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17367" target="_blank" rel="noopener noreferrer">PR #17367</a></li>
<li>@deepaktammali made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17357" target="_blank" rel="noopener noreferrer">PR #17357</a></li>
<li>@axiomofjoy made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16611" target="_blank" rel="noopener noreferrer">PR #16611</a></li>
<li>@DevajMody made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17445" target="_blank" rel="noopener noreferrer">PR #17445</a></li>
<li>@andrewtruong made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17439" target="_blank" rel="noopener noreferrer">PR #17439</a></li>
<li>@AnasAbdelR made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17490" target="_blank" rel="noopener noreferrer">PR #17490</a></li>
<li>@dominicfeliton made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17516" target="_blank" rel="noopener noreferrer">PR #17516</a></li>
<li>@kristianmitk made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17504" target="_blank" rel="noopener noreferrer">PR #17504</a></li>
<li>@rgshr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17130" target="_blank" rel="noopener noreferrer">PR #17130</a></li>
<li>@dominicfallows made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17489" target="_blank" rel="noopener noreferrer">PR #17489</a></li>
<li>@irfansofyana made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17467" target="_blank" rel="noopener noreferrer">PR #17467</a></li>
<li>@GusBricker made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17191" target="_blank" rel="noopener noreferrer">PR #17191</a></li>
<li>@OlivverX made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17255" target="_blank" rel="noopener noreferrer">PR #17255</a></li>
<li>@withsmilo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/17585" target="_blank" rel="noopener noreferrer">PR #17585</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-80-8#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.80.7-nightly...v1.80.8" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.80.5-stable - Gemini 3.0 Support]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-80-5</link>
            <guid>https://docs.litellm.ai/release_notes/v1-80-5</guid>
            <pubDate>Sat, 22 Nov 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-80-5#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.80.5-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.5</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-80-5#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Gemini 3</strong> - <a href="https://docs.litellm.ai/blog/gemini_3">Day-0 support for Gemini 3 models with thought signatures</a></li>
<li><strong>Prompt Management</strong> - <a href="https://docs.litellm.ai/docs/proxy/litellm_prompt_management">Full prompt versioning support with UI for editing, testing, and version history</a></li>
<li><strong>MCP Hub</strong> - <a href="https://docs.litellm.ai/docs/proxy/ai_hub#mcp-servers">Publish and discover MCP servers within your organization</a></li>
<li><strong>Model Compare UI</strong> - <a href="https://docs.litellm.ai/docs/proxy/model_compare_ui">Side-by-side model comparison interface for testing</a></li>
<li><strong>Batch API Spend Tracking</strong> - <a href="https://docs.litellm.ai/docs/proxy/cost_tracking#-custom-spend-log-metadata">Granular spend tracking with custom metadata for batch and file creation requests</a></li>
<li><strong>AWS IAM Secret Manager</strong> - <a href="https://docs.litellm.ai/docs/secret_managers/aws_secret_manager#iam-role-assumption">IAM role authentication support for AWS Secret Manager</a></li>
<li><strong>Logging Callback Controls</strong> - <a href="https://docs.litellm.ai/docs/proxy/dynamic_logging#disabling-dynamic-callback-management-enterprise">Admin-level controls to prevent callers from disabling logging callbacks in compliance environments</a></li>
<li><strong>Proxy CLI JWT Authentication</strong> - <a href="https://docs.litellm.ai/docs/proxy/cli_sso">Enable developers to authenticate to LiteLLM AI Gateway using the Proxy CLI</a></li>
<li><strong>Batch API Routing</strong> - <a href="https://docs.litellm.ai/docs/batches#multi-account--model-based-routing">Route batch operations to different provider accounts using model-specific credentials from your config.yaml</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-80-5#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAeklEQVR4nEWNywqDUAxE7/9/ohtXighakGqet6ekIg0cGDKZTFvXlWmaWJaF0iJChONeGGb2022eZ4ZhYBxHtm1HVYkIIhM1R9XovdMqUZRZyTIyO2rB8RZOUbJ/aHfFTdWqGc94JK9Dubz/D+ujXMJ5Xrjf1c++Z/IFPt/CP4TPQfAAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/prompt_history.0899e07.640.png" srcset="/assets/ideal-img/prompt_history.0899e07.640.png 640w,/assets/ideal-img/prompt_history.6f089cb.1920.png 1920w" width="640" height="334"></noscript></div>
<br>
<br>
<p>This release introduces <strong>LiteLLM Prompt Studio</strong> - a comprehensive prompt management solution built directly into the LiteLLM UI. Create, test, and version your prompts without leaving your browser.</p>
<p>You can now do the following on LiteLLM Prompt Studio:</p>
<ul>
<li><strong>Create &amp; Test Prompts</strong>: Build prompts with developer messages (system instructions) and test them in real-time with an interactive chat interface</li>
<li><strong>Dynamic Variables</strong>: Use <code>{{variable_name}}</code> syntax to create reusable prompt templates with automatic variable detection</li>
<li><strong>Version Control</strong>: Automatic versioning for every prompt update with complete version history tracking and rollback capabilities</li>
<li><strong>Prompt Studio</strong>: Edit prompts in a dedicated studio environment with live testing and preview</li>
</ul>
<p><strong>API Integration:</strong></p>
<p>Use your prompts in any application with simple API calls:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"gpt-4"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    extra_body</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"prompt_id"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"your-prompt-id"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"prompt_version"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Optional: specify version</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">"prompt_variables"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">"name"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"value"</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Optional: pass variables</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Get started here: <a href="https://docs.litellm.ai/docs/proxy/litellm_prompt_management">LiteLLM Prompt Management Documentation</a></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance--realtime-182-lower-p99-latency">Performance – <code>/realtime</code> 182× Lower p99 Latency<a href="https://docs.litellm.ai/release_notes/v1-80-5#performance--realtime-182-lower-p99-latency" class="hash-link" aria-label="performance--realtime-182-lower-p99-latency的直接链接" title="performance--realtime-182-lower-p99-latency的直接链接">​</a></h3>
<p>This update reduces <code>/realtime</code> latency by removing redundant encodings on the hot path, reusing shared SSL contexts, and caching formatting strings that were being regenerated twice per request despite rarely changing.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://docs.litellm.ai/release_notes/v1-80-5#results" class="hash-link" aria-label="Results的直接链接" title="Results的直接链接">​</a></h4>
<table><thead><tr><th>Metric</th><th>Before</th><th>After</th><th>Improvement</th></tr></thead><tbody><tr><td>Median latency</td><td>2,200 ms</td><td><strong>59 ms</strong></td><td><strong>−97% (~37× faster)</strong></td></tr><tr><td>p95 latency</td><td>8,500 ms</td><td><strong>67 ms</strong></td><td><strong>−99% (~127× faster)</strong></td></tr><tr><td>p99 latency</td><td>18,000 ms</td><td><strong>99 ms</strong></td><td><strong>−99% (~182× faster)</strong></td></tr><tr><td>Average latency</td><td>3,214 ms</td><td><strong>63 ms</strong></td><td><strong>−98% (~51× faster)</strong></td></tr><tr><td>RPS</td><td>165</td><td><strong>1,207</strong></td><td><strong>+631% (~7.3× increase)</strong></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="https://docs.litellm.ai/release_notes/v1-80-5#test-setup" class="hash-link" aria-label="Test Setup的直接链接" title="Test Setup的直接链接">​</a></h4>
<table><thead><tr><th>Category</th><th>Specification</th></tr></thead><tbody><tr><td><strong>Load Testing</strong></td><td>Locust: 1,000 concurrent users, 500 ramp-up</td></tr><tr><td><strong>System</strong></td><td>4 vCPUs, 8 GB RAM, 4 workers, 4 instances</td></tr><tr><td><strong>Database</strong></td><td>PostgreSQL (Redis unused)</td></tr><tr><td><strong>Configuration</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/420fb44c31c00b4f17a99588637f01ec" target="_blank" rel="noopener noreferrer">config.yaml</a></td></tr><tr><td><strong>Load Script</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/73b83ada21d9b84d4fe09665cf1745f5" target="_blank" rel="noopener noreferrer">no_cache_hits.py</a></td></tr></tbody></table>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-compare-ui">Model Compare UI<a href="https://docs.litellm.ai/release_notes/v1-80-5#model-compare-ui" class="hash-link" aria-label="Model Compare UI的直接链接" title="Model Compare UI的直接链接">​</a></h3>
<p>New interactive playground UI enables side-by-side comparison of multiple LLM models, making it easy to evaluate and compare model responses.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Compare responses from multiple models in real-time</li>
<li>Side-by-side view with synchronized scrolling</li>
<li>Support for all LiteLLM-supported models</li>
<li>Cost tracking per model</li>
<li>Response time comparison</li>
<li>Pre-configured prompts for quick and easy testing</li>
</ul>
<p><strong>Details:</strong></p>
<ul>
<li>
<p><strong>Parameterization</strong>: Configure API keys, endpoints, models, and model parameters, as well as interaction types (chat completions, embeddings, etc.)</p>
</li>
<li>
<p><strong>Model Comparison</strong>: Compare up to 3 different models simultaneously with side-by-side response views</p>
</li>
<li>
<p><strong>Comparison Metrics</strong>: View detailed comparison information including:</p>
<ul>
<li>Time To First Token</li>
<li>Input / Output / Reasoning Tokens</li>
<li>Total Latency</li>
<li>Cost (if enabled in config)</li>
</ul>
</li>
<li>
<p><strong>Safety Filters</strong>: Configure and test guardrails (safety filters) directly in the playground interface</p>
</li>
</ul>
<p><a href="https://docs.litellm.ai/docs/proxy/model_compare_ui">Get Started with Model Compare</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-and-endpoints">New Providers and Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-5#new-providers-and-endpoints" class="hash-link" aria-label="New Providers and Endpoints的直接链接" title="New Providers and Endpoints的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers">New Providers<a href="https://docs.litellm.ai/release_notes/v1-80-5#new-providers" class="hash-link" aria-label="New Providers的直接链接" title="New Providers的直接链接">​</a></h3>
<table><thead><tr><th>Provider</th><th>Supported Endpoints</th><th>Description</th></tr></thead><tbody><tr><td><strong><a href="https://docs.litellm.ai/docs/providers/docker_model_runner">Docker Model Runner</a></strong></td><td><code>/v1/chat/completions</code></td><td>Run LLM models in Docker containers</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-80-5#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-80-5#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Azure</td><td><code>azure/gpt-5.1</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-2025-11-13</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-codex</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-codex-2025-11-13</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-codex-mini</code></td><td>272K</td><td>$0.275</td><td>$2.20</td><td>Responses API, reasoning, vision</td></tr><tr><td>Azure</td><td><code>azure/gpt-5.1-codex-mini-2025-11-13</code></td><td>272K</td><td>$0.275</td><td>$2.20</td><td>Responses API, reasoning, vision</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5-2025-08-07</code></td><td>272K</td><td>$1.375</td><td>$11.00</td><td>Reasoning, vision, PDF input</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5-mini-2025-08-07</code></td><td>272K</td><td>$0.275</td><td>$2.20</td><td>Reasoning, vision, PDF input</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5-nano-2025-08-07</code></td><td>272K</td><td>$0.055</td><td>$0.44</td><td>Reasoning, vision, PDF input</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5.1</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5.1-codex</code></td><td>272K</td><td>$1.38</td><td>$11.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>Azure EU</td><td><code>azure/eu/gpt-5.1-codex-mini</code></td><td>272K</td><td>$0.275</td><td>$2.20</td><td>Responses API, reasoning, vision</td></tr><tr><td>Gemini</td><td><code>gemini-3-pro-preview</code></td><td>2M</td><td>$1.25</td><td>$5.00</td><td>Reasoning, vision, function calling</td></tr><tr><td>Gemini</td><td><code>gemini-3-pro-image</code></td><td>2M</td><td>$1.25</td><td>$5.00</td><td>Image generation, reasoning</td></tr><tr><td>OpenRouter</td><td><code>openrouter/deepseek/deepseek-v3p1-terminus</code></td><td>164K</td><td>$0.20</td><td>$0.40</td><td>Function calling, reasoning</td></tr><tr><td>OpenRouter</td><td><code>openrouter/moonshot/kimi-k2-instruct</code></td><td>262K</td><td>$0.60</td><td>$2.50</td><td>Function calling, web search</td></tr><tr><td>OpenRouter</td><td><code>openrouter/gemini/gemini-3-pro-preview</code></td><td>2M</td><td>$1.25</td><td>$5.00</td><td>Reasoning, vision, function calling</td></tr><tr><td>XAI</td><td><code>xai/grok-4.1-fast</code></td><td>2M</td><td>$0.20</td><td>$0.50</td><td>Reasoning, function calling</td></tr><tr><td>Together AI</td><td><code>together_ai/z-ai/glm-4.6</code></td><td>203K</td><td>$0.40</td><td>$1.75</td><td>Function calling, reasoning</td></tr><tr><td>Cerebras</td><td><code>cerebras/gpt-oss-120b</code></td><td>131K</td><td>$0.60</td><td>$0.60</td><td>Function calling</td></tr><tr><td>Bedrock</td><td><code>anthropic.claude-sonnet-4-5-20250929-v1:0</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Computer use, reasoning, vision</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-80-5#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini (Google AI Studio + Vertex AI)</a></strong></p>
<ul>
<li>Add Day 0 gemini-3-pro-preview support - <a href="https://github.com/BerriAI/litellm/pull/16719" target="_blank" rel="noopener noreferrer">PR #16719</a></li>
<li>Add support for Gemini 3 Pro Image model - <a href="https://github.com/BerriAI/litellm/pull/16938" target="_blank" rel="noopener noreferrer">PR #16938</a></li>
<li>Add reasoning_content to streaming responses with tools enabled - <a href="https://github.com/BerriAI/litellm/pull/16854" target="_blank" rel="noopener noreferrer">PR #16854</a></li>
<li>Add includeThoughts=True for Gemini 3 reasoning_effort - <a href="https://github.com/BerriAI/litellm/pull/16838" target="_blank" rel="noopener noreferrer">PR #16838</a></li>
<li>Support thought signatures for Gemini 3 in responses API - <a href="https://github.com/BerriAI/litellm/pull/16872" target="_blank" rel="noopener noreferrer">PR #16872</a></li>
<li>Correct wrong system message handling for gemma - <a href="https://github.com/BerriAI/litellm/pull/16767" target="_blank" rel="noopener noreferrer">PR #16767</a></li>
<li>Gemini 3 Pro Image: capture image_tokens and support cost_per_output_image - <a href="https://github.com/BerriAI/litellm/pull/16912" target="_blank" rel="noopener noreferrer">PR #16912</a></li>
<li>Fix missing costs for gemini-2.5-flash-image - <a href="https://github.com/BerriAI/litellm/pull/16882" target="_blank" rel="noopener noreferrer">PR #16882</a></li>
<li>Gemini 3 thought signatures in tool call id - <a href="https://github.com/BerriAI/litellm/pull/16895" target="_blank" rel="noopener noreferrer">PR #16895</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Add azure gpt-5.1 models - <a href="https://github.com/BerriAI/litellm/pull/16817" target="_blank" rel="noopener noreferrer">PR #16817</a></li>
<li>Add Azure models 2025 11 to cost maps - <a href="https://github.com/BerriAI/litellm/pull/16762" target="_blank" rel="noopener noreferrer">PR #16762</a></li>
<li>Update Azure Pricing - <a href="https://github.com/BerriAI/litellm/pull/16371" target="_blank" rel="noopener noreferrer">PR #16371</a></li>
<li>Add SSML Support for Azure Text-to-Speech (AVA) - <a href="https://github.com/BerriAI/litellm/pull/16747" target="_blank" rel="noopener noreferrer">PR #16747</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Support GPT-5.1 reasoning.effort='none' in proxy - <a href="https://github.com/BerriAI/litellm/pull/16745" target="_blank" rel="noopener noreferrer">PR #16745</a></li>
<li>Add gpt-5.1-codex and gpt-5.1-codex-mini models to documentation - <a href="https://github.com/BerriAI/litellm/pull/16735" target="_blank" rel="noopener noreferrer">PR #16735</a></li>
<li>Inherit BaseVideoConfig to enable async content response for OpenAI video - <a href="https://github.com/BerriAI/litellm/pull/16708" target="_blank" rel="noopener noreferrer">PR #16708</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Add support for <code>strict</code> parameter in Anthropic tool schemas - <a href="https://github.com/BerriAI/litellm/pull/16725" target="_blank" rel="noopener noreferrer">PR #16725</a></li>
<li>Add image as url support to anthropic - <a href="https://github.com/BerriAI/litellm/pull/16868" target="_blank" rel="noopener noreferrer">PR #16868</a></li>
<li>Add thought signature support to v1/messages api - <a href="https://github.com/BerriAI/litellm/pull/16812" target="_blank" rel="noopener noreferrer">PR #16812</a></li>
<li>Anthropic - support Structured Outputs <code>output_format</code> for Claude 4.5 sonnet and Opus 4.1 - <a href="https://github.com/BerriAI/litellm/pull/16949" target="_blank" rel="noopener noreferrer">PR #16949</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Haiku 4.5 correct Bedrock configs - <a href="https://github.com/BerriAI/litellm/pull/16732" target="_blank" rel="noopener noreferrer">PR #16732</a></li>
<li>Ensure consistent chunk IDs in Bedrock streaming responses - <a href="https://github.com/BerriAI/litellm/pull/16596" target="_blank" rel="noopener noreferrer">PR #16596</a></li>
<li>Add Claude 4.5 to US Gov Cloud - <a href="https://github.com/BerriAI/litellm/pull/16957" target="_blank" rel="noopener noreferrer">PR #16957</a></li>
<li>Fix images being dropped from tool results for bedrock - <a href="https://github.com/BerriAI/litellm/pull/16492" target="_blank" rel="noopener noreferrer">PR #16492</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong></p>
<ul>
<li>Add Vertex AI Image Edit Support - <a href="https://github.com/BerriAI/litellm/pull/16828" target="_blank" rel="noopener noreferrer">PR #16828</a></li>
<li>Update veo 3 pricing and add prod models - <a href="https://github.com/BerriAI/litellm/pull/16781" target="_blank" rel="noopener noreferrer">PR #16781</a></li>
<li>Fix Video download for veo3 - <a href="https://github.com/BerriAI/litellm/pull/16875" target="_blank" rel="noopener noreferrer">PR #16875</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/snowflake">Snowflake</a></strong></p>
<ul>
<li>Snowflake provider support: added embeddings, PAT, account_id - <a href="https://github.com/BerriAI/litellm/pull/15727" target="_blank" rel="noopener noreferrer">PR #15727</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI</a></strong></p>
<ul>
<li>Add oci_endpoint_id Parameter for OCI Dedicated Endpoints - <a href="https://github.com/BerriAI/litellm/pull/16723" target="_blank" rel="noopener noreferrer">PR #16723</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/xai">XAI</a></strong></p>
<ul>
<li>Add support for Grok 4.1 Fast models - <a href="https://github.com/BerriAI/litellm/pull/16936" target="_blank" rel="noopener noreferrer">PR #16936</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/togetherai">Together AI</a></strong></p>
<ul>
<li>Add GLM 4.6 from together.ai - <a href="https://github.com/BerriAI/litellm/pull/16942" target="_blank" rel="noopener noreferrer">PR #16942</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/cerebras">Cerebras</a></strong></p>
<ul>
<li>Fix Cerebras GPT-OSS-120B model name - <a href="https://github.com/BerriAI/litellm/pull/16939" target="_blank" rel="noopener noreferrer">PR #16939</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-5#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Fix for 16863 - openai conversion from responses to completions - <a href="https://github.com/BerriAI/litellm/pull/16864" target="_blank" rel="noopener noreferrer">PR #16864</a></li>
<li>Revert "Make all gpt-5 and reasoning models to responses by default" - <a href="https://github.com/BerriAI/litellm/pull/16849" target="_blank" rel="noopener noreferrer">PR #16849</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Get custom_llm_provider from query param - <a href="https://github.com/BerriAI/litellm/pull/16731" target="_blank" rel="noopener noreferrer">PR #16731</a></li>
<li>Fix optional param mapping - <a href="https://github.com/BerriAI/litellm/pull/16852" target="_blank" rel="noopener noreferrer">PR #16852</a></li>
<li>Add None check for litellm_params - <a href="https://github.com/BerriAI/litellm/pull/16754" target="_blank" rel="noopener noreferrer">PR #16754</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-5#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-80-5#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Add Responses API support for gpt-5.1-codex model - <a href="https://github.com/BerriAI/litellm/pull/16845" target="_blank" rel="noopener noreferrer">PR #16845</a></li>
<li>Add managed files support for responses API - <a href="https://github.com/BerriAI/litellm/pull/16733" target="_blank" rel="noopener noreferrer">PR #16733</a></li>
<li>Add extra_body support for response supported api params from chat completion - <a href="https://github.com/BerriAI/litellm/pull/16765" target="_blank" rel="noopener noreferrer">PR #16765</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/batches">Batch API</a></strong></p>
<ul>
<li>Support /delete for files + support /cancel for batches - <a href="https://github.com/BerriAI/litellm/pull/16387" target="_blank" rel="noopener noreferrer">PR #16387</a></li>
<li>Add config based routing support for batches and files - <a href="https://github.com/BerriAI/litellm/pull/16872" target="_blank" rel="noopener noreferrer">PR #16872</a></li>
<li>Populate spend_logs_metadata in batch and files endpoints - <a href="https://github.com/BerriAI/litellm/pull/16921" target="_blank" rel="noopener noreferrer">PR #16921</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/search">Search APIs</a></strong></p>
<ul>
<li>Search APIs - error in firecrawl-search "Invalid request body" - <a href="https://github.com/BerriAI/litellm/pull/16943" target="_blank" rel="noopener noreferrer">PR #16943</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/vector_stores">Vector Stores</a></strong></p>
<ul>
<li>Fix vector store create issue - <a href="https://github.com/BerriAI/litellm/pull/16804" target="_blank" rel="noopener noreferrer">PR #16804</a></li>
<li>Team vector-store permissions now respected for key access - <a href="https://github.com/BerriAI/litellm/pull/16639" target="_blank" rel="noopener noreferrer">PR #16639</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/audio_transcription">Audio Transcription</a></strong></p>
<ul>
<li>Fix audio transcription cost tracking - <a href="https://github.com/BerriAI/litellm/pull/16478" target="_blank" rel="noopener noreferrer">PR #16478</a></li>
<li>Add missing shared_sessions to audio/transcriptions - <a href="https://github.com/BerriAI/litellm/pull/16858" target="_blank" rel="noopener noreferrer">PR #16858</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Fix videos tagging - <a href="https://github.com/BerriAI/litellm/pull/16770" target="_blank" rel="noopener noreferrer">PR #16770</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-5#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Responses API cost tracking with custom deployment names - <a href="https://github.com/BerriAI/litellm/pull/16778" target="_blank" rel="noopener noreferrer">PR #16778</a></li>
<li>Trim logged response strings in spend-logs - <a href="https://github.com/BerriAI/litellm/pull/16654" target="_blank" rel="noopener noreferrer">PR #16654</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-80-5#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-80-5#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Proxy CLI Auth</strong></p>
<ul>
<li>Allow using JWTs for signing in with Proxy CLI - <a href="https://github.com/BerriAI/litellm/pull/16756" target="_blank" rel="noopener noreferrer">PR #16756</a></li>
</ul>
</li>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Fix Key Model Alias Not Working - <a href="https://github.com/BerriAI/litellm/pull/16896" target="_blank" rel="noopener noreferrer">PR #16896</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Add additional model settings to chat models in test key - <a href="https://github.com/BerriAI/litellm/pull/16793" target="_blank" rel="noopener noreferrer">PR #16793</a></li>
<li>Deactivate delete button on model table for config models - <a href="https://github.com/BerriAI/litellm/pull/16787" target="_blank" rel="noopener noreferrer">PR #16787</a></li>
<li>Change Public Model Hub to use proxyBaseUrl - <a href="https://github.com/BerriAI/litellm/pull/16892" target="_blank" rel="noopener noreferrer">PR #16892</a></li>
<li>Add JSON Viewer to request/response panel - <a href="https://github.com/BerriAI/litellm/pull/16687" target="_blank" rel="noopener noreferrer">PR #16687</a></li>
<li>Standarize icon images - <a href="https://github.com/BerriAI/litellm/pull/16837" target="_blank" rel="noopener noreferrer">PR #16837</a></li>
</ul>
</li>
<li>
<p><strong>Teams</strong></p>
<ul>
<li>Teams table empty state - <a href="https://github.com/BerriAI/litellm/pull/16738" target="_blank" rel="noopener noreferrer">PR #16738</a></li>
</ul>
</li>
<li>
<p><strong>Fallbacks</strong></p>
<ul>
<li>Fallbacks icon button tooltips and delete with friction - <a href="https://github.com/BerriAI/litellm/pull/16737" target="_blank" rel="noopener noreferrer">PR #16737</a></li>
</ul>
</li>
<li>
<p><strong>MCP Servers</strong></p>
<ul>
<li>Delete user and MCP Server Modal, MCP Table Tooltips - <a href="https://github.com/BerriAI/litellm/pull/16751" target="_blank" rel="noopener noreferrer">PR #16751</a></li>
</ul>
</li>
<li>
<p><strong>Callbacks</strong></p>
<ul>
<li>Expose backend endpoint for callbacks settings - <a href="https://github.com/BerriAI/litellm/pull/16698" target="_blank" rel="noopener noreferrer">PR #16698</a></li>
<li>Edit add callbacks route to use data from backend - <a href="https://github.com/BerriAI/litellm/pull/16699" target="_blank" rel="noopener noreferrer">PR #16699</a></li>
</ul>
</li>
<li>
<p><strong>Usage &amp; Analytics</strong></p>
<ul>
<li>Allow partial matches for user ID in User Table - <a href="https://github.com/BerriAI/litellm/pull/16952" target="_blank" rel="noopener noreferrer">PR #16952</a></li>
</ul>
</li>
<li>
<p><strong>General UI</strong></p>
<ul>
<li>Allow setting base_url in API reference docs - <a href="https://github.com/BerriAI/litellm/pull/16674" target="_blank" rel="noopener noreferrer">PR #16674</a></li>
<li>Change /public fields to honor server root path - <a href="https://github.com/BerriAI/litellm/pull/16930" target="_blank" rel="noopener noreferrer">PR #16930</a></li>
<li>Correct ui build - <a href="https://github.com/BerriAI/litellm/pull/16702" target="_blank" rel="noopener noreferrer">PR #16702</a></li>
<li>Enable automatic dark/light mode based on system preference - <a href="https://github.com/BerriAI/litellm/pull/16748" target="_blank" rel="noopener noreferrer">PR #16748</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-5#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li>
<p><strong>UI Fixes</strong></p>
<ul>
<li>Fix flaky tests due to antd Notification Manager - <a href="https://github.com/BerriAI/litellm/pull/16740" target="_blank" rel="noopener noreferrer">PR #16740</a></li>
<li>Fix UI MCP Tool Test Regression - <a href="https://github.com/BerriAI/litellm/pull/16695" target="_blank" rel="noopener noreferrer">PR #16695</a></li>
<li>Fix edit logging settings not appearing - <a href="https://github.com/BerriAI/litellm/pull/16798" target="_blank" rel="noopener noreferrer">PR #16798</a></li>
<li>Add css to truncate long request ids in request viewer - <a href="https://github.com/BerriAI/litellm/pull/16665" target="_blank" rel="noopener noreferrer">PR #16665</a></li>
<li>Remove azure/ prefix in Placeholder for Azure in Add Model - <a href="https://github.com/BerriAI/litellm/pull/16597" target="_blank" rel="noopener noreferrer">PR #16597</a></li>
<li>Remove UI Session Token from user/info return - <a href="https://github.com/BerriAI/litellm/pull/16851" target="_blank" rel="noopener noreferrer">PR #16851</a></li>
<li>Remove console logs and errors from model tab - <a href="https://github.com/BerriAI/litellm/pull/16455" target="_blank" rel="noopener noreferrer">PR #16455</a></li>
<li>Change Bulk Invite User Roles to Match Backend - <a href="https://github.com/BerriAI/litellm/pull/16906" target="_blank" rel="noopener noreferrer">PR #16906</a></li>
<li>Mock Tremor's Tooltip to Fix Flaky UI Tests - <a href="https://github.com/BerriAI/litellm/pull/16786" target="_blank" rel="noopener noreferrer">PR #16786</a></li>
<li>Fix e2e ui playwright test - <a href="https://github.com/BerriAI/litellm/pull/16799" target="_blank" rel="noopener noreferrer">PR #16799</a></li>
<li>Fix Tests in CI/CD - <a href="https://github.com/BerriAI/litellm/pull/16972" target="_blank" rel="noopener noreferrer">PR #16972</a></li>
</ul>
</li>
<li>
<p><strong>SSO</strong></p>
<ul>
<li>Ensure <code>role</code> from SSO provider is used when a user is inserted onto LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/16794" target="_blank" rel="noopener noreferrer">PR #16794</a></li>
<li>Docs - SSO - Manage User Roles via Azure App Roles - <a href="https://github.com/BerriAI/litellm/pull/16796" target="_blank" rel="noopener noreferrer">PR #16796</a></li>
</ul>
</li>
<li>
<p><strong>Auth</strong></p>
<ul>
<li>Ensure Team Tags works when using JWT Auth - <a href="https://github.com/BerriAI/litellm/pull/16797" target="_blank" rel="noopener noreferrer">PR #16797</a></li>
<li>Fix key never expires - <a href="https://github.com/BerriAI/litellm/pull/16692" target="_blank" rel="noopener noreferrer">PR #16692</a></li>
</ul>
</li>
<li>
<p><strong>Swagger UI</strong></p>
<ul>
<li>Fixes Swagger UI resolver errors for chat completion endpoints caused by Pydantic v2 <code>$defs</code> not being properly exposed in the OpenAPI schema - <a href="https://github.com/BerriAI/litellm/pull/16784" target="_blank" rel="noopener noreferrer">PR #16784</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-integrations">AI Integrations<a href="https://docs.litellm.ai/release_notes/v1-80-5#ai-integrations" class="hash-link" aria-label="AI Integrations的直接链接" title="AI Integrations的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging">Logging<a href="https://docs.litellm.ai/release_notes/v1-80-5#logging" class="hash-link" aria-label="Logging的直接链接" title="Logging的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/observability/arize_phoenix">Arize Phoenix</a></strong></p>
<ul>
<li>Fix arize phoenix logging - <a href="https://github.com/BerriAI/litellm/pull/16301" target="_blank" rel="noopener noreferrer">PR #16301</a></li>
<li>Arize Phoenix - root span logging - <a href="https://github.com/BerriAI/litellm/pull/16949" target="_blank" rel="noopener noreferrer">PR #16949</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong></p>
<ul>
<li>Filter secret fields form Langfuse - <a href="https://github.com/BerriAI/litellm/pull/16842" target="_blank" rel="noopener noreferrer">PR #16842</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Exclude litellm_credential_name from Sensitive Data Masker (Updated) - <a href="https://github.com/BerriAI/litellm/pull/16958" target="_blank" rel="noopener noreferrer">PR #16958</a></li>
<li>Allow admins to disable, dynamic callback controls - <a href="https://github.com/BerriAI/litellm/pull/16750" target="_blank" rel="noopener noreferrer">PR #16750</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-80-5#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">IBM Guardrails</a></strong></p>
<ul>
<li>Fix IBM Guardrails optional params, add extra_headers field - <a href="https://github.com/BerriAI/litellm/pull/16771" target="_blank" rel="noopener noreferrer">PR #16771</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Noma Guardrail</a></strong></p>
<ul>
<li>Use LiteLLM key alias as fallback Noma applicationId in NomaGuardrail - <a href="https://github.com/BerriAI/litellm/pull/16832" target="_blank" rel="noopener noreferrer">PR #16832</a></li>
<li>Allow custom violation message for tool-permission guardrail - <a href="https://github.com/BerriAI/litellm/pull/16916" target="_blank" rel="noopener noreferrer">PR #16916</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Grayswan Guardrail</a></strong></p>
<ul>
<li>Grayswan guardrail passthrough on flagged - <a href="https://github.com/BerriAI/litellm/pull/16891" target="_blank" rel="noopener noreferrer">PR #16891</a></li>
</ul>
</li>
<li>
<p><strong>General Guardrails</strong></p>
<ul>
<li>Fix prompt injection not working - <a href="https://github.com/BerriAI/litellm/pull/16701" target="_blank" rel="noopener noreferrer">PR #16701</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management-1">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-80-5#prompt-management-1" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/prompt_management">Prompt Management</a></strong>
<ul>
<li>Allow specifying just prompt_id in a request to a model - <a href="https://github.com/BerriAI/litellm/pull/16834" target="_blank" rel="noopener noreferrer">PR #16834</a></li>
<li>Add support for versioning prompts - <a href="https://github.com/BerriAI/litellm/pull/16836" target="_blank" rel="noopener noreferrer">PR #16836</a></li>
<li>Allow storing prompt version in DB - <a href="https://github.com/BerriAI/litellm/pull/16848" target="_blank" rel="noopener noreferrer">PR #16848</a></li>
<li>Add UI for editing the prompts - <a href="https://github.com/BerriAI/litellm/pull/16853" target="_blank" rel="noopener noreferrer">PR #16853</a></li>
<li>Allow testing prompts with Chat UI - <a href="https://github.com/BerriAI/litellm/pull/16898" target="_blank" rel="noopener noreferrer">PR #16898</a></li>
<li>Allow viewing version history - <a href="https://github.com/BerriAI/litellm/pull/16901" target="_blank" rel="noopener noreferrer">PR #16901</a></li>
<li>Allow specifying prompt version in code - <a href="https://github.com/BerriAI/litellm/pull/16929" target="_blank" rel="noopener noreferrer">PR #16929</a></li>
<li>UI, allow seeing model, prompt id for Prompt - <a href="https://github.com/BerriAI/litellm/pull/16932" target="_blank" rel="noopener noreferrer">PR #16932</a></li>
<li>Show "get code" section for prompt management + minor polish of showing version history - <a href="https://github.com/BerriAI/litellm/pull/16941" target="_blank" rel="noopener noreferrer">PR #16941</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="secret-managers">Secret Managers<a href="https://docs.litellm.ai/release_notes/v1-80-5#secret-managers" class="hash-link" aria-label="Secret Managers的直接链接" title="Secret Managers的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/secret_managers">AWS Secrets Manager</a></strong>
<ul>
<li>Adds IAM role assumption support for AWS Secret Manager - <a href="https://github.com/BerriAI/litellm/pull/16887" target="_blank" rel="noopener noreferrer">PR #16887</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-80-5#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>MCP Hub</strong> - Publish/discover MCP Servers within a company - <a href="https://github.com/BerriAI/litellm/pull/16857" target="_blank" rel="noopener noreferrer">PR #16857</a></li>
<li><strong>MCP Resources</strong> - MCP resources support - <a href="https://github.com/BerriAI/litellm/pull/16800" target="_blank" rel="noopener noreferrer">PR #16800</a></li>
<li><strong>MCP OAuth</strong> - Docs - mcp oauth flow details - <a href="https://github.com/BerriAI/litellm/pull/16742" target="_blank" rel="noopener noreferrer">PR #16742</a></li>
<li><strong>MCP Lifecycle</strong> - Drop MCPClient.connect and use run_with_session lifecycle - <a href="https://github.com/BerriAI/litellm/pull/16696" target="_blank" rel="noopener noreferrer">PR #16696</a></li>
<li><strong>MCP Server IDs</strong> - Add mcp server ids - <a href="https://github.com/BerriAI/litellm/pull/16904" target="_blank" rel="noopener noreferrer">PR #16904</a></li>
<li><strong>MCP URL Format</strong> - Fix mcp url format - <a href="https://github.com/BerriAI/litellm/pull/16940" target="_blank" rel="noopener noreferrer">PR #16940</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-80-5#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>Realtime Endpoint Performance</strong> - Fix bottlenecks degrading realtime endpoint performance - <a href="https://github.com/BerriAI/litellm/pull/16670" target="_blank" rel="noopener noreferrer">PR #16670</a></li>
<li><strong>SSL Context Caching</strong> - Cache SSL contexts to prevent excessive memory allocation - <a href="https://github.com/BerriAI/litellm/pull/16955" target="_blank" rel="noopener noreferrer">PR #16955</a></li>
<li><strong>Cache Optimization</strong> - Fix cache cooldown key generation - <a href="https://github.com/BerriAI/litellm/pull/16954" target="_blank" rel="noopener noreferrer">PR #16954</a></li>
<li><strong>Router Cache</strong> - Fix routing for requests with same cacheable prefix but different user messages - <a href="https://github.com/BerriAI/litellm/pull/16951" target="_blank" rel="noopener noreferrer">PR #16951</a></li>
<li><strong>Redis Event Loop</strong> - Fix redis event loop closed at first call - <a href="https://github.com/BerriAI/litellm/pull/16913" target="_blank" rel="noopener noreferrer">PR #16913</a></li>
<li><strong>Dependency Management</strong> - Upgrade pydantic to version 2.11.0 - <a href="https://github.com/BerriAI/litellm/pull/16909" target="_blank" rel="noopener noreferrer">PR #16909</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-80-5#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Add missing details to benchmark comparison - <a href="https://github.com/BerriAI/litellm/pull/16690" target="_blank" rel="noopener noreferrer">PR #16690</a></li>
<li>Fix anthropic pass-through endpoint - <a href="https://github.com/BerriAI/litellm/pull/16883" target="_blank" rel="noopener noreferrer">PR #16883</a></li>
<li>Cleanup repo and improve AI docs - <a href="https://github.com/BerriAI/litellm/pull/16775" target="_blank" rel="noopener noreferrer">PR #16775</a></li>
</ul>
</li>
<li>
<p><strong>API Documentation</strong></p>
<ul>
<li>Add docs related to openai metadata - <a href="https://github.com/BerriAI/litellm/pull/16872" target="_blank" rel="noopener noreferrer">PR #16872</a></li>
<li>Update docs with all supported endpoints and cost tracking - <a href="https://github.com/BerriAI/litellm/pull/16872" target="_blank" rel="noopener noreferrer">PR #16872</a></li>
</ul>
</li>
<li>
<p><strong>General Documentation</strong></p>
<ul>
<li>Add mini-swe-agent to Projects built on LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/16971" target="_blank" rel="noopener noreferrer">PR #16971</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure--cicd">Infrastructure / CI/CD<a href="https://docs.litellm.ai/release_notes/v1-80-5#infrastructure--cicd" class="hash-link" aria-label="Infrastructure / CI/CD的直接链接" title="Infrastructure / CI/CD的直接链接">​</a></h2>
<ul>
<li>
<p><strong>UI Testing</strong></p>
<ul>
<li>Break e2e_ui_testing into build, unit, and e2e steps - <a href="https://github.com/BerriAI/litellm/pull/16783" target="_blank" rel="noopener noreferrer">PR #16783</a></li>
<li>Building UI for Testing - <a href="https://github.com/BerriAI/litellm/pull/16968" target="_blank" rel="noopener noreferrer">PR #16968</a></li>
<li>CI/CD Fixes - <a href="https://github.com/BerriAI/litellm/pull/16937" target="_blank" rel="noopener noreferrer">PR #16937</a></li>
</ul>
</li>
<li>
<p><strong>Dependency Management</strong></p>
<ul>
<li>Bump js-yaml from 3.14.1 to 3.14.2 in /tests/proxy_admin_ui_tests/ui_unit_tests - <a href="https://github.com/BerriAI/litellm/pull/16755" target="_blank" rel="noopener noreferrer">PR #16755</a></li>
<li>Bump js-yaml from 3.14.1 to 3.14.2 - <a href="https://github.com/BerriAI/litellm/pull/16802" target="_blank" rel="noopener noreferrer">PR #16802</a></li>
</ul>
</li>
<li>
<p><strong>Migration</strong></p>
<ul>
<li>Migration job labels - <a href="https://github.com/BerriAI/litellm/pull/16831" target="_blank" rel="noopener noreferrer">PR #16831</a></li>
</ul>
</li>
<li>
<p><strong>Config</strong></p>
<ul>
<li>This yaml actually works - <a href="https://github.com/BerriAI/litellm/pull/16757" target="_blank" rel="noopener noreferrer">PR #16757</a></li>
</ul>
</li>
<li>
<p><strong>Release Notes</strong></p>
<ul>
<li>Add perf improvements on embeddings to release notes - <a href="https://github.com/BerriAI/litellm/pull/16697" target="_blank" rel="noopener noreferrer">PR #16697</a></li>
<li>Docs - v1.80.0 - <a href="https://github.com/BerriAI/litellm/pull/16694" target="_blank" rel="noopener noreferrer">PR #16694</a></li>
</ul>
</li>
<li>
<p><strong>Investigation</strong></p>
<ul>
<li>Investigate issue root cause - <a href="https://github.com/BerriAI/litellm/pull/16859" target="_blank" rel="noopener noreferrer">PR #16859</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-80-5#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@mattmorgis made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16371" target="_blank" rel="noopener noreferrer">PR #16371</a></li>
<li>@mmandic-coatue made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16732" target="_blank" rel="noopener noreferrer">PR #16732</a></li>
<li>@Bradley-Butcher made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16725" target="_blank" rel="noopener noreferrer">PR #16725</a></li>
<li>@BenjaminLevy made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16757" target="_blank" rel="noopener noreferrer">PR #16757</a></li>
<li>@CatBraaain made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16767" target="_blank" rel="noopener noreferrer">PR #16767</a></li>
<li>@tushar8408 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16831" target="_blank" rel="noopener noreferrer">PR #16831</a></li>
<li>@nbsp1221 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16845" target="_blank" rel="noopener noreferrer">PR #16845</a></li>
<li>@idola9 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16832" target="_blank" rel="noopener noreferrer">PR #16832</a></li>
<li>@nkukard made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16864" target="_blank" rel="noopener noreferrer">PR #16864</a></li>
<li>@alhuang10 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16852" target="_blank" rel="noopener noreferrer">PR #16852</a></li>
<li>@sebslight made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16838" target="_blank" rel="noopener noreferrer">PR #16838</a></li>
<li>@TsurumaruTsuyoshi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16905" target="_blank" rel="noopener noreferrer">PR #16905</a></li>
<li>@cyberjunk made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16492" target="_blank" rel="noopener noreferrer">PR #16492</a></li>
<li>@colinlin-stripe made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16895" target="_blank" rel="noopener noreferrer">PR #16895</a></li>
<li>@sureshdsk made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16883" target="_blank" rel="noopener noreferrer">PR #16883</a></li>
<li>@eiliyaabedini made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16875" target="_blank" rel="noopener noreferrer">PR #16875</a></li>
<li>@justin-tahara made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16957" target="_blank" rel="noopener noreferrer">PR #16957</a></li>
<li>@wangsoft made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16913" target="_blank" rel="noopener noreferrer">PR #16913</a></li>
<li>@dsduenas made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16891" target="_blank" rel="noopener noreferrer">PR #16891</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="known-issues">Known Issues<a href="https://docs.litellm.ai/release_notes/v1-80-5#known-issues" class="hash-link" aria-label="Known Issues的直接链接" title="Known Issues的直接链接">​</a></h2>
<ul>
<li><code>/audit</code> and <code>/user/available_users</code> routes return 404. Fixed in <a href="https://github.com/BerriAI/litellm/pull/17337" target="_blank" rel="noopener noreferrer">PR #17337</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-80-5#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.80.0-nightly...v1.80.5.rc.2" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.80.0-stable - Introducing Agent Hub: Register, Publish, and Share Agents]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-80-0</link>
            <guid>https://docs.litellm.ai/release_notes/v1-80-0</guid>
            <pubDate>Sat, 15 Nov 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-80-0#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.80.0-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.0</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-80-0#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>🆕 Agent Hub Support</strong> - Register and make agents public for your organization</li>
<li><strong>RunwayML Provider</strong> - Complete video generation, image generation, and text-to-speech support</li>
<li><strong>GPT-5.1 Family Support</strong> - Day-0 support for OpenAI's latest GPT-5.1 and GPT-5.1-Codex models</li>
<li><strong>Prometheus OSS</strong> - Prometheus metrics now available in open-source version</li>
<li><strong>Vector Store Files API</strong> - Complete OpenAI-compatible Vector Store Files API with full CRUD operations</li>
<li><strong>Embeddings Performance</strong> - O(1) lookup optimization for router embeddings with shared sessions</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-hub">Agent Hub<a href="https://docs.litellm.ai/release_notes/v1-80-0#agent-hub" class="hash-link" aria-label="Agent Hub的直接链接" title="Agent Hub的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAbklEQVR4nE2N4QoAIQiDe//XDIKgH0GoWdqOujtI+BDd2ELOGTFGEBFEBCyCMQbcDHYRSilIKaHWitYaiBi9K9wd/6y1ELZ7P/eec55U6f2IN0FV8bMrmRmiA74A/0zmjrDFG5YOYoWZn3vOt/EB/L7DnNBwMoAAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/agent_hub_clean.26a5a7f.640.png" srcset="/assets/ideal-img/agent_hub_clean.26a5a7f.640.png 640w,/assets/ideal-img/agent_hub_clean.2a6b3b3.1920.png 1920w" width="640" height="334"></noscript></div>
<p>This release adds support for registering and making agents public for your organization. This is great for <strong>Proxy Admins</strong> who want a central place to make agents built in their organization, discoverable to their users.</p>
<p>Here's the flow:</p>
<ol>
<li>Add agent to litellm.</li>
<li>Make it public.</li>
<li>Allow anyone to discover it on the public AI Hub page.</li>
</ol>
<p><a href="https://docs.litellm.ai/docs/proxy/ai_hub"><strong>Get Started with Agent Hub</strong></a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance--embeddings-13-lower-p95-latency">Performance – <code>/embeddings</code> 13× Lower p95 Latency<a href="https://docs.litellm.ai/release_notes/v1-80-0#performance--embeddings-13-lower-p95-latency" class="hash-link" aria-label="performance--embeddings-13-lower-p95-latency的直接链接" title="performance--embeddings-13-lower-p95-latency的直接链接">​</a></h3>
<p>This update significantly improves <code>/embeddings</code> latency by routing it through the same optimized pipeline as <code>/chat/completions</code>, benefiting from all previously applied networking optimizations.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://docs.litellm.ai/release_notes/v1-80-0#results" class="hash-link" aria-label="Results的直接链接" title="Results的直接链接">​</a></h3>
<table><thead><tr><th>Metric</th><th>Before</th><th>After</th><th>Improvement</th></tr></thead><tbody><tr><td>p95 latency</td><td>5,700 ms</td><td><strong>430 ms</strong></td><td>−92% (~13× faster)**</td></tr><tr><td>p99 latency</td><td>7,200 ms</td><td><strong>780 ms</strong></td><td>−89%</td></tr><tr><td>Average latency</td><td>844 ms</td><td><strong>262 ms</strong></td><td>−69%</td></tr><tr><td>Median latency</td><td>290 ms</td><td><strong>230 ms</strong></td><td>−21%</td></tr><tr><td>RPS</td><td>1,216.7</td><td><strong>1,219.7</strong></td><td><strong>+0.25%</strong></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="https://docs.litellm.ai/release_notes/v1-80-0#test-setup" class="hash-link" aria-label="Test Setup的直接链接" title="Test Setup的直接链接">​</a></h3>
<table><thead><tr><th>Category</th><th>Specification</th></tr></thead><tbody><tr><td><strong>Load Testing</strong></td><td>Locust: 1,000 concurrent users, 500 ramp-up</td></tr><tr><td><strong>System</strong></td><td>4 vCPUs, 8 GB RAM, 4 workers, 4 instances</td></tr><tr><td><strong>Database</strong></td><td>PostgreSQL (Redis unused)</td></tr><tr><td><strong>Configuration</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/550791675fd752befcac6a9e44024652" target="_blank" rel="noopener noreferrer">config.yaml</a></td></tr><tr><td><strong>Load Script</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/99d673bf74cdd81fd39f59fa9048f2e8" target="_blank" rel="noopener noreferrer">no_cache_hits.py</a></td></tr></tbody></table>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-runwayml">🆕 RunwayML<a href="https://docs.litellm.ai/release_notes/v1-80-0#-runwayml" class="hash-link" aria-label="🆕 RunwayML的直接链接" title="🆕 RunwayML的直接链接">​</a></h3>
<p>Complete integration for RunwayML's Gen-4 family of models, supporting video generation, image generation, and text-to-speech.</p>
<p><strong>Supported Endpoints:</strong></p>
<ul>
<li><code>/v1/videos</code> - Video generation (Gen-4 Turbo, Gen-4 Aleph, Gen-3A Turbo)</li>
<li><code>/v1/images/generations</code> - Image generation (Gen-4 Image, Gen-4 Image Turbo)</li>
<li><code>/v1/audio/speech</code> - Text-to-speech (ElevenLabs Multilingual v2)</li>
</ul>
<p><strong>Quick Start:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Generate Video with RunwayML</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">curl --location 'http://localhost:4000/v1/videos' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--header 'Content-Type: application/json' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--header 'Authorization: Bearer sk-1234' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--data '{</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "model": "runwayml/gen4_turbo",</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "prompt": "A high quality demo video of litellm ai gateway",</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "input_reference": "https://example.com/image.jpg",</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "seconds": 5,</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "size": "1280x720"</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">}'</span></span><br></span></code></pre></div></div>
<p><a href="https://docs.litellm.ai/docs/providers/runwayml/videos">Get Started with RunwayML</a></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prometheus-metrics---open-source">Prometheus Metrics - Open Source<a href="https://docs.litellm.ai/release_notes/v1-80-0#prometheus-metrics---open-source" class="hash-link" aria-label="Prometheus Metrics - Open Source的直接链接" title="Prometheus Metrics - Open Source的直接链接">​</a></h3>
<p>Prometheus metrics are now available in the open-source version of LiteLLM, providing comprehensive observability for your AI Gateway without requiring an enterprise license.</p>
<p><strong>Quick Start:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">litellm_settings</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">success_callback</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"prometheus"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">failure_callback</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"prometheus"</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div>
<p><a href="https://docs.litellm.ai/docs/proxy/logging#prometheus">Get Started with Prometheus</a></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vector-store-files-api">Vector Store Files API<a href="https://docs.litellm.ai/release_notes/v1-80-0#vector-store-files-api" class="hash-link" aria-label="Vector Store Files API的直接链接" title="Vector Store Files API的直接链接">​</a></h3>
<p>Complete OpenAI-compatible Vector Store Files API now stable, enabling full file lifecycle management within vector stores.</p>
<p><strong>Supported Endpoints:</strong></p>
<ul>
<li><code>POST /v1/vector_stores/{vector_store_id}/files</code> - Create vector store file</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files</code> - List vector store files</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files/{file_id}</code> - Retrieve vector store file</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files/{file_id}/content</code> - Retrieve file content</li>
<li><code>DELETE /v1/vector_stores/{vector_store_id}/files/{file_id}</code> - Delete vector store file</li>
<li><code>DELETE /v1/vector_stores/{vector_store_id}</code> - Delete vector store</li>
</ul>
<p><strong>Quick Start:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Create Vector Store File</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">curl --location 'http://localhost:4000/v1/vector_stores/vs_123/files' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--header 'Content-Type: application/json' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--header 'Authorization: Bearer sk-1234' \</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">--data '{</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    "file_id": "file_abc"</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">}'</span></span><br></span></code></pre></div></div>
<p><a href="https://docs.litellm.ai/docs/vector_store_files">Get Started with Vector Stores</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers-and-endpoints">New Providers and Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-providers-and-endpoints" class="hash-link" aria-label="New Providers and Endpoints的直接链接" title="New Providers and Endpoints的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-providers">New Providers<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-providers" class="hash-link" aria-label="New Providers的直接链接" title="New Providers的直接链接">​</a></h3>
<table><thead><tr><th>Provider</th><th>Supported Endpoints</th><th>Description</th></tr></thead><tbody><tr><td><strong><a href="https://docs.litellm.ai/docs/providers/runwayml/videos">RunwayML</a></strong></td><td><code>/v1/videos</code>, <code>/v1/images/generations</code>, <code>/v1/audio/speech</code></td><td>Gen-4 video generation, image generation, and text-to-speech</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="new-llm-api-endpoints">New LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-llm-api-endpoints" class="hash-link" aria-label="New LLM API Endpoints的直接链接" title="New LLM API Endpoints的直接链接">​</a></h3>
<table><thead><tr><th>Endpoint</th><th>Method</th><th>Description</th><th>Documentation</th></tr></thead><tbody><tr><td><code>/v1/vector_stores/{vector_store_id}/files</code></td><td>POST</td><td>Create vector store file</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr><tr><td><code>/v1/vector_stores/{vector_store_id}/files</code></td><td>GET</td><td>List vector store files</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr><tr><td><code>/v1/vector_stores/{vector_store_id}/files/{file_id}</code></td><td>GET</td><td>Retrieve vector store file</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr><tr><td><code>/v1/vector_stores/{vector_store_id}/files/{file_id}/content</code></td><td>GET</td><td>Retrieve file content</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr><tr><td><code>/v1/vector_stores/{vector_store_id}/files/{file_id}</code></td><td>DELETE</td><td>Delete vector store file</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr><tr><td><code>/v1/vector_stores/{vector_store_id}</code></td><td>DELETE</td><td>Delete vector store</td><td><a href="https://docs.litellm.ai/docs/vector_store_files">Docs</a></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>OpenAI</td><td><code>gpt-5.1</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>OpenAI</td><td><code>gpt-5.1-2025-11-13</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Reasoning, vision, PDF input, responses API</td></tr><tr><td>OpenAI</td><td><code>gpt-5.1-chat-latest</code></td><td>128K</td><td>$1.25</td><td>$10.00</td><td>Reasoning, vision, PDF input</td></tr><tr><td>OpenAI</td><td><code>gpt-5.1-codex</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>OpenAI</td><td><code>gpt-5.1-codex-mini</code></td><td>272K</td><td>$0.25</td><td>$2.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>Moonshot</td><td><code>moonshot/kimi-k2-thinking</code></td><td>262K</td><td>$0.60</td><td>$2.50</td><td>Function calling, web search, reasoning</td></tr><tr><td>Mistral</td><td><code>mistral/magistral-medium-2509</code></td><td>40K</td><td>$2.00</td><td>$5.00</td><td>Reasoning, function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/moonshotai/kimi-k2-thinking-maas</code></td><td>256K</td><td>$0.60</td><td>$2.50</td><td>Function calling, web search</td></tr><tr><td>OpenRouter</td><td><code>openrouter/deepseek/deepseek-v3.2-exp</code></td><td>164K</td><td>$0.20</td><td>$0.40</td><td>Function calling, prompt caching</td></tr><tr><td>OpenRouter</td><td><code>openrouter/minimax/minimax-m2</code></td><td>205K</td><td>$0.26</td><td>$1.02</td><td>Function calling, reasoning</td></tr><tr><td>OpenRouter</td><td><code>openrouter/z-ai/glm-4.6</code></td><td>203K</td><td>$0.40</td><td>$1.75</td><td>Function calling, reasoning</td></tr><tr><td>OpenRouter</td><td><code>openrouter/z-ai/glm-4.6:exacto</code></td><td>203K</td><td>$0.45</td><td>$1.90</td><td>Function calling, reasoning</td></tr><tr><td>Voyage</td><td><code>voyage/voyage-3.5</code></td><td>32K</td><td>$0.06</td><td>-</td><td>Embeddings</td></tr><tr><td>Voyage</td><td><code>voyage/voyage-3.5-lite</code></td><td>32K</td><td>$0.02</td><td>-</td><td>Embeddings</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="video-generation-models">Video Generation Models<a href="https://docs.litellm.ai/release_notes/v1-80-0#video-generation-models" class="hash-link" aria-label="Video Generation Models的直接链接" title="Video Generation Models的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Cost Per Second</th><th>Resolutions</th><th>Features</th></tr></thead><tbody><tr><td>RunwayML</td><td><code>runwayml/gen4_turbo</code></td><td>$0.05</td><td>1280x720, 720x1280</td><td>Text + image to video</td></tr><tr><td>RunwayML</td><td><code>runwayml/gen4_aleph</code></td><td>$0.15</td><td>1280x720, 720x1280</td><td>Text + image to video</td></tr><tr><td>RunwayML</td><td><code>runwayml/gen3a_turbo</code></td><td>$0.05</td><td>1280x720, 720x1280</td><td>Text + image to video</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="image-generation-models">Image Generation Models<a href="https://docs.litellm.ai/release_notes/v1-80-0#image-generation-models" class="hash-link" aria-label="Image Generation Models的直接链接" title="Image Generation Models的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Cost Per Image</th><th>Resolutions</th><th>Features</th></tr></thead><tbody><tr><td>RunwayML</td><td><code>runwayml/gen4_image</code></td><td>$0.05</td><td>1280x720, 1920x1080</td><td>Text + image to image</td></tr><tr><td>RunwayML</td><td><code>runwayml/gen4_image_turbo</code></td><td>$0.02</td><td>1280x720, 1920x1080</td><td>Text + image to image</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/flux-pro/v1.1</code></td><td>$0.04/image</td><td>-</td><td>Image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/flux/schnell</code></td><td>$0.003/image</td><td>-</td><td>Fast image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/bytedance/seedream/v3/text-to-image</code></td><td>$0.03/image</td><td>-</td><td>Image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/bytedance/dreamina/v3.1/text-to-image</code></td><td>$0.03/image</td><td>-</td><td>Image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/ideogram/v3</code></td><td>$0.06/image</td><td>-</td><td>Image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/imagen4/preview/fast</code></td><td>$0.02/image</td><td>-</td><td>Fast image generation</td></tr><tr><td>Fal.ai</td><td><code>fal_ai/fal-ai/imagen4/preview/ultra</code></td><td>$0.06/image</td><td>-</td><td>High-quality image generation</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="audio-models">Audio Models<a href="https://docs.litellm.ai/release_notes/v1-80-0#audio-models" class="hash-link" aria-label="Audio Models的直接链接" title="Audio Models的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Cost</th><th>Features</th></tr></thead><tbody><tr><td>RunwayML</td><td><code>runwayml/eleven_multilingual_v2</code></td><td>$0.0003/char</td><td>Text-to-speech</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-80-0#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Add GPT-5.1 family support with reasoning capabilities - <a href="https://github.com/BerriAI/litellm/pull/16598" target="_blank" rel="noopener noreferrer">PR #16598</a></li>
<li>Add support for <code>reasoning_effort='none'</code> for GPT-5.1 - <a href="https://github.com/BerriAI/litellm/pull/16658" target="_blank" rel="noopener noreferrer">PR #16658</a></li>
<li>Add <code>verbosity</code> parameter support for GPT-5 family models - <a href="https://github.com/BerriAI/litellm/pull/16660" target="_blank" rel="noopener noreferrer">PR #16660</a></li>
<li>Fix forward OpenAI organization for image generation - <a href="https://github.com/BerriAI/litellm/pull/16607" target="_blank" rel="noopener noreferrer">PR #16607</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini (Google AI Studio + Vertex AI)</a></strong></p>
<ul>
<li>Add support for <code>reasoning_effort='none'</code> for Gemini models - <a href="https://github.com/BerriAI/litellm/pull/16548" target="_blank" rel="noopener noreferrer">PR #16548</a></li>
<li>Add all Gemini image models support in image generation - <a href="https://github.com/BerriAI/litellm/pull/16526" target="_blank" rel="noopener noreferrer">PR #16526</a></li>
<li>Add Gemini image edit support - <a href="https://github.com/BerriAI/litellm/pull/16430" target="_blank" rel="noopener noreferrer">PR #16430</a></li>
<li>Fix preserve non-ASCII characters in function call arguments - <a href="https://github.com/BerriAI/litellm/pull/16550" target="_blank" rel="noopener noreferrer">PR #16550</a></li>
<li>Fix Gemini conversation format issue with MCP auto-execution - <a href="https://github.com/BerriAI/litellm/pull/16592" target="_blank" rel="noopener noreferrer">PR #16592</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Add support for filtering knowledge base queries - <a href="https://github.com/BerriAI/litellm/pull/16543" target="_blank" rel="noopener noreferrer">PR #16543</a></li>
<li>Ensure correct <code>aws_region</code> is used when provided dynamically for embeddings - <a href="https://github.com/BerriAI/litellm/pull/16547" target="_blank" rel="noopener noreferrer">PR #16547</a></li>
<li>Add support for custom KMS encryption keys in Bedrock Batch operations - <a href="https://github.com/BerriAI/litellm/pull/16662" target="_blank" rel="noopener noreferrer">PR #16662</a></li>
<li>Add bearer token authentication support for AgentCore - <a href="https://github.com/BerriAI/litellm/pull/16556" target="_blank" rel="noopener noreferrer">PR #16556</a></li>
<li>Fix AgentCore SSE stream iterator to async for proper streaming support - <a href="https://github.com/BerriAI/litellm/pull/16293" target="_blank" rel="noopener noreferrer">PR #16293</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Add context management param support - <a href="https://github.com/BerriAI/litellm/pull/16528" target="_blank" rel="noopener noreferrer">PR #16528</a></li>
<li>Fix preserve <code>$defs</code> for Anthropic tools input schema - <a href="https://github.com/BerriAI/litellm/pull/16648" target="_blank" rel="noopener noreferrer">PR #16648</a></li>
<li>Fix support Anthropic tool_use and tool_result in token counter - <a href="https://github.com/BerriAI/litellm/pull/16351" target="_blank" rel="noopener noreferrer">PR #16351</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex_ai">Vertex AI</a></strong></p>
<ul>
<li>Add Vertex Kimi-K2-Thinking support - <a href="https://github.com/BerriAI/litellm/pull/16671" target="_blank" rel="noopener noreferrer">PR #16671</a></li>
<li>Add <code>vertex_credentials</code> support to <code>litellm.rerank()</code> - <a href="https://github.com/BerriAI/litellm/pull/16479" target="_blank" rel="noopener noreferrer">PR #16479</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong></p>
<ul>
<li>Fix Magistral streaming to emit reasoning chunks - <a href="https://github.com/BerriAI/litellm/pull/16434" target="_blank" rel="noopener noreferrer">PR #16434</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/moonshot">Moonshot (Kimi)</a></strong></p>
<ul>
<li>Add Kimi K2 thinking model support - <a href="https://github.com/BerriAI/litellm/pull/16445" target="_blank" rel="noopener noreferrer">PR #16445</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/sambanova">SambaNova</a></strong></p>
<ul>
<li>Fix SambaNova API rejecting requests when message content is passed as a list format - <a href="https://github.com/BerriAI/litellm/pull/16612" target="_blank" rel="noopener noreferrer">PR #16612</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong></p>
<ul>
<li>Fix use vllm passthrough config for hosted vllm provider instead of raising error - <a href="https://github.com/BerriAI/litellm/pull/16537" target="_blank" rel="noopener noreferrer">PR #16537</a></li>
<li>Add headers to VLLM Passthrough requests with success event logging - <a href="https://github.com/BerriAI/litellm/pull/16532" target="_blank" rel="noopener noreferrer">PR #16532</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Fix improve Azure auth parameter handling for None values - <a href="https://github.com/BerriAI/litellm/pull/14436" target="_blank" rel="noopener noreferrer">PR #14436</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/groq">Groq</a></strong></p>
<ul>
<li>Fix parse failed chunks for Groq - <a href="https://github.com/BerriAI/litellm/pull/16595" target="_blank" rel="noopener noreferrer">PR #16595</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/voyage">Voyage</a></strong></p>
<ul>
<li>Add Voyage 3.5 and 3.5-lite embeddings pricing and doc update - <a href="https://github.com/BerriAI/litellm/pull/16641" target="_blank" rel="noopener noreferrer">PR #16641</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/image_generation">Fal.ai</a></strong></p>
<ul>
<li>Add fal-ai/flux/schnell support - <a href="https://github.com/BerriAI/litellm/pull/16580" target="_blank" rel="noopener noreferrer">PR #16580</a></li>
<li>Add all Imagen4 variants of fal ai in model map - <a href="https://github.com/BerriAI/litellm/pull/16579" target="_blank" rel="noopener noreferrer">PR #16579</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-80-0#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix sanitize null token usage in OpenAI-compatible responses - <a href="https://github.com/BerriAI/litellm/pull/16493" target="_blank" rel="noopener noreferrer">PR #16493</a></li>
<li>Fix apply provided timeout value to ClientTimeout.total - <a href="https://github.com/BerriAI/litellm/pull/16395" target="_blank" rel="noopener noreferrer">PR #16395</a></li>
<li>Fix raising wrong 429 error on wrong exception - <a href="https://github.com/BerriAI/litellm/pull/16482" target="_blank" rel="noopener noreferrer">PR #16482</a></li>
<li>Add new models, delete repeat models, update pricing - <a href="https://github.com/BerriAI/litellm/pull/16491" target="_blank" rel="noopener noreferrer">PR #16491</a></li>
<li>Update model logging format for custom LLM provider - <a href="https://github.com/BerriAI/litellm/pull/16485" target="_blank" rel="noopener noreferrer">PR #16485</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-0#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-endpoints">New Endpoints<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-endpoints" class="hash-link" aria-label="New Endpoints的直接链接" title="New Endpoints的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/management_endpoints">GET /providers</a></strong>
<ul>
<li>Add GET list of providers endpoint - <a href="https://github.com/BerriAI/litellm/pull/16432" target="_blank" rel="noopener noreferrer">PR #16432</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-80-0#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Allow internal users to access video generation routes - <a href="https://github.com/BerriAI/litellm/pull/16472" target="_blank" rel="noopener noreferrer">PR #16472</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/vector_stores">Vector Stores API</a></strong></p>
<ul>
<li>Vector store files stable release with complete CRUD operations - <a href="https://github.com/BerriAI/litellm/pull/16643" target="_blank" rel="noopener noreferrer">PR #16643</a>
<ul>
<li><code>POST /v1/vector_stores/{vector_store_id}/files</code> - Create vector store file</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files</code> - List vector store files</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files/{file_id}</code> - Retrieve vector store file</li>
<li><code>GET /v1/vector_stores/{vector_store_id}/files/{file_id}/content</code> - Retrieve file content</li>
<li><code>DELETE /v1/vector_stores/{vector_store_id}/files/{file_id}</code> - Delete vector store file</li>
<li><code>DELETE /v1/vector_stores/{vector_store_id}</code> - Delete vector store</li>
</ul>
</li>
<li>Ensure users can access <code>search_results</code> for both stream + non-stream response - <a href="https://github.com/BerriAI/litellm/pull/16459" target="_blank" rel="noopener noreferrer">PR #16459</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-0#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Fix use GET for <code>/v1/videos/{video_id}/content</code> - <a href="https://github.com/BerriAI/litellm/pull/16672" target="_blank" rel="noopener noreferrer">PR #16672</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fix remove generic exception handling - <a href="https://github.com/BerriAI/litellm/pull/16599" target="_blank" rel="noopener noreferrer">PR #16599</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-80-0#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-80-0#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Proxy CLI Auth</strong></p>
<ul>
<li>Fix remove strict master_key check in add_deployment - <a href="https://github.com/BerriAI/litellm/pull/16453" target="_blank" rel="noopener noreferrer">PR #16453</a></li>
</ul>
</li>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>UI - Add Tags To Edit Key Flow - <a href="https://github.com/BerriAI/litellm/pull/16500" target="_blank" rel="noopener noreferrer">PR #16500</a></li>
<li>UI - Test Key Page show models based on selected endpoint - <a href="https://github.com/BerriAI/litellm/pull/16452" target="_blank" rel="noopener noreferrer">PR #16452</a></li>
<li>UI - Expose user_alias in view and update path - <a href="https://github.com/BerriAI/litellm/pull/16669" target="_blank" rel="noopener noreferrer">PR #16669</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>UI - Add LiteLLM Params to Edit Model - <a href="https://github.com/BerriAI/litellm/pull/16496" target="_blank" rel="noopener noreferrer">PR #16496</a></li>
<li>UI - Add Model use backend data - <a href="https://github.com/BerriAI/litellm/pull/16664" target="_blank" rel="noopener noreferrer">PR #16664</a></li>
<li>UI - Remove Description Field from LLM Credentials - <a href="https://github.com/BerriAI/litellm/pull/16608" target="_blank" rel="noopener noreferrer">PR #16608</a></li>
<li>UI - Add RunwayML on Admin UI supported models/providers - <a href="https://github.com/BerriAI/litellm/pull/16606" target="_blank" rel="noopener noreferrer">PR #16606</a></li>
<li>Infra - Migrate Add Model Fields to Backend - <a href="https://github.com/BerriAI/litellm/pull/16620" target="_blank" rel="noopener noreferrer">PR #16620</a></li>
<li>Add API Endpoint for creating model access group - <a href="https://github.com/BerriAI/litellm/pull/16663" target="_blank" rel="noopener noreferrer">PR #16663</a></li>
</ul>
</li>
<li>
<p><strong>Teams</strong></p>
<ul>
<li>UI - Invite User Searchable Team Select - <a href="https://github.com/BerriAI/litellm/pull/16454" target="_blank" rel="noopener noreferrer">PR #16454</a></li>
<li>Fix use user budget instead of key budget when creating new team - <a href="https://github.com/BerriAI/litellm/pull/16074" target="_blank" rel="noopener noreferrer">PR #16074</a></li>
</ul>
</li>
<li>
<p><strong>Budgets</strong></p>
<ul>
<li>UI - Move Budgets out of Experimental - <a href="https://github.com/BerriAI/litellm/pull/16544" target="_blank" rel="noopener noreferrer">PR #16544</a></li>
</ul>
</li>
<li>
<p><strong>Guardrails</strong></p>
<ul>
<li>UI - Config Guardrails should not be deletable from table - <a href="https://github.com/BerriAI/litellm/pull/16540" target="_blank" rel="noopener noreferrer">PR #16540</a></li>
<li>Fix remove enterprise restriction from guardrails list endpoint - <a href="https://github.com/BerriAI/litellm/pull/15333" target="_blank" rel="noopener noreferrer">PR #15333</a></li>
</ul>
</li>
<li>
<p><strong>Callbacks</strong></p>
<ul>
<li>UI - New Callbacks table - <a href="https://github.com/BerriAI/litellm/pull/16512" target="_blank" rel="noopener noreferrer">PR #16512</a></li>
<li>Fix delete callbacks failing - <a href="https://github.com/BerriAI/litellm/pull/16473" target="_blank" rel="noopener noreferrer">PR #16473</a></li>
</ul>
</li>
<li>
<p><strong>Usage &amp; Analytics</strong></p>
<ul>
<li>UI - Improve Usage Indicator - <a href="https://github.com/BerriAI/litellm/pull/16504" target="_blank" rel="noopener noreferrer">PR #16504</a></li>
<li>UI - Model Info Page Health Check - <a href="https://github.com/BerriAI/litellm/pull/16416" target="_blank" rel="noopener noreferrer">PR #16416</a></li>
<li>Infra - Show Deprecation Warning for Model Analytics Tab - <a href="https://github.com/BerriAI/litellm/pull/16417" target="_blank" rel="noopener noreferrer">PR #16417</a></li>
<li>Fix Litellm tags usage add request_id - <a href="https://github.com/BerriAI/litellm/pull/16111" target="_blank" rel="noopener noreferrer">PR #16111</a></li>
</ul>
</li>
<li>
<p><strong>Health Check</strong></p>
<ul>
<li>Add Langfuse OTEL and SQS to Health Check - <a href="https://github.com/BerriAI/litellm/pull/16514" target="_blank" rel="noopener noreferrer">PR #16514</a></li>
</ul>
</li>
<li>
<p><strong>General UI</strong></p>
<ul>
<li>UI - Normalize table action columns appearance - <a href="https://github.com/BerriAI/litellm/pull/16657" target="_blank" rel="noopener noreferrer">PR #16657</a></li>
<li>UI - Button Styles and Sizing in Settings Pages - <a href="https://github.com/BerriAI/litellm/pull/16600" target="_blank" rel="noopener noreferrer">PR #16600</a></li>
<li>UI - SSO Modal Cosmetic Changes - <a href="https://github.com/BerriAI/litellm/pull/16554" target="_blank" rel="noopener noreferrer">PR #16554</a></li>
<li>Fix UI logos loading with SERVER_ROOT_PATH - <a href="https://github.com/BerriAI/litellm/pull/16618" target="_blank" rel="noopener noreferrer">PR #16618</a></li>
<li>Fix remove misleading 'Custom' option mention from OpenAI endpoint tooltips - <a href="https://github.com/BerriAI/litellm/pull/16622" target="_blank" rel="noopener noreferrer">PR #16622</a></li>
</ul>
</li>
<li>
<p><strong>SSO</strong></p>
<ul>
<li>Ensure <code>role</code> from SSO provider is used when a user is inserted onto LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/16794" target="_blank" rel="noopener noreferrer">PR #16794</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-80-0#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Management Endpoints</strong>
<ul>
<li>Fix inconsistent error responses in customer management endpoints - <a href="https://github.com/BerriAI/litellm/pull/16450" target="_blank" rel="noopener noreferrer">PR #16450</a></li>
<li>Fix correct date range filtering in /spend/logs endpoint - <a href="https://github.com/BerriAI/litellm/pull/16443" target="_blank" rel="noopener noreferrer">PR #16443</a></li>
<li>Fix /spend/logs/ui Access Control - <a href="https://github.com/BerriAI/litellm/pull/16446" target="_blank" rel="noopener noreferrer">PR #16446</a></li>
<li>Add pagination for /spend/logs/session/ui endpoint - <a href="https://github.com/BerriAI/litellm/pull/16603" target="_blank" rel="noopener noreferrer">PR #16603</a></li>
<li>Fix LiteLLM Usage shows key_hash - <a href="https://github.com/BerriAI/litellm/pull/16471" target="_blank" rel="noopener noreferrer">PR #16471</a></li>
<li>Fix app_roles missing from jwt payload - <a href="https://github.com/BerriAI/litellm/pull/16448" target="_blank" rel="noopener noreferrer">PR #16448</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-80-0#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-integration">New Integration<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-integration" class="hash-link" aria-label="New Integration的直接链接" title="New Integration的直接链接">​</a></h4>
<ul>
<li><strong>🆕 <a href="https://docs.litellm.ai/docs/proxy/guardrails/zscaler_ai_guard">Zscaler AI Guard</a></strong>
<ul>
<li>Add Zscaler AI Guard hook for security policy enforcement - <a href="https://github.com/BerriAI/litellm/pull/15691" target="_blank" rel="noopener noreferrer">PR #15691</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="logging">Logging<a href="https://docs.litellm.ai/release_notes/v1-80-0#logging" class="hash-link" aria-label="Logging的直接链接" title="Logging的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong></p>
<ul>
<li>Fix handle null usage values to prevent validation errors - <a href="https://github.com/BerriAI/litellm/pull/16396" target="_blank" rel="noopener noreferrer">PR #16396</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging">CloudZero</a></strong></p>
<ul>
<li>Fix updated spend would not be sent to CloudZero - <a href="https://github.com/BerriAI/litellm/pull/16201" target="_blank" rel="noopener noreferrer">PR #16201</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-80-0#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">IBM Detector</a></strong>
<ul>
<li>Ensure detector-id is passed as header to IBM detector server - <a href="https://github.com/BerriAI/litellm/pull/16649" target="_blank" rel="noopener noreferrer">PR #16649</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-80-0#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/prompt_management">Custom Prompt Management</a></strong>
<ul>
<li>Add SDK focused examples for custom prompt management - <a href="https://github.com/BerriAI/litellm/pull/16441" target="_blank" rel="noopener noreferrer">PR #16441</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-80-0#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>End User Budgets</strong>
<ul>
<li>Allow pointing max_end_user budget to an id, so the default ID applies to all end users - <a href="https://github.com/BerriAI/litellm/pull/16456" target="_blank" rel="noopener noreferrer">PR #16456</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-80-0#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>Configuration</strong>
<ul>
<li>Add dynamic OAuth2 metadata discovery for MCP servers - <a href="https://github.com/BerriAI/litellm/pull/16676" target="_blank" rel="noopener noreferrer">PR #16676</a></li>
<li>Fix allow tool call even when server name prefix is missing - <a href="https://github.com/BerriAI/litellm/pull/16425" target="_blank" rel="noopener noreferrer">PR #16425</a></li>
<li>Fix exclude unauthorized MCP servers from allowed server list - <a href="https://github.com/BerriAI/litellm/pull/16551" target="_blank" rel="noopener noreferrer">PR #16551</a></li>
<li>Fix unable to delete MCP server from permission settings - <a href="https://github.com/BerriAI/litellm/pull/16407" target="_blank" rel="noopener noreferrer">PR #16407</a></li>
<li>Fix avoid crashing when MCP server record lacks credentials - <a href="https://github.com/BerriAI/litellm/pull/16601" target="_blank" rel="noopener noreferrer">PR #16601</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agents">Agents<a href="https://docs.litellm.ai/release_notes/v1-80-0#agents" class="hash-link" aria-label="Agents的直接链接" title="Agents的直接链接">​</a></h2>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/agents">Agent Registration (A2A Spec)</a></strong>
<ul>
<li>Support agent registration + discovery following Agent-to-Agent specification - <a href="https://github.com/BerriAI/litellm/pull/16615" target="_blank" rel="noopener noreferrer">PR #16615</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-80-0#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Embeddings Performance</strong></p>
<ul>
<li>Use router's O(1) lookup and shared sessions for embeddings - <a href="https://github.com/BerriAI/litellm/pull/16344" target="_blank" rel="noopener noreferrer">PR #16344</a></li>
</ul>
</li>
<li>
<p><strong>Router Reliability</strong></p>
<ul>
<li>Support default fallbacks for unknown models - <a href="https://github.com/BerriAI/litellm/pull/16419" target="_blank" rel="noopener noreferrer">PR #16419</a></li>
</ul>
</li>
<li>
<p><strong>Callback Management</strong></p>
<ul>
<li>Add atexit handlers to flush callbacks for async completions - <a href="https://github.com/BerriAI/litellm/pull/16487" target="_blank" rel="noopener noreferrer">PR #16487</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-80-0#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<ul>
<li><strong>Configuration Management</strong>
<ul>
<li>Fix update model_cost_map_url to use environment variable - <a href="https://github.com/BerriAI/litellm/pull/16429" target="_blank" rel="noopener noreferrer">PR #16429</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-80-0#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Fix streaming example in README - <a href="https://github.com/BerriAI/litellm/pull/16461" target="_blank" rel="noopener noreferrer">PR #16461</a></li>
<li>Update broken Slack invite links to support page - <a href="https://github.com/BerriAI/litellm/pull/16546" target="_blank" rel="noopener noreferrer">PR #16546</a></li>
<li>Fix code block indentation for fallbacks page - <a href="https://github.com/BerriAI/litellm/pull/16542" target="_blank" rel="noopener noreferrer">PR #16542</a></li>
<li>Documentation code example corrections - <a href="https://github.com/BerriAI/litellm/pull/16502" target="_blank" rel="noopener noreferrer">PR #16502</a></li>
<li>Document <code>reasoning_effort</code> summary field options - <a href="https://github.com/BerriAI/litellm/pull/16549" target="_blank" rel="noopener noreferrer">PR #16549</a></li>
</ul>
</li>
<li>
<p><strong>API Documentation</strong></p>
<ul>
<li>Add docs on APIs for model access management - <a href="https://github.com/BerriAI/litellm/pull/16673" target="_blank" rel="noopener noreferrer">PR #16673</a></li>
<li>Add docs for showing how to auto reload new pricing data - <a href="https://github.com/BerriAI/litellm/pull/16675" target="_blank" rel="noopener noreferrer">PR #16675</a></li>
<li>LiteLLM Quick start - show how model resolution works - <a href="https://github.com/BerriAI/litellm/pull/16602" target="_blank" rel="noopener noreferrer">PR #16602</a></li>
<li>Add docs for tracking callback failure - <a href="https://github.com/BerriAI/litellm/pull/16474" target="_blank" rel="noopener noreferrer">PR #16474</a></li>
</ul>
</li>
<li>
<p><strong>General Documentation</strong></p>
<ul>
<li>Fix container api link in release page - <a href="https://github.com/BerriAI/litellm/pull/16440" target="_blank" rel="noopener noreferrer">PR #16440</a></li>
<li>Add softgen to projects that are using litellm - <a href="https://github.com/BerriAI/litellm/pull/16423" target="_blank" rel="noopener noreferrer">PR #16423</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-80-0#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@artplan1 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16423" target="_blank" rel="noopener noreferrer">PR #16423</a></li>
<li>@JehandadK made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16472" target="_blank" rel="noopener noreferrer">PR #16472</a></li>
<li>@vmiscenko made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16453" target="_blank" rel="noopener noreferrer">PR #16453</a></li>
<li>@mcowger made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16429" target="_blank" rel="noopener noreferrer">PR #16429</a></li>
<li>@yellowsubmarine372 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16395" target="_blank" rel="noopener noreferrer">PR #16395</a></li>
<li>@Hebruwu made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16201" target="_blank" rel="noopener noreferrer">PR #16201</a></li>
<li>@jwang-gif made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15691" target="_blank" rel="noopener noreferrer">PR #15691</a></li>
<li>@AnthonyMonaco made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16502" target="_blank" rel="noopener noreferrer">PR #16502</a></li>
<li>@andrewm4894 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16487" target="_blank" rel="noopener noreferrer">PR #16487</a></li>
<li>@f14-bertolotti made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16485" target="_blank" rel="noopener noreferrer">PR #16485</a></li>
<li>@busla made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16293" target="_blank" rel="noopener noreferrer">PR #16293</a></li>
<li>@MightyGoldenOctopus made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16537" target="_blank" rel="noopener noreferrer">PR #16537</a></li>
<li>@ultmaster made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14436" target="_blank" rel="noopener noreferrer">PR #14436</a></li>
<li>@bchrobot made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16542" target="_blank" rel="noopener noreferrer">PR #16542</a></li>
<li>@sep-grindr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16622" target="_blank" rel="noopener noreferrer">PR #16622</a></li>
<li>@pnookala-godaddy made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16607" target="_blank" rel="noopener noreferrer">PR #16607</a></li>
<li>@dtunikov made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16592" target="_blank" rel="noopener noreferrer">PR #16592</a></li>
<li>@lukapecnik made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16648" target="_blank" rel="noopener noreferrer">PR #16648</a></li>
<li>@jyeros made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16618" target="_blank" rel="noopener noreferrer">PR #16618</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-80-0#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.79.3.rc.1...v1.80.0.rc.1" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>
<hr>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.79.3-stable - Built-in Guardrails on AI Gateway]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-79-3</link>
            <guid>https://docs.litellm.ai/release_notes/v1-79-3</guid>
            <pubDate>Sat, 08 Nov 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-79-3#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.79.3-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.79.3.rc.1</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-79-3#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>LiteLLM Custom Guardrail</strong> - Built-in guardrail with UI configuration support</li>
<li><strong>Performance Improvements</strong> - <code>/responses</code> API 19× Lower Median Latency</li>
<li><strong>Veo3 Video Generation (Vertex AI + Google AI Studio)</strong> - Use OpenAI Video API to generate videos with Vertex AI and Google AI Studio Veo3 models</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="built-in-guardrails-on-ai-gateway">Built-in Guardrails on AI Gateway<a href="https://docs.litellm.ai/release_notes/v1-79-3#built-in-guardrails-on-ai-gateway" class="hash-link" aria-label="Built-in Guardrails on AI Gateway的直接链接" title="Built-in Guardrails on AI Gateway的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAhklEQVR4nE2NUQrCMBAFc/+D6S0UpKRVWtA2MbubTUdSEfyYv3lvwjRNxBgZx5GUEiIFr0LRShGlVsPMCMuy0OVhGMg5cX+sxPhkXhuv7X1Iokpwd7409t25XIXTeWOZMznLIbbWCKrKj2pGskouGbOe7fnCXo3QF/+oG9pfvNGaI+IMN+MDAF/BZMhZpgYAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/built_in_guard.e6c1ea5.640.png" srcset="/assets/ideal-img/built_in_guard.e6c1ea5.640.png 640w,/assets/ideal-img/built_in_guard.105707e.1920.png 1920w" width="640" height="334"></noscript></div>
<br>
<p>This release introduces built-in guardrails for LiteLLM AI Gateway, allowing you to enforce protections without depending on an external guardrail API.</p>
<ul>
<li><strong>Blocking Keywords</strong> - Block known sensitive keywords like "litellm", "python", etc.</li>
<li><strong>Pattern Detection</strong> - Block known sensitive patterns like emails, Social Security Numbers, API keys, etc.</li>
<li><strong>Custom Regex Patterns</strong> - Define custom regex patterns for your specific use case.</li>
</ul>
<p>Get started with the built-in guardrails on AI Gateway <a href="https://docs.litellm.ai/docs/proxy/guardrails/litellm_content_filter" target="_blank" rel="noopener noreferrer">here</a>.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance--responses-19-lower-median-latency">Performance – <code>/responses</code> 19× Lower Median Latency<a href="https://docs.litellm.ai/release_notes/v1-79-3#performance--responses-19-lower-median-latency" class="hash-link" aria-label="performance--responses-19-lower-median-latency的直接链接" title="performance--responses-19-lower-median-latency的直接链接">​</a></h3>
<p>This update significantly improves <code>/responses</code> latency by integrating our internal network management for connection handling, eliminating per-request setup overhead.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://docs.litellm.ai/release_notes/v1-79-3#results" class="hash-link" aria-label="Results的直接链接" title="Results的直接链接">​</a></h4>
<table><thead><tr><th>Metric</th><th>Before</th><th>After</th><th>Improvement</th></tr></thead><tbody><tr><td>Median latency</td><td>3,600 ms</td><td><strong>190 ms</strong></td><td><strong>−95% (~19× faster)</strong></td></tr><tr><td>p95 latency</td><td>4,300 ms</td><td><strong>280 ms</strong></td><td>−93%</td></tr><tr><td>p99 latency</td><td>4,600 ms</td><td><strong>590 ms</strong></td><td>−87%</td></tr><tr><td>Average latency</td><td>3,571 ms</td><td><strong>208 ms</strong></td><td>−94%</td></tr><tr><td>RPS</td><td>231</td><td><strong>1,059</strong></td><td>+358%</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="https://docs.litellm.ai/release_notes/v1-79-3#test-setup" class="hash-link" aria-label="Test Setup的直接链接" title="Test Setup的直接链接">​</a></h4>
<table><thead><tr><th>Category</th><th>Specification</th></tr></thead><tbody><tr><td><strong>Load Testing</strong></td><td>Locust: 1,000 concurrent users, 500 ramp-up</td></tr><tr><td><strong>System</strong></td><td>4 vCPUs, 8 GB RAM, 4 workers, 4 instances</td></tr><tr><td><strong>Database</strong></td><td>PostgreSQL (Redis unused)</td></tr><tr><td><strong>Configuration</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/550791675fd752befcac6a9e44024652" target="_blank" rel="noopener noreferrer">config.yaml</a></td></tr><tr><td><strong>Load Script</strong></td><td><a href="https://gist.github.com/AlexsanderHamir/99d673bf74cdd81fd39f59fa9048f2e8" target="_blank" rel="noopener noreferrer">no_cache_hits.py</a></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-79-3#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-79-3#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Azure</td><td><code>azure/gpt-5-pro</code></td><td>272K</td><td>$15.00</td><td>$120.00</td><td>Responses API, reasoning, vision, PDF input</td></tr><tr><td>Azure</td><td><code>azure/gpt-image-1-mini</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - per pixel pricing</td></tr><tr><td>Azure</td><td><code>azure/container</code></td><td>-</td><td>-</td><td>-</td><td>Container API - $0.03/session</td></tr><tr><td>OpenAI</td><td><code>openai/container</code></td><td>-</td><td>-</td><td>-</td><td>Container API - $0.03/session</td></tr><tr><td>Cohere</td><td><code>cohere/embed-v4.0</code></td><td>128K</td><td>$0.12</td><td>-</td><td>Embeddings with image input support</td></tr><tr><td>Gemini</td><td><code>gemini/gemini-live-2.5-flash-preview-native-audio-09-2025</code></td><td>1M</td><td>$0.30</td><td>$2.00</td><td>Native audio, vision, web search</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/minimaxai/minimax-m2-maas</code></td><td>196K</td><td>$0.30</td><td>$1.20</td><td>Function calling, tool choice</td></tr><tr><td>NVIDIA</td><td><code>nvidia/nemotron-nano-9b-v2</code></td><td>-</td><td>-</td><td>-</td><td>Chat completions</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ocr-models">OCR Models<a href="https://docs.litellm.ai/release_notes/v1-79-3#ocr-models" class="hash-link" aria-label="OCR Models的直接链接" title="OCR Models的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Cost Per Page</th><th>Features</th></tr></thead><tbody><tr><td>Azure AI</td><td><code>azure_ai/doc-intelligence/prebuilt-read</code></td><td>$0.0015</td><td>Document reading</td></tr><tr><td>Azure AI</td><td><code>azure_ai/doc-intelligence/prebuilt-layout</code></td><td>$0.01</td><td>Layout analysis</td></tr><tr><td>Azure AI</td><td><code>azure_ai/doc-intelligence/prebuilt-document</code></td><td>$0.01</td><td>Document processing</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/mistral-ocr-2505</code></td><td>$0.0005</td><td>OCR processing</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="search-models">Search Models<a href="https://docs.litellm.ai/release_notes/v1-79-3#search-models" class="hash-link" aria-label="Search Models的直接链接" title="Search Models的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Pricing</th><th>Features</th></tr></thead><tbody><tr><td>Firecrawl</td><td><code>firecrawl/search</code></td><td>Tiered: $0.00166-$0.0166/query</td><td>10-100 results per query</td></tr><tr><td>SearXNG</td><td><code>searxng/search</code></td><td>Free</td><td>Open-source metasearch</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-79-3#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Add Azure GPT-5-Pro Responses API support with reasoning capabilities - <a href="https://github.com/BerriAI/litellm/pull/16235" target="_blank" rel="noopener noreferrer">PR #16235</a></li>
<li>Add gpt-image-1-mini pricing for Azure with quality tiers (low/medium/high) - <a href="https://github.com/BerriAI/litellm/pull/16182" target="_blank" rel="noopener noreferrer">PR #16182</a></li>
<li>Add support for returning Azure Content Policy error information when exceptions from Azure OpenAI occur - <a href="https://github.com/BerriAI/litellm/pull/16231" target="_blank" rel="noopener noreferrer">PR #16231</a></li>
<li>Fix Azure GPT-5 incorrectly routed to O-series config (temperature parameter unsupported) - <a href="https://github.com/BerriAI/litellm/pull/16246" target="_blank" rel="noopener noreferrer">PR #16246</a></li>
<li>Fix Azure doesn't accept extra body param - <a href="https://github.com/BerriAI/litellm/pull/16116" target="_blank" rel="noopener noreferrer">PR #16116</a></li>
<li>Fix Azure DALL-E-3 health check content policy violation by using safe default prompt - <a href="https://github.com/BerriAI/litellm/pull/16329" target="_blank" rel="noopener noreferrer">PR #16329</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Fix empty assistant message handling in AWS Bedrock Converse API to prevent 400 Bad Request errors - <a href="https://github.com/BerriAI/litellm/pull/15850" target="_blank" rel="noopener noreferrer">PR #15850</a></li>
<li>Fix: Filter AWS authentication params from Bedrock InvokeModel request body - <a href="https://github.com/BerriAI/litellm/pull/16315" target="_blank" rel="noopener noreferrer">PR #16315</a></li>
<li>Fix Bedrock proxy adding name to file content, breaks when cache_control in use - <a href="https://github.com/BerriAI/litellm/pull/16275" target="_blank" rel="noopener noreferrer">PR #16275</a></li>
<li>Fix global.anthropic.claude-haiku-4-5-20251001-v1:0 supports_reasoning flag and update pricing - <a href="https://github.com/BerriAI/litellm/pull/16263" target="_blank" rel="noopener noreferrer">PR #16263</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini (Google AI Studio + Vertex AI)</a></strong></p>
<ul>
<li>Add gemini live audio model cost in model map - <a href="https://github.com/BerriAI/litellm/pull/16183" target="_blank" rel="noopener noreferrer">PR #16183</a></li>
<li>Fix translation problem with Gemini parallel tool calls - <a href="https://github.com/BerriAI/litellm/pull/16194" target="_blank" rel="noopener noreferrer">PR #16194</a></li>
<li>Fix: Send Gemini API key via x-goog-api-key header with custom api_base - <a href="https://github.com/BerriAI/litellm/pull/16085" target="_blank" rel="noopener noreferrer">PR #16085</a></li>
<li>Fix image_config.aspect_ratio not working for gemini-2.5-flash-image - <a href="https://github.com/BerriAI/litellm/pull/15999" target="_blank" rel="noopener noreferrer">PR #15999</a></li>
<li>Fix Gemini minimal reasoning env overrides disabling thoughts - <a href="https://github.com/BerriAI/litellm/pull/16347" target="_blank" rel="noopener noreferrer">PR #16347</a></li>
<li>Fix cache_read_input_token_cost for gemini-2.5-flash - <a href="https://github.com/BerriAI/litellm/pull/16354" target="_blank" rel="noopener noreferrer">PR #16354</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Fix Anthropic token counting for VertexAI - <a href="https://github.com/BerriAI/litellm/pull/16171" target="_blank" rel="noopener noreferrer">PR #16171</a></li>
<li>Fix anthropic-adapter: properly translate Anthropic image format to OpenAI - <a href="https://github.com/BerriAI/litellm/pull/16202" target="_blank" rel="noopener noreferrer">PR #16202</a></li>
<li>Enable automated prompt caching message format for Claude on Databricks - <a href="https://github.com/BerriAI/litellm/pull/16200" target="_blank" rel="noopener noreferrer">PR #16200</a></li>
<li>Add support for Anthropic Memory Tool - <a href="https://github.com/BerriAI/litellm/pull/16115" target="_blank" rel="noopener noreferrer">PR #16115</a></li>
<li>Propagate cache creation/read token costs for model info to fix Anthropic long context cost calculations - <a href="https://github.com/BerriAI/litellm/pull/16376" target="_blank" rel="noopener noreferrer">PR #16376</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex_ai">Vertex AI</a></strong></p>
<ul>
<li>Add Vertex MiniMAX m2 model support - <a href="https://github.com/BerriAI/litellm/pull/16373" target="_blank" rel="noopener noreferrer">PR #16373</a></li>
<li>Correctly map 429 Resource Exhausted to RateLimitError - <a href="https://github.com/BerriAI/litellm/pull/16363" target="_blank" rel="noopener noreferrer">PR #16363</a></li>
<li>Add <code>vertex_credentials</code> support to <code>litellm.rerank()</code> for Vertex AI - <a href="https://github.com/BerriAI/litellm/pull/16266" target="_blank" rel="noopener noreferrer">PR #16266</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/databricks">Databricks</a></strong></p>
<ul>
<li>Fix databricks streaming - <a href="https://github.com/BerriAI/litellm/pull/16368" target="_blank" rel="noopener noreferrer">PR #16368</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/deepgram">Deepgram</a></strong></p>
<ul>
<li>Return the diarized transcript when it's required in the request - <a href="https://github.com/BerriAI/litellm/pull/16133" target="_blank" rel="noopener noreferrer">PR #16133</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks</a></strong></p>
<ul>
<li>Update Fireworks audio endpoints to new <code>api.fireworks.ai</code> domains - <a href="https://github.com/BerriAI/litellm/pull/16346" target="_blank" rel="noopener noreferrer">PR #16346</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/cohere">Cohere</a></strong></p>
<ul>
<li>Add cohere embed-v4.0 model support - <a href="https://github.com/BerriAI/litellm/pull/16358" target="_blank" rel="noopener noreferrer">PR #16358</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/watsonx">Watsonx</a></strong></p>
<ul>
<li>Support <code>reasoning_effort</code> for watsonx chat models - <a href="https://github.com/BerriAI/litellm/pull/16261" target="_blank" rel="noopener noreferrer">PR #16261</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Remove automatic summary from reasoning_effort transformation - <a href="https://github.com/BerriAI/litellm/pull/16210" target="_blank" rel="noopener noreferrer">PR #16210</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/xai">XAI</a></strong></p>
<ul>
<li>Remove Grok 4 Models Reasoning Effort Parameter - <a href="https://github.com/BerriAI/litellm/pull/16265" target="_blank" rel="noopener noreferrer">PR #16265</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vllm">Hosted VLLM</a></strong></p>
<ul>
<li>Fix HostedVLLMRerankConfig will not be used - <a href="https://github.com/BerriAI/litellm/pull/16352" target="_blank" rel="noopener noreferrer">PR #16352</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-79-3#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock Agentcore</a></strong>
<ul>
<li>Add Bedrock Agentcore as a provider on LiteLLM Python SDK and LiteLLM AI Gateway - <a href="https://github.com/BerriAI/litellm/pull/16252" target="_blank" rel="noopener noreferrer">PR #16252</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-79-3#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-79-3#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/ocr">OCR API</a></strong></p>
<ul>
<li>Add VertexAI OCR provider support + cost tracking - <a href="https://github.com/BerriAI/litellm/pull/16216" target="_blank" rel="noopener noreferrer">PR #16216</a></li>
<li>Add Azure AI Doc Intelligence OCR support - <a href="https://github.com/BerriAI/litellm/pull/16219" target="_blank" rel="noopener noreferrer">PR #16219</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/search">Search API</a></strong></p>
<ul>
<li>Add firecrawl search API support with tiered pricing - <a href="https://github.com/BerriAI/litellm/pull/16257" target="_blank" rel="noopener noreferrer">PR #16257</a></li>
<li>Add searxng search API provider - <a href="https://github.com/BerriAI/litellm/pull/16259" target="_blank" rel="noopener noreferrer">PR #16259</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Support responses API streaming in langfuse otel - <a href="https://github.com/BerriAI/litellm/pull/16153" target="_blank" rel="noopener noreferrer">PR #16153</a></li>
<li>Pass extra_body parameters to provider in Responses API requests - <a href="https://github.com/BerriAI/litellm/pull/16320" target="_blank" rel="noopener noreferrer">PR #16320</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/container_api">Container API</a></strong></p>
<ul>
<li>Add E2E Container API Support - <a href="https://github.com/BerriAI/litellm/pull/16136" target="_blank" rel="noopener noreferrer">PR #16136</a></li>
<li>Update container documentation to be similar to others - <a href="https://github.com/BerriAI/litellm/pull/16327" target="_blank" rel="noopener noreferrer">PR #16327</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Add Vertex and Gemini Videos API with Cost Tracking + UI support - <a href="https://github.com/BerriAI/litellm/pull/16323" target="_blank" rel="noopener noreferrer">PR #16323</a></li>
<li>Add <code>custom_llm_provider</code> support for video endpoints (non-generation) - <a href="https://github.com/BerriAI/litellm/pull/16121" target="_blank" rel="noopener noreferrer">PR #16121</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/audio">Audio API</a></strong></p>
<ul>
<li>Add gpt-4o-transcribe cost tracking - <a href="https://github.com/BerriAI/litellm/pull/16412" target="_blank" rel="noopener noreferrer">PR #16412</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/vector_stores">Vector Stores</a></strong></p>
<ul>
<li>Milvus - search vector store support + support multi-part form data on passthrough - <a href="https://github.com/BerriAI/litellm/pull/16035" target="_blank" rel="noopener noreferrer">PR #16035</a></li>
<li>Azure AI Vector Stores - support "virtual" indexes + create vector store on passthrough API - <a href="https://github.com/BerriAI/litellm/pull/16160" target="_blank" rel="noopener noreferrer">PR #16160</a></li>
<li>Milvus - Passthrough API support - adds create + read vector store support via passthrough API's - <a href="https://github.com/BerriAI/litellm/pull/16170" target="_blank" rel="noopener noreferrer">PR #16170</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/embedding/supported_embedding">Embeddings API</a></strong></p>
<ul>
<li>Use valid CallTypes enum value in embeddings endpoint - <a href="https://github.com/BerriAI/litellm/pull/16328" target="_blank" rel="noopener noreferrer">PR #16328</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/rerank">Rerank API</a></strong></p>
<ul>
<li>Generalize tiered pricing in generic cost calculator - <a href="https://github.com/BerriAI/litellm/pull/16150" target="_blank" rel="noopener noreferrer">PR #16150</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-79-3#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix index field not populated in streaming mode with n&gt;1 and tool calls - <a href="https://github.com/BerriAI/litellm/pull/15962" target="_blank" rel="noopener noreferrer">PR #15962</a></li>
<li>Pass aws_region_name in litellm_params - <a href="https://github.com/BerriAI/litellm/pull/16321" target="_blank" rel="noopener noreferrer">PR #16321</a></li>
<li>Add <code>retry-after</code> header support for errors <code>502</code>, <code>503</code>, <code>504</code> - <a href="https://github.com/BerriAI/litellm/pull/16288" target="_blank" rel="noopener noreferrer">PR #16288</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-79-3#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-79-3#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>UI - Delete Team Member with friction - <a href="https://github.com/BerriAI/litellm/pull/16167" target="_blank" rel="noopener noreferrer">PR #16167</a></li>
<li>UI - Litellm test key audio support - <a href="https://github.com/BerriAI/litellm/pull/16251" target="_blank" rel="noopener noreferrer">PR #16251</a></li>
<li>UI - Test Key Page Revert Model To Single Select - <a href="https://github.com/BerriAI/litellm/pull/16390" target="_blank" rel="noopener noreferrer">PR #16390</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>UI - Add Model Existing Credentials Improvement - <a href="https://github.com/BerriAI/litellm/pull/16166" target="_blank" rel="noopener noreferrer">PR #16166</a></li>
<li>UI - Add Azure AD Token field and Azure API Key optional - <a href="https://github.com/BerriAI/litellm/pull/16331" target="_blank" rel="noopener noreferrer">PR #16331</a></li>
<li>UI - Fixed Label for vLLM in Model Create Flow - <a href="https://github.com/BerriAI/litellm/pull/16285" target="_blank" rel="noopener noreferrer">PR #16285</a></li>
<li>UI - Include Model Access Group Models on Team Models Table - <a href="https://github.com/BerriAI/litellm/pull/16298" target="_blank" rel="noopener noreferrer">PR #16298</a></li>
<li>Fix /model_group/info Returning Entire Model List for SSO Users - <a href="https://github.com/BerriAI/litellm/pull/16296" target="_blank" rel="noopener noreferrer">PR #16296</a></li>
<li>Litellm non root docker Model Hub Table fix - <a href="https://github.com/BerriAI/litellm/pull/16282" target="_blank" rel="noopener noreferrer">PR #16282</a></li>
</ul>
</li>
<li>
<p><strong>Guardrails</strong></p>
<ul>
<li>UI - Fix regression where Guardrail Entity Could not be selected and entity was not displayed - <a href="https://github.com/BerriAI/litellm/pull/16165" target="_blank" rel="noopener noreferrer">PR #16165</a></li>
<li>UI - Guardrail Info Page Show PII Config - <a href="https://github.com/BerriAI/litellm/pull/16164" target="_blank" rel="noopener noreferrer">PR #16164</a></li>
<li>Change guardrail_information to list type - <a href="https://github.com/BerriAI/litellm/pull/16127" target="_blank" rel="noopener noreferrer">PR #16127</a></li>
<li>UI - LiteLLM Guardrail - ensure you can see UI Friendly name for PII Patterns - <a href="https://github.com/BerriAI/litellm/pull/16382" target="_blank" rel="noopener noreferrer">PR #16382</a></li>
<li>UI - Guardrails - LiteLLM Content Filter, Allow Viewing/Editing Content Filter Settings - <a href="https://github.com/BerriAI/litellm/pull/16383" target="_blank" rel="noopener noreferrer">PR #16383</a></li>
<li>UI - Guardrails - allow updating guardrails through UI. Ensure litellm_params actually get updated in memory - <a href="https://github.com/BerriAI/litellm/pull/16384" target="_blank" rel="noopener noreferrer">PR #16384</a></li>
</ul>
</li>
<li>
<p><strong>SSO Settings</strong></p>
<ul>
<li>Support dot notation on ui sso - <a href="https://github.com/BerriAI/litellm/pull/16135" target="_blank" rel="noopener noreferrer">PR #16135</a></li>
<li>UI - Prevent trailing slash in sso proxy base url input - <a href="https://github.com/BerriAI/litellm/pull/16244" target="_blank" rel="noopener noreferrer">PR #16244</a></li>
<li>UI - SSO Proxy Base URL input validation and remove normalizing / - <a href="https://github.com/BerriAI/litellm/pull/16332" target="_blank" rel="noopener noreferrer">PR #16332</a></li>
<li>UI - Surface SSO Create errors on create flow - <a href="https://github.com/BerriAI/litellm/pull/16369" target="_blank" rel="noopener noreferrer">PR #16369</a></li>
</ul>
</li>
<li>
<p><strong>Usage &amp; Analytics</strong></p>
<ul>
<li>UI - Tag Usage Top Model Table View and Label Fix - <a href="https://github.com/BerriAI/litellm/pull/16249" target="_blank" rel="noopener noreferrer">PR #16249</a></li>
<li>UI - Litellm usage date picker - <a href="https://github.com/BerriAI/litellm/pull/16264" target="_blank" rel="noopener noreferrer">PR #16264</a></li>
</ul>
</li>
<li>
<p><strong>Cache Settings</strong></p>
<ul>
<li>UI - Cache Settings Redis Add Semantic Cache Settings - <a href="https://github.com/BerriAI/litellm/pull/16398" target="_blank" rel="noopener noreferrer">PR #16398</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-79-3#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>UI - Remove encoding_format in request for embedding models - <a href="https://github.com/BerriAI/litellm/pull/16367" target="_blank" rel="noopener noreferrer">PR #16367</a></li>
<li>UI - Revert Changes for Test Key Multiple Model Select - <a href="https://github.com/BerriAI/litellm/pull/16372" target="_blank" rel="noopener noreferrer">PR #16372</a></li>
<li>UI - Various Small Issues - <a href="https://github.com/BerriAI/litellm/pull/16406" target="_blank" rel="noopener noreferrer">PR #16406</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-integrations">AI Integrations<a href="https://docs.litellm.ai/release_notes/v1-79-3#ai-integrations" class="hash-link" aria-label="AI Integrations的直接链接" title="AI Integrations的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging">Logging<a href="https://docs.litellm.ai/release_notes/v1-79-3#logging" class="hash-link" aria-label="Logging的直接链接" title="Logging的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong></p>
<ul>
<li>Fix langfuse input tokens logic for cached tokens - <a href="https://github.com/BerriAI/litellm/pull/16203" target="_blank" rel="noopener noreferrer">PR #16203</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opik">Opik</a></strong></p>
<ul>
<li>Fix the bug with not incorrect attachment to existing trace &amp; refactor - <a href="https://github.com/BerriAI/litellm/pull/15529" target="_blank" rel="noopener noreferrer">PR #15529</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#s3">S3</a></strong></p>
<ul>
<li>S3 logger, add support for ssl_verify when using minio logger - <a href="https://github.com/BerriAI/litellm/pull/16211" target="_blank" rel="noopener noreferrer">PR #16211</a></li>
<li>Strip base64 in s3 - <a href="https://github.com/BerriAI/litellm/pull/16157" target="_blank" rel="noopener noreferrer">PR #16157</a></li>
<li>Add allowing Key based prefix to s3 path - <a href="https://github.com/BerriAI/litellm/pull/16237" target="_blank" rel="noopener noreferrer">PR #16237</a></li>
<li>Add Prometheus metric to track callback logging failures in S3 - <a href="https://github.com/BerriAI/litellm/pull/16209" target="_blank" rel="noopener noreferrer">PR #16209</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opentelemetry">OpenTelemetry</a></strong></p>
<ul>
<li>OTEL - Log Cost Breakdown on OTEL Logger - <a href="https://github.com/BerriAI/litellm/pull/16334" target="_blank" rel="noopener noreferrer">PR #16334</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">DataDog</a></strong></p>
<ul>
<li>Add DD Agent Host support for <code>datadog</code> callback - <a href="https://github.com/BerriAI/litellm/pull/16379" target="_blank" rel="noopener noreferrer">PR #16379</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-79-3#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Noma</a></strong></p>
<ul>
<li>Revert Noma Apply Guardrail implementation - <a href="https://github.com/BerriAI/litellm/pull/16214" target="_blank" rel="noopener noreferrer">PR #16214</a></li>
<li>Litellm noma guardrail support images - <a href="https://github.com/BerriAI/litellm/pull/16199" target="_blank" rel="noopener noreferrer">PR #16199</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">PANW Prisma AIRS</a></strong></p>
<ul>
<li>PANW prisma airs guardrail deduplication and enhanced session tracking - <a href="https://github.com/BerriAI/litellm/pull/16273" target="_blank" rel="noopener noreferrer">PR #16273</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">LiteLLM Custom Guardrail</a></strong></p>
<ul>
<li>Add LiteLLM Gateway built in guardrail - <a href="https://github.com/BerriAI/litellm/pull/16338" target="_blank" rel="noopener noreferrer">PR #16338</a></li>
<li>UI - Allow configuring LiteLLM Custom Guardrail - <a href="https://github.com/BerriAI/litellm/pull/16339" target="_blank" rel="noopener noreferrer">PR #16339</a></li>
<li>Bug Fix: Content Filter Guard - <a href="https://github.com/BerriAI/litellm/pull/16414" target="_blank" rel="noopener noreferrer">PR #16414</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="secret-managers">Secret Managers<a href="https://docs.litellm.ai/release_notes/v1-79-3#secret-managers" class="hash-link" aria-label="Secret Managers的直接链接" title="Secret Managers的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/secret_managers">CyberArk</a></strong></p>
<ul>
<li>Add CyberArk Secrets Manager Integration - <a href="https://github.com/BerriAI/litellm/pull/16278" target="_blank" rel="noopener noreferrer">PR #16278</a></li>
<li>Cyber Ark - Add Key Rotations support - <a href="https://github.com/BerriAI/litellm/pull/16289" target="_blank" rel="noopener noreferrer">PR #16289</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/secret_managers">HashiCorp Vault</a></strong></p>
<ul>
<li>Add configurable mount name and path prefix for HashiCorp Vault - <a href="https://github.com/BerriAI/litellm/pull/16253" target="_blank" rel="noopener noreferrer">PR #16253</a></li>
<li>Secret Manager - Hashicorp, add auth via approle - <a href="https://github.com/BerriAI/litellm/pull/16374" target="_blank" rel="noopener noreferrer">PR #16374</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/secret_managers">AWS Secrets Manager</a></strong></p>
<ul>
<li>Add tags and descriptions support to aws secrets manager - <a href="https://github.com/BerriAI/litellm/pull/16224" target="_blank" rel="noopener noreferrer">PR #16224</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/secret_managers">Custom Secret Manager</a></strong></p>
<ul>
<li>Add Custom Secret Manager - Allow users to define and write a custom secret manager - <a href="https://github.com/BerriAI/litellm/pull/16297" target="_blank" rel="noopener noreferrer">PR #16297</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Email Notifications - Ensure Users get Key Rotated Email - <a href="https://github.com/BerriAI/litellm/pull/16292" target="_blank" rel="noopener noreferrer">PR #16292</a></li>
<li>Fix verify ssl on sts boto3 - <a href="https://github.com/BerriAI/litellm/pull/16313" target="_blank" rel="noopener noreferrer">PR #16313</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-79-3#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Cost Tracking</strong>
<ul>
<li>Fix OpenAI Responses API streaming tests usage field names and cost calculation - <a href="https://github.com/BerriAI/litellm/pull/16236" target="_blank" rel="noopener noreferrer">PR #16236</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-79-3#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>Configuration</strong>
<ul>
<li>Configure static mcp header - <a href="https://github.com/BerriAI/litellm/pull/16179" target="_blank" rel="noopener noreferrer">PR #16179</a></li>
<li>Persist mcp credentials in db - <a href="https://github.com/BerriAI/litellm/pull/16308" target="_blank" rel="noopener noreferrer">PR #16308</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-79-3#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Memory Leak Fixes</strong></p>
<ul>
<li>Resolve memory accumulation caused by Pydantic 2.11+ deprecation warnings - <a href="https://github.com/BerriAI/litellm/pull/16110" target="_blank" rel="noopener noreferrer">PR #16110</a></li>
</ul>
</li>
<li>
<p><strong>Session Management</strong></p>
<ul>
<li>Add shared_session support to responses API - <a href="https://github.com/BerriAI/litellm/pull/16260" target="_blank" rel="noopener noreferrer">PR #16260</a></li>
</ul>
</li>
<li>
<p><strong>Error Handling</strong></p>
<ul>
<li>Gracefully handle connection closed errors during streaming - <a href="https://github.com/BerriAI/litellm/pull/16294" target="_blank" rel="noopener noreferrer">PR #16294</a></li>
<li>Handle None values in daily spend sort key - <a href="https://github.com/BerriAI/litellm/pull/16245" target="_blank" rel="noopener noreferrer">PR #16245</a></li>
</ul>
</li>
<li>
<p><strong>Configuration</strong></p>
<ul>
<li>Remove minimum validation for cache control injection index - <a href="https://github.com/BerriAI/litellm/pull/16149" target="_blank" rel="noopener noreferrer">PR #16149</a></li>
<li>Improve clearing logic - only remove unvisited endpoints - <a href="https://github.com/BerriAI/litellm/pull/16400" target="_blank" rel="noopener noreferrer">PR #16400</a></li>
</ul>
</li>
<li>
<p><strong>Redis</strong></p>
<ul>
<li>Handle float redis_version from AWS ElastiCache Valkey - <a href="https://github.com/BerriAI/litellm/pull/16207" target="_blank" rel="noopener noreferrer">PR #16207</a></li>
</ul>
</li>
<li>
<p><strong>Hooks</strong></p>
<ul>
<li>Add parallel execution handling in during_call_hook - <a href="https://github.com/BerriAI/litellm/pull/16279" target="_blank" rel="noopener noreferrer">PR #16279</a></li>
</ul>
</li>
<li>
<p><strong>Infrastructure</strong></p>
<ul>
<li>Install runtime node for prisma - <a href="https://github.com/BerriAI/litellm/pull/16410" target="_blank" rel="noopener noreferrer">PR #16410</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-79-3#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Docs - v1.79.1 - <a href="https://github.com/BerriAI/litellm/pull/16163" target="_blank" rel="noopener noreferrer">PR #16163</a></li>
<li>Fix broken link on model_management.md - <a href="https://github.com/BerriAI/litellm/pull/16217" target="_blank" rel="noopener noreferrer">PR #16217</a></li>
<li>Fix image generation response format - use 'images' array instead of 'image' object - <a href="https://github.com/BerriAI/litellm/pull/16378" target="_blank" rel="noopener noreferrer">PR #16378</a></li>
</ul>
</li>
<li>
<p><strong>General Documentation</strong></p>
<ul>
<li>Add minimum resource requirement for production - <a href="https://github.com/BerriAI/litellm/pull/16146" target="_blank" rel="noopener noreferrer">PR #16146</a></li>
<li>Add benchmark comparison with other AI gateways - <a href="https://github.com/BerriAI/litellm/pull/16248" target="_blank" rel="noopener noreferrer">PR #16248</a></li>
<li>LiteLLM content filter guard documentation - <a href="https://github.com/BerriAI/litellm/pull/16413" target="_blank" rel="noopener noreferrer">PR #16413</a></li>
<li>Fix typo of the word orginal - <a href="https://github.com/BerriAI/litellm/pull/16255" target="_blank" rel="noopener noreferrer">PR #16255</a></li>
</ul>
</li>
<li>
<p><strong>Security</strong></p>
<ul>
<li>Remove tornado test files (including test.key), fixes Python 3.13 security issues - <a href="https://github.com/BerriAI/litellm/pull/16342" target="_blank" rel="noopener noreferrer">PR #16342</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-79-3#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@steve-gore-snapdocs made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16149" target="_blank" rel="noopener noreferrer">PR #16149</a></li>
<li>@timbmg made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16120" target="_blank" rel="noopener noreferrer">PR #16120</a></li>
<li>@Nivg made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16202" target="_blank" rel="noopener noreferrer">PR #16202</a></li>
<li>@pablobgar made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16194" target="_blank" rel="noopener noreferrer">PR #16194</a></li>
<li>@AlanPonnachan made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16150" target="_blank" rel="noopener noreferrer">PR #16150</a></li>
<li>@Chesars made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16236" target="_blank" rel="noopener noreferrer">PR #16236</a></li>
<li>@bowenliang123 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16255" target="_blank" rel="noopener noreferrer">PR #16255</a></li>
<li>@dean-zavad made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16199" target="_blank" rel="noopener noreferrer">PR #16199</a></li>
<li>@alexkuzmik made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15529" target="_blank" rel="noopener noreferrer">PR #15529</a></li>
<li>@Granine made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16281" target="_blank" rel="noopener noreferrer">PR #16281</a></li>
<li>@Oodapow made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16279" target="_blank" rel="noopener noreferrer">PR #16279</a></li>
<li>@jgoodyear made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16275" target="_blank" rel="noopener noreferrer">PR #16275</a></li>
<li>@Qanpi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16321" target="_blank" rel="noopener noreferrer">PR #16321</a></li>
<li>@ShimonMimoun made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16313" target="_blank" rel="noopener noreferrer">PR #16313</a></li>
<li>@andriykislitsyn made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16288" target="_blank" rel="noopener noreferrer">PR #16288</a></li>
<li>@reckless-huang made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16263" target="_blank" rel="noopener noreferrer">PR #16263</a></li>
<li>@chenmoneygithub made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16368" target="_blank" rel="noopener noreferrer">PR #16368</a></li>
<li>@stembe-digitalex made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16354" target="_blank" rel="noopener noreferrer">PR #16354</a></li>
<li>@jfcherng made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16352" target="_blank" rel="noopener noreferrer">PR #16352</a></li>
<li>@xingyaoww made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16246" target="_blank" rel="noopener noreferrer">PR #16246</a></li>
<li>@emerzon made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16373" target="_blank" rel="noopener noreferrer">PR #16373</a></li>
<li>@wwwillchen made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16376" target="_blank" rel="noopener noreferrer">PR #16376</a></li>
<li>@fabriciojoc made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16203" target="_blank" rel="noopener noreferrer">PR #16203</a></li>
<li>@jroberts2600 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16273" target="_blank" rel="noopener noreferrer">PR #16273</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-79-3#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.79.1-nightly...v1.79.2.rc.1" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.79.1-stable - Guardrail Playground]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-79-1</link>
            <guid>https://docs.litellm.ai/release_notes/v1-79-1</guid>
            <pubDate>Sat, 01 Nov 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-79-1#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.79.1-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.80.0</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-79-1#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Container API Support</strong> - End-to-end OpenAI Container API support with proxy integration, logging, and cost tracking</li>
<li><strong>FAL AI Image Generation</strong> - Native support for FAL AI image generation models with cost tracking</li>
<li><strong>UI Enhancements</strong> - Guardrail Playground, Cache Settings, Tag Routing, SSO Settings</li>
<li><strong>Batch API Rate Limiting</strong> - Input-based rate limits support for Batch API requests</li>
<li><strong>Vector Store Expansion</strong> - Milvus vector store support and Azure AI virtual indexes</li>
<li><strong>Memory Leak Fixes</strong> - Resolved issues accounting for 90% of memory leaks on Python SDK &amp; AI Gateway</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dependency-upgrades">Dependency Upgrades<a href="https://docs.litellm.ai/release_notes/v1-79-1#dependency-upgrades" class="hash-link" aria-label="Dependency Upgrades的直接链接" title="Dependency Upgrades的直接链接">​</a></h2>
<ul>
<li><strong>Dependencies</strong>
<ul>
<li>Build(deps): bump starlette from 0.47.2 to 0.49.1 - <a href="https://github.com/BerriAI/litellm/pull/16027" target="_blank" rel="noopener noreferrer">PR #16027</a></li>
<li>Build(deps): bump fastapi from 0.116.1 to 0.120.1 - <a href="https://github.com/BerriAI/litellm/pull/16054" target="_blank" rel="noopener noreferrer">PR #16054</a></li>
<li>Build(deps): bump hono from 4.9.7 to 4.10.3 in /litellm-js/spend-logs - <a href="https://github.com/BerriAI/litellm/pull/15915" target="_blank" rel="noopener noreferrer">PR #15915</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-79-1#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-79-1#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Mistral</td><td><code>mistral/codestral-embed</code></td><td>8K</td><td>$0.15</td><td>-</td><td>Embeddings</td></tr><tr><td>Mistral</td><td><code>mistral/codestral-embed-2505</code></td><td>8K</td><td>$0.15</td><td>-</td><td>Embeddings</td></tr><tr><td>Gemini</td><td><code>gemini/gemini-embedding-001</code></td><td>2K</td><td>$0.15</td><td>-</td><td>Embeddings</td></tr><tr><td>FAL AI</td><td><code>fal_ai/fal-ai/flux-pro/v1.1-ultra</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.0398/image</td></tr><tr><td>FAL AI</td><td><code>fal_ai/fal-ai/imagen4/preview</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.0398/image</td></tr><tr><td>FAL AI</td><td><code>fal_ai/fal-ai/recraft/v3/text-to-image</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.0398/image</td></tr><tr><td>FAL AI</td><td><code>fal_ai/fal-ai/stable-diffusion-v35-medium</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.0398/image</td></tr><tr><td>FAL AI</td><td><code>fal_ai/bria/text-to-image/3.2</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.0398/image</td></tr><tr><td>OpenAI</td><td><code>openai/sora-2-pro</code></td><td>-</td><td>-</td><td>-</td><td>Video generation - $0.30/video/second</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-79-1#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Extended Claude 3-7 Sonnet deprecation date from 2026-02-01 to 2026-02-19 - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Extended Claude Opus 4-0 deprecation date from 2025-03-01 to 2026-05-01 - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Removed Claude Haiku 3-5 deprecation date (previously 2025-03-01) - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Added Claude Opus 4-1, Claude Opus 4-0 20250513, Claude Sonnet 4 20250514 deprecation dates - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Added web search support for Claude Opus 4-1 - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Fix empty assistant message handling in AWS Bedrock Converse API to prevent 400 Bad Request errors - <a href="https://github.com/BerriAI/litellm/pull/15850" target="_blank" rel="noopener noreferrer">PR #15850</a></li>
<li>Allow using ARNs when generating images via Bedrock - <a href="https://github.com/BerriAI/litellm/pull/15789" target="_blank" rel="noopener noreferrer">PR #15789</a></li>
<li>Add per model group header forwarding for Bedrock Invoke API - <a href="https://github.com/BerriAI/litellm/pull/16042" target="_blank" rel="noopener noreferrer">PR #16042</a></li>
<li>Preserve Bedrock inference profile IDs in health checks - <a href="https://github.com/BerriAI/litellm/pull/15947" target="_blank" rel="noopener noreferrer">PR #15947</a></li>
<li>Added fallback logic for detecting file content-type when S3 returns generic type - When using Bedrock with S3-hosted files, if the S3 object's Content-Type is not correctly set (e.g., binary/octet-stream instead of image/png), Bedrock can now handle it correctly - <a href="https://github.com/BerriAI/litellm/pull/15635" target="_blank" rel="noopener noreferrer">PR #15635</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Add deprecation dates for Azure OpenAI models (gpt-4o-2024-08-06, gpt-4o-2024-11-20, gpt-4.1 series, o3-2025-04-16, text-embedding-3-small) - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Fix Azure OpenAI ContextWindowExceededError mapping from Azure errors - <a href="https://github.com/BerriAI/litellm/pull/15981" target="_blank" rel="noopener noreferrer">PR #15981</a></li>
<li>Add handling for <code>v1</code> under Azure API versions - <a href="https://github.com/BerriAI/litellm/pull/15984" target="_blank" rel="noopener noreferrer">PR #15984</a></li>
<li>Fix azure doesn't accept extra body param - <a href="https://github.com/BerriAI/litellm/pull/16116" target="_blank" rel="noopener noreferrer">PR #16116</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Add deprecation dates for gpt-3.5-turbo-1106, gpt-4-0125-preview, gpt-4-1106-preview, o1-mini-2024-09-12 - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Add extended Sora-2 modality support (text + image inputs) - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>Updated OpenAI Sora-2-Pro pricing to $0.30/video/second - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong></p>
<ul>
<li>Add Claude Haiku 4.5 pricing for OpenRouter - <a href="https://github.com/BerriAI/litellm/pull/15909" target="_blank" rel="noopener noreferrer">PR #15909</a></li>
<li>Add base_url config with environment variables documentation - <a href="https://github.com/BerriAI/litellm/pull/15946" target="_blank" rel="noopener noreferrer">PR #15946</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong></p>
<ul>
<li>Add codestral-embed-2505 embedding model - <a href="https://github.com/BerriAI/litellm/pull/16071" target="_blank" rel="noopener noreferrer">PR #16071</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini (Google AI Studio + Vertex AI)</a></strong></p>
<ul>
<li>Fix gemini request mutation for tool use - <a href="https://github.com/BerriAI/litellm/pull/16002" target="_blank" rel="noopener noreferrer">PR #16002</a></li>
<li>Add gemini-embedding-001 pricing entry for Google GenAI API - <a href="https://github.com/BerriAI/litellm/pull/16078" target="_blank" rel="noopener noreferrer">PR #16078</a></li>
<li>Changes to fix frequency_penalty and presence_penalty issue for gemini-2.5-pro model - <a href="https://github.com/BerriAI/litellm/pull/16041" target="_blank" rel="noopener noreferrer">PR #16041</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/deepinfra">DeepInfra</a></strong></p>
<ul>
<li>Add vision support for Qwen/Qwen3-chat-32b model - <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vercel_ai_gateway">Vercel AI Gateway</a></strong></p>
<ul>
<li>Fix vercel_ai_gateway entry for glm-4.6 (moved from vercel_ai_gateway/glm-4.6 to vercel_ai_gateway/zai/glm-4.6) - <a href="https://github.com/BerriAI/litellm/pull/16084" target="_blank" rel="noopener noreferrer">PR #16084</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks</a></strong></p>
<ul>
<li>Don't add "accounts/fireworks/models" prefix for Fireworks Provider - <a href="https://github.com/BerriAI/litellm/pull/15938" target="_blank" rel="noopener noreferrer">PR #15938</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/cohere">Cohere</a></strong></p>
<ul>
<li>Add OpenAI-compatible annotations support for Cohere v2 citations - <a href="https://github.com/BerriAI/litellm/pull/16038" target="_blank" rel="noopener noreferrer">PR #16038</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/deepgram">Deepgram</a></strong></p>
<ul>
<li>Handle Deepgram detected language when available - <a href="https://github.com/BerriAI/litellm/pull/16093" target="_blank" rel="noopener noreferrer">PR #16093</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-79-1#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/xai">Xai</a></strong>
<ul>
<li>Add Xai websearch cost tracking - <a href="https://github.com/BerriAI/litellm/pull/16001" target="_blank" rel="noopener noreferrer">PR #16001</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-79-1#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/image_generation">FAL AI</a></strong></p>
<ul>
<li>Add FAL AI Image Generation support - <a href="https://github.com/BerriAI/litellm/pull/16067" target="_blank" rel="noopener noreferrer">PR #16067</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI (Oracle Cloud Infrastructure)</a></strong></p>
<ul>
<li>Add OCI Signer Authentication support - <a href="https://github.com/BerriAI/litellm/pull/16064" target="_blank" rel="noopener noreferrer">PR #16064</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-79-1#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-79-1#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/containers">Container API</a></strong></p>
<ul>
<li>Add end-to-end OpenAI Container API support to LiteLLM SDK - <a href="https://github.com/BerriAI/litellm/pull/16136" target="_blank" rel="noopener noreferrer">PR #16136</a></li>
<li>Add proxy support for container APIs - <a href="https://github.com/BerriAI/litellm/pull/16049" target="_blank" rel="noopener noreferrer">PR #16049</a></li>
<li>Add logging support for Container API - <a href="https://github.com/BerriAI/litellm/pull/16049" target="_blank" rel="noopener noreferrer">PR #16049</a></li>
<li>Add cost tracking support for containers with documentation - <a href="https://github.com/BerriAI/litellm/pull/16117" target="_blank" rel="noopener noreferrer">PR #16117</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Respect <code>LiteLLM-Disable-Message-Redaction</code> header for Responses API - <a href="https://github.com/BerriAI/litellm/pull/15966" target="_blank" rel="noopener noreferrer">PR #15966</a></li>
<li>Add /openai routes for responses API (Azure OpenAI SDK Compatibility) - <a href="https://github.com/BerriAI/litellm/pull/15988" target="_blank" rel="noopener noreferrer">PR #15988</a></li>
<li>Redact reasoning summaries in ResponsesAPI output when message logging is disabled - <a href="https://github.com/BerriAI/litellm/pull/15965" target="_blank" rel="noopener noreferrer">PR #15965</a></li>
<li>Support text.format parameter in Responses API for providers without native ResponsesAPIConfig - <a href="https://github.com/BerriAI/litellm/pull/16023" target="_blank" rel="noopener noreferrer">PR #16023</a></li>
<li>Add LLM provider response headers to Responses API - <a href="https://github.com/BerriAI/litellm/pull/16091" target="_blank" rel="noopener noreferrer">PR #16091</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Add <code>custom_llm_provider</code> support for video endpoints (non-generation) - <a href="https://github.com/BerriAI/litellm/pull/16121" target="_blank" rel="noopener noreferrer">PR #16121</a></li>
<li>Fix documentation for videos - <a href="https://github.com/BerriAI/litellm/pull/15937" target="_blank" rel="noopener noreferrer">PR #15937</a></li>
<li>Add OpenAI client usage documentation for videos and fix navigation visibility - <a href="https://github.com/BerriAI/litellm/pull/15996" target="_blank" rel="noopener noreferrer">PR #15996</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/moderations">Moderations API</a></strong></p>
<ul>
<li>Moderations endpoint now respects <code>api_base</code> configuration parameter - <a href="https://github.com/BerriAI/litellm/pull/16087" target="_blank" rel="noopener noreferrer">PR #16087</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/vector_stores">Vector Stores</a></strong></p>
<ul>
<li>Milvus - search vector store support - <a href="https://github.com/BerriAI/litellm/pull/16035" target="_blank" rel="noopener noreferrer">PR #16035</a></li>
<li>Azure AI Vector Stores - support "virtual" indexes + create vector store on passthrough API - <a href="https://github.com/BerriAI/litellm/pull/16160" target="_blank" rel="noopener noreferrer">PR #16160</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/pass_through/vertex_ai">Passthrough Endpoints</a></strong></p>
<ul>
<li>Support multi-part form data on passthrough - <a href="https://github.com/BerriAI/litellm/pull/16035" target="_blank" rel="noopener noreferrer">PR #16035</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-79-1#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-79-1#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Validation for Proxy Base URL in SSO Settings - <a href="https://github.com/BerriAI/litellm/pull/16082" target="_blank" rel="noopener noreferrer">PR #16082</a></li>
<li>Test Key UI Embeddings support - <a href="https://github.com/BerriAI/litellm/pull/16065" target="_blank" rel="noopener noreferrer">PR #16065</a></li>
<li>Add Key Type Select in Key Settings - <a href="https://github.com/BerriAI/litellm/pull/16034" target="_blank" rel="noopener noreferrer">PR #16034</a></li>
<li>Key Already Exist Error Notification - <a href="https://github.com/BerriAI/litellm/pull/15993" target="_blank" rel="noopener noreferrer">PR #15993</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Changed API Base from Select to Input in New LLM Credentials - <a href="https://github.com/BerriAI/litellm/pull/15987" target="_blank" rel="noopener noreferrer">PR #15987</a></li>
<li>Remove limit from admin UI numerical input - <a href="https://github.com/BerriAI/litellm/pull/15991" target="_blank" rel="noopener noreferrer">PR #15991</a></li>
<li>Config Models should not be editable - <a href="https://github.com/BerriAI/litellm/pull/16020" target="_blank" rel="noopener noreferrer">PR #16020</a></li>
<li>Add tags in model creation - <a href="https://github.com/BerriAI/litellm/pull/16138" target="_blank" rel="noopener noreferrer">PR #16138</a></li>
<li>Add Tags to update model - <a href="https://github.com/BerriAI/litellm/pull/16140" target="_blank" rel="noopener noreferrer">PR #16140</a></li>
</ul>
</li>
<li>
<p><strong>Guardrails</strong></p>
<ul>
<li>Add Apply Guardrail Testing Playground - <a href="https://github.com/BerriAI/litellm/pull/16030" target="_blank" rel="noopener noreferrer">PR #16030</a></li>
<li>Config Guardrails should not be editable and guardrail info fix - <a href="https://github.com/BerriAI/litellm/pull/16142" target="_blank" rel="noopener noreferrer">PR #16142</a></li>
</ul>
</li>
<li>
<p><strong>Cache Settings</strong></p>
<ul>
<li>Allow setting cache settings on UI - <a href="https://github.com/BerriAI/litellm/pull/16143" target="_blank" rel="noopener noreferrer">PR #16143</a></li>
</ul>
</li>
<li>
<p><strong>Routing</strong></p>
<ul>
<li>Allow setting all routing strategies, tag filtering on UI - <a href="https://github.com/BerriAI/litellm/pull/16139" target="_blank" rel="noopener noreferrer">PR #16139</a></li>
</ul>
</li>
<li>
<p><strong>Admin Settings</strong></p>
<ul>
<li>Add license metadata to health/readiness endpoint - <a href="https://github.com/BerriAI/litellm/pull/15997" target="_blank" rel="noopener noreferrer">PR #15997</a></li>
<li>Litellm Backend SSO Changes - <a href="https://github.com/BerriAI/litellm/pull/16029" target="_blank" rel="noopener noreferrer">PR #16029</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-79-1#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-79-1#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opentelemetry">OpenTelemetry</a></strong></p>
<ul>
<li>Enable OpenTelemetry context propagation by external tracers - <a href="https://github.com/BerriAI/litellm/pull/15940" target="_blank" rel="noopener noreferrer">PR #15940</a></li>
<li>Ensure error information is logged on OTEL - <a href="https://github.com/BerriAI/litellm/pull/15978" target="_blank" rel="noopener noreferrer">PR #15978</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong></p>
<ul>
<li>Fix duplicate trace in langfuse_otel - <a href="https://github.com/BerriAI/litellm/pull/15931" target="_blank" rel="noopener noreferrer">PR #15931</a></li>
<li>Support tool usage messages with Langfuse OTEL integration - <a href="https://github.com/BerriAI/litellm/pull/15932" target="_blank" rel="noopener noreferrer">PR #15932</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">DataDog</a></strong></p>
<ul>
<li>Ensure key's metadata + guardrail is logged on DD - <a href="https://github.com/BerriAI/litellm/pull/15980" target="_blank" rel="noopener noreferrer">PR #15980</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opik">Opik</a></strong></p>
<ul>
<li>Enhance requester metadata retrieval from API key auth - <a href="https://github.com/BerriAI/litellm/pull/15897" target="_blank" rel="noopener noreferrer">PR #15897</a></li>
<li>User auth key metadata Documentation - <a href="https://github.com/BerriAI/litellm/pull/16004" target="_blank" rel="noopener noreferrer">PR #16004</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#sqs">SQS</a></strong></p>
<ul>
<li>Add Base64 handling for SQS Logger - <a href="https://github.com/BerriAI/litellm/pull/16028" target="_blank" rel="noopener noreferrer">PR #16028</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fix: User API key and team id and user id missing from custom callback is not misfiring - <a href="https://github.com/BerriAI/litellm/pull/15982" target="_blank" rel="noopener noreferrer">PR #15982</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-79-1#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">IBM Guardrails</a></strong></p>
<ul>
<li>Update IBM Guardrails to correctly use SSL Verify argument - <a href="https://github.com/BerriAI/litellm/pull/15975" target="_blank" rel="noopener noreferrer">PR #15975</a></li>
<li>Add additional detail to ibm_guardrails.md documentation - <a href="https://github.com/BerriAI/litellm/pull/15971" target="_blank" rel="noopener noreferrer">PR #15971</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Model Armor</a></strong></p>
<ul>
<li>Support during_call for model armor guardrails - <a href="https://github.com/BerriAI/litellm/pull/15970" target="_blank" rel="noopener noreferrer">PR #15970</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Lasso Security</a></strong></p>
<ul>
<li>Upgrade to Lasso API v3 and fix ULID generation - <a href="https://github.com/BerriAI/litellm/pull/15941" target="_blank" rel="noopener noreferrer">PR #15941</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">PANW Prisma AIRS</a></strong></p>
<ul>
<li>Add per-request profile overrides to PANW Prisma AIRS - <a href="https://github.com/BerriAI/litellm/pull/16069" target="_blank" rel="noopener noreferrer">PR #16069</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Grayswan</a></strong></p>
<ul>
<li>Improve Grayswan guardrail documentation - <a href="https://github.com/BerriAI/litellm/pull/15875" target="_blank" rel="noopener noreferrer">PR #15875</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Pillar AI</a></strong></p>
<ul>
<li>Graceful degradation for pillar service when using litellm - <a href="https://github.com/BerriAI/litellm/pull/15857" target="_blank" rel="noopener noreferrer">PR #15857</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Ensure Key Guardrails are applied - <a href="https://github.com/BerriAI/litellm/pull/16025" target="_blank" rel="noopener noreferrer">PR #16025</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-79-1#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/prompt_management">GitLab</a></strong>
<ul>
<li>Add GitlabPromptCache and enable subfolder access - <a href="https://github.com/BerriAI/litellm/pull/15712" target="_blank" rel="noopener noreferrer">PR #15712</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-79-1#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Cost Tracking</strong></p>
<ul>
<li>Fix spend tracking for OCR/aOCR requests (log <code>pages_processed</code> + recognize <code>OCRResponse</code>) - <a href="https://github.com/BerriAI/litellm/pull/16070" target="_blank" rel="noopener noreferrer">PR #16070</a></li>
</ul>
</li>
<li>
<p><strong>Rate Limiting</strong></p>
<ul>
<li>Add support for Batch API Rate limiting - PR1 adds support for input based rate limits - <a href="https://github.com/BerriAI/litellm/pull/16075" target="_blank" rel="noopener noreferrer">PR #16075</a></li>
<li>Handle multiple rate limit types per descriptor and prevent IndexError - <a href="https://github.com/BerriAI/litellm/pull/16039" target="_blank" rel="noopener noreferrer">PR #16039</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-79-1#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>OAuth</strong>
<ul>
<li>Add support for dynamic client registration - <a href="https://github.com/BerriAI/litellm/pull/15921" target="_blank" rel="noopener noreferrer">PR #15921</a></li>
<li>Respect X-Forwarded- headers in OAuth endpoints - <a href="https://github.com/BerriAI/litellm/pull/16036" target="_blank" rel="noopener noreferrer">PR #16036</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-79-1#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Memory Leak Fixes</strong></p>
<ul>
<li>Fix: prevent httpx DeprecationWarning memory leak in AsyncHTTPHandler - <a href="https://github.com/BerriAI/litellm/pull/16024" target="_blank" rel="noopener noreferrer">PR #16024</a></li>
<li>Fix: resolve memory accumulation caused by Pydantic 2.11+ deprecation warnings - <a href="https://github.com/BerriAI/litellm/pull/16110" target="_blank" rel="noopener noreferrer">PR #16110</a></li>
<li>Fix(apscheduler): prevent memory leaks from jitter and frequent job intervals - <a href="https://github.com/BerriAI/litellm/pull/15846" target="_blank" rel="noopener noreferrer">PR #15846</a></li>
</ul>
</li>
<li>
<p><strong>Configuration</strong></p>
<ul>
<li>Remove minimum validation for cache control injection index - <a href="https://github.com/BerriAI/litellm/pull/16149" target="_blank" rel="noopener noreferrer">PR #16149</a></li>
<li>Fix prompt_caching.md: wrong prompt_tokens definition - <a href="https://github.com/BerriAI/litellm/pull/16044" target="_blank" rel="noopener noreferrer">PR #16044</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-79-1#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Use custom-llm-provider header in examples - <a href="https://github.com/BerriAI/litellm/pull/16055" target="_blank" rel="noopener noreferrer">PR #16055</a></li>
<li>Litellm docs readme fixes - <a href="https://github.com/BerriAI/litellm/pull/16107" target="_blank" rel="noopener noreferrer">PR #16107</a></li>
<li>Readme fixes add supported providers - <a href="https://github.com/BerriAI/litellm/pull/16109" target="_blank" rel="noopener noreferrer">PR #16109</a></li>
</ul>
</li>
<li>
<p><strong>Model References</strong></p>
<ul>
<li>Add supports vision field to qwen-vl models in model_prices_and_context_window.json - <a href="https://github.com/BerriAI/litellm/pull/16106" target="_blank" rel="noopener noreferrer">PR #16106</a></li>
</ul>
</li>
<li>
<p><strong>General Documentation</strong></p>
<ul>
<li>1-79-0 docs - <a href="https://github.com/BerriAI/litellm/pull/15936" target="_blank" rel="noopener noreferrer">PR #15936</a></li>
<li>Add minimum resource requirement for production - <a href="https://github.com/BerriAI/litellm/pull/16146" target="_blank" rel="noopener noreferrer">PR #16146</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-79-1#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@RobGeada made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15975" target="_blank" rel="noopener noreferrer">PR #15975</a></li>
<li>@shanto12 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15946" target="_blank" rel="noopener noreferrer">PR #15946</a></li>
<li>@dima-hx430 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15976" target="_blank" rel="noopener noreferrer">PR #15976</a></li>
<li>@m-misiura made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15971" target="_blank" rel="noopener noreferrer">PR #15971</a></li>
<li>@ylgibby made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15947" target="_blank" rel="noopener noreferrer">PR #15947</a></li>
<li>@Somtom made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15909" target="_blank" rel="noopener noreferrer">PR #15909</a></li>
<li>@rodolfo-nobrega made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16023" target="_blank" rel="noopener noreferrer">PR #16023</a></li>
<li>@bernata made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15997" target="_blank" rel="noopener noreferrer">PR #15997</a></li>
<li>@AlbertDeFusco made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15881" target="_blank" rel="noopener noreferrer">PR #15881</a></li>
<li>@komarovd95 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15789" target="_blank" rel="noopener noreferrer">PR #15789</a></li>
<li>@langpingxue made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15635" target="_blank" rel="noopener noreferrer">PR #15635</a></li>
<li>@OrionCodeDev made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16070" target="_blank" rel="noopener noreferrer">PR #16070</a></li>
<li>@sbinnee made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16078" target="_blank" rel="noopener noreferrer">PR #16078</a></li>
<li>@JetoPistola made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16106" target="_blank" rel="noopener noreferrer">PR #16106</a></li>
<li>@gvioss made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16093" target="_blank" rel="noopener noreferrer">PR #16093</a></li>
<li>@pale-aura made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16084" target="_blank" rel="noopener noreferrer">PR #16084</a></li>
<li>@tanvithakur94 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16041" target="_blank" rel="noopener noreferrer">PR #16041</a></li>
<li>@li-boxuan made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16044" target="_blank" rel="noopener noreferrer">PR #16044</a></li>
<li>@1stprinciple made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15938" target="_blank" rel="noopener noreferrer">PR #15938</a></li>
<li>@raghav-stripe made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16137" target="_blank" rel="noopener noreferrer">PR #16137</a></li>
<li>@steve-gore-snapdocs made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/16149" target="_blank" rel="noopener noreferrer">PR #16149</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-79-1#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.79.0-stable...v1.80.0-stable" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.79.0-stable - Search APIs]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-79-0</link>
            <guid>https://docs.litellm.ai/release_notes/v1-79-0</guid>
            <pubDate>Sun, 26 Oct 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-79-0#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.79.0-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.79.0</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="major-changes">Major Changes<a href="https://docs.litellm.ai/release_notes/v1-79-0#major-changes" class="hash-link" aria-label="Major Changes的直接链接" title="Major Changes的直接链接">​</a></h2>
<ul>
<li><strong>Cohere models will now be routed to Cohere v2 API by default</strong> - <a href="https://github.com/BerriAI/litellm/pull/15722" target="_blank" rel="noopener noreferrer">PR #15722</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-79-0#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Search APIs</strong> - Native <code>/v1/search</code> endpoint with support for Perplexity, Tavily, Parallel AI, Exa AI, DataforSEO, and Google PSE with cost tracking</li>
<li><strong>Vector Stores</strong> - Vertex AI Search API integration as vector store through LiteLLM with passthrough endpoint support</li>
<li><strong>Guardrails Expansion</strong> - Apply guardrails across Responses API, Image Gen, Text completions, Audio transcriptions, Audio Speech, Rerank, and Anthropic Messages API via unified <code>apply_guardrails</code> function</li>
<li><strong>New Guardrail Providers</strong> - Gray Swan, Dynamo AI, IBM Guardrails, Lasso Security v3, and Bedrock Guardrail apply_guardrail endpoint support</li>
<li><strong>Video Generation API</strong> - Native support for OpenAI Sora-2 and Azure Sora-2 (Pro, Pro-High-Res) with cost tracking and logging support</li>
<li><strong>Azure AI Speech (TTS)</strong> - Native Azure AI Speech integration with cost tracking for standard and HD voices</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-79-0#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-79-0#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Bedrock</td><td><code>anthropic.claude-3-7-sonnet-20240620-v1:0</code></td><td>200K</td><td>$3.60</td><td>$18.00</td><td>Chat, reasoning, vision, function calling, prompt caching, computer use</td></tr><tr><td>Bedrock GovCloud</td><td><code>us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0</code></td><td>200K</td><td>$3.60</td><td>$18.00</td><td>Chat, reasoning, vision, function calling, prompt caching, computer use</td></tr><tr><td>Vertex AI</td><td><code>mistral-medium-3</code></td><td>128K</td><td>$0.40</td><td>$2.00</td><td>Chat, function calling, tool choice</td></tr><tr><td>Vertex AI</td><td><code>codestral-2</code></td><td>128K</td><td>$0.30</td><td>$0.90</td><td>Chat, function calling, tool choice</td></tr><tr><td>Bedrock</td><td><code>amazon.titan-image-generator-v1</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.008/image, $0.01/premium image</td></tr><tr><td>Bedrock</td><td><code>amazon.titan-image-generator-v2</code></td><td>-</td><td>-</td><td>-</td><td>Image generation - $0.008/image, $0.01/premium image</td></tr><tr><td>OpenAI</td><td><code>sora-2</code></td><td>-</td><td>-</td><td>-</td><td>Video generation - $0.10/video/second</td></tr><tr><td>Azure</td><td><code>sora-2</code></td><td>-</td><td>-</td><td>-</td><td>Video generation - $0.10/video/second</td></tr><tr><td>Azure</td><td><code>sora-2-pro</code></td><td>-</td><td>-</td><td>-</td><td>Video generation - $0.30/video/second</td></tr><tr><td>Azure</td><td><code>sora-2-pro-high-res</code></td><td>-</td><td>-</td><td>-</td><td>Video generation - $0.50/video/second</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-79-0#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Fix cache_control incorrectly applied to all content items instead of last item only - <a href="https://github.com/BerriAI/litellm/pull/15699" target="_blank" rel="noopener noreferrer">PR #15699</a></li>
<li>Forward anthropic-beta headers to Bedrock, VertexAI - <a href="https://github.com/BerriAI/litellm/pull/15700" target="_blank" rel="noopener noreferrer">PR #15700</a></li>
<li>Change max_tokens value to match max_output_tokens for claude sonnet - <a href="https://github.com/BerriAI/litellm/pull/15715" target="_blank" rel="noopener noreferrer">PR #15715</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Add AWS us-gov-west-1 Claude 3.7 Sonnet costs - <a href="https://github.com/BerriAI/litellm/pull/15775" target="_blank" rel="noopener noreferrer">PR #15775</a></li>
<li>Fix the date for sonnet 3.7 in govcloud - <a href="https://github.com/BerriAI/litellm/pull/15800" target="_blank" rel="noopener noreferrer">PR #15800</a></li>
<li>Use proper bedrock model name in health check - <a href="https://github.com/BerriAI/litellm/pull/15808" target="_blank" rel="noopener noreferrer">PR #15808</a></li>
<li>Support for embeddings_by_type Response Format in Bedrock Cohere Embed v1 - <a href="https://github.com/BerriAI/litellm/pull/15707" target="_blank" rel="noopener noreferrer">PR #15707</a></li>
<li>Add titan image generations with cost tracking - <a href="https://github.com/BerriAI/litellm/pull/15916" target="_blank" rel="noopener noreferrer">PR #15916</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong></p>
<ul>
<li>Add imageConfig parameter for gemini-2.5-flash-image - <a href="https://github.com/BerriAI/litellm/pull/15530" target="_blank" rel="noopener noreferrer">PR #15530</a></li>
<li>Replace deprecated gemini-1.5-pro-preview-0514 - <a href="https://github.com/BerriAI/litellm/pull/15852" target="_blank" rel="noopener noreferrer">PR #15852</a></li>
<li>Update vertex ai gemini costs - <a href="https://github.com/BerriAI/litellm/pull/15911" target="_blank" rel="noopener noreferrer">PR #15911</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong></p>
<ul>
<li>Set 'think' to False when reasoning effort is minimal/none/disable - <a href="https://github.com/BerriAI/litellm/pull/15763" target="_blank" rel="noopener noreferrer">PR #15763</a></li>
<li>Handle parsing ollama chunk error - <a href="https://github.com/BerriAI/litellm/pull/15717" target="_blank" rel="noopener noreferrer">PR #15717</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong></p>
<ul>
<li>Add mistral medium 3 and Codestral 2 on vertex - <a href="https://github.com/BerriAI/litellm/pull/15887" target="_blank" rel="noopener noreferrer">PR #15887</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/databricks">Databricks</a></strong></p>
<ul>
<li>Allow prompt caching to be used for Anthropic Claude on Databricks - <a href="https://github.com/BerriAI/litellm/pull/15801" target="_blank" rel="noopener noreferrer">PR #15801</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Add Azure AVA TTS integration - <a href="https://github.com/BerriAI/litellm/pull/15749" target="_blank" rel="noopener noreferrer">PR #15749</a></li>
<li>Add Azure AVA (Speech AI) Cost Tracking - <a href="https://github.com/BerriAI/litellm/pull/15754" target="_blank" rel="noopener noreferrer">PR #15754</a></li>
<li>Azure AI Speech - Ensure <code>voice</code> is mapped from request body to SSML body, allow sending <code>role</code> and <code>style</code> - <a href="https://github.com/BerriAI/litellm/pull/15810" target="_blank" rel="noopener noreferrer">PR #15810</a></li>
<li>Add Azure support for video generation functionality (Sora-2) - <a href="https://github.com/BerriAI/litellm/pull/15901" target="_blank" rel="noopener noreferrer">PR #15901</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>OpenAI videos refactoring - <a href="https://github.com/BerriAI/litellm/pull/15900" target="_blank" rel="noopener noreferrer">PR #15900</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Read from custom-llm-provider header - <a href="https://github.com/BerriAI/litellm/pull/15528" target="_blank" rel="noopener noreferrer">PR #15528</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-79-0#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-79-0#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Add gpt 4.1 pricing for response endpoint - <a href="https://github.com/BerriAI/litellm/pull/15593" target="_blank" rel="noopener noreferrer">PR #15593</a></li>
<li>Fix Incorrect status value in responses api with gemini - <a href="https://github.com/BerriAI/litellm/pull/15753" target="_blank" rel="noopener noreferrer">PR #15753</a></li>
<li>Simplify reasoning item handling for gpt-5-codex - <a href="https://github.com/BerriAI/litellm/pull/15815" target="_blank" rel="noopener noreferrer">PR #15815</a></li>
<li>ErrorEvent ValidationError when OpenAI Responses API returns nested error structure - <a href="https://github.com/BerriAI/litellm/pull/15804" target="_blank" rel="noopener noreferrer">PR #15804</a></li>
<li>Fix reasoning item ID auto-generation causing encrypted content verification errors - <a href="https://github.com/BerriAI/litellm/pull/15782" target="_blank" rel="noopener noreferrer">PR #15782</a></li>
<li>Support tags in metadata - <a href="https://github.com/BerriAI/litellm/pull/15867" target="_blank" rel="noopener noreferrer">PR #15867</a></li>
<li>Security: prevent User A from retrieving User B's response, if response.id is leaked - <a href="https://github.com/BerriAI/litellm/pull/15757" target="_blank" rel="noopener noreferrer">PR #15757</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/batch_api">Batch API</a></strong></p>
<ul>
<li>Add pre and post call for list batches - <a href="https://github.com/BerriAI/litellm/pull/15673" target="_blank" rel="noopener noreferrer">PR #15673</a></li>
<li>Add function responsible to call precall - <a href="https://github.com/BerriAI/litellm/pull/15636" target="_blank" rel="noopener noreferrer">PR #15636</a></li>
<li>Fix "User default_user_id does not have access to the object" when object not in db - <a href="https://github.com/BerriAI/litellm/pull/15873" target="_blank" rel="noopener noreferrer">PR #15873</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/ocr">OCR API</a></strong></p>
<ul>
<li>Add Azure AI - OCR to docs - <a href="https://github.com/BerriAI/litellm/pull/15768" target="_blank" rel="noopener noreferrer">PR #15768</a></li>
<li>Add mode + Health check support for OCR models - <a href="https://github.com/BerriAI/litellm/pull/15767" target="_blank" rel="noopener noreferrer">PR #15767</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/search_api">Search API</a></strong></p>
<ul>
<li>Add def search() APIs for Web Search - Perplexity API - <a href="https://github.com/BerriAI/litellm/pull/15769" target="_blank" rel="noopener noreferrer">PR #15769</a></li>
<li>Add Tavily Search API - <a href="https://github.com/BerriAI/litellm/pull/15770" target="_blank" rel="noopener noreferrer">PR #15770</a></li>
<li>Add Parallel AI - Search API - <a href="https://github.com/BerriAI/litellm/pull/15772" target="_blank" rel="noopener noreferrer">PR #15772</a></li>
<li>Add EXA AI Search API to LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/15774" target="_blank" rel="noopener noreferrer">PR #15774</a></li>
<li>Add /search endpoint on LiteLLM Gateway - <a href="https://github.com/BerriAI/litellm/pull/15780" target="_blank" rel="noopener noreferrer">PR #15780</a></li>
<li>Add DataforSEO Search API - <a href="https://github.com/BerriAI/litellm/pull/15817" target="_blank" rel="noopener noreferrer">PR #15817</a></li>
<li>Add Google PSE Search Provider - <a href="https://github.com/BerriAI/litellm/pull/15816" target="_blank" rel="noopener noreferrer">PR #15816</a></li>
<li>Add cost tracking for Search API requests - Google PSE, Tavily, Parallel AI, Exa AI - <a href="https://github.com/BerriAI/litellm/pull/15821" target="_blank" rel="noopener noreferrer">PR #15821</a></li>
<li>Backend: Allow storing configured Search APIs in DB - <a href="https://github.com/BerriAI/litellm/pull/15862" target="_blank" rel="noopener noreferrer">PR #15862</a></li>
<li>Exa Search API - ensure request params are sent to Exa AI - <a href="https://github.com/BerriAI/litellm/pull/15855" target="_blank" rel="noopener noreferrer">PR #15855</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/vector_stores">Vector Stores</a></strong></p>
<ul>
<li>Support Vertex AI Search API as vector store through LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/15781" target="_blank" rel="noopener noreferrer">PR #15781</a></li>
<li>Azure AI - Search Vector Stores - <a href="https://github.com/BerriAI/litellm/pull/15873" target="_blank" rel="noopener noreferrer">PR #15873</a></li>
<li>VertexAI Search Vector Store - Passthrough endpoint support + Vector store search Cost tracking support - <a href="https://github.com/BerriAI/litellm/pull/15824" target="_blank" rel="noopener noreferrer">PR #15824</a></li>
<li>Don't raise error if managed object is not found - <a href="https://github.com/BerriAI/litellm/pull/15873" target="_blank" rel="noopener noreferrer">PR #15873</a></li>
<li>Show config.yaml vector stores on UI - <a href="https://github.com/BerriAI/litellm/pull/15873" target="_blank" rel="noopener noreferrer">PR #15873</a></li>
<li>Cost tracking for search spend - <a href="https://github.com/BerriAI/litellm/pull/15859" target="_blank" rel="noopener noreferrer">PR #15859</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/image_generation">Images API</a></strong></p>
<ul>
<li>Pass user-defined headers and extra_headers to image-edit calls - <a href="https://github.com/BerriAI/litellm/pull/15811" target="_blank" rel="noopener noreferrer">PR #15811</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/video_generation">Video Generation API</a></strong></p>
<ul>
<li>Add Azure support for video generation functionality (Sora-2, Sora-2-Pro, Sora-2-Pro-High-Res) - <a href="https://github.com/BerriAI/litellm/pull/15901" target="_blank" rel="noopener noreferrer">PR #15901</a></li>
<li>OpenAI video generation refactoring (Sora-2) - <a href="https://github.com/BerriAI/litellm/pull/15900" target="_blank" rel="noopener noreferrer">PR #15900</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/bedrock_invoke">Bedrock /invoke</a></strong></p>
<ul>
<li>Fix: Hooks broken on /bedrock passthrough due to missing metadata - <a href="https://github.com/BerriAI/litellm/pull/15849" target="_blank" rel="noopener noreferrer">PR #15849</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/realtime_api">Realtime API</a></strong></p>
<ul>
<li>Fix: OpenAI Realtime API integration fails due to websockets.exceptions.PayloadTooBig error - <a href="https://github.com/BerriAI/litellm/pull/15751" target="_blank" rel="noopener noreferrer">PR #15751</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-79-0#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-79-0#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Passthrough</strong></p>
<ul>
<li>Set auth on passthrough endpoints, on the UI - <a href="https://github.com/BerriAI/litellm/pull/15778" target="_blank" rel="noopener noreferrer">PR #15778</a></li>
<li>Fix pass-through endpoint budget enforcement bug - <a href="https://github.com/BerriAI/litellm/pull/15805" target="_blank" rel="noopener noreferrer">PR #15805</a></li>
</ul>
</li>
<li>
<p><strong>Organizations</strong></p>
<ul>
<li>Allow org admins to create teams on UI - <a href="https://github.com/BerriAI/litellm/pull/15924" target="_blank" rel="noopener noreferrer">PR #15924</a></li>
</ul>
</li>
<li>
<p><strong>Search Tools</strong></p>
<ul>
<li>UI - Search Tools, allow adding search tools on UI + testing search - <a href="https://github.com/BerriAI/litellm/pull/15871" target="_blank" rel="noopener noreferrer">PR #15871</a></li>
<li>UI - Add logos for search providers - <a href="https://github.com/BerriAI/litellm/pull/15872" target="_blank" rel="noopener noreferrer">PR #15872</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fix routing for custom server root path - <a href="https://github.com/BerriAI/litellm/pull/15701" target="_blank" rel="noopener noreferrer">PR #15701</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-79-0#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-79-0#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opentelemetry">OpenTelemetry</a></strong></p>
<ul>
<li>Fix OpenTelemetry Logging functionality - <a href="https://github.com/BerriAI/litellm/pull/15645" target="_blank" rel="noopener noreferrer">PR #15645</a></li>
<li>Fix issue where headers were not being split correctly - <a href="https://github.com/BerriAI/litellm/pull/15916" target="_blank" rel="noopener noreferrer">PR #15916</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#sentry">Sentry</a></strong></p>
<ul>
<li>Add SENTRY_ENVIRONMENT configuration for Sentry integration - <a href="https://github.com/BerriAI/litellm/pull/15760" target="_blank" rel="noopener noreferrer">PR #15760</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#helicone">Helicone</a></strong></p>
<ul>
<li>Fix JSON serialization error in Helicone logging by removing OpenTelemetry span from metadata - <a href="https://github.com/BerriAI/litellm/pull/15728" target="_blank" rel="noopener noreferrer">PR #15728</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/logging#mlflow">MLFlow</a></strong></p>
<ul>
<li>Fix MLFlow tags - split request_tags into (key, val) if request_tag has colon - <a href="https://github.com/BerriAI/litellm/pull/15914" target="_blank" rel="noopener noreferrer">PR #15914</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Rename configured_cold_storage_logger to cold_storage_custom_logger - <a href="https://github.com/BerriAI/litellm/pull/15798" target="_blank" rel="noopener noreferrer">PR #15798</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-79-0#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Gray Swan</a></strong></p>
<ul>
<li>Add GraySwan Guardrails support - <a href="https://github.com/BerriAI/litellm/pull/15756" target="_blank" rel="noopener noreferrer">PR #15756</a></li>
<li>Rename GraySwan to Gray Swan - <a href="https://github.com/BerriAI/litellm/pull/15771" target="_blank" rel="noopener noreferrer">PR #15771</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Dynamo AI</a></strong></p>
<ul>
<li>New Guardrail - Dynamo AI Guardrail - <a href="https://github.com/BerriAI/litellm/pull/15920" target="_blank" rel="noopener noreferrer">PR #15920</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">IBM Guardrails</a></strong></p>
<ul>
<li>IBM Guardrails integration - <a href="https://github.com/BerriAI/litellm/pull/15924" target="_blank" rel="noopener noreferrer">PR #15924</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Lasso Security</a></strong></p>
<ul>
<li>Add v3 API Support - <a href="https://github.com/BerriAI/litellm/pull/12452" target="_blank" rel="noopener noreferrer">PR #12452</a></li>
<li>Fixed lasso import config, redis cluster hash tags for test keys - <a href="https://github.com/BerriAI/litellm/pull/15917" target="_blank" rel="noopener noreferrer">PR #15917</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Bedrock Guardrails</a></strong></p>
<ul>
<li>Implement Bedrock Guardrail apply_guardrail endpoint support - <a href="https://github.com/BerriAI/litellm/pull/15892" target="_blank" rel="noopener noreferrer">PR #15892</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Guardrails - Responses API, Image Gen, Text completions, Audio transcriptions, Audio Speech, Rerank, Anthropic Messages API support via the unified <code>apply_guardrails</code> function - <a href="https://github.com/BerriAI/litellm/pull/15706" target="_blank" rel="noopener noreferrer">PR #15706</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-79-0#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Rate Limiting</strong>
<ul>
<li>Support absolute RPM/TPM in priority_reservation - <a href="https://github.com/BerriAI/litellm/pull/15813" target="_blank" rel="noopener noreferrer">PR #15813</a></li>
<li>Org level tpm/rpm limits + Team tpm/rpm validation when assigned to org - <a href="https://github.com/BerriAI/litellm/pull/15549" target="_blank" rel="noopener noreferrer">PR #15549</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-79-0#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>OAuth</strong>
<ul>
<li>Auth Header Fix for MCP Tool Call - <a href="https://github.com/BerriAI/litellm/pull/15736" target="_blank" rel="noopener noreferrer">PR #15736</a></li>
<li>Add response_type + PKCE parameters to OAuth authorization endpoint - <a href="https://github.com/BerriAI/litellm/pull/15720" target="_blank" rel="noopener noreferrer">PR #15720</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-79-0#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Database</strong></p>
<ul>
<li>Minimize the occurrence of deadlocks - <a href="https://github.com/BerriAI/litellm/pull/15281" target="_blank" rel="noopener noreferrer">PR #15281</a></li>
</ul>
</li>
<li>
<p><strong>Redis</strong></p>
<ul>
<li>Apply max_connections configuration to Redis async client - <a href="https://github.com/BerriAI/litellm/pull/15797" target="_blank" rel="noopener noreferrer">PR #15797</a></li>
</ul>
</li>
<li>
<p><strong>Caching</strong></p>
<ul>
<li>Add documentation for <code>enable_caching_on_provider_specific_optional_params</code> setting - <a href="https://github.com/BerriAI/litellm/pull/15885" target="_blank" rel="noopener noreferrer">PR #15885</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-79-0#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li><strong>Provider Documentation</strong>
<ul>
<li>Update worker recommendation - <a href="https://github.com/BerriAI/litellm/pull/15702" target="_blank" rel="noopener noreferrer">PR #15702</a></li>
<li>Fix the wrong request body in json mode doc - <a href="https://github.com/BerriAI/litellm/pull/15729" target="_blank" rel="noopener noreferrer">PR #15729</a></li>
<li>Add details in docs - <a href="https://github.com/BerriAI/litellm/pull/15721" target="_blank" rel="noopener noreferrer">PR #15721</a></li>
<li>Add responses api on openai docs - <a href="https://github.com/BerriAI/litellm/pull/15866" target="_blank" rel="noopener noreferrer">PR #15866</a></li>
<li>Add OpenAI responses api - <a href="https://github.com/BerriAI/litellm/pull/15868" target="_blank" rel="noopener noreferrer">PR #15868</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-79-0#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@tlecomte made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15528" target="_blank" rel="noopener noreferrer">PR #15528</a></li>
<li>@tomhaynes made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15645" target="_blank" rel="noopener noreferrer">PR #15645</a></li>
<li>@talalryz made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15720" target="_blank" rel="noopener noreferrer">PR #15720</a></li>
<li>@1vinodsingh1 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15736" target="_blank" rel="noopener noreferrer">PR #15736</a></li>
<li>@nuernber made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15775" target="_blank" rel="noopener noreferrer">PR #15775</a></li>
<li>@Thomas-Mildner made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15760" target="_blank" rel="noopener noreferrer">PR #15760</a></li>
<li>@javiergarciapleo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15721" target="_blank" rel="noopener noreferrer">PR #15721</a></li>
<li>@lshgdut made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15717" target="_blank" rel="noopener noreferrer">PR #15717</a></li>
<li>@kk-wangjifeng made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15530" target="_blank" rel="noopener noreferrer">PR #15530</a></li>
<li>@anthonyivn2 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15801" target="_blank" rel="noopener noreferrer">PR #15801</a></li>
<li>@romanglo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15707" target="_blank" rel="noopener noreferrer">PR #15707</a></li>
<li>@mythral made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15859" target="_blank" rel="noopener noreferrer">PR #15859</a></li>
<li>@mubashirosmani made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15866" target="_blank" rel="noopener noreferrer">PR #15866</a></li>
<li>@CAFxX made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15281" target="_blank" rel="noopener noreferrer">PR #15281</a></li>
<li>@reflection made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15914" target="_blank" rel="noopener noreferrer">PR #15914</a></li>
<li>@shadielfares made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15917" target="_blank" rel="noopener noreferrer">PR #15917</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="pr-count-summary">PR Count Summary<a href="https://docs.litellm.ai/release_notes/v1-79-0#pr-count-summary" class="hash-link" aria-label="PR Count Summary的直接链接" title="PR Count Summary的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="10262025">10/26/2025<a href="https://docs.litellm.ai/release_notes/v1-79-0#10262025" class="hash-link" aria-label="10/26/2025的直接链接" title="10/26/2025的直接链接">​</a></h3>
<ul>
<li>New Models / Updated Models: 20</li>
<li>LLM API Endpoints: 29</li>
<li>Management Endpoints / UI: 5</li>
<li>Logging / Guardrail / Prompt Management Integrations: 10</li>
<li>Spend Tracking, Budgets and Rate Limiting: 2</li>
<li>MCP Gateway: 2</li>
<li>Performance / Loadbalancing / Reliability improvements: 3</li>
<li>Documentation Updates: 5</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-79-0#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.78.5-stable...v1.79.0-stable" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.78.5-stable - Native OCR Support]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-78-5</link>
            <guid>https://docs.litellm.ai/release_notes/v1-78-5</guid>
            <pubDate>Sat, 18 Oct 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-78-5#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.78.5-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.78.5</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-78-5#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Native OCR Endpoints</strong> - Native <code>/v1/ocr</code> endpoint support with cost tracking for Mistral OCR and Azure AI OCR</li>
<li><strong>Global Vendor Discounts</strong> - Specify global vendor discount percentages for accurate cost tracking and reporting</li>
<li><strong>Team Spending Reports</strong> - Team admins can now export detailed spending reports for their teams</li>
<li><strong>Claude Haiku 4.5</strong> - Day 0 support for Claude Haiku 4.5 across Bedrock, Vertex AI, and OpenRouter with 200K context window</li>
<li><strong>GPT-5-Codex</strong> - Support for GPT-5-Codex via Responses API on OpenAI and Azure</li>
<li><strong>Performance Improvements</strong> - Major router optimizations: O(1) model lookups, 10-100x faster shallow copy, 30-40% faster timing calls, and O(n) to O(1) hash generation</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-78-5#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-78-5#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Anthropic</td><td><code>claude-haiku-4-5</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Chat, reasoning, vision, function calling, prompt caching, computer use</td></tr><tr><td>Anthropic</td><td><code>claude-haiku-4-5-20251001</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Chat, reasoning, vision, function calling, prompt caching, computer use</td></tr><tr><td>Bedrock</td><td><code>anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>global.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>jp.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.10</td><td>$5.50</td><td>Chat, reasoning, vision, function calling, prompt caching (JP Cross-Region)</td></tr><tr><td>Bedrock</td><td><code>us.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.10</td><td>$5.50</td><td>Chat, reasoning, vision, function calling, prompt caching (US region)</td></tr><tr><td>Bedrock</td><td><code>eu.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.10</td><td>$5.50</td><td>Chat, reasoning, vision, function calling, prompt caching (EU region)</td></tr><tr><td>Bedrock</td><td><code>apac.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.10</td><td>$5.50</td><td>Chat, reasoning, vision, function calling, prompt caching (APAC region)</td></tr><tr><td>Bedrock</td><td><code>au.anthropic.claude-haiku-4-5-20251001-v1:0</code></td><td>200K</td><td>$1.10</td><td>$5.50</td><td>Chat, reasoning, vision, function calling, prompt caching (AU region)</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/claude-haiku-4-5@20251001</code></td><td>200K</td><td>$1.00</td><td>$5.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>OpenAI</td><td><code>gpt-5</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Chat, responses API, reasoning, vision, function calling, prompt caching</td></tr><tr><td>OpenAI</td><td><code>gpt-5-codex</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Responses API mode</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-codex</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Responses API mode</td></tr><tr><td>Gemini</td><td><code>gemini-2.5-flash-image</code></td><td>32K</td><td>$0.30</td><td>$2.50</td><td>Image generation (GA - Nano Banana) - $0.039/image</td></tr><tr><td>ZhipuAI</td><td><code>glm-4.6</code></td><td>-</td><td>-</td><td>-</td><td>Chat completions</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-78-5#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>GPT-5 return reasoning content via /chat/completions + GPT-5-Codex working on Claude Code - <a href="https://github.com/BerriAI/litellm/pull/15441" target="_blank" rel="noopener noreferrer">PR #15441</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Reduce claude-4-sonnet max_output_tokens to 64k - <a href="https://github.com/BerriAI/litellm/pull/15409" target="_blank" rel="noopener noreferrer">PR #15409</a></li>
<li>Added claude-haiku-4.5 - <a href="https://github.com/BerriAI/litellm/pull/15579" target="_blank" rel="noopener noreferrer">PR #15579</a></li>
<li>Add support for thinking blocks and redacted thinking blocks in Anthropic v1/messages API - <a href="https://github.com/BerriAI/litellm/pull/15501" target="_blank" rel="noopener noreferrer">PR #15501</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Add anthropic.claude-haiku-4-5-20251001-v1:0 on Bedrock, VertexAI - <a href="https://github.com/BerriAI/litellm/pull/15581" target="_blank" rel="noopener noreferrer">PR #15581</a></li>
<li>Add Claude Haiku 4.5 support for Bedrock global and US regions - <a href="https://github.com/BerriAI/litellm/pull/15650" target="_blank" rel="noopener noreferrer">PR #15650</a></li>
<li>Add Claude Haiku 4.5 support for Bedrock Other regions - <a href="https://github.com/BerriAI/litellm/pull/15653" target="_blank" rel="noopener noreferrer">PR #15653</a></li>
<li>Add JP Cross-Region Inference jp.anthropic.claude-haiku-4-5-20251001 - <a href="https://github.com/BerriAI/litellm/pull/15598" target="_blank" rel="noopener noreferrer">PR #15598</a></li>
<li>Fix: bedrock-pricing-geo-inregion-cross-region / add Global Cross-Region Inference - <a href="https://github.com/BerriAI/litellm/pull/15685" target="_blank" rel="noopener noreferrer">PR #15685</a></li>
<li>Fix: Support us-gov prefix for AWS GovCloud Bedrock models - <a href="https://github.com/BerriAI/litellm/pull/15626" target="_blank" rel="noopener noreferrer">PR #15626</a></li>
<li>Fix GPT-OSS in Bedrock now supports streaming. Revert fake streaming - <a href="https://github.com/BerriAI/litellm/pull/15668" target="_blank" rel="noopener noreferrer">PR #15668</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong></p>
<ul>
<li>Feat(pricing): Add Gemini 2.5 Flash Image (Nano Banana) in GA - <a href="https://github.com/BerriAI/litellm/pull/15557" target="_blank" rel="noopener noreferrer">PR #15557</a></li>
<li>Fix: Gemini 2.5 Flash Image should not have supports_web_search=true - <a href="https://github.com/BerriAI/litellm/pull/15642" target="_blank" rel="noopener noreferrer">PR #15642</a></li>
<li>Remove penalty params as supported params for gemini preview model - <a href="https://github.com/BerriAI/litellm/pull/15503" target="_blank" rel="noopener noreferrer">PR #15503</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong></p>
<ul>
<li>Fix(ollama/chat): correctly map reasoning_effort to think in requests - <a href="https://github.com/BerriAI/litellm/pull/15465" target="_blank" rel="noopener noreferrer">PR #15465</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong></p>
<ul>
<li>Add anthropic/claude-sonnet-4.5 to OpenRouter cost map - <a href="https://github.com/BerriAI/litellm/pull/15472" target="_blank" rel="noopener noreferrer">PR #15472</a></li>
<li>Prompt caching for anthropic models with OpenRouter - <a href="https://github.com/BerriAI/litellm/pull/15535" target="_blank" rel="noopener noreferrer">PR #15535</a></li>
<li>Get completion cost directly from OpenRouter - <a href="https://github.com/BerriAI/litellm/pull/15448" target="_blank" rel="noopener noreferrer">PR #15448</a></li>
<li>Fix OpenRouter Claude Opus 4 model naming - <a href="https://github.com/BerriAI/litellm/pull/15495" target="_blank" rel="noopener noreferrer">PR #15495</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/comet">CometAPI</a></strong></p>
<ul>
<li>Fix(cometapi): improve CometAPI provider support (embeddings, image generation, docs) - <a href="https://github.com/BerriAI/litellm/pull/15591" target="_blank" rel="noopener noreferrer">PR #15591</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/lemonade">Lemonade</a></strong></p>
<ul>
<li>Adding new models to the lemonade provider - <a href="https://github.com/BerriAI/litellm/pull/15554" target="_blank" rel="noopener noreferrer">PR #15554</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/watsonx">Watson X</a></strong></p>
<ul>
<li>Fix (pricing): Fix pricing for watsonx model family for various models - <a href="https://github.com/BerriAI/litellm/pull/15670" target="_blank" rel="noopener noreferrer">PR #15670</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vercel_ai_gateway">Vercel AI Gateway</a></strong></p>
<ul>
<li>Add glm-4.6 model to pricing configuration - <a href="https://github.com/BerriAI/litellm/pull/15679" target="_blank" rel="noopener noreferrer">PR #15679</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong></p>
<ul>
<li>Add Vertex AI Discovery Engine Rerank Support - <a href="https://github.com/BerriAI/litellm/pull/15532" target="_blank" rel="noopener noreferrer">PR #15532</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-78-5#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong></p>
<ul>
<li>Fix: Pricing for Claude Sonnet 4.5 in US regions is 10x too high - <a href="https://github.com/BerriAI/litellm/pull/15374" target="_blank" rel="noopener noreferrer">PR #15374</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong></p>
<ul>
<li>Change gpt-5-codex support in model_price json - <a href="https://github.com/BerriAI/litellm/pull/15540" target="_blank" rel="noopener noreferrer">PR #15540</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Fix filtering headers for signature calcs - <a href="https://github.com/BerriAI/litellm/pull/15590" target="_blank" rel="noopener noreferrer">PR #15590</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Add native reasoning and streaming support flag for gpt-5-codex - <a href="https://github.com/BerriAI/litellm/pull/15569" target="_blank" rel="noopener noreferrer">PR #15569</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-78-5#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-78-5#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Responses API - enable calling anthropic/gemini models in Responses API streaming in openai ruby sdk + DB - sanity check pending migrations before startup - <a href="https://github.com/BerriAI/litellm/pull/15432" target="_blank" rel="noopener noreferrer">PR #15432</a></li>
<li>Add support for responses mode in health check - <a href="https://github.com/BerriAI/litellm/pull/15658" target="_blank" rel="noopener noreferrer">PR #15658</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/ocr">OCR API</a></strong></p>
<ul>
<li>Feat: Add native litellm.ocr() functions - <a href="https://github.com/BerriAI/litellm/pull/15567" target="_blank" rel="noopener noreferrer">PR #15567</a></li>
<li>Feat: Add /ocr route on LiteLLM AI Gateway - Adds support for native Mistral OCR calling - <a href="https://github.com/BerriAI/litellm/pull/15571" target="_blank" rel="noopener noreferrer">PR #15571</a></li>
<li>Feat: Add Azure AI Mistral OCR Integration - <a href="https://github.com/BerriAI/litellm/pull/15572" target="_blank" rel="noopener noreferrer">PR #15572</a></li>
<li>Feat: Native /ocr endpoint support - <a href="https://github.com/BerriAI/litellm/pull/15573" target="_blank" rel="noopener noreferrer">PR #15573</a></li>
<li>Feat: Add Cost Tracking for /ocr endpoints - <a href="https://github.com/BerriAI/litellm/pull/15678" target="_blank" rel="noopener noreferrer">PR #15678</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">/generateContent</a></strong></p>
<ul>
<li>Fix: GEMINI - CLI - add google_routes to llm_api_routes - <a href="https://github.com/BerriAI/litellm/pull/15500" target="_blank" rel="noopener noreferrer">PR #15500</a></li>
<li>Fix Pydantic validation error for citationMetadata.citationSources in Google GenAI responses - <a href="https://github.com/BerriAI/litellm/pull/15592" target="_blank" rel="noopener noreferrer">PR #15592</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/image_generation">Images API</a></strong></p>
<ul>
<li>Fix: Dall-e-2 for Image Edits API - <a href="https://github.com/BerriAI/litellm/pull/15604" target="_blank" rel="noopener noreferrer">PR #15604</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/pass_through/bedrock">Bedrock Passthrough</a></strong></p>
<ul>
<li>Feat: Allow calling /invoke, /converse routes through AI Gateway + models on config.yaml - <a href="https://github.com/BerriAI/litellm/pull/15618" target="_blank" rel="noopener noreferrer">PR #15618</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-78-5#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix: Convert object to a correct type - <a href="https://github.com/BerriAI/litellm/pull/15634" target="_blank" rel="noopener noreferrer">PR #15634</a></li>
<li>Bug Fix: Tags as metadata dicts were raising exceptions - <a href="https://github.com/BerriAI/litellm/pull/15625" target="_blank" rel="noopener noreferrer">PR #15625</a></li>
<li>Add type hint to function_to_dict and fix typo - <a href="https://github.com/BerriAI/litellm/pull/15580" target="_blank" rel="noopener noreferrer">PR #15580</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-78-5#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-78-5#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Docs: Key Rotations - <a href="https://github.com/BerriAI/litellm/pull/15455" target="_blank" rel="noopener noreferrer">PR #15455</a></li>
<li>Fix: UI - Key Max Budget Removal Error Fix - <a href="https://github.com/BerriAI/litellm/pull/15672" target="_blank" rel="noopener noreferrer">PR #15672</a></li>
<li>litellm_Key Settings Max Budget Removal Error Fix - <a href="https://github.com/BerriAI/litellm/pull/15669" target="_blank" rel="noopener noreferrer">PR #15669</a></li>
</ul>
</li>
<li>
<p><strong>Teams</strong></p>
<ul>
<li>Feat: Allow Team Admins to export a report of the team spending - <a href="https://github.com/BerriAI/litellm/pull/15542" target="_blank" rel="noopener noreferrer">PR #15542</a></li>
</ul>
</li>
<li>
<p><strong>Passthrough</strong></p>
<ul>
<li>Feat: Passthrough - allow admin to give access to specific passthrough endpoints - <a href="https://github.com/BerriAI/litellm/pull/15401" target="_blank" rel="noopener noreferrer">PR #15401</a></li>
</ul>
</li>
<li>
<p><strong>SCIM v2</strong></p>
<ul>
<li>Feat(scim_v2.py): if group.id doesn't exist, use external id + Passthrough - ensure updates and deletions persist across instances - <a href="https://github.com/BerriAI/litellm/pull/15276" target="_blank" rel="noopener noreferrer">PR #15276</a></li>
</ul>
</li>
<li>
<p><strong>SSO</strong></p>
<ul>
<li>Feat: UI SSO - Add PKCE for OKTA SSO - <a href="https://github.com/BerriAI/litellm/pull/15608" target="_blank" rel="noopener noreferrer">PR #15608</a></li>
<li>Fix: Separate OAuth M2M authentication from UI SSO + Handle Introspection endpoint for Oauth2 - <a href="https://github.com/BerriAI/litellm/pull/15667" target="_blank" rel="noopener noreferrer">PR #15667</a></li>
<li>Fix/entraid app roles jwt claim clean - <a href="https://github.com/BerriAI/litellm/pull/15583" target="_blank" rel="noopener noreferrer">PR #15583</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-78-5#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-78-5#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fix apply_guardrail endpoint returning raw string instead of ApplyGuardrailResponse - <a href="https://github.com/BerriAI/litellm/pull/15436" target="_blank" rel="noopener noreferrer">PR #15436</a></li>
<li>Fix: Ensure guardrail memory sync after database updates - <a href="https://github.com/BerriAI/litellm/pull/15633" target="_blank" rel="noopener noreferrer">PR #15633</a></li>
<li>Feat: add guardrail for image generation - <a href="https://github.com/BerriAI/litellm/pull/15619" target="_blank" rel="noopener noreferrer">PR #15619</a></li>
<li>Feat: Add Guardrails for /v1/messages and /v1/responses API - <a href="https://github.com/BerriAI/litellm/pull/15686" target="_blank" rel="noopener noreferrer">PR #15686</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Pillar Security</a></strong></p>
<ul>
<li>Feature: update pillar security integration to support no persistence mode in litellm proxy - <a href="https://github.com/BerriAI/litellm/pull/15599" target="_blank" rel="noopener noreferrer">PR #15599</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-78-5#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Small fix code snippet custom_prompt_management.md - <a href="https://github.com/BerriAI/litellm/pull/15544" target="_blank" rel="noopener noreferrer">PR #15544</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-78-5#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Cost Tracking</strong></p>
<ul>
<li>Feat: Cost Tracking - specify a global vendor discount for costs - <a href="https://github.com/BerriAI/litellm/pull/15546" target="_blank" rel="noopener noreferrer">PR #15546</a></li>
<li>Feat: UI - Allow setting Provider Discounts on UI - <a href="https://github.com/BerriAI/litellm/pull/15550" target="_blank" rel="noopener noreferrer">PR #15550</a></li>
</ul>
</li>
<li>
<p><strong>Budgets</strong></p>
<ul>
<li>Fix: improve budget clarity - <a href="https://github.com/BerriAI/litellm/pull/15682" target="_blank" rel="noopener noreferrer">PR #15682</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-78-5#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Router Optimizations</strong></p>
<ul>
<li>Perf(router): use shallow copy instead of deepcopy for model aliases - 10-100x faster than deepcopy on nested dict structures - <a href="https://github.com/BerriAI/litellm/pull/15576" target="_blank" rel="noopener noreferrer">PR #15576</a></li>
<li>Perf(router): optimize string concatenation in hash generation - Improves time complexity from O(n²) to O(n) - <a href="https://github.com/BerriAI/litellm/pull/15575" target="_blank" rel="noopener noreferrer">PR #15575</a></li>
<li>Perf(router): optimize model lookups with O(1) data structures - Replace O(n) scans with index map lookups - <a href="https://github.com/BerriAI/litellm/pull/15578" target="_blank" rel="noopener noreferrer">PR #15578</a></li>
<li>Perf(router): optimize model lookups with O(1) index maps - Use model_id_to_deployment_index_map and model_name_to_deployment_indices for instant lookups - <a href="https://github.com/BerriAI/litellm/pull/15574" target="_blank" rel="noopener noreferrer">PR #15574</a></li>
<li>Perf(router): optimize timing functions in completion hot path - Use time.perf_counter() for duration measurements and time.monotonic() for timeout calculations, providing 30-40% faster timing calls - <a href="https://github.com/BerriAI/litellm/pull/15617" target="_blank" rel="noopener noreferrer">PR #15617</a></li>
</ul>
</li>
<li>
<p><strong>SSL/TLS Performance</strong></p>
<ul>
<li>Feat(ssl): add configurable ECDH curve for TLS performance - Configure via ssl_ecdh_curve setting to disable PQC on OpenSSL 3.x for better performance - <a href="https://github.com/BerriAI/litellm/pull/15617" target="_blank" rel="noopener noreferrer">PR #15617</a></li>
</ul>
</li>
<li>
<p><strong>Token Counter</strong></p>
<ul>
<li>Fix(token-counter): extract model_info from deployment for custom_tokenizer - <a href="https://github.com/BerriAI/litellm/pull/15680" target="_blank" rel="noopener noreferrer">PR #15680</a></li>
</ul>
</li>
<li>
<p><strong>Performance Metrics</strong></p>
<ul>
<li>Add: perf summary - <a href="https://github.com/BerriAI/litellm/pull/15458" target="_blank" rel="noopener noreferrer">PR #15458</a></li>
</ul>
</li>
<li>
<p><strong>CI/CD</strong></p>
<ul>
<li>Fix: CI/CD - Missing env key &amp; Linter type error - <a href="https://github.com/BerriAI/litellm/pull/15606" target="_blank" rel="noopener noreferrer">PR #15606</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-78-5#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Litellm docs 10 11 2025 - <a href="https://github.com/BerriAI/litellm/pull/15457" target="_blank" rel="noopener noreferrer">PR #15457</a></li>
<li>Docs: add ecs deployment guide - <a href="https://github.com/BerriAI/litellm/pull/15468" target="_blank" rel="noopener noreferrer">PR #15468</a></li>
<li>Docs: Update benchmark results - <a href="https://github.com/BerriAI/litellm/pull/15461" target="_blank" rel="noopener noreferrer">PR #15461</a></li>
<li>Fix: add missing context to benchmark docs - <a href="https://github.com/BerriAI/litellm/pull/15688" target="_blank" rel="noopener noreferrer">PR #15688</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Fixed a few typos - <a href="https://github.com/BerriAI/litellm/pull/15267" target="_blank" rel="noopener noreferrer">PR #15267</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-78-5#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@jlan-nl made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15374" target="_blank" rel="noopener noreferrer">PR #15374</a></li>
<li>@ImadSaddik made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15267" target="_blank" rel="noopener noreferrer">PR #15267</a></li>
<li>@huangyafei made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15472" target="_blank" rel="noopener noreferrer">PR #15472</a></li>
<li>@mubashir1osmani made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15468" target="_blank" rel="noopener noreferrer">PR #15468</a></li>
<li>@kowyo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15465" target="_blank" rel="noopener noreferrer">PR #15465</a></li>
<li>@dhruvyad made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15448" target="_blank" rel="noopener noreferrer">PR #15448</a></li>
<li>@davizucon made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15544" target="_blank" rel="noopener noreferrer">PR #15544</a></li>
<li>@FelipeRodriguesGare made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15540" target="_blank" rel="noopener noreferrer">PR #15540</a></li>
<li>@ndrsfel made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15557" target="_blank" rel="noopener noreferrer">PR #15557</a></li>
<li>@shinharaguchi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15598" target="_blank" rel="noopener noreferrer">PR #15598</a></li>
<li>@TensorNull made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15591" target="_blank" rel="noopener noreferrer">PR #15591</a></li>
<li>@TeddyAmkie made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15583" target="_blank" rel="noopener noreferrer">PR #15583</a></li>
<li>@aniketmaurya made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15580" target="_blank" rel="noopener noreferrer">PR #15580</a></li>
<li>@eddierichter-amd made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15554" target="_blank" rel="noopener noreferrer">PR #15554</a></li>
<li>@konekohana made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15535" target="_blank" rel="noopener noreferrer">PR #15535</a></li>
<li>@Classic298 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15495" target="_blank" rel="noopener noreferrer">PR #15495</a></li>
<li>@afogel made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15599" target="_blank" rel="noopener noreferrer">PR #15599</a></li>
<li>@orolega made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15633" target="_blank" rel="noopener noreferrer">PR #15633</a></li>
<li>@LucasSugi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15634" target="_blank" rel="noopener noreferrer">PR #15634</a></li>
<li>@uc4w6c made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15619" target="_blank" rel="noopener noreferrer">PR #15619</a></li>
<li>@Sameerlite made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15658" target="_blank" rel="noopener noreferrer">PR #15658</a></li>
<li>@yuneng-jiang made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15672" target="_blank" rel="noopener noreferrer">PR #15672</a></li>
<li>@Nikro made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15680" target="_blank" rel="noopener noreferrer">PR #15680</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog">Full Changelog<a href="https://docs.litellm.ai/release_notes/v1-78-5#full-changelog" class="hash-link" aria-label="Full Changelog的直接链接" title="Full Changelog的直接链接">​</a></h2>
<p><strong><a href="https://github.com/BerriAI/litellm/compare/v1.78.0-stable...v1.78.4-stable" target="_blank" rel="noopener noreferrer">View complete changelog on GitHub</a></strong></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.78.0-stable - MCP Gateway: Control Tool Access by Team, Key]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-78-0</link>
            <guid>https://docs.litellm.ai/release_notes/v1-78-0</guid>
            <pubDate>Sat, 11 Oct 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-78-0#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.78.0-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.78.0.post1</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-78-0#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>MCP Gateway - Control Tool Access by Team, Key</strong> - Control MCP tool access by team/key.</li>
<li><strong>Performance Improvements</strong> - 70% Lower p99 Latency</li>
<li><strong>GPT-5 Pro &amp; GPT-Image-1-Mini</strong> - Day 0 support for OpenAI's GPT-5 Pro (400K context) and gpt-image-1-mini image generation</li>
<li><strong>EnkryptAI Guardrails</strong> - New guardrail integration for content moderation</li>
<li><strong>Tag-Based Budgets</strong> - Support for setting budgets based on request tags</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway---control-tool-access-by-team-key">MCP Gateway - Control Tool Access by Team, Key<a href="https://docs.litellm.ai/release_notes/v1-78-0#mcp-gateway---control-tool-access-by-team-key" class="hash-link" aria-label="MCP Gateway - Control Tool Access by Team, Key的直接链接" title="MCP Gateway - Control Tool Access by Team, Key的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAeUlEQVR4nD2N2wrEIAxE/f/fFME+dLVbreZSZ0lKN3AggZOZkLcNMUaUUsDMmHOCiHwXkT/BhJQScs4u1aNjjEdWvWGz1kIwW1UdIkbrA/0aYBaIKhaA79kQrMK+37rWL5fPPrHX5on7pz7ii8n3sgyARVGO6Tcx4weoYcKyMzLPngAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/tool_control.ac192bc.640.png" srcset="/assets/ideal-img/tool_control.ac192bc.640.png 640w,/assets/ideal-img/tool_control.e24c881.1920.png 1920w" width="640" height="334"></noscript></div>
<br>
<p>Proxy admins can now control MCP tool access by team or key. This makes it easy to grant different teams selective access to tools from the same MCP server.</p>
<p>For example, you can now give your Engineering team access to <code>list_repositories</code>, <code>create_issue</code>, and <code>search_code</code> tools, while Sales only gets <code>search_code</code> and <code>close_issue</code> tools.</p>
<p>This makes it easier for Proxy Admins to govern MCP Tool Access.</p>
<p><a href="https://docs.litellm.ai/docs/mcp_control#set-allowed-tools-for-a-key-team-or-organization">Get Started</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance---70-lower-p99-latency">Performance - 70% Lower p99 Latency<a href="https://docs.litellm.ai/release_notes/v1-78-0#performance---70-lower-p99-latency" class="hash-link" aria-label="Performance - 70% Lower p99 Latency的直接链接" title="Performance - 70% Lower p99 Latency的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAYAAAC3OK7NAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAgUlEQVR4nG2Muw6CQBQF+Xgr/2AJBpFCe6OhdNfnH9AaE+3o9hHgXseIrZOcak4m67qOGCOjCP9QVYZhIEsp0WwbNtWaelWT5znGGMplSVEUWGuncxZCYHGomO3m7G3D7XzleDlNc87Rtu2v2Pc9T//iHh/EMfJWRURQ0an09d57PqvQjw8/qE4/AAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="251"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/1_78_0_perf.6b236b5.640.png" srcset="/assets/ideal-img/1_78_0_perf.6b236b5.640.png 640w,/assets/ideal-img/1_78_0_perf.c68642f.1920.png 1920w" width="640" height="251"></noscript></div>
<br>
<p>This release cuts p99 latency by 70% on LiteLLM AI Gateway, making it even better for low-latency use cases.</p>
<p>These gains come from two key enhancements:</p>
<p><strong>Reliable Sessions</strong></p>
<p>Added support for shared sessions with aiohttp. The shared_session parameter is now consistently used across all calls, enabling connection pooling.</p>
<p><strong>Faster Routing</strong></p>
<p>A new <code>model_name_to_deployment_indices</code> hash map replaces O(n) list scans in <code>_get_all_deployments()</code> with O(1) hash lookups, boosting routing performance and scalability.</p>
<p>As a result, performance improved across all latency percentiles:</p>
<ul>
<li><strong>Median latency:</strong> 110 ms → <strong>100 ms</strong> (−9.1%)</li>
<li><strong>p95 latency:</strong> 440 ms → <strong>150 ms</strong> (−65.9%)</li>
<li><strong>p99 latency:</strong> 810 ms → <strong>240 ms</strong> (−70.4%)</li>
<li><strong>Average latency:</strong> 310 ms → <strong>111.73 ms</strong> (−64.0%)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup"><strong>Test Setup</strong><a href="https://docs.litellm.ai/release_notes/v1-78-0#test-setup" class="hash-link" aria-label="test-setup的直接链接" title="test-setup的直接链接">​</a></h3>
<p><strong>Locust</strong></p>
<ul>
<li><strong>Concurrent users:</strong>&nbsp;1,000</li>
<li><strong>Ramp-up:</strong>&nbsp;500</li>
</ul>
<p><strong>System Specs</strong></p>
<ul>
<li><strong>Database was used</strong></li>
<li><strong>CPU:</strong>&nbsp;4 vCPUs</li>
<li><strong>Memory:</strong>&nbsp;8 GB RAM</li>
<li><strong>LiteLLM Workers:</strong>&nbsp;4</li>
<li><strong>Instances</strong>: 4</li>
</ul>
<p><strong>Configuration (config.yaml)</strong></p>
<p>View the complete configuration:&nbsp;<a href="https://gist.github.com/AlexsanderHamir/53f7d554a5d2afcf2c4edb5b6be68ff4" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/config.yaml</a></p>
<p><strong>Load Script (no_cache_hits.py)</strong></p>
<p>View the complete load testing script:&nbsp;<a href="https://gist.github.com/AlexsanderHamir/42c33d7a4dc7a57f56a78b560dee3a42" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/no_cache_hits.py</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-78-0#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-78-0#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>OpenAI</td><td><code>gpt-5-pro</code></td><td>400K</td><td>$15.00</td><td>$120.00</td><td>Responses API, reasoning, vision, function calling, prompt caching, web search</td></tr><tr><td>OpenAI</td><td><code>gpt-5-pro-2025-10-06</code></td><td>400K</td><td>$15.00</td><td>$120.00</td><td>Responses API, reasoning, vision, function calling, prompt caching, web search</td></tr><tr><td>OpenAI</td><td><code>gpt-image-1-mini</code></td><td>-</td><td>$2.00/img</td><td>-</td><td>Image generation and editing</td></tr><tr><td>OpenAI</td><td><code>gpt-realtime-mini</code></td><td>128K</td><td>$0.60</td><td>$2.40</td><td>Realtime audio, function calling</td></tr><tr><td>Azure AI</td><td><code>azure_ai/Phi-4-mini-reasoning</code></td><td>131K</td><td>$0.08</td><td>$0.32</td><td>Function calling</td></tr><tr><td>Azure AI</td><td><code>azure_ai/Phi-4-reasoning</code></td><td>32K</td><td>$0.125</td><td>$0.50</td><td>Function calling, reasoning</td></tr><tr><td>Azure AI</td><td><code>azure_ai/MAI-DS-R1</code></td><td>128K</td><td>$1.35</td><td>$5.40</td><td>Reasoning, function calling</td></tr><tr><td>Bedrock</td><td><code>au.anthropic.claude-sonnet-4-5-20250929-v1:0</code></td><td>200K</td><td>$3.30</td><td>$16.50</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>global.anthropic.claude-sonnet-4-5-20250929-v1:0</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>global.anthropic.claude-sonnet-4-20250514-v1:0</code></td><td>1M</td><td>$3.00</td><td>$15.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>cohere.embed-v4:0</code></td><td>128K</td><td>$0.12</td><td>-</td><td>Embeddings, image input support</td></tr><tr><td>OCI</td><td><code>oci/cohere.command-latest</code></td><td>128K</td><td>$1.56</td><td>$1.56</td><td>Function calling</td></tr><tr><td>OCI</td><td><code>oci/cohere.command-a-03-2025</code></td><td>256K</td><td>$1.56</td><td>$1.56</td><td>Function calling</td></tr><tr><td>OCI</td><td><code>oci/cohere.command-plus-latest</code></td><td>128K</td><td>$1.56</td><td>$1.56</td><td>Function calling</td></tr><tr><td>Together AI</td><td><code>together_ai/moonshotai/Kimi-K2-Instruct-0905</code></td><td>262K</td><td>$1.00</td><td>$3.00</td><td>Function calling</td></tr><tr><td>Together AI</td><td><code>together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct</code></td><td>262K</td><td>$0.15</td><td>$1.50</td><td>Function calling</td></tr><tr><td>Together AI</td><td><code>together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking</code></td><td>262K</td><td>$0.15</td><td>$1.50</td><td>Function calling</td></tr><tr><td>Vertex AI</td><td>MedGemma models</td><td>Varies</td><td>Varies</td><td>Varies</td><td>Medical-focused Gemma models on custom endpoints</td></tr><tr><td>Watson X</td><td>27 new foundation models</td><td>Varies</td><td>Varies</td><td>Varies</td><td>Granite, Llama, Mistral families</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-78-0#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong></p>
<ul>
<li>Add GPT-5 Pro model configuration and documentation - <a href="https://github.com/BerriAI/litellm/pull/15258" target="_blank" rel="noopener noreferrer">PR #15258</a></li>
<li>Add stop parameter to non-supported params for GPT-5 - <a href="https://github.com/BerriAI/litellm/pull/15244" target="_blank" rel="noopener noreferrer">PR #15244</a></li>
<li>Day 0 Support, Add gpt-image-1-mini - <a href="https://github.com/BerriAI/litellm/pull/15259" target="_blank" rel="noopener noreferrer">PR #15259</a></li>
<li>Add gpt-realtime-mini support - <a href="https://github.com/BerriAI/litellm/pull/15283" target="_blank" rel="noopener noreferrer">PR #15283</a></li>
<li>Add gpt-5-pro-2025-10-06 to model costs - <a href="https://github.com/BerriAI/litellm/pull/15344" target="_blank" rel="noopener noreferrer">PR #15344</a></li>
<li>Minimal fix: gpt5 models should not go on cooldown when called with temperature!=1 - <a href="https://github.com/BerriAI/litellm/pull/15330" target="_blank" rel="noopener noreferrer">PR #15330</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/snowflake">Snowflake Cortex</a></strong></p>
<ul>
<li>Add function calling support for Snowflake Cortex REST API - <a href="https://github.com/BerriAI/litellm/pull/15221" target="_blank" rel="noopener noreferrer">PR #15221</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong></p>
<ul>
<li>Fix header forwarding for Gemini/Vertex AI providers in proxy mode - <a href="https://github.com/BerriAI/litellm/pull/15231" target="_blank" rel="noopener noreferrer">PR #15231</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong></p>
<ul>
<li>Removed stop param from unsupported azure models - <a href="https://github.com/BerriAI/litellm/pull/15229" target="_blank" rel="noopener noreferrer">PR #15229</a></li>
<li>Fix(azure/responses): remove invalid status param from azure call - <a href="https://github.com/BerriAI/litellm/pull/15253" target="_blank" rel="noopener noreferrer">PR #15253</a></li>
<li>Add new Azure AI models with pricing details - <a href="https://github.com/BerriAI/litellm/pull/15387" target="_blank" rel="noopener noreferrer">PR #15387</a></li>
<li>AzureAD Default credentials - select credential type based on environment - <a href="https://github.com/BerriAI/litellm/pull/14470" target="_blank" rel="noopener noreferrer">PR #14470</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong></p>
<ul>
<li>Add Global Cross-Region Inference - <a href="https://github.com/BerriAI/litellm/pull/15210" target="_blank" rel="noopener noreferrer">PR #15210</a></li>
<li>Add Cohere Embed v4 support for AWS Bedrock - <a href="https://github.com/BerriAI/litellm/pull/15298" target="_blank" rel="noopener noreferrer">PR #15298</a></li>
<li>Fix(bedrock): include cacheWriteInputTokens in prompt_tokens calculation - <a href="https://github.com/BerriAI/litellm/pull/15292" target="_blank" rel="noopener noreferrer">PR #15292</a></li>
<li>Add Bedrock AU Cross-Region Inference for Claude Sonnet 4.5 - <a href="https://github.com/BerriAI/litellm/pull/15402" target="_blank" rel="noopener noreferrer">PR #15402</a></li>
<li>Converse → /v1/messages streaming doesn't handle parallel tool calls with Claude models - <a href="https://github.com/BerriAI/litellm/pull/15315" target="_blank" rel="noopener noreferrer">PR #15315</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong></p>
<ul>
<li>Implement Context Caching for Vertex AI provider - <a href="https://github.com/BerriAI/litellm/pull/15226" target="_blank" rel="noopener noreferrer">PR #15226</a></li>
<li>Support for Vertex AI Gemma Models on Custom Endpoints - <a href="https://github.com/BerriAI/litellm/pull/15397" target="_blank" rel="noopener noreferrer">PR #15397</a></li>
<li>VertexAI - gemma model family support (custom endpoints) - <a href="https://github.com/BerriAI/litellm/pull/15419" target="_blank" rel="noopener noreferrer">PR #15419</a></li>
<li>VertexAI Gemma model family streaming support + Added MedGemma - <a href="https://github.com/BerriAI/litellm/pull/15427" target="_blank" rel="noopener noreferrer">PR #15427</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI</a></strong></p>
<ul>
<li>Add OCI Cohere support with tool calling and streaming capabilities - <a href="https://github.com/BerriAI/litellm/pull/15365" target="_blank" rel="noopener noreferrer">PR #15365</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/watsonx">Watson X</a></strong></p>
<ul>
<li>Add Watson X foundation model definitions to model_prices_and_context_window.json - <a href="https://github.com/BerriAI/litellm/pull/15219" target="_blank" rel="noopener noreferrer">PR #15219</a></li>
<li>Watsonx - Apply correct prompt templates for openai/gpt-oss model family - <a href="https://github.com/BerriAI/litellm/pull/15341" target="_blank" rel="noopener noreferrer">PR #15341</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong></p>
<ul>
<li>Fix - (openrouter): move cache_control to content blocks for claude/gemini - <a href="https://github.com/BerriAI/litellm/pull/15345" target="_blank" rel="noopener noreferrer">PR #15345</a></li>
<li>Fix - OpenRouter cache_control to only apply to last content block - <a href="https://github.com/BerriAI/litellm/pull/15395" target="_blank" rel="noopener noreferrer">PR #15395</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/togetherai">Together AI</a></strong></p>
<ul>
<li>Add new together models - <a href="https://github.com/BerriAI/litellm/pull/15383" target="_blank" rel="noopener noreferrer">PR #15383</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-78-0#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong>General</strong>
<ul>
<li>Bug fix: gpt-5-chat-latest has incorrect max_input_tokens value - <a href="https://github.com/BerriAI/litellm/pull/15116" target="_blank" rel="noopener noreferrer">PR #15116</a></li>
<li>Fix reasoning response ID - <a href="https://github.com/BerriAI/litellm/pull/15265" target="_blank" rel="noopener noreferrer">PR #15265</a></li>
<li>Fix issue with parsing assistant messages - <a href="https://github.com/BerriAI/litellm/pull/15320" target="_blank" rel="noopener noreferrer">PR #15320</a></li>
<li>Fix litellm_param based costing - <a href="https://github.com/BerriAI/litellm/pull/15336" target="_blank" rel="noopener noreferrer">PR #15336</a></li>
<li>Fix lint errors - <a href="https://github.com/BerriAI/litellm/pull/15406" target="_blank" rel="noopener noreferrer">PR #15406</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-78-0#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-78-0#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Added streaming support for response api streaming image generation - <a href="https://github.com/BerriAI/litellm/pull/15269" target="_blank" rel="noopener noreferrer">PR #15269</a></li>
<li>Add native Responses API support for litellm_proxy provider - <a href="https://github.com/BerriAI/litellm/pull/15347" target="_blank" rel="noopener noreferrer">PR #15347</a></li>
<li>Temporarily relax ResponsesAPIResponse parsing to support custom backends (e.g., vLLM) - <a href="https://github.com/BerriAI/litellm/pull/15362" target="_blank" rel="noopener noreferrer">PR #15362</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/files_api">Files API</a></strong></p>
<ul>
<li>Feat(files): add @client decorator to file operations - <a href="https://github.com/BerriAI/litellm/pull/15339" target="_blank" rel="noopener noreferrer">PR #15339</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">/generateContent</a></strong></p>
<ul>
<li>Fix gemini cli by actually streaming the response - <a href="https://github.com/BerriAI/litellm/pull/15264" target="_blank" rel="noopener noreferrer">PR #15264</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/pass_through/azure">Azure Passthrough</a></strong></p>
<ul>
<li>Azure - passthrough support with router models - <a href="https://github.com/BerriAI/litellm/pull/15240" target="_blank" rel="noopener noreferrer">PR #15240</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-78-0#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix x-litellm-cache-key header not being returned on cache hit - <a href="https://github.com/BerriAI/litellm/pull/15348" target="_blank" rel="noopener noreferrer">PR #15348</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-78-0#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-78-0#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Proxy CLI Auth</strong></p>
<ul>
<li>Proxy CLI - dont store existing key in the URL, store it in the state param - <a href="https://github.com/BerriAI/litellm/pull/15290" target="_blank" rel="noopener noreferrer">PR #15290</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Make PATCH <code>/model/{model_id}/update</code> handle <code>team_id</code> consistently with POST <code>/model/new</code> - <a href="https://github.com/BerriAI/litellm/pull/15297" target="_blank" rel="noopener noreferrer">PR #15297</a></li>
<li>Feature: adds Infinity as a provider in the UI - <a href="https://github.com/BerriAI/litellm/pull/15285" target="_blank" rel="noopener noreferrer">PR #15285</a></li>
<li>Fix: model + endpoints page crash when config file contains router_settings.model_group_alias - <a href="https://github.com/BerriAI/litellm/pull/15308" target="_blank" rel="noopener noreferrer">PR #15308</a></li>
<li>Models &amp; Endpoints Initial Refactor - <a href="https://github.com/BerriAI/litellm/pull/15435" target="_blank" rel="noopener noreferrer">PR #15435</a></li>
<li>Litellm UI API Reference page updates - <a href="https://github.com/BerriAI/litellm/pull/15438" target="_blank" rel="noopener noreferrer">PR #15438</a></li>
</ul>
</li>
<li>
<p><strong>Teams</strong></p>
<ul>
<li>Teams page: new column "Your Role" on the teams table - <a href="https://github.com/BerriAI/litellm/pull/15384" target="_blank" rel="noopener noreferrer">PR #15384</a></li>
<li>LiteLLM Dashboard Teams UI refactor - <a href="https://github.com/BerriAI/litellm/pull/15418" target="_blank" rel="noopener noreferrer">PR #15418</a></li>
</ul>
</li>
<li>
<p><strong>UI Infrastructure</strong></p>
<ul>
<li>Added prettier to autoformat frontend - <a href="https://github.com/BerriAI/litellm/pull/15215" target="_blank" rel="noopener noreferrer">PR #15215</a></li>
<li>Adds turbopack to the npm run dev command in UI to build faster during development - <a href="https://github.com/BerriAI/litellm/pull/15250" target="_blank" rel="noopener noreferrer">PR #15250</a></li>
<li>(perf) fix: Replaces bloated key list calls with lean key aliases endpoint - <a href="https://github.com/BerriAI/litellm/pull/15252" target="_blank" rel="noopener noreferrer">PR #15252</a></li>
<li>Potentially fixes a UI spasm issue with an expired cookie - <a href="https://github.com/BerriAI/litellm/pull/15309" target="_blank" rel="noopener noreferrer">PR #15309</a></li>
<li>LiteLLM UI Refactor Infrastructure - <a href="https://github.com/BerriAI/litellm/pull/15236" target="_blank" rel="noopener noreferrer">PR #15236</a></li>
<li>Enforces removal of unused imports from UI - <a href="https://github.com/BerriAI/litellm/pull/15416" target="_blank" rel="noopener noreferrer">PR #15416</a></li>
<li>Fix: usage page &gt;&gt; Model Activity &gt;&gt; spend per day graph: y-axis clipping on large spend values - <a href="https://github.com/BerriAI/litellm/pull/15389" target="_blank" rel="noopener noreferrer">PR #15389</a></li>
<li>Updates guardrail provider logos - <a href="https://github.com/BerriAI/litellm/pull/15421" target="_blank" rel="noopener noreferrer">PR #15421</a></li>
</ul>
</li>
<li>
<p><strong>Admin Settings</strong></p>
<ul>
<li>Fix: Router settings do not update despite success message - <a href="https://github.com/BerriAI/litellm/pull/15249" target="_blank" rel="noopener noreferrer">PR #15249</a></li>
<li>Fix: Prevents DB from accidentally overriding config file values if they are empty in DB - <a href="https://github.com/BerriAI/litellm/pull/15340" target="_blank" rel="noopener noreferrer">PR #15340</a></li>
</ul>
</li>
<li>
<p><strong>SSO</strong></p>
<ul>
<li>SSO - support EntraID app roles - <a href="https://github.com/BerriAI/litellm/pull/15351" target="_blank" rel="noopener noreferrer">PR #15351</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-78-0#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-78-0#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/observability/posthog">PostHog</a></strong>
<ul>
<li>Feat: posthog per request api key - <a href="https://github.com/BerriAI/litellm/pull/15379" target="_blank" rel="noopener noreferrer">PR #15379</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-78-0#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">EnkryptAI</a></strong>
<ul>
<li>Add EnkryptAI Guardrails on LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/15390" target="_blank" rel="noopener noreferrer">PR #15390</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-78-0#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Tag Management</strong></p>
<ul>
<li>Tag Management - Add support for setting tag based budgets - <a href="https://github.com/BerriAI/litellm/pull/15433" target="_blank" rel="noopener noreferrer">PR #15433</a></li>
</ul>
</li>
<li>
<p><strong>Dynamic Rate Limiter v3</strong></p>
<ul>
<li>QA/Fixes - Dynamic Rate Limiter v3 - final QA - <a href="https://github.com/BerriAI/litellm/pull/15311" target="_blank" rel="noopener noreferrer">PR #15311</a></li>
<li>Fix dynamic Rate limiter v3 - inserting litellm_model_saturation - <a href="https://github.com/BerriAI/litellm/pull/15394" target="_blank" rel="noopener noreferrer">PR #15394</a></li>
</ul>
</li>
<li>
<p><strong>Shared Health Check</strong></p>
<ul>
<li>Implement Shared Health Check State Across Pods - <a href="https://github.com/BerriAI/litellm/pull/15380" target="_blank" rel="noopener noreferrer">PR #15380</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-78-0#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Tool Control</strong></p>
<ul>
<li>MCP Gateway - UI - Select allowed tools for Key, Teams - <a href="https://github.com/BerriAI/litellm/pull/15241" target="_blank" rel="noopener noreferrer">PR #15241</a></li>
<li>MCP Gateway - Backend - Allow storing allowed tools by team/key - <a href="https://github.com/BerriAI/litellm/pull/15243" target="_blank" rel="noopener noreferrer">PR #15243</a></li>
<li>MCP Gateway - Fine-grained Database Object Storage Control - <a href="https://github.com/BerriAI/litellm/pull/15255" target="_blank" rel="noopener noreferrer">PR #15255</a></li>
<li>MCP Gateway - Litellm mcp fixes team control - <a href="https://github.com/BerriAI/litellm/pull/15304" target="_blank" rel="noopener noreferrer">PR #15304</a></li>
<li>MCP Gateway - QA/Fixes - Ensure Team/Key level enforcement works for MCPs - <a href="https://github.com/BerriAI/litellm/pull/15305" target="_blank" rel="noopener noreferrer">PR #15305</a></li>
<li>Feature: Include server_name in /v1/mcp/server/health endpoint response - <a href="https://github.com/BerriAI/litellm/pull/15431" target="_blank" rel="noopener noreferrer">PR #15431</a></li>
</ul>
</li>
<li>
<p><strong>OpenAPI Integration</strong></p>
<ul>
<li>MCP - support converting OpenAPI specs to MCP servers - <a href="https://github.com/BerriAI/litellm/pull/15343" target="_blank" rel="noopener noreferrer">PR #15343</a></li>
<li>MCP - specify allowed params per tool - <a href="https://github.com/BerriAI/litellm/pull/15346" target="_blank" rel="noopener noreferrer">PR #15346</a></li>
</ul>
</li>
<li>
<p><strong>Configuration</strong></p>
<ul>
<li>MCP - support setting CA_BUNDLE_PATH - <a href="https://github.com/BerriAI/litellm/pull/15253" target="_blank" rel="noopener noreferrer">PR #15253</a></li>
<li>Fix: Ensure MCP client stays open during tool call - <a href="https://github.com/BerriAI/litellm/pull/15391" target="_blank" rel="noopener noreferrer">PR #15391</a></li>
<li>Remove hardcoded "public" schema in migration.sql - <a href="https://github.com/BerriAI/litellm/pull/15363" target="_blank" rel="noopener noreferrer">PR #15363</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-78-0#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Router Optimizations</strong></p>
<ul>
<li>Fix - Router: add model_name index for O(1) deployment lookups - <a href="https://github.com/BerriAI/litellm/pull/15113" target="_blank" rel="noopener noreferrer">PR #15113</a></li>
<li>Refactor Utils: extract inner function from client - <a href="https://github.com/BerriAI/litellm/pull/15234" target="_blank" rel="noopener noreferrer">PR #15234</a></li>
<li>Fix Networking: remove limitations - <a href="https://github.com/BerriAI/litellm/pull/15302" target="_blank" rel="noopener noreferrer">PR #15302</a></li>
</ul>
</li>
<li>
<p><strong>Session Management</strong></p>
<ul>
<li>Fix - Sessions not being shared - <a href="https://github.com/BerriAI/litellm/pull/15388" target="_blank" rel="noopener noreferrer">PR #15388</a></li>
<li>Fix: remove panic from hot path - <a href="https://github.com/BerriAI/litellm/pull/15396" target="_blank" rel="noopener noreferrer">PR #15396</a></li>
<li>Fix - shared session parsing and usage issue - <a href="https://github.com/BerriAI/litellm/pull/15440" target="_blank" rel="noopener noreferrer">PR #15440</a></li>
<li>Fix: handle closed aiohttp sessions - <a href="https://github.com/BerriAI/litellm/pull/15442" target="_blank" rel="noopener noreferrer">PR #15442</a></li>
<li>Fix: prevent session leaks when recreating aiohttp sessions - <a href="https://github.com/BerriAI/litellm/pull/15443" target="_blank" rel="noopener noreferrer">PR #15443</a></li>
</ul>
</li>
<li>
<p><strong>SSL/TLS Performance</strong></p>
<ul>
<li>Perf: optimize SSL/TLS handshake performance with prioritized cipher - <a href="https://github.com/BerriAI/litellm/pull/15398" target="_blank" rel="noopener noreferrer">PR #15398</a></li>
</ul>
</li>
<li>
<p><strong>Dependencies</strong></p>
<ul>
<li>Upgrades tenacity version to 8.5.0 - <a href="https://github.com/BerriAI/litellm/pull/15303" target="_blank" rel="noopener noreferrer">PR #15303</a></li>
</ul>
</li>
<li>
<p><strong>Data Masking</strong></p>
<ul>
<li>Fix - SensitiveDataMasker converts lists to string - <a href="https://github.com/BerriAI/litellm/pull/15420" target="_blank" rel="noopener noreferrer">PR #15420</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-ai-gateway-improvements">General AI Gateway Improvements<a href="https://docs.litellm.ai/release_notes/v1-78-0#general-ai-gateway-improvements" class="hash-link" aria-label="General AI Gateway Improvements的直接链接" title="General AI Gateway Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="security">Security<a href="https://docs.litellm.ai/release_notes/v1-78-0#security" class="hash-link" aria-label="Security的直接链接" title="Security的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix: redact AWS credentials when redact_user_api_key_info enabled - <a href="https://github.com/BerriAI/litellm/pull/15321" target="_blank" rel="noopener noreferrer">PR #15321</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-78-0#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Provider Documentation</strong></p>
<ul>
<li>Update doc: perf update - <a href="https://github.com/BerriAI/litellm/pull/15211" target="_blank" rel="noopener noreferrer">PR #15211</a></li>
<li>Add W&amp;B Inference documentation - <a href="https://github.com/BerriAI/litellm/pull/15278" target="_blank" rel="noopener noreferrer">PR #15278</a></li>
</ul>
</li>
<li>
<p><strong>Deployment</strong></p>
<ul>
<li>Deletion of docker-compose buggy comment that cause <code>config.yaml</code> based startup fail - <a href="https://github.com/BerriAI/litellm/pull/15425" target="_blank" rel="noopener noreferrer">PR #15425</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-78-0#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@Gal-bloch made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15219" target="_blank" rel="noopener noreferrer">PR #15219</a></li>
<li>@lcfyi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15315" target="_blank" rel="noopener noreferrer">PR #15315</a></li>
<li>@ashengstd made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15362" target="_blank" rel="noopener noreferrer">PR #15362</a></li>
<li>@vkolehmainen made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15363" target="_blank" rel="noopener noreferrer">PR #15363</a></li>
<li>@jlan-nl made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15330" target="_blank" rel="noopener noreferrer">PR #15330</a></li>
<li>@BCook98 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15402" target="_blank" rel="noopener noreferrer">PR #15402</a></li>
<li>@PabloGmz96 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15425" target="_blank" rel="noopener noreferrer">PR #15425</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.77.7.rc.1...v1.78.0.rc.1" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-78-0#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.77.7-stable - 2.9x Lower Median Latency]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-77-7</link>
            <guid>https://docs.litellm.ai/release_notes/v1-77-7</guid>
            <pubDate>Sat, 04 Oct 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-77-7#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.77.7.rc.1</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.77.7.rc.1</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-77-7#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Dynamic Rate Limiter v3</strong> - Automatically maximizes throughput when capacity is available (&lt; 80% saturation) by allowing lower-priority requests to use unused capacity, then switches to fair priority-based allocation under high load (≥ 80%) to prevent blocking</li>
<li><strong>Major Performance Improvements</strong> - 2.9x lower median latency at 1,000 concurrent users.</li>
<li><strong>Claude Sonnet 4.5</strong> - Support for Anthropic's new Claude Sonnet 4.5 model family with 200K+ context and tiered pricing</li>
<li><strong>MCP Gateway Enhancements</strong> - Fine-grained tool control, server permissions, and forwardable headers</li>
<li><strong>AMD Lemonade &amp; Nvidia NIM</strong> - New provider support for AMD Lemonade and Nvidia NIM Rerank</li>
<li><strong>GitLab Prompt Management</strong> - GitLab-based prompt management integration</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance---29x-lower-median-latency">Performance - 2.9x Lower Median Latency<a href="https://docs.litellm.ai/release_notes/v1-77-7#performance---29x-lower-median-latency" class="hash-link" aria-label="Performance - 2.9x Lower Median Latency的直接链接" title="Performance - 2.9x Lower Median Latency的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAICAYAAADA+m62AAAACXBIWXMAACxLAAAsSwGlPZapAAAA50lEQVR4nEVQTWuEMBD1hxUWvGz9G/6dQtljf0QPhb13L7X1JD2vF1GikdWQRTQxib4yU0ohE97MvHnzEVlrIYRA13Vo2xZN06Cua8ZCCGitEUJARMRhGDCOI6qqQlmWuJZX9tWoME0TvPeI6HPOQd81HGMP735j67oyiXC0LAucdzg9n3B4OCBJEhwfj4jjGGmagvKsSFXWWHx953i7nPGRZ3jPL8g+MxRFwaqsaFYDezd4rc94ki8IewB2eju2bftv/TfLbbihlS2klLx53/eMlVKcZyKZpwJreSY6yTzPMMaArkKKP4pcI8ne+ugVAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="488"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/perf_77_7.683a8b8.640.png" srcset="/assets/ideal-img/perf_77_7.683a8b8.640.png 640w,/assets/ideal-img/perf_77_7.4719f17.1920.png 1920w" width="640" height="488"></noscript></div>
<br>
<p>This update removes LiteLLM router inefficiencies, reducing complexity from O(M×N) to O(1). Previously, it built a new array and ran repeated checks like data["model"] in llm_router.get_model_ids(). Now, a direct ID-to-deployment map eliminates redundant allocations and scans.</p>
<p>As a result, performance improved across all latency percentiles:</p>
<ul>
<li><strong>Median latency:</strong> 320 ms → <strong>110 ms</strong> (−65.6%)</li>
<li><strong>p95 latency:</strong> 850 ms → <strong>440 ms</strong> (−48.2%)</li>
<li><strong>p99 latency:</strong> 1,400 ms → <strong>810 ms</strong> (−42.1%)</li>
<li><strong>Average latency:</strong> 864 ms → <strong>310 ms</strong> (−64%)</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="https://docs.litellm.ai/release_notes/v1-77-7#test-setup" class="hash-link" aria-label="Test Setup的直接链接" title="Test Setup的直接链接">​</a></h4>
<p><strong>Locust</strong></p>
<ul>
<li><strong>Concurrent users:</strong> 1,000</li>
<li><strong>Ramp-up:</strong> 500</li>
</ul>
<p><strong>System Specs</strong></p>
<ul>
<li><strong>CPU:</strong> 4 vCPUs</li>
<li><strong>Memory:</strong> 8 GB RAM</li>
<li><strong>LiteLLM Workers:</strong> 4</li>
<li><strong>Instances</strong>: 4</li>
</ul>
<p><strong>Configuration (config.yaml)</strong></p>
<p>View the complete configuration: <a href="https://gist.github.com/AlexsanderHamir/53f7d554a5d2afcf2c4edb5b6be68ff4" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/config.yaml</a></p>
<p><strong>Load Script (no_cache_hits.py)</strong></p>
<p>View the complete load testing script: <a href="https://gist.github.com/AlexsanderHamir/42c33d7a4dc7a57f56a78b560dee3a42" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/no_cache_hits.py</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-oauth-20-support">MCP OAuth 2.0 Support<a href="https://docs.litellm.ai/release_notes/v1-77-7#mcp-oauth-20-support" class="hash-link" aria-label="MCP OAuth 2.0 Support的直接链接" title="MCP OAuth 2.0 Support的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAFAAoDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAQI/8QAHhAAAQQCAwEAAAAAAAAAAAAAAQACAwQRMSEjQWH/xAAVAQEBAAAAAAAAAAAAAAAAAAACBf/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AM4i50ztlr15ZZCXGZ7SXgkec4+62oiMEhEVUX//2Q==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/mcp_updates.17fe936.640.jpg" srcset="/assets/ideal-img/mcp_updates.17fe936.640.jpg 640w,/assets/ideal-img/mcp_updates.6af33b8.1920.jpg 1920w" width="640" height="334"></noscript></div>
<br>
<p>This release adds support for OAuth 2.0 Client Credentials for MCP servers. This is great for <strong>Internal Dev Tools</strong> use-cases, as it enables your users to call MCP servers, with their own credentials. E.g. Allowing your developers to call the Github MCP, with their own credentials.</p>
<p><a href="https://docs.litellm.ai/docs/tutorials/claude_responses_api#connecting-mcp-servers">Set it up today on Claude Code</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scheduled-key-rotations">Scheduled Key Rotations<a href="https://docs.litellm.ai/release_notes/v1-77-7#scheduled-key-rotations" class="hash-link" aria-label="Scheduled Key Rotations的直接链接" title="Scheduled Key Rotations的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAe0lEQVR4nD3OSw7DIAwEUO5/xC6yRURFoQ0E/2AqE6WL2Yyexg4pJez7DiICM6O2BmYBi4CIBwDvXyHnjBgjSikL19bRO0PVIKILqtoWVBVmXspKrQRiwZzTzYJmtgU/92TBduH9OXBeDar34oLPkkfl/u17VkcYY/zhD7F8wqEMj8vpAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="331"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/schedule_key_rotations.6a2e4cd.640.png" srcset="/assets/ideal-img/schedule_key_rotations.6a2e4cd.640.png 640w,/assets/ideal-img/schedule_key_rotations.8f24277.1920.png 1920w" width="640" height="331"></noscript></div>
<br>
<p>This release brings support for scheduling virtual key rotations on LiteLLM AI Gateway.</p>
<p>From this release you can enforce Virtual Keys to rotate on a schedule of your choice e.g every 15 days/30 days/60 days etc.</p>
<p>This is great for Proxy Admins who need to enforce security policies for production workloads.</p>
<p><a href="https://docs.litellm.ai/docs/proxy/virtual_keys#scheduled-key-rotations">Get Started</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-77-7#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-77-7#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Anthropic</td><td><code>claude-sonnet-4-5</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Anthropic</td><td><code>claude-sonnet-4-5-20250929</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Bedrock</td><td><code>eu.anthropic.claude-sonnet-4-5-20250929-v1:0</code></td><td>200K</td><td>$3.00</td><td>$15.00</td><td>Chat, reasoning, vision, function calling, prompt caching</td></tr><tr><td>Azure AI</td><td><code>azure_ai/grok-4</code></td><td>131K</td><td>$5.50</td><td>$27.50</td><td>Chat, reasoning, function calling, web search</td></tr><tr><td>Azure AI</td><td><code>azure_ai/grok-4-fast-reasoning</code></td><td>131K</td><td>$0.43</td><td>$1.73</td><td>Chat, reasoning, function calling, web search</td></tr><tr><td>Azure AI</td><td><code>azure_ai/grok-4-fast-non-reasoning</code></td><td>131K</td><td>$0.43</td><td>$1.73</td><td>Chat, function calling, web search</td></tr><tr><td>Azure AI</td><td><code>azure_ai/grok-code-fast-1</code></td><td>131K</td><td>$3.50</td><td>$17.50</td><td>Chat, function calling, web search</td></tr><tr><td>Groq</td><td><code>groq/moonshotai/kimi-k2-instruct-0905</code></td><td>Context varies</td><td>Pricing varies</td><td>Pricing varies</td><td>Chat, function calling</td></tr><tr><td>Ollama</td><td>Ollama Cloud models</td><td>Varies</td><td>Free</td><td>Free</td><td>Self-hosted models via Ollama Cloud</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-77-7#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Add new claude-sonnet-4-5 model family with tiered pricing above 200K tokens - <a href="https://github.com/BerriAI/litellm/pull/15041" target="_blank" rel="noopener noreferrer">PR #15041</a></li>
<li>Add anthropic/claude-sonnet-4-5 to model price json with prompt caching support - <a href="https://github.com/BerriAI/litellm/pull/15049" target="_blank" rel="noopener noreferrer">PR #15049</a></li>
<li>Add 200K prices for Sonnet 4.5 - <a href="https://github.com/BerriAI/litellm/pull/15140" target="_blank" rel="noopener noreferrer">PR #15140</a></li>
<li>Add cost tracking for /v1/messages in streaming response - <a href="https://github.com/BerriAI/litellm/pull/15102" target="_blank" rel="noopener noreferrer">PR #15102</a></li>
<li>Add /v1/messages/count_tokens to Anthropic routes for non-admin user access - <a href="https://github.com/BerriAI/litellm/pull/15034" target="_blank" rel="noopener noreferrer">PR #15034</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Ignore type param for gemini tools - <a href="https://github.com/BerriAI/litellm/pull/15022" target="_blank" rel="noopener noreferrer">PR #15022</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Add LiteLLM Overhead metric for VertexAI - <a href="https://github.com/BerriAI/litellm/pull/15040" target="_blank" rel="noopener noreferrer">PR #15040</a></li>
<li>Support googlemap grounding in vertex ai - <a href="https://github.com/BerriAI/litellm/pull/15179" target="_blank" rel="noopener noreferrer">PR #15179</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong>
<ul>
<li>Add azure_ai grok-4 model family - <a href="https://github.com/BerriAI/litellm/pull/15137" target="_blank" rel="noopener noreferrer">PR #15137</a></li>
<li>Use the <code>extra_query</code> parameter for GET requests in Azure Batch - <a href="https://github.com/BerriAI/litellm/pull/14997" target="_blank" rel="noopener noreferrer">PR #14997</a></li>
<li>Use extra_query for download results (Batch API) - <a href="https://github.com/BerriAI/litellm/pull/15025" target="_blank" rel="noopener noreferrer">PR #15025</a></li>
<li>Add support for Azure AD token-based authorization - <a href="https://github.com/BerriAI/litellm/pull/14813" target="_blank" rel="noopener noreferrer">PR #14813</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong>
<ul>
<li>Add ollama cloud models - <a href="https://github.com/BerriAI/litellm/pull/15008" target="_blank" rel="noopener noreferrer">PR #15008</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/groq">Groq</a></strong>
<ul>
<li>Add groq/moonshotai/kimi-k2-instruct-0905 - <a href="https://github.com/BerriAI/litellm/pull/15079" target="_blank" rel="noopener noreferrer">PR #15079</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Add support for GPT 5 codex models - <a href="https://github.com/BerriAI/litellm/pull/14841" target="_blank" rel="noopener noreferrer">PR #14841</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/deepinfra">DeepInfra</a></strong>
<ul>
<li>Update DeepInfra model data refresh with latest pricing - <a href="https://github.com/BerriAI/litellm/pull/14939" target="_blank" rel="noopener noreferrer">PR #14939</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Add JP Cross-Region Inference - <a href="https://github.com/BerriAI/litellm/pull/15188" target="_blank" rel="noopener noreferrer">PR #15188</a></li>
<li>Add "eu.anthropic.claude-sonnet-4-5-20250929-v1:0" - <a href="https://github.com/BerriAI/litellm/pull/15181" target="_blank" rel="noopener noreferrer">PR #15181</a></li>
<li>Add twelvelabs bedrock Async Invoke Support - <a href="https://github.com/BerriAI/litellm/pull/14871" target="_blank" rel="noopener noreferrer">PR #14871</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/nvidia_nim">Nvidia NIM</a></strong>
<ul>
<li>Add Nvidia NIM Rerank Support - <a href="https://github.com/BerriAI/litellm/pull/15152" target="_blank" rel="noopener noreferrer">PR #15152</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-7#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong>
<ul>
<li>Fix response_format bug in hosted vllm audio_transcription - <a href="https://github.com/BerriAI/litellm/pull/15010" target="_blank" rel="noopener noreferrer">PR #15010</a></li>
<li>Fix passthrough of atranscription into kwargs going to upstream provider - <a href="https://github.com/BerriAI/litellm/pull/15005" target="_blank" rel="noopener noreferrer">PR #15005</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI</a></strong>
<ul>
<li>Fix OCI Generative AI Integration when using Proxy - <a href="https://github.com/BerriAI/litellm/pull/15072" target="_blank" rel="noopener noreferrer">PR #15072</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Fix: Authorization header to use correct "Bearer" capitalization - <a href="https://github.com/BerriAI/litellm/pull/14764" target="_blank" rel="noopener noreferrer">PR #14764</a></li>
<li>Bug fix: gpt-5-chat-latest has incorrect max_input_tokens value - <a href="https://github.com/BerriAI/litellm/pull/15116" target="_blank" rel="noopener noreferrer">PR #15116</a></li>
<li>Update request handling for original exceptions - <a href="https://github.com/BerriAI/litellm/pull/15013" target="_blank" rel="noopener noreferrer">PR #15013</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-77-7#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/lemonade">AMD Lemonade</a></strong>
<ul>
<li>Add AMD Lemonade provider support - <a href="https://github.com/BerriAI/litellm/pull/14840" target="_blank" rel="noopener noreferrer">PR #14840</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-77-7#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-77-7#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong></p>
<ul>
<li>Return Cost for Responses API Streaming requests - <a href="https://github.com/BerriAI/litellm/pull/15053" target="_blank" rel="noopener noreferrer">PR #15053</a></li>
</ul>
</li>
<li>
<p><strong><a href="https://docs.litellm.ai/docs/providers/gemini">/generateContent</a></strong></p>
<ul>
<li>Add full support for native Gemini API translation - <a href="https://github.com/BerriAI/litellm/pull/15029" target="_blank" rel="noopener noreferrer">PR #15029</a></li>
</ul>
</li>
<li>
<p><strong>Passthrough Gemini Routes</strong></p>
<ul>
<li>Add Gemini generateContent passthrough cost tracking - <a href="https://github.com/BerriAI/litellm/pull/15014" target="_blank" rel="noopener noreferrer">PR #15014</a></li>
<li>Add streamGenerateContent cost tracking in passthrough - <a href="https://github.com/BerriAI/litellm/pull/15199" target="_blank" rel="noopener noreferrer">PR #15199</a></li>
</ul>
</li>
<li>
<p><strong>Passthrough Vertex AI Routes</strong></p>
<ul>
<li>Add cost tracking for Vertex AI Passthrough <code>/predict</code> endpoint - <a href="https://github.com/BerriAI/litellm/pull/15019" target="_blank" rel="noopener noreferrer">PR #15019</a></li>
<li>Add cost tracking for Vertex AI Live API WebSocket Passthrough - <a href="https://github.com/BerriAI/litellm/pull/14956" target="_blank" rel="noopener noreferrer">PR #14956</a></li>
</ul>
</li>
<li>
<p><strong>General</strong></p>
<ul>
<li>Preserve Whitespace Characters in Model Response Streams - <a href="https://github.com/BerriAI/litellm/pull/15160" target="_blank" rel="noopener noreferrer">PR #15160</a></li>
<li>Add provider name to payload specification - <a href="https://github.com/BerriAI/litellm/pull/15130" target="_blank" rel="noopener noreferrer">PR #15130</a></li>
<li>Ensure query params are forwarded from origin url to downstream request - <a href="https://github.com/BerriAI/litellm/pull/15087" target="_blank" rel="noopener noreferrer">PR #15087</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-77-7#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-77-7#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Ensure LLM_API_KEYs can access pass through routes - <a href="https://github.com/BerriAI/litellm/pull/15115" target="_blank" rel="noopener noreferrer">PR #15115</a></li>
<li>Support 'guaranteed_throughput' when setting limits on keys belonging to a team - <a href="https://github.com/BerriAI/litellm/pull/15120" target="_blank" rel="noopener noreferrer">PR #15120</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Ensure OCI secret fields not shared on /models and /v1/models endpoints - <a href="https://github.com/BerriAI/litellm/pull/15085" target="_blank" rel="noopener noreferrer">PR #15085</a></li>
<li>Add snowflake on UI - <a href="https://github.com/BerriAI/litellm/pull/15083" target="_blank" rel="noopener noreferrer">PR #15083</a></li>
<li>Make UI theme settings publicly accessible for custom branding - <a href="https://github.com/BerriAI/litellm/pull/15074" target="_blank" rel="noopener noreferrer">PR #15074</a></li>
</ul>
</li>
<li>
<p><strong>Admin Settings</strong></p>
<ul>
<li>Ensure OTEL settings are saved in DB after set on UI - <a href="https://github.com/BerriAI/litellm/pull/15118" target="_blank" rel="noopener noreferrer">PR #15118</a></li>
<li>Top api key tags - <a href="https://github.com/BerriAI/litellm/pull/15151" target="_blank" rel="noopener noreferrer">PR #15151</a>, <a href="https://github.com/BerriAI/litellm/pull/15156" target="_blank" rel="noopener noreferrer">PR #15156</a></li>
</ul>
</li>
<li>
<p><strong>MCP</strong></p>
<ul>
<li>show health status of MCP servers - <a href="https://github.com/BerriAI/litellm/pull/15185" target="_blank" rel="noopener noreferrer">PR #15185</a></li>
<li>allow setting extra headers on the UI - <a href="https://github.com/BerriAI/litellm/pull/15185" target="_blank" rel="noopener noreferrer">PR #15185</a></li>
<li>allow editing allowed tools on the UI - <a href="https://github.com/BerriAI/litellm/pull/15185" target="_blank" rel="noopener noreferrer">PR #15185</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-1">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-7#bug-fixes-1" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>(security) prevent user key from updating other user keys - <a href="https://github.com/BerriAI/litellm/pull/15201" target="_blank" rel="noopener noreferrer">PR #15201</a></li>
<li>(security) don't return all keys with blank key alias on /v2/key/info - <a href="https://github.com/BerriAI/litellm/pull/15201" target="_blank" rel="noopener noreferrer">PR #15201</a></li>
<li>Fix Session Token Cookie Infinite Logout Loop - <a href="https://github.com/BerriAI/litellm/pull/15146" target="_blank" rel="noopener noreferrer">PR #15146</a></li>
</ul>
</li>
<li>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Make UI theme settings publicly accessible for custom branding - <a href="https://github.com/BerriAI/litellm/pull/15074" target="_blank" rel="noopener noreferrer">PR #15074</a></li>
</ul>
</li>
<li>
<p><strong>Teams</strong></p>
<ul>
<li>fix failed copy to clipboard for http ui - <a href="https://github.com/BerriAI/litellm/pull/15195" target="_blank" rel="noopener noreferrer">PR #15195</a></li>
</ul>
</li>
<li>
<p><strong>Logs</strong></p>
<ul>
<li>fix logs page render logs on filter lookup - <a href="https://github.com/BerriAI/litellm/pull/15195" target="_blank" rel="noopener noreferrer">PR #15195</a></li>
<li>fix lookup list of end users (migrate to more efficient /customers/list lookup) - <a href="https://github.com/BerriAI/litellm/pull/15195" target="_blank" rel="noopener noreferrer">PR #15195</a></li>
</ul>
</li>
<li>
<p><strong>Test key</strong></p>
<ul>
<li>update selected model on key change - <a href="https://github.com/BerriAI/litellm/pull/15197" target="_blank" rel="noopener noreferrer">PR #15197</a></li>
</ul>
</li>
<li>
<p><strong>Dashboard</strong></p>
<ul>
<li>Fix LiteLLM model name fallback in dashboard overview - <a href="https://github.com/BerriAI/litellm/pull/14998" target="_blank" rel="noopener noreferrer">PR #14998</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-77-7#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-77-7#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/observability/otel">OpenTelemetry</a></strong>
<ul>
<li>Use generation_name for span naming in logging method - <a href="https://github.com/BerriAI/litellm/pull/14799" target="_blank" rel="noopener noreferrer">PR #14799</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong>
<ul>
<li>Handle non-serializable objects in Langfuse logging - <a href="https://github.com/BerriAI/litellm/pull/15148" target="_blank" rel="noopener noreferrer">PR #15148</a></li>
<li>Set usage_details.total in langfuse integration - <a href="https://github.com/BerriAI/litellm/pull/15015" target="_blank" rel="noopener noreferrer">PR #15015</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/prometheus">Prometheus</a></strong>
<ul>
<li>support custom metadata labels on key/team - <a href="https://github.com/BerriAI/litellm/pull/15094" target="_blank" rel="noopener noreferrer">PR #15094</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-77-7#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Javelin</a></strong>
<ul>
<li>Add Javelin standalone guardrails integration for LiteLLM Proxy - <a href="https://github.com/BerriAI/litellm/pull/14983" target="_blank" rel="noopener noreferrer">PR #14983</a></li>
<li>Add logging for important status fields in guardrails - <a href="https://github.com/BerriAI/litellm/pull/15090" target="_blank" rel="noopener noreferrer">PR #15090</a></li>
<li>Don't run post_call guardrail if no text returned from Bedrock - <a href="https://github.com/BerriAI/litellm/pull/15106" target="_blank" rel="noopener noreferrer">PR #15106</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-77-7#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/prompt_management">GitLab</a></strong>
<ul>
<li>GitLab based Prompt manager - <a href="https://github.com/BerriAI/litellm/pull/14988" target="_blank" rel="noopener noreferrer">PR #14988</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-77-7#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Cost Tracking</strong>
<ul>
<li>Proxy: end user cost tracking in the responses API - <a href="https://github.com/BerriAI/litellm/pull/15124" target="_blank" rel="noopener noreferrer">PR #15124</a></li>
</ul>
</li>
<li><strong>Parallel Request Limiter v3</strong>
<ul>
<li>Use well known redis cluster hashing algorithm - <a href="https://github.com/BerriAI/litellm/pull/15052" target="_blank" rel="noopener noreferrer">PR #15052</a></li>
<li>Fixes to dynamic rate limiter v3 - add saturation detection - <a href="https://github.com/BerriAI/litellm/pull/15119" target="_blank" rel="noopener noreferrer">PR #15119</a></li>
<li>Dynamic Rate Limiter v3 - fixes for detecting saturation + fixes for post saturation behavior - <a href="https://github.com/BerriAI/litellm/pull/15192" target="_blank" rel="noopener noreferrer">PR #15192</a></li>
</ul>
</li>
<li><strong>Teams</strong>
<ul>
<li>Add model specific tpm/rpm limits to teams on LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/15044" target="_blank" rel="noopener noreferrer">PR #15044</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-77-7#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>Server Configuration</strong>
<ul>
<li>Specify forwardable headers, specify allowed/disallowed tools for MCP servers - <a href="https://github.com/BerriAI/litellm/pull/15002" target="_blank" rel="noopener noreferrer">PR #15002</a></li>
<li>Enforce server permissions on call tools - <a href="https://github.com/BerriAI/litellm/pull/15044" target="_blank" rel="noopener noreferrer">PR #15044</a></li>
<li>MCP Gateway Fine-grained Tools Addition - <a href="https://github.com/BerriAI/litellm/pull/15153" target="_blank" rel="noopener noreferrer">PR #15153</a></li>
</ul>
</li>
<li><strong>Bug Fixes</strong>
<ul>
<li>Remove servername prefix mcp tools tests - <a href="https://github.com/BerriAI/litellm/pull/14986" target="_blank" rel="noopener noreferrer">PR #14986</a></li>
<li>Resolve regression with duplicate Mcp-Protocol-Version header - <a href="https://github.com/BerriAI/litellm/pull/15050" target="_blank" rel="noopener noreferrer">PR #15050</a></li>
<li>Fix test_mcp_server.py - <a href="https://github.com/BerriAI/litellm/pull/15183" target="_blank" rel="noopener noreferrer">PR #15183</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-77-7#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>Router Optimizations</strong>
<ul>
<li><strong>+62.5% P99 Latency Improvement</strong> - Remove router inefficiencies (from O(M*N) to O(1)) - <a href="https://github.com/BerriAI/litellm/pull/15046" target="_blank" rel="noopener noreferrer">PR #15046</a></li>
<li>Remove hasattr checks in Router - <a href="https://github.com/BerriAI/litellm/pull/15082" target="_blank" rel="noopener noreferrer">PR #15082</a></li>
<li>Remove Double Lookups - <a href="https://github.com/BerriAI/litellm/pull/15084" target="_blank" rel="noopener noreferrer">PR #15084</a></li>
<li>Optimize _filter_cooldown_deployments from O(n×m + k×n) to O(n) - <a href="https://github.com/BerriAI/litellm/pull/15091" target="_blank" rel="noopener noreferrer">PR #15091</a></li>
<li>Optimize unhealthy deployment filtering in retry path (O(n*m) → O(n+m)) - <a href="https://github.com/BerriAI/litellm/pull/15110" target="_blank" rel="noopener noreferrer">PR #15110</a></li>
</ul>
</li>
<li><strong>Cache Optimizations</strong>
<ul>
<li>Reduce complexity of InMemoryCache.evict_cache from O(n*log(n)) to O(log(n)) - <a href="https://github.com/BerriAI/litellm/pull/15000" target="_blank" rel="noopener noreferrer">PR #15000</a></li>
<li>Avoiding expensive operations when cache isn't available - <a href="https://github.com/BerriAI/litellm/pull/15182" target="_blank" rel="noopener noreferrer">PR #15182</a></li>
</ul>
</li>
<li><strong>Worker Management</strong>
<ul>
<li>Add proxy CLI option to recycle workers after N requests - <a href="https://github.com/BerriAI/litellm/pull/15007" target="_blank" rel="noopener noreferrer">PR #15007</a></li>
</ul>
</li>
<li><strong>Metrics &amp; Monitoring</strong>
<ul>
<li>LiteLLM Overhead metric tracking - Add support for tracking litellm overhead on cache hits - <a href="https://github.com/BerriAI/litellm/pull/15045" target="_blank" rel="noopener noreferrer">PR #15045</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-77-7#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li><strong>Provider Documentation</strong>
<ul>
<li>Update litellm docs from latest release - <a href="https://github.com/BerriAI/litellm/pull/15004" target="_blank" rel="noopener noreferrer">PR #15004</a></li>
<li>Add missing api_key parameter - <a href="https://github.com/BerriAI/litellm/pull/15058" target="_blank" rel="noopener noreferrer">PR #15058</a></li>
</ul>
</li>
<li><strong>General Documentation</strong>
<ul>
<li>Use docker compose instead of docker-compose - <a href="https://github.com/BerriAI/litellm/pull/15024" target="_blank" rel="noopener noreferrer">PR #15024</a></li>
<li>Add railtracks to projects that are using litellm - <a href="https://github.com/BerriAI/litellm/pull/15144" target="_blank" rel="noopener noreferrer">PR #15144</a></li>
<li>Perf: Last week improvement - <a href="https://github.com/BerriAI/litellm/pull/15193" target="_blank" rel="noopener noreferrer">PR #15193</a></li>
<li>Sync models GitHub documentation with Loom video and cross-reference - <a href="https://github.com/BerriAI/litellm/pull/15191" target="_blank" rel="noopener noreferrer">PR #15191</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="security-fixes">Security Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-7#security-fixes" class="hash-link" aria-label="Security Fixes的直接链接" title="Security Fixes的直接链接">​</a></h2>
<ul>
<li><strong>JWT Token Security</strong> - Don't log JWT SSO token on .info() log - <a href="https://github.com/BerriAI/litellm/pull/15145" target="_blank" rel="noopener noreferrer">PR #15145</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-77-7#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@herve-ves made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14998" target="_blank" rel="noopener noreferrer">PR #14998</a></li>
<li>@wenxi-onyx made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15008" target="_blank" rel="noopener noreferrer">PR #15008</a></li>
<li>@jpetrucciani made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15005" target="_blank" rel="noopener noreferrer">PR #15005</a></li>
<li>@abhijitjavelin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14983" target="_blank" rel="noopener noreferrer">PR #14983</a></li>
<li>@ZeroClover made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15039" target="_blank" rel="noopener noreferrer">PR #15039</a></li>
<li>@cedarm made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15043" target="_blank" rel="noopener noreferrer">PR #15043</a></li>
<li>@Isydmr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15025" target="_blank" rel="noopener noreferrer">PR #15025</a></li>
<li>@serializer made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15013" target="_blank" rel="noopener noreferrer">PR #15013</a></li>
<li>@eddierichter-amd made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14840" target="_blank" rel="noopener noreferrer">PR #14840</a></li>
<li>@malags made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15000" target="_blank" rel="noopener noreferrer">PR #15000</a></li>
<li>@henryhwang made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15029" target="_blank" rel="noopener noreferrer">PR #15029</a></li>
<li>@plafleur made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15111" target="_blank" rel="noopener noreferrer">PR #15111</a></li>
<li>@tyler-liner made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14799" target="_blank" rel="noopener noreferrer">PR #14799</a></li>
<li>@Amir-R25 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15144" target="_blank" rel="noopener noreferrer">PR #15144</a></li>
<li>@georg-wolflein made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15124" target="_blank" rel="noopener noreferrer">PR #15124</a></li>
<li>@niharm made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15140" target="_blank" rel="noopener noreferrer">PR #15140</a></li>
<li>@anthony-liner made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15015" target="_blank" rel="noopener noreferrer">PR #15015</a></li>
<li>@rishiganesh2002 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15153" target="_blank" rel="noopener noreferrer">PR #15153</a></li>
<li>@danielaskdd made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15160" target="_blank" rel="noopener noreferrer">PR #15160</a></li>
<li>@JVenberg made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15146" target="_blank" rel="noopener noreferrer">PR #15146</a></li>
<li>@speglich made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/15072" target="_blank" rel="noopener noreferrer">PR #15072</a></li>
<li>@daily-kim made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14764" target="_blank" rel="noopener noreferrer">PR #14764</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.77.5.rc.4...v1.77.7.rc.1" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-77-7#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.77.5-stable - MCP OAuth 2.0 Support]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-77-5</link>
            <guid>https://docs.litellm.ai/release_notes/v1-77-5</guid>
            <pubDate>Mon, 29 Sep 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-77-5#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.77.5-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.77.5</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-77-5#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>MCP OAuth 2.0 Support</strong> - Enhanced authentication for Model Context Protocol integrations</li>
<li><strong>Scheduled Key Rotations</strong> - Automated key rotation capabilities for enhanced security</li>
<li><strong>New Gemini 2.5 Flash &amp; Flash-lite Models</strong> - Latest September 2025 preview models with improved pricing and features</li>
<li><strong>Performance Improvements</strong> - 54% RPS improvement</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-improvements---54-rps-improvement">Performance Improvements - 54% RPS Improvement<a href="https://docs.litellm.ai/release_notes/v1-77-5#performance-improvements---54-rps-improvement" class="hash-link" aria-label="Performance Improvements - 54% RPS Improvement的直接链接" title="Performance Improvements - 54% RPS Improvement的直接链接">​</a></h3>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAtklEQVR4nB3GwWrCQBAG4H18oWgreFQEESriEwiKevVcWnuoBmMS426ISdZkJuP8peW7fCYM7xzHKbvMsi89owX7xnPe5P//U1PNxtoClyiCSy0Sl2CWLTB0E4zdFCM7wc/jBAhguCV9ylMr9tqLB7rOtupKp7nP9aP41E70ql/VQU3DBCjwHsyxTFcAAWFwRnxLUFYFgscZL99vMEQkTCzdfV+uRSrCItSSMLPUVIu2KpvjTn4BwG23kvGvqE0AAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="332"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/perf_77_5.b2137ff.640.png" srcset="/assets/ideal-img/perf_77_5.b2137ff.640.png 640w,/assets/ideal-img/perf_77_5.26432f4.1920.png 1920w" width="640" height="332"></noscript></div>
<br>
<p>This release brings a 54% RPS improvement (1,040 → 1,602 RPS, aggregated) per instance.</p>
<p>The improvement comes from fixing O(n²) inefficiencies in the LiteLLM Router, primarily caused by repeated use of <code>in</code> statements inside loops over large arrays.</p>
<p>Tests were run with a database-only setup (no cache hits).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="https://docs.litellm.ai/release_notes/v1-77-5#test-setup" class="hash-link" aria-label="Test Setup的直接链接" title="Test Setup的直接链接">​</a></h4>
<p>All benchmarks were executed using Locust with 1,000 concurrent users and a ramp-up of 500. The environment was configured to stress the routing layer and eliminate caching as a variable.</p>
<p><strong>System Specs</strong></p>
<ul>
<li><strong>CPU:</strong> 8 vCPUs</li>
<li><strong>Memory:</strong> 32 GB RAM</li>
</ul>
<p><strong>Configuration (config.yaml)</strong></p>
<p>View the complete configuration: <a href="https://gist.github.com/AlexsanderHamir/53f7d554a5d2afcf2c4edb5b6be68ff4" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/config.yaml</a></p>
<p><strong>Load Script (no_cache_hits.py)</strong></p>
<p>View the complete load testing script: <a href="https://gist.github.com/AlexsanderHamir/42c33d7a4dc7a57f56a78b560dee3a42" target="_blank" rel="noopener noreferrer">gist.github.com/AlexsanderHamir/no_cache_hits.py</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-77-5#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-77-5#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Gemini</td><td><code>gemini-2.5-flash-preview-09-2025</code></td><td>1M</td><td>$0.30</td><td>$2.50</td><td>Chat, reasoning, vision, audio</td></tr><tr><td>Gemini</td><td><code>gemini-2.5-flash-lite-preview-09-2025</code></td><td>1M</td><td>$0.10</td><td>$0.40</td><td>Chat, reasoning, vision, audio</td></tr><tr><td>Gemini</td><td><code>gemini-flash-latest</code></td><td>1M</td><td>$0.30</td><td>$2.50</td><td>Chat, reasoning, vision, audio</td></tr><tr><td>Gemini</td><td><code>gemini-flash-lite-latest</code></td><td>1M</td><td>$0.10</td><td>$0.40</td><td>Chat, reasoning, vision, audio</td></tr><tr><td>DeepSeek</td><td><code>deepseek-chat</code></td><td>131K</td><td>$0.60</td><td>$1.70</td><td>Chat, function calling, caching</td></tr><tr><td>DeepSeek</td><td><code>deepseek-reasoner</code></td><td>131K</td><td>$0.60</td><td>$1.70</td><td>Chat, reasoning</td></tr><tr><td>Bedrock</td><td><code>deepseek.v3-v1:0</code></td><td>164K</td><td>$0.58</td><td>$1.68</td><td>Chat, reasoning, function calling</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-codex</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>OpenAI</td><td><code>gpt-5-codex</code></td><td>272K</td><td>$1.25</td><td>$10.00</td><td>Responses API, reasoning, vision</td></tr><tr><td>SambaNova</td><td><code>sambanova/DeepSeek-V3.1</code></td><td>33K</td><td>$3.00</td><td>$4.50</td><td>Chat, reasoning, function calling</td></tr><tr><td>SambaNova</td><td><code>sambanova/gpt-oss-120b</code></td><td>131K</td><td>$3.00</td><td>$4.50</td><td>Chat, reasoning, function calling</td></tr><tr><td>Bedrock</td><td><code>qwen.qwen3-coder-480b-a35b-v1:0</code></td><td>262K</td><td>$0.22</td><td>$1.80</td><td>Chat, reasoning, function calling</td></tr><tr><td>Bedrock</td><td><code>qwen.qwen3-235b-a22b-2507-v1:0</code></td><td>262K</td><td>$0.22</td><td>$0.88</td><td>Chat, reasoning, function calling</td></tr><tr><td>Bedrock</td><td><code>qwen.qwen3-coder-30b-a3b-v1:0</code></td><td>262K</td><td>$0.15</td><td>$0.60</td><td>Chat, reasoning, function calling</td></tr><tr><td>Bedrock</td><td><code>qwen.qwen3-32b-v1:0</code></td><td>131K</td><td>$0.15</td><td>$0.60</td><td>Chat, reasoning, function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas</code></td><td>262K</td><td>$0.15</td><td>$1.20</td><td>Chat, function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas</code></td><td>262K</td><td>$0.15</td><td>$1.20</td><td>Chat, function calling</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/deepseek-ai/deepseek-v3.1-maas</code></td><td>164K</td><td>$1.35</td><td>$5.40</td><td>Chat, reasoning, function calling</td></tr><tr><td>OpenRouter</td><td><code>openrouter/x-ai/grok-4-fast:free</code></td><td>2M</td><td>$0.00</td><td>$0.00</td><td>Chat, reasoning, function calling</td></tr><tr><td>XAI</td><td><code>xai/grok-4-fast-reasoning</code></td><td>2M</td><td>$0.20</td><td>$0.50</td><td>Chat, reasoning, function calling</td></tr><tr><td>XAI</td><td><code>xai/grok-4-fast-non-reasoning</code></td><td>2M</td><td>$0.20</td><td>$0.50</td><td>Chat, function calling</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-77-5#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Added Gemini 2.5 Flash and Flash-lite preview models (September 2025 release) with improved pricing - <a href="https://github.com/BerriAI/litellm/pull/14948" target="_blank" rel="noopener noreferrer">PR #14948</a></li>
<li>Added new Anthropic web fetch tool support - <a href="https://github.com/BerriAI/litellm/pull/14951" target="_blank" rel="noopener noreferrer">PR #14951</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/xai">XAI</a></strong>
<ul>
<li>Add xai/grok-4-fast models - <a href="https://github.com/BerriAI/litellm/pull/14833" target="_blank" rel="noopener noreferrer">PR #14833</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Updated Claude Sonnet 4 configs to reflect million-token context window pricing - <a href="https://github.com/BerriAI/litellm/pull/14639" target="_blank" rel="noopener noreferrer">PR #14639</a></li>
<li>Added supported text field to anthropic citation response - <a href="https://github.com/BerriAI/litellm/pull/14164" target="_blank" rel="noopener noreferrer">PR #14164</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Added support for Qwen models family &amp; Deepseek 3.1 to Amazon Bedrock - <a href="https://github.com/BerriAI/litellm/pull/14845" target="_blank" rel="noopener noreferrer">PR #14845</a></li>
<li>Support requestMetadata in Bedrock Converse API - <a href="https://github.com/BerriAI/litellm/pull/14570" target="_blank" rel="noopener noreferrer">PR #14570</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Added vertex_ai/qwen models and azure/gpt-5-codex - <a href="https://github.com/BerriAI/litellm/pull/14844" target="_blank" rel="noopener noreferrer">PR #14844</a></li>
<li>Update vertex ai qwen model pricing - <a href="https://github.com/BerriAI/litellm/pull/14828" target="_blank" rel="noopener noreferrer">PR #14828</a></li>
<li>Vertex AI Context Caching: use Vertex ai API v1 instead of v1beta1 and accept 'cachedContent' param - <a href="https://github.com/BerriAI/litellm/pull/14831" target="_blank" rel="noopener noreferrer">PR #14831</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/sambanova">SambaNova</a></strong>
<ul>
<li>Add sambanova deepseek v3.1 and gpt-oss-120b - <a href="https://github.com/BerriAI/litellm/pull/14866" target="_blank" rel="noopener noreferrer">PR #14866</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Fix inconsistent token configs for gpt-5 models - <a href="https://github.com/BerriAI/litellm/pull/14942" target="_blank" rel="noopener noreferrer">PR #14942</a></li>
<li>GPT-3.5-Turbo price updated - <a href="https://github.com/BerriAI/litellm/pull/14858" target="_blank" rel="noopener noreferrer">PR #14858</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Add gpt-5 and gpt-5-codex to OpenRouter cost map - <a href="https://github.com/BerriAI/litellm/pull/14879" target="_blank" rel="noopener noreferrer">PR #14879</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong>
<ul>
<li>Fix vllm passthrough - <a href="https://github.com/BerriAI/litellm/pull/14778" target="_blank" rel="noopener noreferrer">PR #14778</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/image_generation">Flux</a></strong>
<ul>
<li>Support flux image edit - <a href="https://github.com/BerriAI/litellm/pull/14790" target="_blank" rel="noopener noreferrer">PR #14790</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-5#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Fix: Support claude code auth via subscription (anthropic) - <a href="https://github.com/BerriAI/litellm/pull/14821" target="_blank" rel="noopener noreferrer">PR #14821</a></li>
<li>Fix Anthropic streaming IDs - <a href="https://github.com/BerriAI/litellm/pull/14965" target="_blank" rel="noopener noreferrer">PR #14965</a></li>
<li>Revert incorrect changes to sonnet-4 max output tokens - <a href="https://github.com/BerriAI/litellm/pull/14933" target="_blank" rel="noopener noreferrer">PR #14933</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Fix a bug where openai image edit silently ignores multiple images - <a href="https://github.com/BerriAI/litellm/pull/14893" target="_blank" rel="noopener noreferrer">PR #14893</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong>
<ul>
<li>Fix: vLLM provider's rerank endpoint from /v1/rerank to /rerank - <a href="https://github.com/BerriAI/litellm/pull/14938" target="_blank" rel="noopener noreferrer">PR #14938</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-77-5#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/wandb">W&amp;B Inference</a></strong>
<ul>
<li>Add W&amp;B Inference to LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/14416" target="_blank" rel="noopener noreferrer">PR #14416</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-77-5#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-77-5#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Add SDK support for additional headers - <a href="https://github.com/BerriAI/litellm/pull/14761" target="_blank" rel="noopener noreferrer">PR #14761</a></li>
<li>Add shared_session parameter for aiohttp ClientSession reuse - <a href="https://github.com/BerriAI/litellm/pull/14721" target="_blank" rel="noopener noreferrer">PR #14721</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-77-5#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fix: Streaming tool call index assignment for multiple tool calls - <a href="https://github.com/BerriAI/litellm/pull/14587" target="_blank" rel="noopener noreferrer">PR #14587</a></li>
<li>Fix load credentials in token counter proxy - <a href="https://github.com/BerriAI/litellm/pull/14808" target="_blank" rel="noopener noreferrer">PR #14808</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-77-5#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-77-5#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Proxy CLI Auth</strong>
<ul>
<li>Allow re-using cli auth token - <a href="https://github.com/BerriAI/litellm/pull/14780" target="_blank" rel="noopener noreferrer">PR #14780</a></li>
<li>Create a python method to login using litellm proxy - <a href="https://github.com/BerriAI/litellm/pull/14782" target="_blank" rel="noopener noreferrer">PR #14782</a></li>
<li>Fixes for LiteLLM Proxy CLI to Auth to Gateway - <a href="https://github.com/BerriAI/litellm/pull/14836" target="_blank" rel="noopener noreferrer">PR #14836</a></li>
</ul>
</li>
</ul>
<p><strong>Virtual Keys</strong></p>
<ul>
<li>Initial support for scheduled key rotations - <a href="https://github.com/BerriAI/litellm/pull/14877" target="_blank" rel="noopener noreferrer">PR #14877</a></li>
<li>Allow scheduling key rotations when creating virtual keys - <a href="https://github.com/BerriAI/litellm/pull/14960" target="_blank" rel="noopener noreferrer">PR #14960</a></li>
</ul>
<p><strong>Models + Endpoints</strong></p>
<ul>
<li>Fix: added Oracle to provider's list - <a href="https://github.com/BerriAI/litellm/pull/14835" target="_blank" rel="noopener noreferrer">PR #14835</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-77-5#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>SSO</strong> - Fix: SSO "Clear" button writes empty values instead of removing SSO config - <a href="https://github.com/BerriAI/litellm/pull/14826" target="_blank" rel="noopener noreferrer">PR #14826</a></li>
<li><strong>Admin Settings</strong> - Remove useful links from admin settings - <a href="https://github.com/BerriAI/litellm/pull/14918" target="_blank" rel="noopener noreferrer">PR #14918</a></li>
<li><strong>Management Routes</strong> - Add /user/list to management routes - <a href="https://github.com/BerriAI/litellm/pull/14868" target="_blank" rel="noopener noreferrer">PR #14868</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail--prompt-management-integrations">Logging / Guardrail / Prompt Management Integrations<a href="https://docs.litellm.ai/release_notes/v1-77-5#logging--guardrail--prompt-management-integrations" class="hash-link" aria-label="Logging / Guardrail / Prompt Management Integrations的直接链接" title="Logging / Guardrail / Prompt Management Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-77-5#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">DataDog</a></strong>
<ul>
<li>Logging - <code>datadog</code> callback Log message content w/o sending to datadog - <a href="https://github.com/BerriAI/litellm/pull/14909" target="_blank" rel="noopener noreferrer">PR #14909</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong>
<ul>
<li>Adding langfuse usage details for cached tokens - <a href="https://github.com/BerriAI/litellm/pull/10955" target="_blank" rel="noopener noreferrer">PR #10955</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opik">Opik</a></strong>
<ul>
<li>Improve opik integration code - <a href="https://github.com/BerriAI/litellm/pull/14888" target="_blank" rel="noopener noreferrer">PR #14888</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#sqs">SQS</a></strong>
<ul>
<li>Error logging support for SQS Logger - <a href="https://github.com/BerriAI/litellm/pull/14974" target="_blank" rel="noopener noreferrer">PR #14974</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-77-5#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li><strong>LakeraAI v2 Guardrail</strong> - Ensure exception is raised correctly - <a href="https://github.com/BerriAI/litellm/pull/14867" target="_blank" rel="noopener noreferrer">PR #14867</a></li>
<li><strong>Presidio Guardrail</strong> - Support custom entity types in Presidio guardrail with Union[PiiEntityType, str] - <a href="https://github.com/BerriAI/litellm/pull/14899" target="_blank" rel="noopener noreferrer">PR #14899</a></li>
<li><strong>Noma Guardrail</strong> - Add noma guardrail provider to ui - <a href="https://github.com/BerriAI/litellm/pull/14415" target="_blank" rel="noopener noreferrer">PR #14415</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-77-5#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h4>
<ul>
<li><strong>BitBucket Integration</strong> - Add BitBucket Integration for Prompt Management - <a href="https://github.com/BerriAI/litellm/pull/14882" target="_blank" rel="noopener noreferrer">PR #14882</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-77-5#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Service Tier Pricing</strong> - Add service_tier based pricing support for openai (BOTH Service &amp; Priority Support) - <a href="https://github.com/BerriAI/litellm/pull/14796" target="_blank" rel="noopener noreferrer">PR #14796</a></li>
<li><strong>Cost Tracking</strong> - Show input, output, tool call cost breakdown in StandardLoggingPayload - <a href="https://github.com/BerriAI/litellm/pull/14921" target="_blank" rel="noopener noreferrer">PR #14921</a></li>
<li><strong>Parallel Request Limiter v3</strong>
<ul>
<li>Ensure Lua scripts can execute on redis cluster - <a href="https://github.com/BerriAI/litellm/pull/14968" target="_blank" rel="noopener noreferrer">PR #14968</a></li>
<li>Fix: get metadata info from both metadata and litellm_metadata fields - <a href="https://github.com/BerriAI/litellm/pull/14783" target="_blank" rel="noopener noreferrer">PR #14783</a></li>
</ul>
</li>
<li><strong>Priority Reservation</strong> - Fix: Priority Reservation: keys without priority metadata receive higher priority than keys with explicit priority configurations - <a href="https://github.com/BerriAI/litellm/pull/14832" target="_blank" rel="noopener noreferrer">PR #14832</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-77-5#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>MCP Configuration</strong> - Enable custom fields in mcp_info configuration - <a href="https://github.com/BerriAI/litellm/pull/14794" target="_blank" rel="noopener noreferrer">PR #14794</a></li>
<li><strong>MCP Tools</strong> - Remove server_name prefix from list_tools - <a href="https://github.com/BerriAI/litellm/pull/14720" target="_blank" rel="noopener noreferrer">PR #14720</a></li>
<li><strong>OAuth Flow</strong> - Initial commit for v2 oauth flow - <a href="https://github.com/BerriAI/litellm/pull/14964" target="_blank" rel="noopener noreferrer">PR #14964</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-77-5#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>Memory Leak Fix</strong> - Fix InMemoryCache unbounded growth when TTLs are set - <a href="https://github.com/BerriAI/litellm/pull/14869" target="_blank" rel="noopener noreferrer">PR #14869</a></li>
<li><strong>Cache Performance</strong> - Fix: cache root cause - <a href="https://github.com/BerriAI/litellm/pull/14827" target="_blank" rel="noopener noreferrer">PR #14827</a></li>
<li><strong>Concurrency Fix</strong> - Fix concurrency/scaling when many Python threads do streaming using <em>sync</em> completions - <a href="https://github.com/BerriAI/litellm/pull/14816" target="_blank" rel="noopener noreferrer">PR #14816</a></li>
<li><strong>Performance Optimization</strong> - Fix: reduce get_deployment cost to O(1) - <a href="https://github.com/BerriAI/litellm/pull/14967" target="_blank" rel="noopener noreferrer">PR #14967</a></li>
<li><strong>Performance Optimization</strong> - Fix: remove slow string operation - <a href="https://github.com/BerriAI/litellm/pull/14955" target="_blank" rel="noopener noreferrer">PR #14955</a></li>
<li><strong>DB Connection Management</strong> - Fix: DB connection state retries - <a href="https://github.com/BerriAI/litellm/pull/14925" target="_blank" rel="noopener noreferrer">PR #14925</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="documentation-updates">Documentation Updates<a href="https://docs.litellm.ai/release_notes/v1-77-5#documentation-updates" class="hash-link" aria-label="Documentation Updates的直接链接" title="Documentation Updates的直接链接">​</a></h2>
<ul>
<li><strong>Provider Documentation</strong> - Fix docs for provider_specific_params.md - <a href="https://github.com/BerriAI/litellm/pull/14787" target="_blank" rel="noopener noreferrer">PR #14787</a></li>
<li><strong>Model References</strong> - Update model references from gemini-pro to gemini-2.5-pro - <a href="https://github.com/BerriAI/litellm/pull/14775" target="_blank" rel="noopener noreferrer">PR #14775</a></li>
<li><strong>Letta Guide</strong> - Add Letta Guide documentation - <a href="https://github.com/BerriAI/litellm/pull/14798" target="_blank" rel="noopener noreferrer">PR #14798</a></li>
<li><strong>README</strong> - Make the README document clearer - <a href="https://github.com/BerriAI/litellm/pull/14860" target="_blank" rel="noopener noreferrer">PR #14860</a></li>
<li><strong>Session Management</strong> - Update docs for session management availability - <a href="https://github.com/BerriAI/litellm/pull/14914" target="_blank" rel="noopener noreferrer">PR #14914</a></li>
<li><strong>Cost Documentation</strong> - Add documentation for additional cost-related keys in custom pricing - <a href="https://github.com/BerriAI/litellm/pull/14949" target="_blank" rel="noopener noreferrer">PR #14949</a></li>
<li><strong>Azure Passthrough</strong> - Add azure passthrough documentation - <a href="https://github.com/BerriAI/litellm/pull/14958" target="_blank" rel="noopener noreferrer">PR #14958</a></li>
<li><strong>General Documentation</strong> - Doc updates sept 2025 - <a href="https://github.com/BerriAI/litellm/pull/14769" target="_blank" rel="noopener noreferrer">PR #14769</a>
<ul>
<li>Clarified bridging between endpoints and mode in docs.</li>
<li>Added Vertex AI Gemini API configuration as an alternative in relevant guides.
Linked AWS authentication info in the Bedrock guardrails documentation.</li>
<li>Added Cancel Response API usage with code snippets</li>
<li>Clarified that SSO (Single Sign-On) is free for up to 5 users:</li>
<li>Alphabetized sidebar, leaving quick start / intros at top of categories</li>
<li>Documented max_connections under cache_params.</li>
<li>Clarified IAM AssumeRole Policy requirements.</li>
<li>Added transform utilities example to Getting Started (showing request transformation).</li>
<li>Added references to models.litellm.ai as the full models list in various docs.</li>
<li>Added a code snippet for async_post_call_success_hook.</li>
<li>Removed broken links to callbacks management guide. - Reformatted and linked cookbooks + other relevant docs</li>
</ul>
</li>
<li><strong>Documentation Corrections</strong> - Corrected docs updates sept 2025 - <a href="https://github.com/BerriAI/litellm/pull/14916" target="_blank" rel="noopener noreferrer">PR #14916</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-77-5#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@uzaxirr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14761" target="_blank" rel="noopener noreferrer">PR #14761</a></li>
<li>@xprilion made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14416" target="_blank" rel="noopener noreferrer">PR #14416</a></li>
<li>@CH-GAGANRAJ made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14779" target="_blank" rel="noopener noreferrer">PR #14779</a></li>
<li>@otaviofbrito made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14778" target="_blank" rel="noopener noreferrer">PR #14778</a></li>
<li>@danielmklein made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14639" target="_blank" rel="noopener noreferrer">PR #14639</a></li>
<li>@Jetemple made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14826" target="_blank" rel="noopener noreferrer">PR #14826</a></li>
<li>@akshoop made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14818" target="_blank" rel="noopener noreferrer">PR #14818</a></li>
<li>@hazyone made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14821" target="_blank" rel="noopener noreferrer">PR #14821</a></li>
<li>@leventov made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14816" target="_blank" rel="noopener noreferrer">PR #14816</a></li>
<li>@fabriciojoc made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/10955" target="_blank" rel="noopener noreferrer">PR #10955</a></li>
<li>@onlylonly made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14845" target="_blank" rel="noopener noreferrer">PR #14845</a></li>
<li>@Copilot made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14869" target="_blank" rel="noopener noreferrer">PR #14869</a></li>
<li>@arsh72 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14899" target="_blank" rel="noopener noreferrer">PR #14899</a></li>
<li>@berri-teddy made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14914" target="_blank" rel="noopener noreferrer">PR #14914</a></li>
<li>@vpbill made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14415" target="_blank" rel="noopener noreferrer">PR #14415</a></li>
<li>@kgritesh made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14893" target="_blank" rel="noopener noreferrer">PR #14893</a></li>
<li>@oytunkutrup1 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14858" target="_blank" rel="noopener noreferrer">PR #14858</a></li>
<li>@nherment made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14933" target="_blank" rel="noopener noreferrer">PR #14933</a></li>
<li>@deepanshululla made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14974" target="_blank" rel="noopener noreferrer">PR #14974</a></li>
<li>@TeddyAmkie made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14758" target="_blank" rel="noopener noreferrer">PR #14758</a></li>
<li>@SmartManoj made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14775" target="_blank" rel="noopener noreferrer">PR #14775</a></li>
<li>@uc4w6c made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14720" target="_blank" rel="noopener noreferrer">PR #14720</a></li>
<li>@luizrennocosta made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14783" target="_blank" rel="noopener noreferrer">PR #14783</a></li>
<li>@AlexsanderHamir made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14827" target="_blank" rel="noopener noreferrer">PR #14827</a></li>
<li>@dharamendrak made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14721" target="_blank" rel="noopener noreferrer">PR #14721</a></li>
<li>@TomeHirata made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14164" target="_blank" rel="noopener noreferrer">PR #14164</a></li>
<li>@mrFranklin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14860" target="_blank" rel="noopener noreferrer">PR #14860</a></li>
<li>@luisfucros made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14866" target="_blank" rel="noopener noreferrer">PR #14866</a></li>
<li>@huangyafei made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14879" target="_blank" rel="noopener noreferrer">PR #14879</a></li>
<li>@thiswillbeyourgithub made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14949" target="_blank" rel="noopener noreferrer">PR #14949</a></li>
<li>@Maximgitman made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14965" target="_blank" rel="noopener noreferrer">PR #14965</a></li>
<li>@subnet-dev made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14938" target="_blank" rel="noopener noreferrer">PR #14938</a></li>
<li>@22mSqRi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14972" target="_blank" rel="noopener noreferrer">PR #14972</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.77.3.rc.1...v1.77.5.rc.1" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-77-5#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.77.3-stable - Priority Based Rate Limiting]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-77-3</link>
            <guid>https://docs.litellm.ai/release_notes/v1-77-3</guid>
            <pubDate>Sun, 21 Sep 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-77-3#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.77.3-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.77.3</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-77-3#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>+550 RPS Performance Improvements</strong> - Optimizations in request handling and object initialization.</li>
<li><strong>Priority Quota Reservation</strong> - Proxy admins can now reserve TPM/RPM capacity for specific keys.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="priority-quota-reservation">Priority Quota Reservation<a href="https://docs.litellm.ai/release_notes/v1-77-3#priority-quota-reservation" class="hash-link" aria-label="Priority Quota Reservation的直接链接" title="Priority Quota Reservation的直接链接">​</a></h2>
<p>This release adds support for priority quota reservation. This allows Proxy Admins to reserve specific percentages of model capacity for different use cases.</p>
<p>This is great for use cases where you want to ensure your realtime use cases must always get priority responses and background development jobs can take longer.</p>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAi0lEQVR4nEWOSw7CMAwFezROyIZLcBC2iK64AIgIqVFpksaOUxjUj9TFLJ4878mNc44Z33mKFmqt/KoxVcNspxERQgj0wwfXv4k5ch8qXS6oCjHLKtrW1FKolmm953BuOd5e8DVEyyaaMeaRlBJjDPiUOV0fXJ49U1VS1l1U1YX5jTlLCphkynJbF/9+Wr8wSsh6/wAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="314"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/quota.8eb7614.640.png" srcset="/assets/ideal-img/quota.8eb7614.640.png 640w,/assets/ideal-img/quota.afd7194.1920.png 1920w" width="640" height="314"></noscript></div>
<br>
<p>This release adds support for priority quota reservation. This allows <strong>Proxy Admins</strong> to reserve TPM/RPM capacity for keys based on metadata priority levels, ensuring critical production workloads get guaranteed access regardless of development traffic volume.</p>
<p>Get started <a href="https://docs.litellm.ai/docs/proxy/dynamic_rate_limit#priority-quota-reservation">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="550-rps-performance-improvements">+550 RPS Performance Improvements<a href="https://docs.litellm.ai/release_notes/v1-77-3#550-rps-performance-improvements" class="hash-link" aria-label="+550 RPS Performance Improvements的直接链接" title="+550 RPS Performance Improvements的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAt0lEQVR4nB3GwUrDQBQF0Pl9kaKCy4pURErBHygo0rXLItJNCUkTkkzSNplJMi933hU8q2Oy9Ioir1DbCr73oBD92OMyXv4fQ8QwDTC27pjnBW1pWV9rrtt3LpsVn5tXPtkXHoeEBGlkDhoR1YnXRfGon+1O277RszvrvvvRm/xOf91BzSQTqeRbsuG2+iCFPKUnZmVG5x0Tn/L2cE8TQoAEweL7AWVXYRYgSICIYJxG6BzxddzhD8Jxt5JFcXmTAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="331"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/perf_imp.1e940ae.640.png" srcset="/assets/ideal-img/perf_imp.1e940ae.640.png 640w,/assets/ideal-img/perf_imp.dc7bf16.1920.png 1920w" width="640" height="331"></noscript></div>
<br>
<p>This release delivers significant RPS improvements through targeted optimizations.</p>
<p>We've achieved a +500 RPS boost by fixing cache type inconsistencies that were causing frequent cache misses, plus an additional +50 RPS by removing unnecessary coroutine checks from the hot path.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-77-3#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-77-3#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>SambaNova</td><td><code>sambanova/deepseek-v3.1</code></td><td>128K</td><td>$0.90</td><td>$0.90</td><td>Chat completions</td></tr><tr><td>SambaNova</td><td><code>sambanova/gpt-oss-120b</code></td><td>128K</td><td>$0.72</td><td>$0.72</td><td>Chat completions</td></tr><tr><td>OVHCloud</td><td>Various models</td><td>Varies</td><td>Contact provider</td><td>Contact provider</td><td>Chat completions</td></tr><tr><td>CompactifAI</td><td>Various models</td><td>Varies</td><td>Contact provider</td><td>Contact provider</td><td>Chat completions</td></tr><tr><td>TwelveLabs</td><td><code>twelvelabs/marengo-embed-2.7</code></td><td>32K</td><td>$0.12</td><td>$0.00</td><td>Embeddings</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-77-3#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ovhcloud">OVHCloud AI Endpoints</a></strong>
<ul>
<li>New provider support with comprehensive model catalog - <a href="https://github.com/BerriAI/litellm/pull/14494" target="_blank" rel="noopener noreferrer">PR #14494</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/compactifai">CompactifAI</a></strong>
<ul>
<li>New provider integration - <a href="https://github.com/BerriAI/litellm/pull/14532" target="_blank" rel="noopener noreferrer">PR #14532</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/sambanova">SambaNova</a></strong>
<ul>
<li>Added DeepSeek v3.1 and GPT-OSS-120B models - <a href="https://github.com/BerriAI/litellm/pull/14500" target="_blank" rel="noopener noreferrer">PR #14500</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Cross-region inference profile cost calculation - <a href="https://github.com/BerriAI/litellm/pull/14566" target="_blank" rel="noopener noreferrer">PR #14566</a></li>
<li>AWS external ID parameter support for authentication - <a href="https://github.com/BerriAI/litellm/pull/14582" target="_blank" rel="noopener noreferrer">PR #14582</a></li>
<li>CountTokens API implementation - <a href="https://github.com/BerriAI/litellm/pull/14557" target="_blank" rel="noopener noreferrer">PR #14557</a></li>
<li>Titan V2 encoding_format parameter support - <a href="https://github.com/BerriAI/litellm/pull/14687" target="_blank" rel="noopener noreferrer">PR #14687</a></li>
<li>Nova Canvas image generation inference profiles - <a href="https://github.com/BerriAI/litellm/pull/14578" target="_blank" rel="noopener noreferrer">PR #14578</a></li>
<li>Bedrock Batches API - batch processing support with file upload and request transformation - <a href="https://github.com/BerriAI/litellm/pull/14618" target="_blank" rel="noopener noreferrer">PR #14618</a></li>
<li>Bedrock Twelve Labs embedding provider support - <a href="https://github.com/BerriAI/litellm/pull/14697" target="_blank" rel="noopener noreferrer">PR #14697</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Gemini labels field provider-aware filtering - <a href="https://github.com/BerriAI/litellm/pull/14563" target="_blank" rel="noopener noreferrer">PR #14563</a></li>
<li>Gemini Batch API support - <a href="https://github.com/BerriAI/litellm/pull/14733" target="_blank" rel="noopener noreferrer">PR #14733</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/volcengine">Volcengine</a></strong>
<ul>
<li>Fixed thinking parameters when disabled - <a href="https://github.com/BerriAI/litellm/pull/14569" target="_blank" rel="noopener noreferrer">PR #14569</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/cohere">Cohere</a></strong>
<ul>
<li>Handle Generate API deprecation, default to chat endpoints - <a href="https://github.com/BerriAI/litellm/pull/14676" target="_blank" rel="noopener noreferrer">PR #14676</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/twelvelabs">TwelveLabs</a></strong>
<ul>
<li>Added Marengo Embed 2.7 embedding support - <a href="https://github.com/BerriAI/litellm/pull/14674" target="_blank" rel="noopener noreferrer">PR #14674</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-3#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Empty arguments handling in tool call invocation - <a href="https://github.com/BerriAI/litellm/pull/14583" target="_blank" rel="noopener noreferrer">PR #14583</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Avoid deepcopy crash with non-pickleables in Gemini/Vertex - <a href="https://github.com/BerriAI/litellm/pull/14418" target="_blank" rel="noopener noreferrer">PR #14418</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/xai">XAI</a></strong>
<ul>
<li>Fix unsupported stop parameter for grok-code models - <a href="https://github.com/BerriAI/litellm/pull/14565" target="_blank" rel="noopener noreferrer">PR #14565</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Updated error message for Gemini API - <a href="https://github.com/BerriAI/litellm/pull/14589" target="_blank" rel="noopener noreferrer">PR #14589</a></li>
<li>Fixed 2.5 Flash Image Preview model routing - <a href="https://github.com/BerriAI/litellm/pull/14715" target="_blank" rel="noopener noreferrer">PR #14715</a></li>
<li>API key passing for token counting endpoints - <a href="https://github.com/BerriAI/litellm/pull/14744" target="_blank" rel="noopener noreferrer">PR #14744</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-77-3#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ovhcloud">OVHCloud AI Endpoints</a></strong>
<ul>
<li>Complete provider integration with model catalog and authentication - <a href="https://github.com/BerriAI/litellm/pull/14494" target="_blank" rel="noopener noreferrer">PR #14494</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/compactifai">CompactifAI</a></strong>
<ul>
<li>New provider support with documentation - <a href="https://github.com/BerriAI/litellm/pull/14532" target="_blank" rel="noopener noreferrer">PR #14532</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-77-3#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-77-3#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">/responses</a></strong>
<ul>
<li>Added cancel endpoint support for non-admin users - <a href="https://github.com/BerriAI/litellm/pull/14594" target="_blank" rel="noopener noreferrer">PR #14594</a></li>
<li>Improved response session handling and cold storage configuration with s3 - <a href="https://github.com/BerriAI/litellm/pull/14534" target="_blank" rel="noopener noreferrer">PR #14534</a></li>
<li>Added OpenAI &amp; Azure /responses/cancel endpoint support - <a href="https://github.com/BerriAI/litellm/pull/14561" target="_blank" rel="noopener noreferrer">PR #14561</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Enhanced rate limit error messages with details - <a href="https://github.com/BerriAI/litellm/pull/14736" target="_blank" rel="noopener noreferrer">PR #14736</a></li>
<li>Middle-truncation for spend log payloads - <a href="https://github.com/BerriAI/litellm/pull/14637" target="_blank" rel="noopener noreferrer">PR #14637</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-77-3#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/completion/input">/chat/completions</a></strong>
<ul>
<li>Fixed completion chat ID handling - <a href="https://github.com/BerriAI/litellm/pull/14548" target="_blank" rel="noopener noreferrer">PR #14548</a></li>
<li>Prevent AttributeError for _get_tags_from_request_kwargs - <a href="https://github.com/BerriAI/litellm/pull/14735" target="_blank" rel="noopener noreferrer">PR #14735</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">/responses</a></strong>
<ul>
<li>Fixed cost calculation - <a href="https://github.com/BerriAI/litellm/pull/14675" target="_blank" rel="noopener noreferrer">PR #14675</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Rate limiter AttributeError fix - <a href="https://github.com/BerriAI/litellm/pull/14609" target="_blank" rel="noopener noreferrer">PR #14609</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-77-3#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<ul>
<li><strong>Responses API Cost Calculation</strong> fix - <a href="https://github.com/BerriAI/litellm/pull/14675" target="_blank" rel="noopener noreferrer">PR #14675</a></li>
<li><strong>Anthropic Cache Token Pricing</strong> - Separate 1-hour vs 5-minute cache creation costs - <a href="https://github.com/BerriAI/litellm/pull/14620" target="_blank" rel="noopener noreferrer">PR #14620</a>, <a href="https://github.com/BerriAI/litellm/pull/14652" target="_blank" rel="noopener noreferrer">PR #14652</a></li>
<li><strong>Indochina Time Timezone</strong> support for budget resets - <a href="https://github.com/BerriAI/litellm/pull/14666" target="_blank" rel="noopener noreferrer">PR #14666</a></li>
<li><strong>Soft Budget Alert Cache Issues</strong> - Resolved soft budget alert cache issues - <a href="https://github.com/BerriAI/litellm/pull/14491" target="_blank" rel="noopener noreferrer">PR #14491</a></li>
<li><strong>Dynamic Rate Limiter v3</strong> - Priority routing improvements - <a href="https://github.com/BerriAI/litellm/pull/14734" target="_blank" rel="noopener noreferrer">PR #14734</a></li>
<li><strong>Enhanced Rate Limit Errors</strong> - More detailed error messages - <a href="https://github.com/BerriAI/litellm/pull/14736" target="_blank" rel="noopener noreferrer">PR #14736</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-77-3#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-77-3#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Team Member Service Account Keys</strong> - Allow team members to view keys they create - <a href="https://github.com/BerriAI/litellm/pull/14619" target="_blank" rel="noopener noreferrer">PR #14619</a></li>
<li><strong>Default Budget for JWT Teams</strong> - Auto-assign budgets to generated teams - <a href="https://github.com/BerriAI/litellm/pull/14514" target="_blank" rel="noopener noreferrer">PR #14514</a></li>
<li><strong>SSO Access Control Groups</strong> - Enhanced token info endpoint integration - <a href="https://github.com/BerriAI/litellm/pull/14738" target="_blank" rel="noopener noreferrer">PR #14738</a></li>
<li><strong>Health Test Connect Protection</strong> - Restrict access based on model creation permissions - <a href="https://github.com/BerriAI/litellm/pull/14650" target="_blank" rel="noopener noreferrer">PR #14650</a></li>
<li><strong>Amazon Bedrock Guardrail Info View</strong> - Enhanced logging visualization - <a href="https://github.com/BerriAI/litellm/pull/14696" target="_blank" rel="noopener noreferrer">PR #14696</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-1">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-3#bug-fixes-1" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h4>
<ul>
<li><strong>SCIM v2</strong> - Fix group PUSH and PUT operations for non-existent members - <a href="https://github.com/BerriAI/litellm/pull/14581" target="_blank" rel="noopener noreferrer">PR #14581</a></li>
<li><strong>Guardrail View/Edit/Delete</strong> behavior fixes - <a href="https://github.com/BerriAI/litellm/pull/14622" target="_blank" rel="noopener noreferrer">PR #14622</a></li>
<li><strong>In-Memory Guardrail</strong> update failures - <a href="https://github.com/BerriAI/litellm/pull/14653" target="_blank" rel="noopener noreferrer">PR #14653</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-77-3#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-77-3#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">DataDog</a></strong>
<ul>
<li>Enhanced spend tracking metrics - <a href="https://github.com/BerriAI/litellm/pull/14555" target="_blank" rel="noopener noreferrer">PR #14555</a></li>
<li>Stream support with is_streamed_request parameter - <a href="https://github.com/BerriAI/litellm/pull/14673" target="_blank" rel="noopener noreferrer">PR #14673</a></li>
<li>Fixed tool calls metadata passing - <a href="https://github.com/BerriAI/litellm/pull/14531" target="_blank" rel="noopener noreferrer">PR #14531</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse</a></strong>
<ul>
<li>Added logging support for Responses API - <a href="https://github.com/BerriAI/litellm/pull/14597" target="_blank" rel="noopener noreferrer">PR #14597</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langsmith">Langsmith</a></strong>
<ul>
<li>Langsmith Sampling Rate - Key/Team-level tracing configuration - <a href="https://github.com/BerriAI/litellm/pull/14740" target="_blank" rel="noopener noreferrer">PR #14740</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#prometheus">Prometheus</a></strong>
<ul>
<li>Multi-worker support improvements - <a href="https://github.com/BerriAI/litellm/pull/14530" target="_blank" rel="noopener noreferrer">PR #14530</a></li>
<li>User email labels in monitoring - <a href="https://github.com/BerriAI/litellm/pull/14520" target="_blank" rel="noopener noreferrer">PR #14520</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#opik">Opik</a></strong>
<ul>
<li>Fixed timezone issue - <a href="https://github.com/BerriAI/litellm/pull/14708" target="_blank" rel="noopener noreferrer">PR #14708</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-2">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-3#bug-fixes-2" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#s3-buckets">S3</a></strong>
<ul>
<li>Fixed 404 error when using s3_endpoint_url - <a href="https://github.com/BerriAI/litellm/pull/14559" target="_blank" rel="noopener noreferrer">PR #14559</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-77-3#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li><strong>Tool Permission Guardrail</strong> - Fine-grained tool access control - <a href="https://github.com/BerriAI/litellm/pull/14519" target="_blank" rel="noopener noreferrer">PR #14519</a></li>
<li><strong>Bedrock Guardrails</strong> - Selective guarding support with runtime endpoint configuration - <a href="https://github.com/BerriAI/litellm/pull/14575" target="_blank" rel="noopener noreferrer">PR #14575</a>, <a href="https://github.com/BerriAI/litellm/pull/14650" target="_blank" rel="noopener noreferrer">PR #14650</a></li>
<li><strong>Default Last Message</strong> in guardrails - <a href="https://github.com/BerriAI/litellm/pull/14640" target="_blank" rel="noopener noreferrer">PR #14640</a></li>
<li><strong>AWS exceptions handling despite 200 response</strong> - <a href="https://github.com/BerriAI/litellm/pull/14658" target="_blank" rel="noopener noreferrer">PR #14658</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-integration">New Integration<a href="https://docs.litellm.ai/release_notes/v1-77-3#new-integration" class="hash-link" aria-label="New Integration的直接链接" title="New Integration的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/observability/posthog">PostHog</a></strong> - Complete observability integration for LiteLLM usage tracking and analytics - <a href="https://github.com/BerriAI/litellm/pull/14610" target="_blank" rel="noopener noreferrer">PR #14610</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-77-3#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<ul>
<li><strong>MCP Server Alias Parsing</strong> - Multi-part URL path support - <a href="https://github.com/BerriAI/litellm/pull/14558" target="_blank" rel="noopener noreferrer">PR #14558</a></li>
<li><strong>MCP Filter Recomputation</strong> - After server deletion - <a href="https://github.com/BerriAI/litellm/pull/14542" target="_blank" rel="noopener noreferrer">PR #14542</a></li>
<li><strong>MCP Gateway Tools List</strong> improvements - <a href="https://github.com/BerriAI/litellm/pull/14695" target="_blank" rel="noopener noreferrer">PR #14695</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-77-3#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<ul>
<li><strong>+500 RPS Performance Boost</strong> when sending the <code>user</code> field - <a href="https://github.com/BerriAI/litellm/pull/14616" target="_blank" rel="noopener noreferrer">PR #14616</a></li>
<li><strong>+50 RPS</strong> by removing iscoroutine from hot path - <a href="https://github.com/BerriAI/litellm/pull/14649" target="_blank" rel="noopener noreferrer">PR #14649</a></li>
<li><strong>7% reduction</strong> in <strong>init</strong> overhead - <a href="https://github.com/BerriAI/litellm/pull/14689" target="_blank" rel="noopener noreferrer">PR #14689</a></li>
<li><strong>Generic Object Pool</strong> implementation for better resource management - <a href="https://github.com/BerriAI/litellm/pull/14702" target="_blank" rel="noopener noreferrer">PR #14702</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-77-3#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<ul>
<li><strong>Middle-Truncation</strong> for spend log payloads - <a href="https://github.com/BerriAI/litellm/pull/14637" target="_blank" rel="noopener noreferrer">PR #14637</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="security">Security<a href="https://docs.litellm.ai/release_notes/v1-77-3#security" class="hash-link" aria-label="Security的直接链接" title="Security的直接链接">​</a></h4>
<ul>
<li><strong>Security Update</strong> - Bump aiohttp==3.12.14, fix CVE-2025-53643 - <a href="https://github.com/BerriAI/litellm/pull/14638" target="_blank" rel="noopener noreferrer">PR #14638</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-77-3#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@luisfucros made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14500" target="_blank" rel="noopener noreferrer">PR #14500</a></li>
<li>@hanakannzashi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14548" target="_blank" rel="noopener noreferrer">PR #14548</a></li>
<li>@eliasto made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14494" target="_blank" rel="noopener noreferrer">PR #14494</a></li>
<li>@Rasmusafj made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14491" target="_blank" rel="noopener noreferrer">PR #14491</a></li>
<li>@LingXuanYin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14569" target="_blank" rel="noopener noreferrer">PR #14569</a></li>
<li>@ronaldpereira made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14613" target="_blank" rel="noopener noreferrer">PR #14613</a></li>
<li>@hula-la made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14534" target="_blank" rel="noopener noreferrer">PR #14534</a></li>
<li>@carlos-marchal-ph made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14610" target="_blank" rel="noopener noreferrer">PR #14610</a></li>
<li>@akraines made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14637" target="_blank" rel="noopener noreferrer">PR #14637</a></li>
<li>@mrFranklin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14708" target="_blank" rel="noopener noreferrer">PR #14708</a></li>
<li>@tcx4c70 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14675" target="_blank" rel="noopener noreferrer">PR #14675</a></li>
<li>@michaeltansg made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14666" target="_blank" rel="noopener noreferrer">PR #14666</a></li>
<li>@tosi29 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14725" target="_blank" rel="noopener noreferrer">PR #14725</a></li>
<li>@gmdfalk made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14735" target="_blank" rel="noopener noreferrer">PR #14735</a></li>
<li>@FelipeRodriguesGare made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14733" target="_blank" rel="noopener noreferrer">PR #14733</a></li>
<li>@mritunjaysharma394 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14678" target="_blank" rel="noopener noreferrer">PR #14678</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.77.2.rc.1...v1.77.3.rc.1" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-77-3#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.77.2-stable - Bedrock Batches API]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-77-2</link>
            <guid>https://docs.litellm.ai/release_notes/v1-77-2</guid>
            <pubDate>Sat, 13 Sep 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-77-2#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:main-v1.77.2-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.77.2.post1</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-77-2#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Bedrock Batches API</strong> - Support for creating Batch Inference Jobs on Bedrock using LiteLLM's unified batch API (OpenAI compatible)</li>
<li><strong>Qwen API Tiered Pricing</strong> - Cost tracking support for Dashscope (Qwen) models with multiple pricing tiers</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-77-2#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-77-2#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Pricing ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>DeepInfra</td><td><code>deepinfra/deepseek-ai/DeepSeek-R1</code></td><td>164K</td><td><strong>Input:</strong> $0.70<br><strong>Output:</strong> $2.40</td><td>Chat completions, tool calling</td></tr><tr><td>Heroku</td><td><code>heroku/claude-4-sonnet</code></td><td>8K</td><td>Contact provider for pricing</td><td>Function calling, tool choice</td></tr><tr><td>Heroku</td><td><code>heroku/claude-3-7-sonnet</code></td><td>8K</td><td>Contact provider for pricing</td><td>Function calling, tool choice</td></tr><tr><td>Heroku</td><td><code>heroku/claude-3-5-sonnet-latest</code></td><td>8K</td><td>Contact provider for pricing</td><td>Function calling, tool choice</td></tr><tr><td>Heroku</td><td><code>heroku/claude-3-5-haiku</code></td><td>4K</td><td>Contact provider for pricing</td><td>Function calling, tool choice</td></tr><tr><td>Dashscope</td><td><code>dashscope/qwen-plus-latest</code></td><td>1M</td><td><strong>Tiered Pricing:</strong><br>• 0-256K tokens: $0.40 / $1.20<br>• 256K-1M tokens: $1.20 / $3.60</td><td>Function calling, reasoning</td></tr><tr><td>Dashscope</td><td><code>dashscope/qwen3-max-preview</code></td><td>262K</td><td><strong>Tiered Pricing:</strong><br>• 0-32K tokens: $1.20 / $6.00<br>• 32K-128K tokens: $2.40 / $12.00<br>• 128K-252K tokens: $3.00 / $15.00</td><td>Function calling, reasoning</td></tr><tr><td>Dashscope</td><td><code>dashscope/qwen-flash</code></td><td>1M</td><td><strong>Tiered Pricing:</strong><br>• 0-256K tokens: $0.05 / $0.40<br>• 256K-1M tokens: $0.25 / $2.00</td><td>Function calling, reasoning</td></tr><tr><td>Dashscope</td><td><code>dashscope/qwen3-coder-plus</code></td><td>1M</td><td><strong>Tiered Pricing:</strong><br>• 0-32K tokens: $1.00 / $5.00<br>• 32K-128K tokens: $1.80 / $9.00<br>• 128K-256K tokens: $3.00 / $15.00<br>• 256K-1M tokens: $6.00 / $60.00</td><td>Function calling, reasoning, caching</td></tr><tr><td>Dashscope</td><td><code>dashscope/qwen3-coder-flash</code></td><td>1M</td><td><strong>Tiered Pricing:</strong><br>• 0-32K tokens: $0.30 / $1.50<br>• 32K-128K tokens: $0.50 / $2.50<br>• 128K-256K tokens: $0.80 / $4.00<br>• 256K-1M tokens: $1.60 / $9.60</td><td>Function calling, reasoning, caching</td></tr></tbody></table>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-77-2#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock_batches">Bedrock</a></strong>
<ul>
<li>Bedrock Batches API - batch processing support with file upload and request transformation - <a href="https://github.com/BerriAI/litellm/pull/14518" target="_blank" rel="noopener noreferrer">PR #14518</a>, <a href="https://github.com/BerriAI/litellm/pull/14522" target="_blank" rel="noopener noreferrer">PR #14522</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong>
<ul>
<li>Added transcription endpoint support - <a href="https://github.com/BerriAI/litellm/pull/14523" target="_blank" rel="noopener noreferrer">PR #14523</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong>
<ul>
<li><code>ollama_chat/</code> - images, thinking, and content as list handling - <a href="https://github.com/BerriAI/litellm/pull/14523" target="_blank" rel="noopener noreferrer">PR #14523</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>New debug flag for detailed request/response logging <a href="https://github.com/BerriAI/litellm/pull/14482" target="_blank" rel="noopener noreferrer">PR #14482</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-2#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure OpenAI</a></strong>
<ul>
<li>Fixed extra_body injection causing payload rejection in image generation - <a href="https://github.com/BerriAI/litellm/pull/14475" target="_blank" rel="noopener noreferrer">PR #14475</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/lm-studio">LM Studio</a></strong>
<ul>
<li>Resolved illegal Bearer header value issue - <a href="https://github.com/BerriAI/litellm/pull/14512" target="_blank" rel="noopener noreferrer">PR #14512</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-77-2#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-1">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-2#bug-fixes-1" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/anthropic_unified">/messages</a></strong>
<ul>
<li>Don't send content block after message w/ finish reason + usage block - <a href="https://github.com/BerriAI/litellm/pull/14477" target="_blank" rel="noopener noreferrer">PR #14477</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/generateContent">/generateContent</a></strong>
<ul>
<li>Gemini CLI Integration - Fixed token count errors - <a href="https://github.com/BerriAI/litellm/pull/14451" target="_blank" rel="noopener noreferrer">PR #14451</a>, <a href="https://github.com/BerriAI/litellm/pull/14417" target="_blank" rel="noopener noreferrer">PR #14417</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-77-2#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-77-2#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/dashscope">Qwen API Tiered Pricing</a></strong> - Added comprehensive tiered cost tracking for Dashscope/Qwen models - <a href="https://github.com/BerriAI/litellm/pull/14471" target="_blank" rel="noopener noreferrer">PR #14471</a>, <a href="https://github.com/BerriAI/litellm/pull/14479" target="_blank" rel="noopener noreferrer">PR #14479</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-2">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-2#bug-fixes-2" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h4>
<ul>
<li><strong>Provider Budgets</strong> - Fixed provider budget calculations - <a href="https://github.com/BerriAI/litellm/pull/14459" target="_blank" rel="noopener noreferrer">PR #14459</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-77-2#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-77-2#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>User Headers Mapping</strong> - New X-LiteLLM Users mapping feature for enhanced user tracking - <a href="https://github.com/BerriAI/litellm/pull/14485" target="_blank" rel="noopener noreferrer">PR #14485</a></li>
<li><strong>Key Unblocking</strong> - Support for hashed tokens in <code>/key/unblock</code> endpoint - <a href="https://github.com/BerriAI/litellm/pull/14477" target="_blank" rel="noopener noreferrer">PR #14477</a></li>
<li><strong>Model Group Header Forwarding</strong> - Enhanced wildcard model support with documentation - <a href="https://github.com/BerriAI/litellm/pull/14528" target="_blank" rel="noopener noreferrer">PR #14528</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-3">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-77-2#bug-fixes-3" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h4>
<ul>
<li><strong>Log Tab Key Alias</strong> - Fixed filtering inaccuracies for failed logs - <a href="https://github.com/BerriAI/litellm/pull/14469" target="_blank" rel="noopener noreferrer">PR #14469</a>, <a href="https://github.com/BerriAI/litellm/pull/14529" target="_blank" rel="noopener noreferrer">PR #14529</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-77-2#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-77-2#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Noma Integration</strong> - Added non-blocking monitor mode with anonymize input support - <a href="https://github.com/BerriAI/litellm/pull/14401" target="_blank" rel="noopener noreferrer">PR #14401</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-77-2#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="performance">Performance<a href="https://docs.litellm.ai/release_notes/v1-77-2#performance" class="hash-link" aria-label="Performance的直接链接" title="Performance的直接链接">​</a></h4>
<ul>
<li>Removed dynamic creation of static values - <a href="https://github.com/BerriAI/litellm/pull/14538" target="_blank" rel="noopener noreferrer">PR #14538</a></li>
<li>Using <code>_PROXY_MaxParallelRequestsHandler_v3</code> by default for optimal throughput - <a href="https://github.com/BerriAI/litellm/pull/14450" target="_blank" rel="noopener noreferrer">PR #14450</a></li>
<li>Improved execution context propagation into logging tasks - <a href="https://github.com/BerriAI/litellm/pull/14455" target="_blank" rel="noopener noreferrer">PR #14455</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-77-2#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@Sameerlite made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14460" target="_blank" rel="noopener noreferrer">PR #14460</a></li>
<li>@holzman made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14459" target="_blank" rel="noopener noreferrer">PR #14459</a></li>
<li>@sashank5644 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14469" target="_blank" rel="noopener noreferrer">PR #14469</a></li>
<li>@TomAlon made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14401" target="_blank" rel="noopener noreferrer">PR #14401</a></li>
<li>@AlexsanderHamir made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14538" target="_blank" rel="noopener noreferrer">PR #14538</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.77.1.dev.2...v1.77.2.dev" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-77-2#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.76.3-stable - Performance, Video Generation & CloudZero Integration]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-76-3</link>
            <guid>https://docs.litellm.ai/release_notes/v1-76-3</guid>
            <pubDate>Sat, 06 Sep 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[This release has a known issue where startup is leading to Out of Memory errors when deploying on Kubernetes. We recommend waiting before upgrading to this version.]]></description>
            <content:encoded><![CDATA[<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>注意</div><div class="admonitionContent_BuS1"><p>This release has a known issue where startup is leading to Out of Memory errors when deploying on Kubernetes. We recommend waiting before upgrading to this version.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-76-3#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.76.3</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.76.3</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-76-3#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Major Performance Improvements</strong> +400 RPS when using correct amount of workers + CPU cores combination</li>
<li><strong>Video Generation Support</strong> - Added Google AI Studio  and Vertex AI Veo Video Generation through LiteLLM Pass through routes</li>
<li><strong>CloudZero Integration</strong> - New cost tracking integration for exporting LiteLLM Usage and Spend data to CloudZero.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="major-changes">Major Changes<a href="https://docs.litellm.ai/release_notes/v1-76-3#major-changes" class="hash-link" aria-label="Major Changes的直接链接" title="Major Changes的直接链接">​</a></h2>
<ul>
<li>
<p><strong>Performance Optimization</strong>: LiteLLM Proxy now achieves +400 RPS when using correct amount of CPU cores - <a href="https://github.com/BerriAI/litellm/pull/14153" target="_blank" rel="noopener noreferrer">PR #14153</a>, <a href="https://github.com/BerriAI/litellm/pull/14242" target="_blank" rel="noopener noreferrer">PR #14242</a></p>
<p>By default, LiteLLM will now use <code>num_workers = os.cpu_count()</code> to achieve optimal performance.</p>
<p><strong>Override Options:</strong></p>
<p>Set environment variable:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">DEFAULT_NUM_WORKERS_LITELLM_PROXY=1</span><br></span></code></pre></div></div>
<p>Or start LiteLLM Proxy with:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">litellm --num_workers 1</span><br></span></code></pre></div></div>
</li>
<li>
<p><strong>Security Fix</strong>: Fixed memory_usage_in_mem_cache cache endpoint vulnerability - <a href="https://github.com/BerriAI/litellm/pull/14229" target="_blank" rel="noopener noreferrer">PR #14229</a></p>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-improvements">Performance Improvements<a href="https://docs.litellm.ai/release_notes/v1-76-3#performance-improvements" class="hash-link" aria-label="Performance Improvements的直接链接" title="Performance Improvements的直接链接">​</a></h2>
<p>This release includes significant performance optimizations. On our internal benchmarks we saw 1 instance get +400 RPS when using correct amount of  workers + CPU cores combination.</p>
<ul>
<li><strong>+400 RPS Performance Boost</strong> - LiteLLM Proxy now uses correct amount of CPU cores for optimal performance - <a href="https://github.com/BerriAI/litellm/pull/14153" target="_blank" rel="noopener noreferrer">PR #14153</a></li>
<li><strong>Default CPU Workers</strong> - Changed DEFAULT_NUM_WORKERS_LITELLM_PROXY default to number of CPUs - <a href="https://github.com/BerriAI/litellm/pull/14242" target="_blank" rel="noopener noreferrer">PR #14242</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-76-3#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-76-3#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>OpenRouter</td><td><code>openrouter/openai/gpt-4.1</code></td><td>1M</td><td>$2.00</td><td>$8.00</td><td>Chat completions with vision</td></tr><tr><td>OpenRouter</td><td><code>openrouter/openai/gpt-4.1-mini</code></td><td>1M</td><td>$0.40</td><td>$1.60</td><td>Efficient chat completions</td></tr><tr><td>OpenRouter</td><td><code>openrouter/openai/gpt-4.1-nano</code></td><td>1M</td><td>$0.10</td><td>$0.40</td><td>Ultra-efficient chat</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/openai/gpt-oss-20b-maas</code></td><td>131K</td><td>$0.075</td><td>$0.30</td><td>Reasoning support</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/openai/gpt-oss-120b-maas</code></td><td>131K</td><td>$0.15</td><td>$0.60</td><td>Advanced reasoning</td></tr><tr><td>Gemini</td><td><code>gemini/veo-3.0-generate-preview</code></td><td>1K</td><td>-</td><td>$0.75/sec</td><td>Video generation</td></tr><tr><td>Gemini</td><td><code>gemini/veo-3.0-fast-generate-preview</code></td><td>1K</td><td>-</td><td>$0.40/sec</td><td>Fast video generation</td></tr><tr><td>Gemini</td><td><code>gemini/veo-2.0-generate-001</code></td><td>1K</td><td>-</td><td>$0.35/sec</td><td>Video generation</td></tr><tr><td>Volcengine</td><td><code>doubao-embedding-large</code></td><td>4K</td><td>Free</td><td>Free</td><td>2048-dim embeddings</td></tr><tr><td>Together AI</td><td><code>together_ai/deepseek-ai/DeepSeek-V3.1</code></td><td>128K</td><td>$0.60</td><td>$1.70</td><td>Reasoning support</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Google Gemini</a></strong>
<ul>
<li>Added 'thoughtSignature' support via 'thinking_blocks' - <a href="https://github.com/BerriAI/litellm/pull/14122" target="_blank" rel="noopener noreferrer">PR #14122</a></li>
<li>Added support for reasoning_effort='minimal' for Gemini models - <a href="https://github.com/BerriAI/litellm/pull/14262" target="_blank" rel="noopener noreferrer">PR #14262</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Added GPT-4.1 model family - <a href="https://github.com/BerriAI/litellm/pull/14101" target="_blank" rel="noopener noreferrer">PR #14101</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/groq">Groq</a></strong>
<ul>
<li>Added support for reasoning_effort parameter - <a href="https://github.com/BerriAI/litellm/pull/14207" target="_blank" rel="noopener noreferrer">PR #14207</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/xai">X.AI</a></strong>
<ul>
<li>Fixed XAI cost calculation - <a href="https://github.com/BerriAI/litellm/pull/14127" target="_blank" rel="noopener noreferrer">PR #14127</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Added support for GPT-OSS models on Vertex AI - <a href="https://github.com/BerriAI/litellm/pull/14184" target="_blank" rel="noopener noreferrer">PR #14184</a></li>
<li>Added additionalProperties to Vertex AI Schema definition - <a href="https://github.com/BerriAI/litellm/pull/14252" target="_blank" rel="noopener noreferrer">PR #14252</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">VLLM</a></strong>
<ul>
<li>Handle output parsing responses API output - <a href="https://github.com/BerriAI/litellm/pull/14121" target="_blank" rel="noopener noreferrer">PR #14121</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong>
<ul>
<li>Added unified 'thinking' param support via <code>reasoning_content</code> - <a href="https://github.com/BerriAI/litellm/pull/14121" target="_blank" rel="noopener noreferrer">PR #14121</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Added supported text field to anthropic citation response - <a href="https://github.com/BerriAI/litellm/pull/14126" target="_blank" rel="noopener noreferrer">PR #14126</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI Provider</a></strong>
<ul>
<li>Handle assistant messages with both content and tool_calls - <a href="https://github.com/BerriAI/litellm/pull/14171" target="_blank" rel="noopener noreferrer">PR #14171</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Fixed structure output - <a href="https://github.com/BerriAI/litellm/pull/14130" target="_blank" rel="noopener noreferrer">PR #14130</a></li>
<li>Added initial support for Bedrock Batches API - <a href="https://github.com/BerriAI/litellm/pull/14190" target="_blank" rel="noopener noreferrer">PR #14190</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/databricks">Databricks</a></strong>
<ul>
<li>Added support for anthropic citation API in Databricks - <a href="https://github.com/BerriAI/litellm/pull/14077" target="_blank" rel="noopener noreferrer">PR #14077</a></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-76-3#bug-fixes" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Google Gemini (Google AI Studio + Vertex AI)</a></strong>
<ul>
<li>Fixed Gemini 2.5 Pro schema validation with OpenAI-style type arrays in tools - <a href="https://github.com/BerriAI/litellm/pull/14154" target="_blank" rel="noopener noreferrer">PR #14154</a></li>
<li>Fixed Gemini Tool Calling empty enum property - <a href="https://github.com/BerriAI/litellm/pull/14155" target="_blank" rel="noopener noreferrer">PR #14155</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-76-3#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/volcengine">Volcengine</a></strong>
<ul>
<li>Added Volcengine embedding module with handler and transformation logic - <a href="https://github.com/BerriAI/litellm/pull/14028" target="_blank" rel="noopener noreferrer">PR #14028</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-76-3#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/image_generation">Images API</a></strong>
<ul>
<li>Added pass through image generation and image editing on OpenAI - <a href="https://github.com/BerriAI/litellm/pull/14292" target="_blank" rel="noopener noreferrer">PR #14292</a></li>
<li>Support extra_body parameter for image generation - <a href="https://github.com/BerriAI/litellm/pull/14211" target="_blank" rel="noopener noreferrer">PR #14211</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>Fixed response API for reasoning item in input for litellm proxy - <a href="https://github.com/BerriAI/litellm/pull/14200" target="_blank" rel="noopener noreferrer">PR #14200</a></li>
<li>Added structured output for SDK - <a href="https://github.com/BerriAI/litellm/pull/14206" target="_blank" rel="noopener noreferrer">PR #14206</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/pass_through/bedrock">Bedrock Passthrough</a></strong>
<ul>
<li>Support AWS_BEDROCK_RUNTIME_ENDPOINT on bedrock passthrough - <a href="https://github.com/BerriAI/litellm/pull/14156" target="_blank" rel="noopener noreferrer">PR #14156</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/pass_through/google_ai_studio">Google AI Studio Passthrough</a></strong>
<ul>
<li>Allow using Veo Video Generation through LiteLLM Pass through routes - <a href="https://github.com/BerriAI/litellm/pull/14228" target="_blank" rel="noopener noreferrer">PR #14228</a></li>
</ul>
</li>
<li><strong>General</strong>
<ul>
<li>Added support for safety_identifier parameter in chat.completions.create - <a href="https://github.com/BerriAI/litellm/pull/14174" target="_blank" rel="noopener noreferrer">PR #14174</a></li>
<li>Fixed misclassified 500 error on invalid image_url in /chat/completions request - <a href="https://github.com/BerriAI/litellm/pull/14149" target="_blank" rel="noopener noreferrer">PR #14149</a></li>
<li>Fixed token count error for Gemini CLI - <a href="https://github.com/BerriAI/litellm/pull/14133" target="_blank" rel="noopener noreferrer">PR #14133</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-3#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Remove "/" or ":" from model name when being used as h11 header name - <a href="https://github.com/BerriAI/litellm/pull/14191" target="_blank" rel="noopener noreferrer">PR #14191</a></li>
<li>Bug fix for openai.gpt-oss when using reasoning_effort parameter - <a href="https://github.com/BerriAI/litellm/pull/14300" target="_blank" rel="noopener noreferrer">PR #14300</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spend-tracking-budgets-and-rate-limiting">Spend Tracking, Budgets and Rate Limiting<a href="https://docs.litellm.ai/release_notes/v1-76-3#spend-tracking-budgets-and-rate-limiting" class="hash-link" aria-label="Spend Tracking, Budgets and Rate Limiting的直接链接" title="Spend Tracking, Budgets and Rate Limiting的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h3>
<ul>
<li>Added header support for spend_logs_metadata - <a href="https://github.com/BerriAI/litellm/pull/14186" target="_blank" rel="noopener noreferrer">PR #14186</a></li>
<li>Litellm passthrough cost tracking for chat completion - <a href="https://github.com/BerriAI/litellm/pull/14256" target="_blank" rel="noopener noreferrer">PR #14256</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bug-fixes-1">Bug Fixes<a href="https://docs.litellm.ai/release_notes/v1-76-3#bug-fixes-1" class="hash-link" aria-label="Bug Fixes的直接链接" title="Bug Fixes的直接链接">​</a></h3>
<ul>
<li>Fixed TPM Rate Limit Bug - <a href="https://github.com/BerriAI/litellm/pull/14237" target="_blank" rel="noopener noreferrer">PR #14237</a></li>
<li>Fixed Key Budget not resets at expectable times - <a href="https://github.com/BerriAI/litellm/pull/14241" target="_blank" rel="noopener noreferrer">PR #14241</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-76-3#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>UI Improvements</strong>
<ul>
<li>Logs page screen size fixed - <a href="https://github.com/BerriAI/litellm/pull/14135" target="_blank" rel="noopener noreferrer">PR #14135</a></li>
<li>Create Organization Tooltip added on Success - <a href="https://github.com/BerriAI/litellm/pull/14132" target="_blank" rel="noopener noreferrer">PR #14132</a></li>
<li>Back to Keys should say Back to Logs - <a href="https://github.com/BerriAI/litellm/pull/14134" target="_blank" rel="noopener noreferrer">PR #14134</a></li>
<li>Add client side pagination on All Models table - <a href="https://github.com/BerriAI/litellm/pull/14136" target="_blank" rel="noopener noreferrer">PR #14136</a></li>
<li>Model Filters UI improvement - <a href="https://github.com/BerriAI/litellm/pull/14131" target="_blank" rel="noopener noreferrer">PR #14131</a></li>
<li>Remove table filter on user info page - <a href="https://github.com/BerriAI/litellm/pull/14169" target="_blank" rel="noopener noreferrer">PR #14169</a></li>
<li>Team name badge added on the User Details - <a href="https://github.com/BerriAI/litellm/pull/14003" target="_blank" rel="noopener noreferrer">PR #14003</a></li>
<li>Fix: Log page parameter passing error - <a href="https://github.com/BerriAI/litellm/pull/14193" target="_blank" rel="noopener noreferrer">PR #14193</a></li>
</ul>
</li>
<li><strong>Authentication &amp; Authorization</strong>
<ul>
<li>Support for ES256/ES384/ES512 and EdDSA JWT verification - <a href="https://github.com/BerriAI/litellm/pull/14118" target="_blank" rel="noopener noreferrer">PR #14118</a></li>
<li>Ensure <code>team_id</code> is a required field for generating service account keys - <a href="https://github.com/BerriAI/litellm/pull/14270" target="_blank" rel="noopener noreferrer">PR #14270</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-3#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Validate store model in db setting - <a href="https://github.com/BerriAI/litellm/pull/14269" target="_blank" rel="noopener noreferrer">PR #14269</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-76-3#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-4">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-4" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">Datadog</a></strong>
<ul>
<li>Ensure <code>apm_id</code> is set on DD LLM Observability traces - <a href="https://github.com/BerriAI/litellm/pull/14272" target="_blank" rel="noopener noreferrer">PR #14272</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#braintrust">Braintrust</a></strong>
<ul>
<li>Fix logging when OTEL is enabled - <a href="https://github.com/BerriAI/litellm/pull/14122" target="_blank" rel="noopener noreferrer">PR #14122</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#otel">OTEL</a></strong>
<ul>
<li>Optional Metrics and Logs following semantic conventions - <a href="https://github.com/BerriAI/litellm/pull/14179" target="_blank" rel="noopener noreferrer">PR #14179</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/alerting">Slack Alerting</a></strong>
<ul>
<li>Added alert type to alert message to slack for easier handling - <a href="https://github.com/BerriAI/litellm/pull/14176" target="_blank" rel="noopener noreferrer">PR #14176</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="guardrails">Guardrails<a href="https://docs.litellm.ai/release_notes/v1-76-3#guardrails" class="hash-link" aria-label="Guardrails的直接链接" title="Guardrails的直接链接">​</a></h4>
<ul>
<li>Added guardrail to the Anthropic API endpoint - <a href="https://github.com/BerriAI/litellm/pull/14107" target="_blank" rel="noopener noreferrer">PR #14107</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-integration">New Integration<a href="https://docs.litellm.ai/release_notes/v1-76-3#new-integration" class="hash-link" aria-label="New Integration的直接链接" title="New Integration的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/cost_tracking">CloudZero</a></strong>
<ul>
<li>LiteLLM x CloudZero Integration for Cost Tracking - <a href="https://github.com/BerriAI/litellm/pull/14296" target="_blank" rel="noopener noreferrer">PR #14296</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-76-3#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-5">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-5" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Performance</strong>
<ul>
<li>LiteLLM Proxy: +400 RPS when using correct amount of CPU cores - <a href="https://github.com/BerriAI/litellm/pull/14153" target="_blank" rel="noopener noreferrer">PR #14153</a></li>
<li>Allow using <code>x-litellm-stream-timeout</code> header for stream timeout in requests - <a href="https://github.com/BerriAI/litellm/pull/14147" target="_blank" rel="noopener noreferrer">PR #14147</a></li>
<li>Change DEFAULT_NUM_WORKERS_LITELLM_PROXY default to number CPUs - <a href="https://github.com/BerriAI/litellm/pull/14242" target="_blank" rel="noopener noreferrer">PR #14242</a></li>
</ul>
</li>
<li><strong>Monitoring</strong>
<ul>
<li>Added Prometheus missing metrics - <a href="https://github.com/BerriAI/litellm/pull/14139" target="_blank" rel="noopener noreferrer">PR #14139</a></li>
</ul>
</li>
<li><strong>Timeout</strong>
<ul>
<li><strong>Stream Timeout Control</strong> - Allow using <code>x-litellm-stream-timeout</code> header for stream timeout in requests - <a href="https://github.com/BerriAI/litellm/pull/14147" target="_blank" rel="noopener noreferrer">PR #14147</a></li>
</ul>
</li>
<li><strong>Routing</strong>
<ul>
<li>Fixed x-litellm-tags not routing with Responses API - <a href="https://github.com/BerriAI/litellm/pull/14289" target="_blank" rel="noopener noreferrer">PR #14289</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-3#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Security</strong>
<ul>
<li>Fixed memory_usage_in_mem_cache cache endpoint vulnerability - <a href="https://github.com/BerriAI/litellm/pull/14229" target="_blank" rel="noopener noreferrer">PR #14229</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-76-3#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-6">Features<a href="https://docs.litellm.ai/release_notes/v1-76-3#features-6" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>SCIM Support</strong>
<ul>
<li>Added better SCIM debugging - <a href="https://github.com/BerriAI/litellm/pull/14221" target="_blank" rel="noopener noreferrer">PR #14221</a></li>
<li>Bug fixes for handling SCIM Group Memberships - <a href="https://github.com/BerriAI/litellm/pull/14226" target="_blank" rel="noopener noreferrer">PR #14226</a></li>
</ul>
</li>
<li><strong>Kubernetes</strong>
<ul>
<li>Added optional PodDisruptionBudget for litellm proxy - <a href="https://github.com/BerriAI/litellm/pull/14093" target="_blank" rel="noopener noreferrer">PR #14093</a></li>
</ul>
</li>
<li><strong>Error Handling</strong>
<ul>
<li>Add model to azure error message - <a href="https://github.com/BerriAI/litellm/pull/14294" target="_blank" rel="noopener noreferrer">PR #14294</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-76-3#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@iabhi4 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14093" target="_blank" rel="noopener noreferrer">PR #14093</a></li>
<li>@zainhas made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14087" target="_blank" rel="noopener noreferrer">PR #14087</a></li>
<li>@LifeDJIK made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14146" target="_blank" rel="noopener noreferrer">PR #14146</a></li>
<li>@retanoj made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14133" target="_blank" rel="noopener noreferrer">PR #14133</a></li>
<li>@zhxlp made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14193" target="_blank" rel="noopener noreferrer">PR #14193</a></li>
<li>@kayoch1n made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14191" target="_blank" rel="noopener noreferrer">PR #14191</a></li>
<li>@kutsushitaneko made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14171" target="_blank" rel="noopener noreferrer">PR #14171</a></li>
<li>@mjmendo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14176" target="_blank" rel="noopener noreferrer">PR #14176</a></li>
<li>@HarshavardhanK made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14213" target="_blank" rel="noopener noreferrer">PR #14213</a></li>
<li>@eycjur made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14207" target="_blank" rel="noopener noreferrer">PR #14207</a></li>
<li>@22mSqRi made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14241" target="_blank" rel="noopener noreferrer">PR #14241</a></li>
<li>@onlylhf made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14028" target="_blank" rel="noopener noreferrer">PR #14028</a></li>
<li>@btpemercier made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/11319" target="_blank" rel="noopener noreferrer">PR #11319</a></li>
<li>@tremlin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14287" target="_blank" rel="noopener noreferrer">PR #14287</a></li>
<li>@TobiMayr made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14262" target="_blank" rel="noopener noreferrer">PR #14262</a></li>
<li>@Eitan1112 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14252" target="_blank" rel="noopener noreferrer">PR #14252</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.76.1-nightly...v1.76.3-nightly" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-76-3#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.76.1-stable - Gemini 2.5 Flash Image]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-76-1</link>
            <guid>https://docs.litellm.ai/release_notes/v1-76-1</guid>
            <pubDate>Sat, 30 Aug 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-76-1#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.76.1</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.76.1</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-76-1#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Major Performance Improvements</strong> - 6.5x faster LiteLLM Python SDK completion with fastuuid integration.</li>
<li><strong>New Model Support</strong> - Gemini 2.5 Flash Image Preview, Grok Code Fast, and GPT Realtime models</li>
<li><strong>Enhanced Provider Support</strong> - DeepSeek-v3.1 pricing on Fireworks AI, Vercel AI Gateway, and improved Anthropic/GitHub Copilot integration</li>
<li><strong>MCP Improvements</strong> - Better connection testing and SSE MCP tools bug fixes</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="major-changes">Major Changes<a href="https://docs.litellm.ai/release_notes/v1-76-1#major-changes" class="hash-link" aria-label="Major Changes的直接链接" title="Major Changes的直接链接">​</a></h2>
<ul>
<li>Added support for using Gemini 2.5 Flash Image Preview with /chat/completions. <strong>🚨 Warning</strong> If you were using <code>gemini-2.0-flash-exp-image-generation</code> please follow this migration guide.
<a href="https://docs.litellm.ai/docs/extras/gemini_img_migration">Gemini Image Generation Migration Guide</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-improvements">Performance Improvements<a href="https://docs.litellm.ai/release_notes/v1-76-1#performance-improvements" class="hash-link" aria-label="Performance Improvements的直接链接" title="Performance Improvements的直接链接">​</a></h2>
<p>This release includes significant performance optimizations:</p>
<ul>
<li><strong>6.5x faster LiteLLM Python SDK Completion</strong> - Major performance boost for completion operations - <a href="https://github.com/BerriAI/litellm/pull/13990" target="_blank" rel="noopener noreferrer">PR #13990</a></li>
<li><strong>fastuuid Integration</strong> - 2.1x faster UUID generation with +80 RPS improvement for /chat/completions and other LLM endpoints - <a href="https://github.com/BerriAI/litellm/pull/13992" target="_blank" rel="noopener noreferrer">PR #13992</a>, <a href="https://github.com/BerriAI/litellm/pull/14016" target="_blank" rel="noopener noreferrer">PR #14016</a></li>
<li><strong>Optimized Request Logging</strong> - Don't print request params by default for +50 RPS improvement - <a href="https://github.com/BerriAI/litellm/pull/14015" target="_blank" rel="noopener noreferrer">PR #14015</a></li>
<li><strong>Cache Performance</strong> - 21% speedup in InMemoryCache.evict_cache and 45% speedup in <code>_is_debugging_on</code> function - <a href="https://github.com/BerriAI/litellm/pull/14012" target="_blank" rel="noopener noreferrer">PR #14012</a>, <a href="https://github.com/BerriAI/litellm/pull/13988" target="_blank" rel="noopener noreferrer">PR #13988</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-76-1#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-76-1#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Google</td><td><code>gemini-2.5-flash-image-preview</code></td><td>1M</td><td>$0.30</td><td>$2.50</td><td>Chat completions + image generation ($0.039/image)</td></tr><tr><td>X.AI</td><td><code>xai/grok-code-fast</code></td><td>256K</td><td>$0.20</td><td>$1.50</td><td>Code generation</td></tr><tr><td>OpenAI</td><td><code>gpt-realtime</code></td><td>32K</td><td>$4.00</td><td>$16.00</td><td>Real-time conversation + audio</td></tr><tr><td>Vercel AI Gateway</td><td><code>vercel_ai_gateway/openai/o3</code></td><td>200K</td><td>$2.00</td><td>$8.00</td><td>Advanced reasoning</td></tr><tr><td>Vercel AI Gateway</td><td><code>vercel_ai_gateway/openai/o3-mini</code></td><td>200K</td><td>$1.10</td><td>$4.40</td><td>Efficient reasoning</td></tr><tr><td>Vercel AI Gateway</td><td><code>vercel_ai_gateway/openai/o4-mini</code></td><td>200K</td><td>$1.10</td><td>$4.40</td><td>Latest mini model</td></tr><tr><td>DeepInfra</td><td><code>deepinfra/zai-org/GLM-4.5</code></td><td>131K</td><td>$0.55</td><td>$2.00</td><td>Chat completions</td></tr><tr><td>Perplexity</td><td><code>perplexity/codellama-34b-instruct</code></td><td>16K</td><td>$0.35</td><td>$1.40</td><td>Code generation</td></tr><tr><td>Fireworks AI</td><td><code>fireworks_ai/accounts/fireworks/models/deepseek-v3p1</code></td><td>128K</td><td>$0.56</td><td>$1.68</td><td>Chat completions</td></tr></tbody></table>
<p><strong>Additional Models Added:</strong> Various other Vercel AI Gateway models were added too. See <a href="https://models.litellm.ai/" target="_blank" rel="noopener noreferrer">models.litellm.ai</a> for the full list.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Google Gemini</a></strong>
<ul>
<li>Added support for <code>gemini-2.5-flash-image-preview</code> with image return capability - <a href="https://github.com/BerriAI/litellm/pull/13979" target="_blank" rel="noopener noreferrer">PR #13979</a>, <a href="https://github.com/BerriAI/litellm/pull/13983" target="_blank" rel="noopener noreferrer">PR #13983</a></li>
<li>Support for requests with only system prompt - <a href="https://github.com/BerriAI/litellm/pull/14010" target="_blank" rel="noopener noreferrer">PR #14010</a></li>
<li>Fixed invalid model name error for Gemini Imagen models - <a href="https://github.com/BerriAI/litellm/pull/13991" target="_blank" rel="noopener noreferrer">PR #13991</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/xai">X.AI</a></strong>
<ul>
<li>Added <code>xai/grok-code-fast</code> model family support - <a href="https://github.com/BerriAI/litellm/pull/14054" target="_blank" rel="noopener noreferrer">PR #14054</a></li>
<li>Fixed frequency_penalty parameter for grok-4 models - <a href="https://github.com/BerriAI/litellm/pull/14078" target="_blank" rel="noopener noreferrer">PR #14078</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Added support for gpt-realtime models - <a href="https://github.com/BerriAI/litellm/pull/14082" target="_blank" rel="noopener noreferrer">PR #14082</a></li>
<li>Support for reasoning and reasoning_effort parameters by default - <a href="https://github.com/BerriAI/litellm/pull/12865" target="_blank" rel="noopener noreferrer">PR #12865</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI</a></strong>
<ul>
<li>Added DeepSeek-v3.1 pricing - <a href="https://github.com/BerriAI/litellm/pull/13958" target="_blank" rel="noopener noreferrer">PR #13958</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/deepinfra">DeepInfra</a></strong>
<ul>
<li>Fixed reasoning_effort setting for DeepSeek-V3.1 - <a href="https://github.com/BerriAI/litellm/pull/14053" target="_blank" rel="noopener noreferrer">PR #14053</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/github_copilot">GitHub Copilot</a></strong>
<ul>
<li>Added support for thinking and reasoning_effort parameters - <a href="https://github.com/BerriAI/litellm/pull/13691" target="_blank" rel="noopener noreferrer">PR #13691</a></li>
<li>Added image headers support - <a href="https://github.com/BerriAI/litellm/pull/13955" target="_blank" rel="noopener noreferrer">PR #13955</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Support for custom Anthropic-compatible API endpoints - <a href="https://github.com/BerriAI/litellm/pull/13945" target="_blank" rel="noopener noreferrer">PR #13945</a></li>
<li>Fixed /messages fallback from Anthropic API to Bedrock API - <a href="https://github.com/BerriAI/litellm/pull/13946" target="_blank" rel="noopener noreferrer">PR #13946</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/nebius">Nebius</a></strong>
<ul>
<li>Expanded provider models and normalized model IDs - <a href="https://github.com/BerriAI/litellm/pull/13965" target="_blank" rel="noopener noreferrer">PR #13965</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Fixed Vertex Mistral streaming issues - <a href="https://github.com/BerriAI/litellm/pull/13952" target="_blank" rel="noopener noreferrer">PR #13952</a></li>
<li>Fixed anyOf corner cases for Gemini tool calls - <a href="https://github.com/BerriAI/litellm/pull/12797" target="_blank" rel="noopener noreferrer">PR #12797</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Fixed structure output issues - <a href="https://github.com/BerriAI/litellm/pull/14005" target="_blank" rel="noopener noreferrer">PR #14005</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Added GPT-5 family models pricing - <a href="https://github.com/BerriAI/litellm/pull/13536" target="_blank" rel="noopener noreferrer">PR #13536</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-provider-support">New Provider Support<a href="https://docs.litellm.ai/release_notes/v1-76-1#new-provider-support" class="hash-link" aria-label="New Provider Support的直接链接" title="New Provider Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vercel_ai_gateway">Vercel AI Gateway</a></strong>
<ul>
<li>New provider support added - <a href="https://github.com/BerriAI/litellm/pull/13144" target="_blank" rel="noopener noreferrer">PR #13144</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/datarobot">DataRobot</a></strong>
<ul>
<li>Added provider documentation - <a href="https://github.com/BerriAI/litellm/pull/14038" target="_blank" rel="noopener noreferrer">PR #14038</a>, <a href="https://github.com/BerriAI/litellm/pull/14074" target="_blank" rel="noopener noreferrer">PR #14074</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-76-1#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/image_generation">Images API</a></strong>
<ul>
<li>Support for multiple images in OpenAI images/edits endpoint - <a href="https://github.com/BerriAI/litellm/pull/13916" target="_blank" rel="noopener noreferrer">PR #13916</a></li>
<li>Allow using dynamic <code>api_key</code> for image generation requests - <a href="https://github.com/BerriAI/litellm/pull/14007" target="_blank" rel="noopener noreferrer">PR #14007</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>Fixed <code>/responses</code> endpoint ignoring extra_headers in GitHub Copilot - <a href="https://github.com/BerriAI/litellm/pull/13775" target="_blank" rel="noopener noreferrer">PR #13775</a></li>
<li>Added support for new web_search tool - <a href="https://github.com/BerriAI/litellm/pull/14083" target="_blank" rel="noopener noreferrer">PR #14083</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure/azure">Azure Passthrough</a></strong>
<ul>
<li>Fixed Azure Passthrough request with streaming - <a href="https://github.com/BerriAI/litellm/pull/13831" target="_blank" rel="noopener noreferrer">PR #13831</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-1#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>General</strong>
<ul>
<li>Fixed handling of None metadata in batch requests - <a href="https://github.com/BerriAI/litellm/pull/13996" target="_blank" rel="noopener noreferrer">PR #13996</a></li>
<li>Fixed token_counter with special token input - <a href="https://github.com/BerriAI/litellm/pull/13374" target="_blank" rel="noopener noreferrer">PR #13374</a></li>
<li>Removed incorrect web search support for azure/gpt-4.1 family - <a href="https://github.com/BerriAI/litellm/pull/13566" target="_blank" rel="noopener noreferrer">PR #13566</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway"><a href="https://docs.litellm.ai/docs/mcp">MCP Gateway</a><a href="https://docs.litellm.ai/release_notes/v1-76-1#mcp-gateway" class="hash-link" aria-label="mcp-gateway的直接链接" title="mcp-gateway的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>SSE MCP Tools</strong>
<ul>
<li>Bug fix for adding SSE MCP tools - improved connection testing when adding MCPs - <a href="https://github.com/BerriAI/litellm/pull/14048" target="_blank" rel="noopener noreferrer">PR #14048</a></li>
</ul>
</li>
</ul>
<p><a href="https://docs.litellm.ai/docs/mcp">Read More</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-76-1#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Team Management</strong>
<ul>
<li>Allow setting Team Member RPM/TPM limits when creating a team - <a href="https://github.com/BerriAI/litellm/pull/13943" target="_blank" rel="noopener noreferrer">PR #13943</a></li>
</ul>
</li>
<li><strong>UI Improvements</strong>
<ul>
<li>Fixed Next.js Security Vulnerabilities in UI Dashboard - <a href="https://github.com/BerriAI/litellm/pull/14084" target="_blank" rel="noopener noreferrer">PR #14084</a></li>
<li>Fixed collapsible navbar design - <a href="https://github.com/BerriAI/litellm/pull/14075" target="_blank" rel="noopener noreferrer">PR #14075</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-1#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Authentication</strong>
<ul>
<li>Fixed Virtual keys with llm_api type causing Internal Server Error for /anthropic/* and other LLM passthrough routes - <a href="https://github.com/BerriAI/litellm/pull/14046" target="_blank" rel="noopener noreferrer">PR #14046</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-76-1#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-4">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-4" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse OTEL</a></strong>
<ul>
<li>Allow using LANGFUSE_OTEL_HOST for configuring host - <a href="https://github.com/BerriAI/litellm/pull/14013" target="_blank" rel="noopener noreferrer">PR #14013</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#braintrust">Braintrust</a></strong>
<ul>
<li>Added span name metadata feature - <a href="https://github.com/BerriAI/litellm/pull/13573" target="_blank" rel="noopener noreferrer">PR #13573</a></li>
<li>Fixed tests to reference moved attributes in <code>braintrust_logging</code> module - <a href="https://github.com/BerriAI/litellm/pull/13978" target="_blank" rel="noopener noreferrer">PR #13978</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#openmeter">OpenMeter</a></strong>
<ul>
<li>Set user from token user_id for OpenMeter integration - <a href="https://github.com/BerriAI/litellm/pull/13152" target="_blank" rel="noopener noreferrer">PR #13152</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-guardrail-support">New Guardrail Support<a href="https://docs.litellm.ai/release_notes/v1-76-1#new-guardrail-support" class="hash-link" aria-label="New Guardrail Support的直接链接" title="New Guardrail Support的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Noma Security</a></strong>
<ul>
<li>Added Noma Security guardrail support - <a href="https://github.com/BerriAI/litellm/pull/13572" target="_blank" rel="noopener noreferrer">PR #13572</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails">Pangea</a></strong>
<ul>
<li>Updated Pangea Guardrail to support new AIDR endpoint - <a href="https://github.com/BerriAI/litellm/pull/13160" target="_blank" rel="noopener noreferrer">PR #13160</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-76-1#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-5">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-5" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Caching</strong>
<ul>
<li>Verify if cache entry has expired prior to serving it to client - <a href="https://github.com/BerriAI/litellm/pull/13933" target="_blank" rel="noopener noreferrer">PR #13933</a></li>
<li>Fixed error saving latency as timedelta on Redis - <a href="https://github.com/BerriAI/litellm/pull/14040" target="_blank" rel="noopener noreferrer">PR #14040</a></li>
</ul>
</li>
<li><strong>Router</strong>
<ul>
<li>Refactored router to choose weights by 'weight', 'rpm', 'tpm' in one loop for simple_shuffle - <a href="https://github.com/BerriAI/litellm/pull/13562" target="_blank" rel="noopener noreferrer">PR #13562</a></li>
</ul>
</li>
<li><strong>Logging</strong>
<ul>
<li>Fixed LoggingWorker graceful shutdown to prevent CancelledError warnings - <a href="https://github.com/BerriAI/litellm/pull/14050" target="_blank" rel="noopener noreferrer">PR #14050</a></li>
<li>Enhanced logging for containers to log on files both with usual format and json format - <a href="https://github.com/BerriAI/litellm/pull/13394" target="_blank" rel="noopener noreferrer">PR #13394</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-1#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Dependencies</strong>
<ul>
<li>Bumped <code>orjson</code> version to "3.11.2" - <a href="https://github.com/BerriAI/litellm/pull/13969" target="_blank" rel="noopener noreferrer">PR #13969</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-76-1#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-6">Features<a href="https://docs.litellm.ai/release_notes/v1-76-1#features-6" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>AWS</strong>
<ul>
<li>Add support for AWS assume_role with a session token - <a href="https://github.com/BerriAI/litellm/pull/13919" target="_blank" rel="noopener noreferrer">PR #13919</a></li>
</ul>
</li>
<li><strong>OCI Provider</strong>
<ul>
<li>Added oci_key_file as an optional_parameter - <a href="https://github.com/BerriAI/litellm/pull/14036" target="_blank" rel="noopener noreferrer">PR #14036</a></li>
</ul>
</li>
<li><strong>Configuration</strong>
<ul>
<li>Allow configuration to set threshold before request entry in spend log gets truncated - <a href="https://github.com/BerriAI/litellm/pull/14042" target="_blank" rel="noopener noreferrer">PR #14042</a></li>
<li>Enhanced proxy_config configuration: add support for existing configmap in Helm charts - <a href="https://github.com/BerriAI/litellm/pull/14041" target="_blank" rel="noopener noreferrer">PR #14041</a></li>
</ul>
</li>
<li><strong>Docker</strong>
<ul>
<li>Added back supervisor to non-root image - <a href="https://github.com/BerriAI/litellm/pull/13922" target="_blank" rel="noopener noreferrer">PR #13922</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-76-1#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@ArthurRenault made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13922" target="_blank" rel="noopener noreferrer">PR #13922</a></li>
<li>@stevenmanton made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13919" target="_blank" rel="noopener noreferrer">PR #13919</a></li>
<li>@uc4w6c made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13914" target="_blank" rel="noopener noreferrer">PR #13914</a></li>
<li>@nielsbosma made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13573" target="_blank" rel="noopener noreferrer">PR #13573</a></li>
<li>@Yuki-Imajuku made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13567" target="_blank" rel="noopener noreferrer">PR #13567</a></li>
<li>@codeflash-ai[bot] made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13988" target="_blank" rel="noopener noreferrer">PR #13988</a></li>
<li>@ColeFrench made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13978" target="_blank" rel="noopener noreferrer">PR #13978</a></li>
<li>@dttran-glo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13969" target="_blank" rel="noopener noreferrer">PR #13969</a></li>
<li>@manascb1344 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13965" target="_blank" rel="noopener noreferrer">PR #13965</a></li>
<li>@DorZion made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13572" target="_blank" rel="noopener noreferrer">PR #13572</a></li>
<li>@edwardsamuel made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13536" target="_blank" rel="noopener noreferrer">PR #13536</a></li>
<li>@blahgeek made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13374" target="_blank" rel="noopener noreferrer">PR #13374</a></li>
<li>@Deviad made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13394" target="_blank" rel="noopener noreferrer">PR #13394</a></li>
<li>@XSAM made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13775" target="_blank" rel="noopener noreferrer">PR #13775</a></li>
<li>@KRRT7 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14012" target="_blank" rel="noopener noreferrer">PR #14012</a></li>
<li>@ikaadil made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13991" target="_blank" rel="noopener noreferrer">PR #13991</a></li>
<li>@timelfrink made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13691" target="_blank" rel="noopener noreferrer">PR #13691</a></li>
<li>@qidu made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13562" target="_blank" rel="noopener noreferrer">PR #13562</a></li>
<li>@nagyv made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13243" target="_blank" rel="noopener noreferrer">PR #13243</a></li>
<li>@xywei made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12885" target="_blank" rel="noopener noreferrer">PR #12885</a></li>
<li>@ericgtkb made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12797" target="_blank" rel="noopener noreferrer">PR #12797</a></li>
<li>@NoWall57 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13945" target="_blank" rel="noopener noreferrer">PR #13945</a></li>
<li>@lmwang9527 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14050" target="_blank" rel="noopener noreferrer">PR #14050</a></li>
<li>@WilsonSunBritten made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14042" target="_blank" rel="noopener noreferrer">PR #14042</a></li>
<li>@Const-antine made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14041" target="_blank" rel="noopener noreferrer">PR #14041</a></li>
<li>@dmvieira made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14040" target="_blank" rel="noopener noreferrer">PR #14040</a></li>
<li>@gotsysdba made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14036" target="_blank" rel="noopener noreferrer">PR #14036</a></li>
<li>@moshemorad made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/14005" target="_blank" rel="noopener noreferrer">PR #14005</a></li>
<li>@joshualipman123 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13144" target="_blank" rel="noopener noreferrer">PR #13144</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.76.0-nightly...v1.76.1" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-76-1#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.76.0-stable - RPS Improvements]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-76-0</link>
            <guid>https://docs.litellm.ai/release_notes/v1-76-0</guid>
            <pubDate>Sat, 23 Aug 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[LiteLLM is hiring a Founding Backend Engineer, in San Francisco.]]></description>
            <content:encoded><![CDATA[<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>信息</div><div class="admonitionContent_BuS1"><p>LiteLLM is hiring a <strong>Founding Backend Engineer</strong>, in San Francisco.</p><p><a href="https://www.ycombinator.com/companies/litellm/jobs/6uvoBp3-founding-backend-engineer" target="_blank" rel="noopener noreferrer">Apply here</a> if you're interested!</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-76-0#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>信息</div><div class="admonitionContent_BuS1"><p>This release is not live yet.</p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-76-0#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Gpt-5 chat: clarify does not support function calling <a href="https://github.com/BerriAI/litellm/pull/13612" target="_blank" rel="noopener noreferrer">PR #13612</a>, s/o &nbsp;@<a href="https://github.com/superpoussin22" target="_blank" rel="noopener noreferrer">superpoussin22</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">VertexAI</a></strong>
<ul>
<li>fix vertexai batch file format by&nbsp;@<a href="https://github.com/thiagosalvatore" target="_blank" rel="noopener noreferrer">thiagosalvatore</a>&nbsp;in&nbsp;<a href="https://github.com/BerriAI/litellm/pull/13576" target="_blank" rel="noopener noreferrer">PR #13576</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/litellm_proxy">LiteLLM Proxy</a></strong>
<ul>
<li>Add support for calling image_edits + image_generations via SDK to Proxy - <a href="https://github.com/BerriAI/litellm/pull/13735" target="_blank" rel="noopener noreferrer">PR #13735</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Fix max_output_tokens value for anthropic Claude 4 - <a href="https://github.com/BerriAI/litellm/pull/13526" target="_blank" rel="noopener noreferrer">PR #13526</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Fix prompt caching cost calculation - <a href="https://github.com/BerriAI/litellm/pull/13742" target="_blank" rel="noopener noreferrer">PR #13742</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong>
<ul>
<li>Support <code>../openai/v1/respones</code> api base - <a href="https://github.com/BerriAI/litellm/pull/13526" target="_blank" rel="noopener noreferrer">PR #13526</a></li>
<li>Fix azure/gpt-5-chat max_input_tokens - <a href="https://github.com/BerriAI/litellm/pull/13660" target="_blank" rel="noopener noreferrer">PR #13660</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/groq">Groq</a></strong>
<ul>
<li>streaming ASCII encoding issue - <a href="https://github.com/BerriAI/litellm/pull/13675" target="_blank" rel="noopener noreferrer">PR #13675</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/baseten">Baseten</a></strong>
<ul>
<li>Refactored integration to use new openai-compatible endpoints - <a href="https://github.com/BerriAI/litellm/pull/13783" target="_blank" rel="noopener noreferrer">PR #13783</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>fix application inference profile for pass-through endpoints for bedrock - <a href="https://github.com/BerriAI/litellm/pull/13881" target="_blank" rel="noopener noreferrer">PR #13881</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/datarobot">DataRobot</a></strong>
<ul>
<li>Updated URL handling for DataRobot provider URL - <a href="https://github.com/BerriAI/litellm/pull/13880" target="_blank" rel="noopener noreferrer">PR #13880</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-76-0#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/together">Together AI</a></strong>
<ul>
<li>Added Qwen3, Deepseek R1 0528 Throughput, GLM 4.5 and GPT-OSS models cost tracking - <a href="https://github.com/BerriAI/litellm/pull/13637" target="_blank" rel="noopener noreferrer">PR #13637</a>, s/o &nbsp;@<a href="https://github.com/Tasmay-Tibrewal" target="_blank" rel="noopener noreferrer">Tasmay-Tibrewal</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/fireworks_ai">Fireworks AI</a></strong>
<ul>
<li>add fireworks_ai/accounts/fireworks/models/deepseek-v3-0324 - <a href="https://github.com/BerriAI/litellm/pull/13821" target="_blank" rel="noopener noreferrer">PR #13821</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">VertexAI</a></strong>
<ul>
<li>Add VertexAI qwen API Service - <a href="https://github.com/BerriAI/litellm/pull/13828" target="_blank" rel="noopener noreferrer">PR #13828</a></li>
<li>Add new VertexAI image models&nbsp;vertex_ai/imagen-4.0-generate-001,&nbsp;vertex_ai/imagen-4.0-ultra-generate-001,&nbsp;vertex_ai/imagen-4.0-fast-generate-001&nbsp; - <a href="https://github.com/BerriAI/litellm/pull/13874" target="_blank" rel="noopener noreferrer">PR #13874</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Add long context support w/ cost tracking - <a href="https://github.com/BerriAI/litellm/pull/13759" target="_blank" rel="noopener noreferrer">PR #13759</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/deepinfra">DeepInfra</a></strong>
<ul>
<li>Add rerank endpoint support for deepinfra - <a href="https://github.com/BerriAI/litellm/pull/13820" target="_blank" rel="noopener noreferrer">PR #13820</a></li>
<li>Add new models for cost tracking - <a href="https://github.com/BerriAI/litellm/pull/13883" target="_blank" rel="noopener noreferrer">PR #13883</a>, s/o &nbsp;@<a href="https://github.com/Toy-97" target="_blank" rel="noopener noreferrer">Toy-97</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Add tool prompt caching on async calls - <a href="https://github.com/BerriAI/litellm/pull/13803" target="_blank" rel="noopener noreferrer">PR #13803</a>, s/o &nbsp;@<a href="https://github.com/UlookEE" target="_blank" rel="noopener noreferrer">UlookEE</a></li>
<li>role chaining and session name with webauthentication for aws bedrock - <a href="https://github.com/BerriAI/litellm/pull/13753" target="_blank" rel="noopener noreferrer">PR #13753</a>, s/o @<a href="https://github.com/RichardoC" target="_blank" rel="noopener noreferrer">RichardoC</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong>
<ul>
<li>Handle Ollama null response when using tool calling with non-tool trained models - <a href="https://github.com/BerriAI/litellm/pull/13902" target="_blank" rel="noopener noreferrer">PR #13902</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Add deepseek/deepseek-chat-v3.1 support - <a href="https://github.com/BerriAI/litellm/pull/13897" target="_blank" rel="noopener noreferrer">PR #13897</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong>
<ul>
<li>Add support for calling mistral files via chat completions - <a href="https://github.com/BerriAI/litellm/pull/13866" target="_blank" rel="noopener noreferrer">PR #13866</a>, s/o &nbsp;@<a href="https://github.com/jinskjoy" target="_blank" rel="noopener noreferrer">jinskjoy</a></li>
<li>Handle empty assistant content - <a href="https://github.com/BerriAI/litellm/pull/13671" target="_blank" rel="noopener noreferrer">PR #13671</a></li>
<li>Support new ‘thinking’ response block - <a href="https://github.com/BerriAI/litellm/pull/13671" target="_blank" rel="noopener noreferrer">PR #13671</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/databricks">Databricks</a></strong>
<ul>
<li>remove deprecated dbrx models (dbrx-instruct, llama 3.1) - <a href="https://github.com/BerriAI/litellm/pull/13843" target="_blank" rel="noopener noreferrer">PR #13843</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ai_ml_api">AI/ML API</a></strong>
<ul>
<li>Image gen api support - <a href="https://github.com/BerriAI/litellm/pull/13893" target="_blank" rel="noopener noreferrer">PR #13893</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-76-0#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>add default api version for openai responses api calls - <a href="https://github.com/BerriAI/litellm/pull/13526" target="_blank" rel="noopener noreferrer">PR #13526</a></li>
<li>support&nbsp;allowed_openai_params - <a href="https://github.com/BerriAI/litellm/pull/13671" target="_blank" rel="noopener noreferrer">PR #13671</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway">MCP Gateway<a href="https://docs.litellm.ai/release_notes/v1-76-0#mcp-gateway" class="hash-link" aria-label="MCP Gateway的直接链接" title="MCP Gateway的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li>fix StreamableHTTPSessionManager .run() error - <a href="https://github.com/BerriAI/litellm/pull/13666" target="_blank" rel="noopener noreferrer">PR #13666</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="vector-stores">Vector Stores<a href="https://docs.litellm.ai/release_notes/v1-76-0#vector-stores" class="hash-link" aria-label="Vector Stores的直接链接" title="Vector Stores的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-3">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-3" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">Bedrock</a></strong>
<ul>
<li>Using LiteLLM Managed Credentials for Query - <a href="https://github.com/BerriAI/litellm/pull/13787" target="_blank" rel="noopener noreferrer">PR #13787</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-76-0#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-4">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-4" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/pass_through/intro">Passthrough</a></strong>
<ul>
<li>Fix query passthrough deletion - <a href="https://github.com/BerriAI/litellm/pull/13622" target="_blank" rel="noopener noreferrer">PR #13622</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-76-0#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Models</strong>
<ul>
<li>Add Search Functionality for Public Model Names in Model Dashboard - <a href="https://github.com/BerriAI/litellm/pull/13687" target="_blank" rel="noopener noreferrer">PR #13687</a></li>
<li>Auto-Add <code>azure/</code> to deployment Name in UI - <a href="https://github.com/BerriAI/litellm/pull/13685" target="_blank" rel="noopener noreferrer">PR #13685</a></li>
<li>Models page row UI restructure - <a href="https://github.com/BerriAI/litellm/pull/13771" target="_blank" rel="noopener noreferrer">PR #13771</a></li>
</ul>
</li>
<li><strong>Notifications</strong>
<ul>
<li>Add new notifications toast UI everywhere - <a href="https://github.com/BerriAI/litellm/pull/13813" target="_blank" rel="noopener noreferrer">PR #13813</a></li>
</ul>
</li>
<li><strong>Keys</strong>
<ul>
<li>Fix key edit settings after regenerating a key - <a href="https://github.com/BerriAI/litellm/pull/13815" target="_blank" rel="noopener noreferrer">PR #13815</a></li>
<li>Require team_id when creating service account keys - <a href="https://github.com/BerriAI/litellm/pull/13873" target="_blank" rel="noopener noreferrer">PR #13873</a></li>
<li>Filter - show all options on filter option click - <a href="https://github.com/BerriAI/litellm/pull/13858" target="_blank" rel="noopener noreferrer">PR #13858</a></li>
</ul>
</li>
<li><strong>Usage</strong>
<ul>
<li>Fix ‘Cannot read properties of undefined’ exception on user agent activity tab - <a href="https://github.com/BerriAI/litellm/pull/13892" target="_blank" rel="noopener noreferrer">PR #13892</a></li>
</ul>
</li>
<li><strong>SSO</strong>
<ul>
<li>Free SSO usage for up to 5 users - <a href="https://github.com/BerriAI/litellm/pull/13843" target="_blank" rel="noopener noreferrer">PR #13843</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-76-0#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-5">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-5" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/guardrails/bedrock">Bedrock Guardrails</a></strong>
<ul>
<li>Add bedrock api key support - <a href="https://github.com/BerriAI/litellm/pull/13835" target="_blank" rel="noopener noreferrer">PR #13835</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-76-0#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/integrations/datadog">Datadog LLM Observability</a></strong>
<ul>
<li>Add support for Failure Logging&nbsp;<a href="https://github.com/BerriAI/litellm/pull/13726" target="_blank" rel="noopener noreferrer">PR #13726</a></li>
<li>Add time to first token, litellm overhead, guardrail overhead latency metrics - <a href="https://github.com/BerriAI/litellm/pull/13734" target="_blank" rel="noopener noreferrer">PR #13734</a></li>
<li>Add support for tracing guardrail input/output - <a href="https://github.com/BerriAI/litellm/pull/13767" target="_blank" rel="noopener noreferrer">PR #13767</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/integrations/langfuse">Langfuse OTEL</a></strong>
<ul>
<li>Allow using Key/Team Based Logging - <a href="https://github.com/BerriAI/litellm/pull/13791" target="_blank" rel="noopener noreferrer">PR #13791</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/integrations/aim">AIM</a></strong>
<ul>
<li>Migrate to new firewall API - <a href="https://github.com/BerriAI/litellm/pull/13748" target="_blank" rel="noopener noreferrer">PR #13748</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/observability/opentelemetry_integration">OTEL</a></strong>
<ul>
<li>Add OTEL tracing for actual LLM API call - <a href="https://github.com/BerriAI/litellm/pull/13836" target="_blank" rel="noopener noreferrer">PR #13836</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/observability/mlflow_integration">MLFlow</a></strong>
<ul>
<li>Include predicted output in MLflow tracing - <a href="https://github.com/BerriAI/litellm/pull/13795" target="_blank" rel="noopener noreferrer">PR #13795</a>, s/o&nbsp;@TomeHirata&nbsp;</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-76-0#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-6">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-6" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/routing#how-cooldowns-work">Cooldowns</a></strong>
<ul>
<li>don't return raw Azure Exceptions to client (can contain prompt leakage) - <a href="https://github.com/BerriAI/litellm/pull/13529" target="_blank" rel="noopener noreferrer">PR #13529</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/auto_routing">Auto-router</a></strong>
<ul>
<li>Ensures the relevant dependencies for auto router existing on LiteLLM Docker - <a href="https://github.com/BerriAI/litellm/pull/13788" target="_blank" rel="noopener noreferrer">PR #13788</a></li>
</ul>
</li>
<li><strong>Model Alias</strong>
<ul>
<li>Fix calling key with access to model alias - <a href="https://github.com/BerriAI/litellm/pull/13830" target="_blank" rel="noopener noreferrer">PR #13830</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-76-0#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/caching">S3 Caching</a></strong>
<ul>
<li>Use namespace as prefix for s3 cache - <a href="https://github.com/BerriAI/litellm/pull/13704" target="_blank" rel="noopener noreferrer">PR #13704</a></li>
<li>Async S3 Caching support (4x RPS improvement) - <a href="https://github.com/BerriAI/litellm/pull/13852" target="_blank" rel="noopener noreferrer">PR #13852</a>, s/o @<a href="https://github.com/michal-otmianowski" target="_blank" rel="noopener noreferrer">michal-otmianowski</a></li>
</ul>
</li>
<li><strong>Model Group header forwarding</strong>
<ul>
<li>reuse same logic as global header forwarding - <a href="https://github.com/BerriAI/litellm/pull/13741" target="_blank" rel="noopener noreferrer">PR #13741</a></li>
<li>add support for hosted_vllm on UI - <a href="https://github.com/BerriAI/litellm/pull/13885" target="_blank" rel="noopener noreferrer">PR #13885</a></li>
</ul>
</li>
<li><strong>Performance</strong>
<ul>
<li>Improve LiteLLM Python SDK RPS by +200 RPS (braintrust import + aiohttp transport fixes) - <a href="https://github.com/BerriAI/litellm/pull/13839" target="_blank" rel="noopener noreferrer">PR #13839</a></li>
<li>Use O(1) Set lookups for model routing - <a href="https://github.com/BerriAI/litellm/pull/13879" target="_blank" rel="noopener noreferrer">PR #13879</a></li>
<li>Reduce Significant CPU overhead from litellm_logging.py - <a href="https://github.com/BerriAI/litellm/pull/13895" target="_blank" rel="noopener noreferrer">PR #13895</a></li>
<li>Improvements for Async Success Handler (Logging Callbacks) - Approx +130 RPS - <a href="https://github.com/BerriAI/litellm/pull/13905" target="_blank" rel="noopener noreferrer">PR #13905</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-76-0#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-7">Bugs<a href="https://docs.litellm.ai/release_notes/v1-76-0#bugs-7" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>SDK</strong>
<ul>
<li>Fix litellm compatibility with newest release of openAI (&gt;v1.100.0) - <a href="https://github.com/BerriAI/litellm/pull/13728" target="_blank" rel="noopener noreferrer">PR #13728</a></li>
</ul>
</li>
<li><strong>Helm</strong>
<ul>
<li>Add possibility to configure resources for migrations-job - <a href="https://github.com/BerriAI/litellm/pull/13617" target="_blank" rel="noopener noreferrer">PR #13617</a></li>
<li>Ensure Helm chart auto generated master keys follow sk-xxxx format - <a href="https://github.com/BerriAI/litellm/pull/13871" target="_blank" rel="noopener noreferrer">PR #13871</a></li>
<li>Enhance database configuration: add support for optional endpointKey - <a href="https://github.com/BerriAI/litellm/pull/13763" target="_blank" rel="noopener noreferrer">PR #13763</a></li>
</ul>
</li>
<li><strong>Rate Limits</strong>
<ul>
<li>fixing descriptor/response size mismatch on parallel_request_limiter_v3 - <a href="https://github.com/BerriAI/litellm/pull/13863" target="_blank" rel="noopener noreferrer">PR #13863</a>, s/o &nbsp;@<a href="https://github.com/luizrennocosta" target="_blank" rel="noopener noreferrer">luizrennocosta</a></li>
</ul>
</li>
<li><strong>Non-root</strong>
<ul>
<li>fix permission access on prisma migrate in non-root image - <a href="https://github.com/BerriAI/litellm/pull/13848" target="_blank" rel="noopener noreferrer">PR #13848</a>, s/o @<a href="https://github.com/Ithanil" target="_blank" rel="noopener noreferrer">Ithanil</a></li>
</ul>
</li>
</ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.75.8-stable - Team Member Rate Limits]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-75-8</link>
            <guid>https://docs.litellm.ai/release_notes/v1-75-8</guid>
            <pubDate>Sat, 16 Aug 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-75-8#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.75.8-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.75.8</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-75-8#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Team Member Rate Limits</strong> - Individual rate limiting for team members with JWT authentication support.</li>
<li><strong>Performance Improvements</strong> - New experimental HTTP handler flag for 100+ RPS improvement on OpenAI calls.</li>
<li><strong>GPT-5 Model Family Support</strong> - Full support for OpenAI's GPT-5 models with <code>reasoning_effort</code> parameter and Azure OpenAI integration.</li>
<li><strong>Azure AI Flux Image Generation</strong> - Support for Azure AI's Flux image generation models.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="team-member-rate-limits">Team Member Rate Limits<a href="https://docs.litellm.ai/release_notes/v1-75-8#team-member-rate-limits" class="hash-link" aria-label="Team Member Rate Limits的直接链接" title="Team Member Rate Limits的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAaElEQVR4nFWNQQoFIQxDvf8h3QiuR0RoazSfKH9gCo+2NE1SrZU5Z5ZSqLn3zoigu39IYwy21i5Po5kTAJdY6yXpe85JYNLson3vTZW6OEJZq9/bfoXAoruMcIV/Vzc/0R5x4iU8N4A/qJnDTgdDYzwAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/team_member_rate_limits.2820c45.640.png" srcset="/assets/ideal-img/team_member_rate_limits.2820c45.640.png 640w,/assets/ideal-img/team_member_rate_limits.ae9e3aa.1920.png 1920w" width="640" height="334"></noscript></div>
<p style="text-align:left;color:#666"></p><p>LiteLLM MCP Architecture: Use MCP tools with all LiteLLM supported models</p><p></p>
<p>This release adds support for setting rate limits on individual members (including machine users) within a team. Teams can now give each agent its own rate limits—so that heavy-traffic agents don’t impact other agents or human users.</p>
<p>Agents can authenticate with LiteLLM using JWT and the same team role as human users, while still enforcing per-agent rate limits.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-75-8#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-75-8#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Features</th></tr></thead><tbody><tr><td>Azure AI</td><td><code>azure_ai/FLUX-1.1-pro</code></td><td>-</td><td>-</td><td>$40/image</td><td>Image generation</td></tr><tr><td>Azure AI</td><td><code>azure_ai/FLUX.1-Kontext-pro</code></td><td>-</td><td>-</td><td>$40/image</td><td>Image generation</td></tr><tr><td>Vertex AI</td><td><code>vertex_ai/deepseek-ai/deepseek-r1-0528-maas</code></td><td>65k</td><td>$1.35</td><td>$5.4</td><td>Chat completions + reasoning</td></tr><tr><td>OpenRouter</td><td><code>openrouter/deepseek/deepseek-chat-v3-0324</code></td><td>65k</td><td>$0.14</td><td>$0.28</td><td>Chat completions</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Added <code>reasoning_effort</code> parameter support for GPT-5 model family - <a href="https://github.com/BerriAI/litellm/pull/13475" target="_blank" rel="noopener noreferrer">PR #13475</a>, <a href="https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models">Get Started</a></li>
<li>Support for <code>reasoning</code> parameter in Responses API - <a href="https://github.com/BerriAI/litellm/pull/13475" target="_blank" rel="noopener noreferrer">PR #13475</a>, <a href="https://docs.litellm.ai/docs/response_api">Get Started</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure/azure">Azure OpenAI</a></strong>
<ul>
<li>GPT-5 support with max_tokens and <code>reasoning</code> parameter - <a href="https://github.com/BerriAI/litellm/pull/13510" target="_blank" rel="noopener noreferrer">PR #13510</a>, <a href="https://docs.litellm.ai/docs/providers/azure/azure#gpt-5-models">Get Started</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">AWS Bedrock</a></strong>
<ul>
<li>Streaming support for bedrock gpt-oss model family - <a href="https://github.com/BerriAI/litellm/pull/13346" target="_blank" rel="noopener noreferrer">PR #13346</a>, <a href="https://docs.litellm.ai/docs/providers/bedrock#openai-gpt-oss">Get Started</a></li>
<li><code>/messages</code> endpoint compatibility with <code>bedrock/converse/&lt;model&gt;</code> - <a href="https://github.com/BerriAI/litellm/pull/13627" target="_blank" rel="noopener noreferrer">PR #13627</a></li>
<li>Cache point support for assistant and tool messages - <a href="https://github.com/BerriAI/litellm/pull/13640" target="_blank" rel="noopener noreferrer">PR #13640</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure AI</a></strong>
<ul>
<li>New Azure AI Flux Image Generation provider - <a href="https://github.com/BerriAI/litellm/pull/13592" target="_blank" rel="noopener noreferrer">PR #13592</a>, <a href="https://docs.litellm.ai/docs/providers/azure_ai_img">Get Started</a></li>
<li>Fixed Content-Type header for image generation - <a href="https://github.com/BerriAI/litellm/pull/13584" target="_blank" rel="noopener noreferrer">PR #13584</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/comet">CometAPI</a></strong>
<ul>
<li>New provider support with chat completions and streaming - <a href="https://github.com/BerriAI/litellm/pull/13458" target="_blank" rel="noopener noreferrer">PR #13458</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/sambanova">SambaNova</a></strong>
<ul>
<li>Added embedding model support - <a href="https://github.com/BerriAI/litellm/pull/13308" target="_blank" rel="noopener noreferrer">PR #13308</a>, <a href="https://docs.litellm.ai/docs/providers/sambanova#sambanova---embeddings">Get Started</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vertex">Vertex AI</a></strong>
<ul>
<li>Added <code>/countTokens</code> endpoint support for Gemini CLI integration - <a href="https://github.com/BerriAI/litellm/pull/13545" target="_blank" rel="noopener noreferrer">PR #13545</a></li>
<li>Token counter support for VertexAI models - <a href="https://github.com/BerriAI/litellm/pull/13558" target="_blank" rel="noopener noreferrer">PR #13558</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">hosted_vllm</a></strong>
<ul>
<li>Added <code>reasoning_effort</code> parameter support - <a href="https://github.com/BerriAI/litellm/pull/13620" target="_blank" rel="noopener noreferrer">PR #13620</a>, <a href="https://docs.litellm.ai/docs/providers/vllm#reasoning-effort">Get Started</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI</a></strong>
<ul>
<li>Fixed streaming issues - <a href="https://github.com/BerriAI/litellm/pull/13437" target="_blank" rel="noopener noreferrer">PR #13437</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/ollama">Ollama</a></strong>
<ul>
<li>Fixed GPT-OSS streaming with 'thinking' field - <a href="https://github.com/BerriAI/litellm/pull/13375" target="_blank" rel="noopener noreferrer">PR #13375</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/volcengine">VolcEngine</a></strong>
<ul>
<li>Fixed thinking disabled parameter handling - <a href="https://github.com/BerriAI/litellm/pull/13598" target="_blank" rel="noopener noreferrer">PR #13598</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/completion/stream">Streaming</a></strong>
<ul>
<li>Consistent 'finish_reason' chunk indexing - <a href="https://github.com/BerriAI/litellm/pull/13560" target="_blank" rel="noopener noreferrer">PR #13560</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-75-8#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/anthropic/messages">/messages</a></strong>
<ul>
<li>Tool use arguments properly returned for non-anthropic models - <a href="https://github.com/BerriAI/litellm/pull/13638" target="_blank" rel="noopener noreferrer">PR #13638</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/realtime">Real-time API</a></strong>
<ul>
<li>Fixed endpoint for no intent scenarios - <a href="https://github.com/BerriAI/litellm/pull/13476" target="_blank" rel="noopener noreferrer">PR #13476</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/response_api">Responses API</a></strong>
<ul>
<li>Fixed <code>stream=True</code> + <code>background=True</code> with Responses API - <a href="https://github.com/BerriAI/litellm/pull/13654" target="_blank" rel="noopener noreferrer">PR #13654</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway"><a href="https://docs.litellm.ai/docs/mcp">MCP Gateway</a><a href="https://docs.litellm.ai/release_notes/v1-75-8#mcp-gateway" class="hash-link" aria-label="mcp-gateway的直接链接" title="mcp-gateway的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Access Control &amp; Configuration</strong>
<ul>
<li>Enhanced MCPServerManager with access groups and description support - <a href="https://github.com/BerriAI/litellm/pull/13549" target="_blank" rel="noopener noreferrer">PR #13549</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Authentication</strong>
<ul>
<li>Fixed MCP gateway key authentication - <a href="https://github.com/BerriAI/litellm/pull/13630" target="_blank" rel="noopener noreferrer">PR #13630</a></li>
</ul>
</li>
</ul>
<p><a href="https://docs.litellm.ai/docs/mcp">Read More</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-75-8#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Team Management</strong>
<ul>
<li>Team Member Rate Limits implementation - <a href="https://github.com/BerriAI/litellm/pull/13601" target="_blank" rel="noopener noreferrer">PR #13601</a></li>
<li>JWT authentication support for team member rate limits - <a href="https://github.com/BerriAI/litellm/pull/13601" target="_blank" rel="noopener noreferrer">PR #13601</a></li>
<li>Show team member TPM/RPM limits in UI - <a href="https://github.com/BerriAI/litellm/pull/13662" target="_blank" rel="noopener noreferrer">PR #13662</a></li>
<li>Allow editing team member RPM/TPM limits - <a href="https://github.com/BerriAI/litellm/pull/13669" target="_blank" rel="noopener noreferrer">PR #13669</a></li>
<li>Allow unsetting TPM and RPM in Teams Settings - <a href="https://github.com/BerriAI/litellm/pull/13430" target="_blank" rel="noopener noreferrer">PR #13430</a></li>
<li>Team Member Permissions Page access column changes - <a href="https://github.com/BerriAI/litellm/pull/13145" target="_blank" rel="noopener noreferrer">PR #13145</a></li>
</ul>
</li>
<li><strong>Key Management</strong>
<ul>
<li>Display errors from backend on the UI Keys page - <a href="https://github.com/BerriAI/litellm/pull/13435" target="_blank" rel="noopener noreferrer">PR #13435</a></li>
<li>Added confirmation modal before deleting keys - <a href="https://github.com/BerriAI/litellm/pull/13655" target="_blank" rel="noopener noreferrer">PR #13655</a></li>
<li>Support for <code>user</code> parameter in LiteLLM SDK to Proxy communication - <a href="https://github.com/BerriAI/litellm/pull/13555" target="_blank" rel="noopener noreferrer">PR #13555</a></li>
</ul>
</li>
<li><strong>UI Improvements</strong>
<ul>
<li>Fixed internal users table overflow - <a href="https://github.com/BerriAI/litellm/pull/12736" target="_blank" rel="noopener noreferrer">PR #12736</a></li>
<li>Enhanced chart readability with short-form notation for large numbers - <a href="https://github.com/BerriAI/litellm/pull/12370" target="_blank" rel="noopener noreferrer">PR #12370</a></li>
<li>Fixed image overflow in LiteLLM model display - <a href="https://github.com/BerriAI/litellm/pull/13639" target="_blank" rel="noopener noreferrer">PR #13639</a></li>
<li>Removed ambiguous network response errors - <a href="https://github.com/BerriAI/litellm/pull/13582" target="_blank" rel="noopener noreferrer">PR #13582</a></li>
</ul>
</li>
<li><strong>Credentials</strong>
<ul>
<li>Added CredentialDeleteModal component and integration with CredentialsPanel - <a href="https://github.com/BerriAI/litellm/pull/13550" target="_blank" rel="noopener noreferrer">PR #13550</a></li>
</ul>
</li>
<li><strong>Admin &amp; Permissions</strong>
<ul>
<li>Allow routes for admin viewer - <a href="https://github.com/BerriAI/litellm/pull/13588" target="_blank" rel="noopener noreferrer">PR #13588</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-3">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs-3" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>SCIM Integration</strong>
<ul>
<li>Fixed SCIM Team Memberships metadata handling - <a href="https://github.com/BerriAI/litellm/pull/13553" target="_blank" rel="noopener noreferrer">PR #13553</a></li>
</ul>
</li>
<li><strong>Authentication</strong>
<ul>
<li>Fixed incorrect key info endpoint - <a href="https://github.com/BerriAI/litellm/pull/13633" target="_blank" rel="noopener noreferrer">PR #13633</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-75-8#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-4">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-4" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse OTEL</a></strong>
<ul>
<li>Added key/team logging for Langfuse OTEL Logger - <a href="https://github.com/BerriAI/litellm/pull/13512" target="_blank" rel="noopener noreferrer">PR #13512</a></li>
<li>Fixed LangfuseOtelSpanAttributes constants to match expected values - <a href="https://github.com/BerriAI/litellm/pull/13659" target="_blank" rel="noopener noreferrer">PR #13659</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#mlflow">MLflow</a></strong>
<ul>
<li>Updated MLflow logger usage span attributes - <a href="https://github.com/BerriAI/litellm/pull/13561" target="_blank" rel="noopener noreferrer">PR #13561</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-4">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs-4" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Security</strong>
<ul>
<li>Hide sensitive data in <code>/model/info</code> - azure entra client_secret - <a href="https://github.com/BerriAI/litellm/pull/13577" target="_blank" rel="noopener noreferrer">PR #13577</a></li>
<li>Fixed trivy/secrets false positives - <a href="https://github.com/BerriAI/litellm/pull/13631" target="_blank" rel="noopener noreferrer">PR #13631</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-75-8#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-5">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-5" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>HTTP Performance</strong>
<ul>
<li>New 'EXPERIMENTAL_OPENAI_BASE_LLM_HTTP_HANDLER' flag for +100 RPS improvement on OpenAI calls - <a href="https://github.com/BerriAI/litellm/pull/13625" target="_blank" rel="noopener noreferrer">PR #13625</a></li>
</ul>
</li>
<li><strong>Database Monitoring</strong>
<ul>
<li>Added DB metrics to Prometheus - <a href="https://github.com/BerriAI/litellm/pull/13626" target="_blank" rel="noopener noreferrer">PR #13626</a></li>
</ul>
</li>
<li><strong>Error Handling</strong>
<ul>
<li>Added safe divide by 0 protection to prevent crashes - <a href="https://github.com/BerriAI/litellm/pull/13624" target="_blank" rel="noopener noreferrer">PR #13624</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-5">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-8#bugs-5" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Dependencies</strong>
<ul>
<li>Updated boto3 to 1.36.0 and aioboto3 to 13.4.0 - <a href="https://github.com/BerriAI/litellm/pull/13665" target="_blank" rel="noopener noreferrer">PR #13665</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-75-8#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-6">Features<a href="https://docs.litellm.ai/release_notes/v1-75-8#features-6" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Database</strong>
<ul>
<li>Removed redundant <code>use_prisma_migrate</code> flag - now default - <a href="https://github.com/BerriAI/litellm/pull/13555" target="_blank" rel="noopener noreferrer">PR #13555</a></li>
</ul>
</li>
<li><strong>LLM Translation</strong>
<ul>
<li>Added model ID check - <a href="https://github.com/BerriAI/litellm/pull/13507" target="_blank" rel="noopener noreferrer">PR #13507</a></li>
<li>Refactored Anthropic configurations and added support for <code>anthropic_beta</code> headers - <a href="https://github.com/BerriAI/litellm/pull/13590" target="_blank" rel="noopener noreferrer">PR #13590</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-75-8#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@TensorNull made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13458" target="_blank" rel="noopener noreferrer">PR #13458</a></li>
<li>@MajorD00m made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13577" target="_blank" rel="noopener noreferrer">PR #13577</a></li>
<li>@VerunicaM made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13584" target="_blank" rel="noopener noreferrer">PR #13584</a></li>
<li>@huangyafei made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13607" target="_blank" rel="noopener noreferrer">PR #13607</a></li>
<li>@TomeHirata made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13561" target="_blank" rel="noopener noreferrer">PR #13561</a></li>
<li>@willfinnigan made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13659" target="_blank" rel="noopener noreferrer">PR #13659</a></li>
<li>@dcbark01 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13633" target="_blank" rel="noopener noreferrer">PR #13633</a></li>
<li>@javacruft made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13631" target="_blank" rel="noopener noreferrer">PR #13631</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.75.5-stable.rc-draft...v1.75.8-nightly" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-75-8#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.75.5-stable - Redis latency improvements]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-75-5</link>
            <guid>https://docs.litellm.ai/release_notes/v1-75-5</guid>
            <pubDate>Sun, 10 Aug 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-75-5#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.75.5-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.75.5.post2</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-75-5#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>Redis - Latency Improvements</strong> - Reduces P99 latency by 50% with Redis enabled.</li>
<li><strong>Responses API Session Management</strong> - Support for managing responses API sessions with images.</li>
<li><strong>Oracle Cloud Infrastructure</strong> - New LLM provider for calling models on Oracle Cloud Infrastructure.</li>
<li><strong>Digital Ocean's Gradient AI</strong> - New LLM provider for calling models on Digital Ocean's Gradient AI platform.</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="risk-of-upgrade">Risk of Upgrade<a href="https://docs.litellm.ai/release_notes/v1-75-5#risk-of-upgrade" class="hash-link" aria-label="Risk of Upgrade的直接链接" title="Risk of Upgrade的直接链接">​</a></h3>
<p>If you build the proxy from the pip package, you should hold off on upgrading. This version makes <code>prisma migrate deploy</code> our default for managing the DB. This is safer, as it doesn't reset the DB, but it requires a manual <code>prisma generate</code> step.</p>
<p>Users of our Docker image, are <strong>not</strong> affected by this change.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="redis-latency-improvements">Redis Latency Improvements<a href="https://docs.litellm.ai/release_notes/v1-75-5#redis-latency-improvements" class="hash-link" aria-label="Redis Latency Improvements的直接链接" title="Redis Latency Improvements的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZklEQVR4nI2MSQoDMQwE9f8H5g8+eAHZ2ozpIEOGHEdQ9AItaq2hlAIRwd4bEXH59wmNMVBrxVrrKd0dZnb1lymXc07k5977Q46Z+faqCjKzw8zH3Y+qXi8iN6dmzp7w8igiPm/4As9v6EE2ip9vAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="363"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/faster_caching_calls.8ab8368.640.png" srcset="/assets/ideal-img/faster_caching_calls.8ab8368.640.png 640w,/assets/ideal-img/faster_caching_calls.4c1bced.1920.png 1920w" width="640" height="363"></noscript></div>
<br>
<p>This release adds in-memory caching for Redis requests, enabling faster response times in high-traffic. Now, LiteLLM instances will check their in-memory cache for a cache hit, before checking Redis. This reduces caching-related latency from 100ms for LLM API calls to sub-1ms, on cache hits.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="responses-api-session-management-w-images">Responses API Session Management w/ Images<a href="https://docs.litellm.ai/release_notes/v1-75-5#responses-api-session-management-w-images" class="hash-link" aria-label="Responses API Session Management w/ Images的直接链接" title="Responses API Session Management w/ Images的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAFAAoDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAYI/8QAIxAAAgEDAQkAAAAAAAAAAAAAAQIEAAMFBggREhMVITFU0v/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCy2opMvEaKw5xc2XEdshws9q8ysw5TdiQRvFZcbVOoQxHXst59y59UpQf/2Q==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/responses_api_session_mgt_images.d628659.640.jpg" srcset="/assets/ideal-img/responses_api_session_mgt_images.d628659.640.jpg 640w,/assets/ideal-img/responses_api_session_mgt_images.fd3948f.1920.jpg 1920w" width="640" height="334"></noscript></div>
<br>
<p>LiteLLM now supports session management for Responses API requests with images. This is great for use-cases like chatbots, that are using the Responses API to track the state of a conversation. LiteLLM session management works across <strong>ALL</strong> LLM API's (including Anthropic, Bedrock, OpenAI, etc). LiteLLM session management works by storing the request and response content in an s3 bucket, you can specify.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-75-5#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-75-5#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th></tr></thead><tbody><tr><td>Bedrock</td><td><code>bedrock/us.anthropic.claude-opus-4-1-20250805-v1:0</code></td><td>200k</td><td>$15</td><td>$75</td></tr><tr><td>Bedrock</td><td><code>bedrock/openai.gpt-oss-20b-1:0</code></td><td>200k</td><td>0.07</td><td>0.3</td></tr><tr><td>Bedrock</td><td><code>bedrock/openai.gpt-oss-120b-1:0</code></td><td>200k</td><td>0.15</td><td>0.6</td></tr><tr><td>Fireworks AI</td><td><code>fireworks_ai/accounts/fireworks/models/glm-4p5</code></td><td>128k</td><td>0.55</td><td>2.19</td></tr><tr><td>Fireworks AI</td><td><code>fireworks_ai/accounts/fireworks/models/glm-4p5-air</code></td><td>128k</td><td>0.22</td><td>0.88</td></tr><tr><td>Fireworks AI</td><td><code>fireworks_ai/accounts/fireworks/models/gpt-oss-120b</code></td><td>131072</td><td>0.15</td><td>0.6</td></tr><tr><td>Fireworks AI</td><td><code>fireworks_ai/accounts/fireworks/models/gpt-oss-20b</code></td><td>131072</td><td>0.05</td><td>0.2</td></tr><tr><td>Groq</td><td><code>groq/openai/gpt-oss-20b</code></td><td>131072</td><td>0.1</td><td>0.5</td></tr><tr><td>Groq</td><td><code>groq/openai/gpt-oss-120b</code></td><td>131072</td><td>0.15</td><td>0.75</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-2025-08-07</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-mini</code></td><td>400k</td><td>0.25</td><td>2</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-mini-2025-08-07</code></td><td>400k</td><td>0.25</td><td>2</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-nano</code></td><td>400k</td><td>0.05</td><td>0.4</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-nano-2025-08-07</code></td><td>400k</td><td>0.05</td><td>0.4</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-chat</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>OpenAI</td><td><code>openai/gpt-5-chat-latest</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>Azure</td><td><code>azure/gpt-5</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-2025-08-07</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-mini</code></td><td>400k</td><td>0.25</td><td>2</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-mini-2025-08-07</code></td><td>400k</td><td>0.25</td><td>2</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-nano-2025-08-07</code></td><td>400k</td><td>0.05</td><td>0.4</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-nano</code></td><td>400k</td><td>0.05</td><td>0.4</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-chat</code></td><td>400k</td><td>1.25</td><td>10</td></tr><tr><td>Azure</td><td><code>azure/gpt-5-chat-latest</code></td><td>400k</td><td>1.25</td><td>10</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/oci">OCI</a></strong>
<ul>
<li>New LLM provider - <a href="https://github.com/BerriAI/litellm/pull/13206" target="_blank" rel="noopener noreferrer">PR #13206</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/jina_ai">JinaAI</a></strong>
<ul>
<li>support multimodal embedding models - <a href="https://github.com/BerriAI/litellm/pull/13181" target="_blank" rel="noopener noreferrer">PR #13181</a></li>
</ul>
</li>
<li><strong>GPT-5 (<a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a>/<a href="https://docs.litellm.ai/docs/providers/azure">Azure</a>)</strong>
<ul>
<li>Support drop_params for temperature - <a href="https://github.com/BerriAI/litellm/pull/13390" target="_blank" rel="noopener noreferrer">PR #13390</a></li>
<li>Map max_tokens to max_completion_tokens - <a href="https://github.com/BerriAI/litellm/pull/13390" target="_blank" rel="noopener noreferrer">PR #13390</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Add claude-opus-4-1 on model cost map - <a href="https://github.com/BerriAI/litellm/pull/13384" target="_blank" rel="noopener noreferrer">PR #13384</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Add gpt-oss to model cost map - <a href="https://github.com/BerriAI/litellm/pull/13442" target="_blank" rel="noopener noreferrer">PR #13442</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/cerebras">Cerebras</a></strong>
<ul>
<li>Add gpt-oss to model cost map - <a href="https://github.com/BerriAI/litellm/pull/13442" target="_blank" rel="noopener noreferrer">PR #13442</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure">Azure</a></strong>
<ul>
<li>Support drop params for ‘temperature’ on o-series models - <a href="https://github.com/BerriAI/litellm/pull/13353" target="_blank" rel="noopener noreferrer">PR #13353</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gradient_ai">GradientAI</a></strong>
<ul>
<li>New LLM Provider - <a href="https://github.com/BerriAI/litellm/pull/12169" target="_blank" rel="noopener noreferrer">PR #12169</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openai">OpenAI</a></strong>
<ul>
<li>Add ‘service_tier’ and ‘safety_identifier’ as supported responses api params - <a href="https://github.com/BerriAI/litellm/pull/13258" target="_blank" rel="noopener noreferrer">PR #13258</a></li>
<li>Correct pricing for web search on 4o-mini - <a href="https://github.com/BerriAI/litellm/pull/13269" target="_blank" rel="noopener noreferrer">PR #13269</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/mistral">Mistral</a></strong>
<ul>
<li>Handle $id and $schema fields when calling mistral - <a href="https://github.com/BerriAI/litellm/pull/13389" target="_blank" rel="noopener noreferrer">PR #13389</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-75-5#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><code>/responses</code>
<ul>
<li>Responses API Session Handling w/ support for images - <a href="https://github.com/BerriAI/litellm/pull/13347" target="_blank" rel="noopener noreferrer">PR #13347</a></li>
<li>failed if input containing ResponseReasoningItem - <a href="https://github.com/BerriAI/litellm/pull/13465" target="_blank" rel="noopener noreferrer">PR #13465</a></li>
<li>Support custom tools - <a href="https://github.com/BerriAI/litellm/pull/13418" target="_blank" rel="noopener noreferrer">PR #13418</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><code>/chat/completions</code>
<ul>
<li>Fix completion_token_details usage object missing ‘text’ tokens - <a href="https://github.com/BerriAI/litellm/pull/13234" target="_blank" rel="noopener noreferrer">PR #13234</a></li>
<li>(SDK) handle tool being a pydantic object - <a href="https://github.com/BerriAI/litellm/pull/13274" target="_blank" rel="noopener noreferrer">PR #13274</a></li>
<li>include cost in streaming usage object - <a href="https://github.com/BerriAI/litellm/pull/13418" target="_blank" rel="noopener noreferrer">PR #13418</a></li>
<li>Exclude none fields on&nbsp;/chat/completion - allows usage with n8n - <a href="https://github.com/BerriAI/litellm/pull/13320" target="_blank" rel="noopener noreferrer">PR #13320</a></li>
</ul>
</li>
<li><code>/responses</code>
<ul>
<li>Transform function call in response for non-openai models (gemini/anthropic) - <a href="https://github.com/BerriAI/litellm/pull/13260" target="_blank" rel="noopener noreferrer">PR #13260</a></li>
<li>Fix unsupported operand error with model groups - <a href="https://github.com/BerriAI/litellm/pull/13293" target="_blank" rel="noopener noreferrer">PR #13293</a></li>
<li>Responses api session management for streaming responses - <a href="https://github.com/BerriAI/litellm/pull/13396" target="_blank" rel="noopener noreferrer">PR #13396</a></li>
</ul>
</li>
<li><code>/v1/messages</code>
<ul>
<li>Added litellm claude code count tokens - <a href="https://github.com/BerriAI/litellm/pull/13261" target="_blank" rel="noopener noreferrer">PR #13261</a></li>
</ul>
</li>
<li><code>/vector_stores</code>
<ul>
<li>Fix create/search vector store errors - <a href="https://github.com/BerriAI/litellm/pull/13285" target="_blank" rel="noopener noreferrer">PR #13285</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway"><a href="https://docs.litellm.ai/docs/mcp">MCP Gateway</a><a href="https://docs.litellm.ai/release_notes/v1-75-5#mcp-gateway" class="hash-link" aria-label="mcp-gateway的直接链接" title="mcp-gateway的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>Add route check for internal users - <a href="https://github.com/BerriAI/litellm/pull/13350" target="_blank" rel="noopener noreferrer">PR #13350</a></li>
<li>MCP Guardrails - docs - <a href="https://github.com/BerriAI/litellm/pull/13392" target="_blank" rel="noopener noreferrer">PR #13392</a></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li>Fix auth on UI for bearer token servers - <a href="https://github.com/BerriAI/litellm/pull/13312" target="_blank" rel="noopener noreferrer">PR #13312</a></li>
<li>allow access group on mcp tool retrieval - <a href="https://github.com/BerriAI/litellm/pull/13425" target="_blank" rel="noopener noreferrer">PR #13425</a></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-75-5#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Teams</strong>
<ul>
<li>Add team deletion check for teams with keys - <a href="https://github.com/BerriAI/litellm/pull/12953" target="_blank" rel="noopener noreferrer">PR #12953</a></li>
</ul>
</li>
<li><strong>Models</strong>
<ul>
<li>Add ability to set model alias per key/team - <a href="https://github.com/BerriAI/litellm/pull/13276" target="_blank" rel="noopener noreferrer">PR #13276</a></li>
<li>New button to reload model pricing from model cost map - <a href="https://github.com/BerriAI/litellm/pull/13464" target="_blank" rel="noopener noreferrer">PR #13464</a>, <a href="https://github.com/BerriAI/litellm/pull/13470" target="_blank" rel="noopener noreferrer">PR #13470</a></li>
</ul>
</li>
<li><strong>Keys</strong>
<ul>
<li>Make ‘team’ field required when creating service account keys - <a href="https://github.com/BerriAI/litellm/pull/13302" target="_blank" rel="noopener noreferrer">PR #13302</a></li>
<li>Gray out key-based logging settings for non-enterprise users - prevents confusion on if ‘logging’ all up is supported - <a href="https://github.com/BerriAI/litellm/pull/13431" target="_blank" rel="noopener noreferrer">PR #13431</a></li>
</ul>
</li>
<li><strong>Navbar</strong>
<ul>
<li>Add logo customization for LiteLLM admin UI - <a href="https://github.com/BerriAI/litellm/pull/12958" target="_blank" rel="noopener noreferrer">PR #12958</a></li>
</ul>
</li>
<li><strong>Logs</strong>
<ul>
<li>Add token breakdowns on logs + session page - <a href="https://github.com/BerriAI/litellm/pull/13357" target="_blank" rel="noopener noreferrer">PR #13357</a></li>
</ul>
</li>
<li><strong>Usage</strong>
<ul>
<li>Ensure Usage Page loads after the DB has large entries - <a href="https://github.com/BerriAI/litellm/pull/13400" target="_blank" rel="noopener noreferrer">PR #13400</a></li>
</ul>
</li>
<li><strong>Test Key Page</strong>
<ul>
<li>allow uploading images for /chat/completions and /responses - <a href="https://github.com/BerriAI/litellm/pull/13445" target="_blank" rel="noopener noreferrer">PR #13445</a></li>
</ul>
</li>
<li><strong>MCP</strong>
<ul>
<li>Add auth tokens to local storage auth - <a href="https://github.com/BerriAI/litellm/pull/13473" target="_blank" rel="noopener noreferrer">PR #13473</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-3">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs-3" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Custom Root Path</strong>
<ul>
<li>Fix login route when SSO is enabled - <a href="https://github.com/BerriAI/litellm/pull/13267" target="_blank" rel="noopener noreferrer">PR #13267</a></li>
</ul>
</li>
<li><strong>Customers/End-users</strong>
<ul>
<li>Allow calling&nbsp;/v1/models&nbsp;when end user over budget - allows model listing to work on OpenWebUI when customer over budget - <a href="https://github.com/BerriAI/litellm/pull/13320" target="_blank" rel="noopener noreferrer">PR #13320</a></li>
</ul>
</li>
<li><strong>Teams</strong>
<ul>
<li>Remove user - team membership, when user removed from team - <a href="https://github.com/BerriAI/litellm/pull/13433" target="_blank" rel="noopener noreferrer">PR #13433</a></li>
</ul>
</li>
<li><strong>Errors</strong>
<ul>
<li>Bubble up network errors to user for Logging and Alerts page - <a href="https://github.com/BerriAI/litellm/pull/13427" target="_blank" rel="noopener noreferrer">PR #13427</a></li>
</ul>
</li>
<li><strong>Model Hub</strong>
<ul>
<li>Show pricing for azure models, when base model is set - <a href="https://github.com/BerriAI/litellm/pull/13418" target="_blank" rel="noopener noreferrer">PR #13418</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-75-5#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-4">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-4" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Bedrock Guardrails</strong>
<ul>
<li>Redacted sensitive information in bedrock guardrails error message - <a href="https://github.com/BerriAI/litellm/pull/13356" target="_blank" rel="noopener noreferrer">PR #13356</a></li>
</ul>
</li>
<li><strong>Standard Logging Payload</strong>
<ul>
<li>Fix ‘can’t register atextexit’ bug - <a href="https://github.com/BerriAI/litellm/pull/13436" target="_blank" rel="noopener noreferrer">PR #13436</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-4">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs-4" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Braintrust</strong>
<ul>
<li>Allow setting of braintrust callback base url - <a href="https://github.com/BerriAI/litellm/pull/13368" target="_blank" rel="noopener noreferrer">PR #13368</a></li>
</ul>
</li>
<li><strong>OTEL</strong>
<ul>
<li>Track pre_call hook latency  - <a href="https://github.com/BerriAI/litellm/pull/13362" target="_blank" rel="noopener noreferrer">PR #13362</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-75-5#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-5">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-5" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Team-BYOK models</strong>
<ul>
<li>Add wildcard model support - <a href="https://github.com/BerriAI/litellm/pull/13278" target="_blank" rel="noopener noreferrer">PR #13278</a></li>
</ul>
</li>
<li><strong>Caching</strong>
<ul>
<li>GCP IAM auth support for caching - <a href="https://github.com/BerriAI/litellm/pull/13275" target="_blank" rel="noopener noreferrer">PR #13275</a></li>
</ul>
</li>
<li><strong>Latency</strong>
<ul>
<li>reduce p99 latency w/ redis enabled by 50% - only updates model usage if tpm/rpm limits set - <a href="https://github.com/BerriAI/litellm/pull/13362" target="_blank" rel="noopener noreferrer">PR #13362</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-75-5#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-6">Features<a href="https://docs.litellm.ai/release_notes/v1-75-5#features-6" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Models</strong>
<ul>
<li>Support /v1/models/{model_id} retrieval - <a href="https://github.com/BerriAI/litellm/pull/13268" target="_blank" rel="noopener noreferrer">PR #13268</a></li>
</ul>
</li>
<li><strong>Multi-instance</strong>
<ul>
<li>Ensure disable_llm_api_endpoints works - <a href="https://github.com/BerriAI/litellm/pull/13278" target="_blank" rel="noopener noreferrer">PR #13278</a></li>
</ul>
</li>
<li><strong>Logs</strong>
<ul>
<li>Add apscheduler log suppress - <a href="https://github.com/BerriAI/litellm/pull/13299" target="_blank" rel="noopener noreferrer">PR #13299</a></li>
</ul>
</li>
<li><strong>Helm</strong>
<ul>
<li>Add labels to migrations job template - <a href="https://github.com/BerriAI/litellm/pull/13343" target="_blank" rel="noopener noreferrer">PR #13343</a> s/o <a href="https://github.com/unique-jakub" target="_blank" rel="noopener noreferrer">@unique-jakub</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-5">Bugs<a href="https://docs.litellm.ai/release_notes/v1-75-5#bugs-5" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Non-root image</strong>
<ul>
<li>Fix non-root image for migration - <a href="https://github.com/BerriAI/litellm/pull/13379" target="_blank" rel="noopener noreferrer">PR #13379</a></li>
</ul>
</li>
<li><strong>Get Routes</strong>
<ul>
<li>Load get routes when using fastapi-offline - <a href="https://github.com/BerriAI/litellm/pull/13466" target="_blank" rel="noopener noreferrer">PR #13466</a></li>
</ul>
</li>
<li><strong>Health checks</strong>
<ul>
<li>Generate unique trace IDs for Langfuse health checks - <a href="https://github.com/BerriAI/litellm/pull/13468" target="_blank" rel="noopener noreferrer">PR #13468</a></li>
</ul>
</li>
<li><strong>Swagger</strong>
<ul>
<li>Allow using Swagger for /chat/completions - <a href="https://github.com/BerriAI/litellm/pull/13469" target="_blank" rel="noopener noreferrer">PR #13469</a></li>
</ul>
</li>
<li><strong>Auth</strong>
<ul>
<li>Fix JWTs access not working with model access groups - <a href="https://github.com/BerriAI/litellm/pull/13474" target="_blank" rel="noopener noreferrer">PR #13474</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-75-5#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@bbartels made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13244" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13244</a></li>
<li>@breno-aumo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13206" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13206</a></li>
<li>@pascalwhoop made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13122" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13122</a></li>
<li>@ZPerling made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13045" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13045</a></li>
<li>@zjx20 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13181" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13181</a></li>
<li>@edwarddamato made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13368" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13368</a></li>
<li>@msannan2 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12169" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12169</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.74.15-stable...v1.75.5-stable.rc-draft" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-75-5#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[v1.74.15-stable]]></title>
            <link>https://docs.litellm.ai/release_notes/v1-74-15</link>
            <guid>https://docs.litellm.ai/release_notes/v1-74-15</guid>
            <pubDate>Sat, 02 Aug 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[Deploy this version]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-this-version">Deploy this version<a href="https://docs.litellm.ai/release_notes/v1-74-15#deploy-this-version" class="hash-link" aria-label="Deploy this version的直接链接" title="Deploy this version的直接链接">​</a></h2>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Docker</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pip</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">docker run litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-e STORE_MODEL_IN_DB=True \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-p 4000:4000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker.litellm.ai/berriai/litellm:v1.74.15-stable</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-showLineNumbers language-showlinenumbers codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pip install litellm</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-showlinenumbers codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install litellm==1.74.15.post2</span><br></span></code></pre></div></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-highlights">Key Highlights<a href="https://docs.litellm.ai/release_notes/v1-74-15#key-highlights" class="hash-link" aria-label="Key Highlights的直接链接" title="Key Highlights的直接链接">​</a></h2>
<ul>
<li><strong>User Agent Activity Tracking</strong> - Track how much usage each coding tool gets.</li>
<li><strong>Prompt Management</strong> - Use Git-Ops style prompt management with prompt templates.</li>
<li><strong>MCP Gateway: Guardrails</strong> - Support for using Guardrails with MCP servers.</li>
<li><strong>Google AI Studio Imagen4</strong> - Support for using Imagen4 models on Google AI Studio.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="user-agent-activity-tracking">User Agent Activity Tracking<a href="https://docs.litellm.ai/release_notes/v1-74-15#user-agent-activity-tracking" class="hash-link" aria-label="User Agent Activity Tracking的直接链接" title="User Agent Activity Tracking的直接链接">​</a></h2>
<div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAFCAYAAAB8ZH1oAAAACXBIWXMAACxLAAAsSwGlPZapAAAAc0lEQVR4nDVNSw5DIQj0/nd0a6Kbir5WAXUaaCWZTID5hJQSYowopUBVwSwQEagurPUDMyMQEXLOMGYR9Oftj3MO7owxESzFXMaW9Bnjn6guvoZgR0sQYcw58aqEvTeq8Tmg1l3swgurrtS8obXuhtYf37/P0sL15LMXQAAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="334"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/agent_1.63645bb.640.png" srcset="/assets/ideal-img/agent_1.63645bb.640.png 640w,/assets/ideal-img/agent_1.13487bf.1920.png 1920w" width="640" height="334"></noscript></div>
<br>
<p>This release brings support for tracking usage and costs for AI-powered coding tools like Claude Code, Roo Code, Gemini CLI through LiteLLM. You can now track LLM cost, total tokens used, and DAU/WAU/MAU for each coding tool.</p>
<p>This is great to central AI Platform teams looking to track how they are helping developer productivity.</p>
<p><a href="https://docs.litellm.ai/docs/tutorials/cost_tracking_coding" target="_blank" rel="noopener noreferrer">Read More</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-management">Prompt Management<a href="https://docs.litellm.ai/release_notes/v1-74-15#prompt-management" class="hash-link" aria-label="Prompt Management的直接链接" title="Prompt Management的直接链接">​</a></h2>
<br>
<p><a href="https://docs.litellm.ai/docs/proxy/prompt_management">Read More</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-models--updated-models">New Models / Updated Models<a href="https://docs.litellm.ai/release_notes/v1-74-15#new-models--updated-models" class="hash-link" aria-label="New Models / Updated Models的直接链接" title="New Models / Updated Models的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="new-model-support">New Model Support<a href="https://docs.litellm.ai/release_notes/v1-74-15#new-model-support" class="hash-link" aria-label="New Model Support的直接链接" title="New Model Support的直接链接">​</a></h4>
<table><thead><tr><th>Provider</th><th>Model</th><th>Context Window</th><th>Input ($/1M tokens)</th><th>Output ($/1M tokens)</th><th>Cost per Image</th></tr></thead><tbody><tr><td>OpenRouter</td><td><code>openrouter/x-ai/grok-4</code></td><td>256k</td><td>$3</td><td>$15</td><td>N/A</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-4.0-generate-001</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.04</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-4.0-ultra-generate-001</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.06</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-4.0-fast-generate-001</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.02</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-3.0-generate-002</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.04</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-3.0-generate-001</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.04</td></tr><tr><td>Google AI Studio</td><td><code>gemini/imagen-3.0-fast-generate-001</code></td><td>N/A</td><td>N/A</td><td>N/A</td><td>$0.02</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Google AI Studio</a></strong>
<ul>
<li>Added Google AI Studio Imagen4 model family support - <a href="https://github.com/BerriAI/litellm/pull/13065" target="_blank" rel="noopener noreferrer">PR #13065</a>, <a href="https://docs.litellm.ai/docs/providers/google_ai_studio/image_gen">Get Started</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/azure/azure">Azure OpenAI</a></strong>
<ul>
<li>Azure <code>api_version="preview"</code> support - <a href="https://github.com/BerriAI/litellm/pull/13072" target="_blank" rel="noopener noreferrer">PR #13072</a>, <a href="https://docs.litellm.ai/docs/providers/azure/azure#setting-api-version">Get Started</a></li>
<li>Password protected certificate files support - <a href="https://github.com/BerriAI/litellm/pull/12995" target="_blank" rel="noopener noreferrer">PR #12995</a>, <a href="https://docs.litellm.ai/docs/providers/azure/azure#authentication">Get Started</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/bedrock">AWS Bedrock</a></strong>
<ul>
<li>Cost tracking via Anthropic <code>/v1/messages</code> - <a href="https://github.com/BerriAI/litellm/pull/13072" target="_blank" rel="noopener noreferrer">PR #13072</a></li>
<li>Computer use support - <a href="https://github.com/BerriAI/litellm/pull/13150" target="_blank" rel="noopener noreferrer">PR #13150</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/openrouter">OpenRouter</a></strong>
<ul>
<li>Added Grok4 model support - <a href="https://github.com/BerriAI/litellm/pull/13018" target="_blank" rel="noopener noreferrer">PR #13018</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/anthropic">Anthropic</a></strong>
<ul>
<li>Auto Cache Control Injection - Improved cache_control_injection_points with negative index support - <a href="https://github.com/BerriAI/litellm/pull/13187" target="_blank" rel="noopener noreferrer">PR #13187</a>, <a href="https://docs.litellm.ai/docs/tutorials/prompt_caching">Get Started</a></li>
<li>Working mid-stream fallbacks with token usage tracking - <a href="https://github.com/BerriAI/litellm/pull/13149" target="_blank" rel="noopener noreferrer">PR #13149</a>, <a href="https://github.com/BerriAI/litellm/pull/13170" target="_blank" rel="noopener noreferrer">PR #13170</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/perplexity">Perplexity</a></strong>
<ul>
<li>Citation annotations support - <a href="https://github.com/BerriAI/litellm/pull/13225" target="_blank" rel="noopener noreferrer">PR #13225</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/providers/gemini">Gemini</a></strong>
<ul>
<li>Fix merge_reasoning_content_in_choices parameter issue - <a href="https://github.com/BerriAI/litellm/pull/13066" target="_blank" rel="noopener noreferrer">PR #13066</a>, <a href="https://docs.litellm.ai/docs/tutorials/openweb_ui#render-thinking-content-on-open-webui">Get Started</a></li>
<li>Added support for using <code>GOOGLE_API_KEY</code> environment variable for Google AI Studio - <a href="https://github.com/BerriAI/litellm/pull/12507" target="_blank" rel="noopener noreferrer">PR #12507</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/providers/vllm">vLLM/OpenAI-like</a></strong>
<ul>
<li>Fix missing extra_headers support for embeddings - <a href="https://github.com/BerriAI/litellm/pull/13198" target="_blank" rel="noopener noreferrer">PR #13198</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-api-endpoints">LLM API Endpoints<a href="https://docs.litellm.ai/release_notes/v1-74-15#llm-api-endpoints" class="hash-link" aria-label="LLM API Endpoints的直接链接" title="LLM API Endpoints的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-1">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-1" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/generateContent">/generateContent</a></strong>
<ul>
<li>Support for query_params in generateContent routes for API Key setting - <a href="https://github.com/BerriAI/litellm/pull/13100" target="_blank" rel="noopener noreferrer">PR #13100</a></li>
<li>Ensure "x-goog-api-key" is used for auth to google ai studio when using /generateContent on LiteLLM - <a href="https://github.com/BerriAI/litellm/pull/13098" target="_blank" rel="noopener noreferrer">PR #13098</a></li>
<li>Ensure tool calling works as expected on generateContent - <a href="https://github.com/BerriAI/litellm/pull/13189" target="_blank" rel="noopener noreferrer">PR #13189</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/pass_through/vertex_ai">/vertex_ai (Passthrough)</a></strong>
<ul>
<li>Ensure multimodal embedding responses are logged properly - <a href="https://github.com/BerriAI/litellm/pull/13050" target="_blank" rel="noopener noreferrer">PR #13050</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-gateway"><a href="https://docs.litellm.ai/docs/mcp">MCP Gateway</a><a href="https://docs.litellm.ai/release_notes/v1-74-15#mcp-gateway" class="hash-link" aria-label="mcp-gateway的直接链接" title="mcp-gateway的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-1">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features-1" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Health Check Improvements</strong>
<ul>
<li>Add health check endpoints for MCP servers - <a href="https://github.com/BerriAI/litellm/pull/13106" target="_blank" rel="noopener noreferrer">PR #13106</a></li>
</ul>
</li>
<li><strong>Guardrails Integration</strong>
<ul>
<li>Add pre and during call hooks initialization - <a href="https://github.com/BerriAI/litellm/pull/13067" target="_blank" rel="noopener noreferrer">PR #13067</a></li>
<li>Move pre and during hooks to ProxyLogging - <a href="https://github.com/BerriAI/litellm/pull/13109" target="_blank" rel="noopener noreferrer">PR #13109</a></li>
<li>MCP pre and during guardrails implementation - <a href="https://github.com/BerriAI/litellm/pull/13188" target="_blank" rel="noopener noreferrer">PR #13188</a></li>
</ul>
</li>
<li><strong>Protocol &amp; Header Support</strong>
<ul>
<li>Add protocol headers support - <a href="https://github.com/BerriAI/litellm/pull/13062" target="_blank" rel="noopener noreferrer">PR #13062</a></li>
</ul>
</li>
<li><strong>URL &amp; Namespacing</strong>
<ul>
<li>Improve MCP server URL validation for internal/Kubernetes URLs - <a href="https://github.com/BerriAI/litellm/pull/13099" target="_blank" rel="noopener noreferrer">PR #13099</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-2">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-2" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>UI</strong>
<ul>
<li>Fix scrolling issue with MCP tools - <a href="https://github.com/BerriAI/litellm/pull/13015" target="_blank" rel="noopener noreferrer">PR #13015</a></li>
<li>Fix MCP client list failure - <a href="https://github.com/BerriAI/litellm/pull/13114" target="_blank" rel="noopener noreferrer">PR #13114</a></li>
</ul>
</li>
</ul>
<p><a href="https://docs.litellm.ai/docs/mcp">Read More</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="management-endpoints--ui">Management Endpoints / UI<a href="https://docs.litellm.ai/release_notes/v1-74-15#management-endpoints--ui" class="hash-link" aria-label="Management Endpoints / UI的直接链接" title="Management Endpoints / UI的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-2">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features-2" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li>
<p><strong>Usage Analytics</strong></p>
<ul>
<li>New tab for user agent activity tracking - <a href="https://github.com/BerriAI/litellm/pull/13146" target="_blank" rel="noopener noreferrer">PR #13146</a></li>
<li>Daily usage per user analytics - <a href="https://github.com/BerriAI/litellm/pull/13147" target="_blank" rel="noopener noreferrer">PR #13147</a></li>
<li>Default usage chart date range set to last 7 days - <a href="https://github.com/BerriAI/litellm/pull/12917" target="_blank" rel="noopener noreferrer">PR #12917</a></li>
<li>New advanced date range picker component - <a href="https://github.com/BerriAI/litellm/pull/13141" target="_blank" rel="noopener noreferrer">PR #13141</a>, <a href="https://github.com/BerriAI/litellm/pull/13221" target="_blank" rel="noopener noreferrer">PR #13221</a></li>
<li>Show loader on usage cost charts after date selection - <a href="https://github.com/BerriAI/litellm/pull/13113" target="_blank" rel="noopener noreferrer">PR #13113</a></li>
</ul>
</li>
<li>
<p><strong>Models</strong></p>
<ul>
<li>Added Voyage, Jinai, Deepinfra and VolcEngine providers on UI - <a href="https://github.com/BerriAI/litellm/pull/13131" target="_blank" rel="noopener noreferrer">PR #13131</a></li>
<li>Added Sagemaker on UI - <a href="https://github.com/BerriAI/litellm/pull/13117" target="_blank" rel="noopener noreferrer">PR #13117</a></li>
<li>Preserve model order in <code>/v1/models</code> and <code>/model_group/info</code> endpoints - <a href="https://github.com/BerriAI/litellm/pull/13178" target="_blank" rel="noopener noreferrer">PR #13178</a></li>
</ul>
</li>
<li>
<p><strong>Key Management</strong></p>
<ul>
<li>Properly parse JSON options for key generation in UI - <a href="https://github.com/BerriAI/litellm/pull/12989" target="_blank" rel="noopener noreferrer">PR #12989</a></li>
</ul>
</li>
<li>
<p><strong>Authentication</strong></p>
<ul>
<li><strong>JWT Fields</strong>
<ul>
<li>Add dot notation support for all JWT fields - <a href="https://github.com/BerriAI/litellm/pull/13013" target="_blank" rel="noopener noreferrer">PR #13013</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-3">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-3" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Permissions</strong>
<ul>
<li>Fix object permission for organizations - <a href="https://github.com/BerriAI/litellm/pull/13142" target="_blank" rel="noopener noreferrer">PR #13142</a></li>
<li>Fix list team v2 security check - <a href="https://github.com/BerriAI/litellm/pull/13094" target="_blank" rel="noopener noreferrer">PR #13094</a></li>
</ul>
</li>
<li><strong>Models</strong>
<ul>
<li>Fix model reload on model update - <a href="https://github.com/BerriAI/litellm/pull/13216" target="_blank" rel="noopener noreferrer">PR #13216</a></li>
</ul>
</li>
<li><strong>Router Settings</strong>
<ul>
<li>Fix displaying models for fallbacks in UI - <a href="https://github.com/BerriAI/litellm/pull/13191" target="_blank" rel="noopener noreferrer">PR #13191</a></li>
<li>Fix wildcard model name handling with custom values - <a href="https://github.com/BerriAI/litellm/pull/13116" target="_blank" rel="noopener noreferrer">PR #13116</a></li>
<li>Fix fallback delete functionality - <a href="https://github.com/BerriAI/litellm/pull/12606" target="_blank" rel="noopener noreferrer">PR #12606</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="logging--guardrail-integrations">Logging / Guardrail Integrations<a href="https://docs.litellm.ai/release_notes/v1-74-15#logging--guardrail-integrations" class="hash-link" aria-label="Logging / Guardrail Integrations的直接链接" title="Logging / Guardrail Integrations的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-3">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features-3" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#mlflow">MLFlow</a></strong>
<ul>
<li>Allow adding tags for MLFlow logging requests - <a href="https://github.com/BerriAI/litellm/pull/13108" target="_blank" rel="noopener noreferrer">PR #13108</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#langfuse">Langfuse OTEL</a></strong>
<ul>
<li>Add comprehensive metadata support to Langfuse OpenTelemetry integration - <a href="https://github.com/BerriAI/litellm/pull/12956" target="_blank" rel="noopener noreferrer">PR #12956</a></li>
</ul>
</li>
<li><strong><a href="https://docs.litellm.ai/docs/proxy/logging#datadog">Datadog LLM Observability</a></strong>
<ul>
<li>Allow redacting message/response content for specific logging integrations - <a href="https://github.com/BerriAI/litellm/pull/13158" target="_blank" rel="noopener noreferrer">PR #13158</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-4">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-4" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>API Key Logging</strong>
<ul>
<li>Fix API Key being logged inappropriately - <a href="https://github.com/BerriAI/litellm/pull/12978" target="_blank" rel="noopener noreferrer">PR #12978</a></li>
</ul>
</li>
<li><strong>MCP Spend Tracking</strong>
<ul>
<li>Set default value for MCP namespace tool name in spend table - <a href="https://github.com/BerriAI/litellm/pull/12894" target="_blank" rel="noopener noreferrer">PR #12894</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance--loadbalancing--reliability-improvements">Performance / Loadbalancing / Reliability improvements<a href="https://docs.litellm.ai/release_notes/v1-74-15#performance--loadbalancing--reliability-improvements" class="hash-link" aria-label="Performance / Loadbalancing / Reliability improvements的直接链接" title="Performance / Loadbalancing / Reliability improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-4">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features-4" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Background Health Checks</strong>
<ul>
<li>Allow disabling background health checks for specific deployments - <a href="https://github.com/BerriAI/litellm/pull/13186" target="_blank" rel="noopener noreferrer">PR #13186</a></li>
</ul>
</li>
<li><strong>Database Connection Management</strong>
<ul>
<li>Ensure stale Prisma clients disconnect DB connections properly - <a href="https://github.com/BerriAI/litellm/pull/13140" target="_blank" rel="noopener noreferrer">PR #13140</a></li>
</ul>
</li>
<li><strong>Jitter Improvements</strong>
<ul>
<li>Fix jitter calculation (should be added not multiplied) - <a href="https://github.com/BerriAI/litellm/pull/12901" target="_blank" rel="noopener noreferrer">PR #12901</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-5">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-5" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Anthropic Streaming</strong>
<ul>
<li>Always use choice index=0 for Anthropic streaming responses - <a href="https://github.com/BerriAI/litellm/pull/12666" target="_blank" rel="noopener noreferrer">PR #12666</a></li>
</ul>
</li>
<li><strong>Custom Auth</strong>
<ul>
<li>Bubble up custom exceptions properly - <a href="https://github.com/BerriAI/litellm/pull/13093" target="_blank" rel="noopener noreferrer">PR #13093</a></li>
</ul>
</li>
<li><strong>OTEL with Managed Files</strong>
<ul>
<li>Fix using managed files with OTEL integration - <a href="https://github.com/BerriAI/litellm/pull/13171" target="_blank" rel="noopener noreferrer">PR #13171</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-proxy-improvements">General Proxy Improvements<a href="https://docs.litellm.ai/release_notes/v1-74-15#general-proxy-improvements" class="hash-link" aria-label="General Proxy Improvements的直接链接" title="General Proxy Improvements的直接链接">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="features-5">Features<a href="https://docs.litellm.ai/release_notes/v1-74-15#features-5" class="hash-link" aria-label="Features的直接链接" title="Features的直接链接">​</a></h4>
<ul>
<li><strong>Database Migration</strong>
<ul>
<li>Move to use_prisma_migrate by default - <a href="https://github.com/BerriAI/litellm/pull/13117" target="_blank" rel="noopener noreferrer">PR #13117</a></li>
<li>Resolve team-only models on auth checks - <a href="https://github.com/BerriAI/litellm/pull/13117" target="_blank" rel="noopener noreferrer">PR #13117</a></li>
</ul>
</li>
<li><strong>Infrastructure</strong>
<ul>
<li>Loosened MCP Python version restrictions - <a href="https://github.com/BerriAI/litellm/pull/13102" target="_blank" rel="noopener noreferrer">PR #13102</a></li>
<li>Migrate build_and_test to CI/CD Postgres DB - <a href="https://github.com/BerriAI/litellm/pull/13166" target="_blank" rel="noopener noreferrer">PR #13166</a></li>
</ul>
</li>
<li><strong>Helm Charts</strong>
<ul>
<li>Allow Helm hooks for migration jobs - <a href="https://github.com/BerriAI/litellm/pull/13174" target="_blank" rel="noopener noreferrer">PR #13174</a></li>
<li>Fix Helm migration job schema updates - <a href="https://github.com/BerriAI/litellm/pull/12809" target="_blank" rel="noopener noreferrer">PR #12809</a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bugs-6">Bugs<a href="https://docs.litellm.ai/release_notes/v1-74-15#bugs-6" class="hash-link" aria-label="Bugs的直接链接" title="Bugs的直接链接">​</a></h4>
<ul>
<li><strong>Docker</strong>
<ul>
<li>Remove obsolete <code>version</code> attribute in docker-compose - <a href="https://github.com/BerriAI/litellm/pull/13172" target="_blank" rel="noopener noreferrer">PR #13172</a></li>
<li>Add openssl in runtime stage for non-root Dockerfile - <a href="https://github.com/BerriAI/litellm/pull/13168" target="_blank" rel="noopener noreferrer">PR #13168</a></li>
</ul>
</li>
<li><strong>Database Configuration</strong>
<ul>
<li>Fix DB config through environment variables - <a href="https://github.com/BerriAI/litellm/pull/13111" target="_blank" rel="noopener noreferrer">PR #13111</a></li>
</ul>
</li>
<li><strong>Logging</strong>
<ul>
<li>Suppress httpx logging - <a href="https://github.com/BerriAI/litellm/pull/13217" target="_blank" rel="noopener noreferrer">PR #13217</a></li>
</ul>
</li>
<li><strong>Token Counting</strong>
<ul>
<li>Ignore unsupported keys like prefix in token counter - <a href="https://github.com/BerriAI/litellm/pull/11954" target="_blank" rel="noopener noreferrer">PR #11954</a></li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="new-contributors">New Contributors<a href="https://docs.litellm.ai/release_notes/v1-74-15#new-contributors" class="hash-link" aria-label="New Contributors的直接链接" title="New Contributors的直接链接">​</a></h2>
<ul>
<li>@5731la made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12989" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12989</a></li>
<li>@restato made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12980" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12980</a></li>
<li>@strickvl made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12956" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12956</a></li>
<li>@Ne0-1 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12995" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12995</a></li>
<li>@maxrabin made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13079" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13079</a></li>
<li>@lvuna made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12894" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12894</a></li>
<li>@Maximgitman made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12666" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12666</a></li>
<li>@pathikrit made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12901" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12901</a></li>
<li>@huetterma made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12809" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12809</a></li>
<li>@betterthanbreakfast made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13029" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13029</a></li>
<li>@phosae made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12606" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12606</a></li>
<li>@sahusiddharth made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12507" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12507</a></li>
<li>@Amit-kr26 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/11954" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/11954</a></li>
<li>@kowyo made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13172" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13172</a></li>
<li>@AnandKhinvasara made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13187" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13187</a></li>
<li>@unique-jakub made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13174" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13174</a></li>
<li>@tyumentsev4 made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13134" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13134</a></li>
<li>@aayush-malviya-acquia made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/12978" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/12978</a></li>
<li>@kankute-sameer made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13225" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13225</a></li>
<li>@AlexanderYastrebov made their first contribution in <a href="https://github.com/BerriAI/litellm/pull/13178" target="_blank" rel="noopener noreferrer">https://github.com/BerriAI/litellm/pull/13178</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="full-changelog"><strong><a href="https://github.com/BerriAI/litellm/compare/v1.74.9-stable...v1.74.15.rc" target="_blank" rel="noopener noreferrer">Full Changelog</a></strong><a href="https://docs.litellm.ai/release_notes/v1-74-15#full-changelog" class="hash-link" aria-label="full-changelog的直接链接" title="full-changelog的直接链接">​</a></h2>]]></content:encoded>
        </item>
    </channel>
</rss>